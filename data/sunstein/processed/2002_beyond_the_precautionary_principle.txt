University of Chicago Law School
Chicago Unbound

Coase-Sandor Working Paper Series in Law and
Economics

Coase-Sandor Institute for Law and Economics

2002

Beyond the Precautionary Principle
Cass R. Sunstein

Follow this and additional works at: https://chicagounbound.uchicago.edu/law_and_economics

Part of the Law Commons

Recommended Citation
Cass R. Sunstein, "Beyond the Precautionary Principle" ( John M. Olin Program in Law and Economics Working Paper No. 149,
2002).

This Working Paper is brought to you for free and open access by the Coase-Sandor Institute for Law and Economics at Chicago Unbound. It has been
accepted for inclusion in Coase-Sandor Working Paper Series in Law and Economics by an authorized administrator of Chicago Unbound. For more
information, please contact unbound@law.uchicago.edu.

 

C H I C A G O 

JOHN M. OLIN LAW & ECONOMICS WORKING PAPER NO. 149 
(2D SERIES) 
 

 
 
Beyond the Precautionary Principle 
 
Cass R. Sunstein 
 
 
 
THE LAW SCHOOL 
THE UNIVERSITY OF CHICAGO 
 
Updated January 2003 
 
This paper can be downloaded without charge at 
http://www.law.uchicago.edu/Lawecon/index.html 
and at The Social Science Research Network Electronic Paper Collection: 
http://ssrn.com/abstract_id=307098

Preliminary draft 1/12/03 
All rights reserved 

 

Beyond the Precautionary Principle 
 
Cass R. Sunstein* 
 
Abstract 

 
The  precautionary  principle  has  been  highly  influential  in  legal  systems  all  over  the 

world. In its strongest and most distinctive forms, the principle imposes a burden of proof 

on  those  who  create  potential  risks,  and  it  requires  regulation  of  activities  even  if  it 

cannot  be  shown  that  those  activities  are  likely  to  produce  significant  harms.  Taken  in 

this strong form, the precautionary principle should be rejected, not because it leads in 

bad  directions,  but  because  it  leads  in  no  directions  at  all.  The  principle  is  literally 

paralyzing—  forbidding  inaction,  stringent  regulation,  and  everything  in  between.  The 

reason  is  that  in  the  relevant  cases,  every  step,  including  inaction,  creates  a  risk  to 

health,  the  environment,  or  both.  This  point  raises  a  further  puzzle.  Why  is  the 

precautionary  principle  widely  seen  to  offer  real  guidance?  The  answer  lies  in 

identifiable cognitive mechanisms emphasized by behavioral economists. In many cases, 

loss  aversion  plays  a  large  role,  accompanied  by  a  false  belief  that  nature  is  benign. 

Sometimes the availability heuristic is at work. Probability neglect plays a role as well. 

Most often, those who use the precautionary principle fall victim to what might be called 

“system neglect,” which involves a failure to attend to the systemic effects of regulation. 

Examples are given from numerous areas, involving arsenic regulation, global warming 

and  the  Kyoto  Protocol,  nuclear  power,  pharmaceutical  regulation,  cloning,  pesticide 

regulation,  and  genetic  modification  of  food.  The  salutary  moral  and  political  goals  of 

the precautionary principle should be promoted through other, more effective methods. 

 

 

 

                                                 
*  Karl  N.  Llewellyn  Distinguished  Service  Professor  of  Jurisprudence,  Law  School  and  Department  of 
Political  Science,  University  of  Chicago.  I  am  grateful  to  valuable  comments  from  Peter  Dorman,  Jack 
Knetsch,  Saul  Levmore,  Eric  Posner,  Indra  Spiecker,  and  Adrian  Vermeule,  and  from  participants  in  the 
Midwest Faculty Seminar. I am also grateful to Martha Nussbaum for helpful discussions. 

 

I. Introduction 

All over the world, there is increasing interest in a simple idea for the regulation 
of risk: In case of doubt, follow the precautionary principle.1 Avoid steps that will create 

a  risk  of  harm.  Until  safety  is  established,  be  cautious;  do  not  require  unambiguous 

evidence. In a catchphrase: Better safe than sorry. In ordinary life, pleas of this kind seem 

quite sensible, indeed a part of ordinary human rationality. People buy smoke alarms and 

insurance.  They  wear  seatbelts  and  motorcycle  helmets,  even  if  they  are  unlikely  to  be 

involved in an accident. Shouldn’t the same approach be followed by rational regulators 
as well? Many people believe so.2 

 

 

A. Problems With Precautions 

I  aim  to  challenge  the  precautionary  principle  here,  not  because  it  leads  in  bad 

directions,  but  because  read  for  all  that  it  is  worth,  it  leads  in  no  direction  at  all.  The 

principle  threatens  to  be  paralyzing,  forbidding  regulation,  inaction,  and  every  step  in 
between.3 To explain this problem very briefly, the precautionary principle provides help 

only  if  we  blind  ourselves  to  many  aspects  of  risk-related  situations  and  focus  on  a 
narrow subset of what is at stake.4 A significant part of my discussion will be devoted to 

showing why this is so. I will also urge that the precautionary principle gives the (false) 

appearance of being workable only because of identifiable cognitive mechanisms, which 

lead people to have a narrow rather than wide viewscreen. With that narrow viewscreen, 

it  is  possible  to  ignore,  or  to  neglect,  some  of  the  risks  that  are  actually  at  stake.  I 

emphasize that we have good reason to endorse the goals that motivate many people to 

endorse  the  precautionary  principle.  These  goals  include  the  importance  of  protecting 

                                                 
1 See, for general discussion, Interpreting the Precautionary Principle (Tim O'Riordan and James Cameron 
eds.  2002);  Protecting  Public  Health  &  the  Environment:  Implementing  the  Precautionary  Principle 
(Carolyn Raffensberger & Joel Tickner eds. 1999). 
2 See the account of widespread international support below. 
3 For criticisms that also emphasize the range of risks at stake, but without stressing the paralyzing quality 
of the principle, see Wiener, supra note; Indur Goklany, The Precautionary Principle (2001).  
4  For  discussion  of  the  possibly  perverse  effects  of  the  precautionary  principle,  see  Frank  B.  Cross, 
Paradoxical Perils of the Precautionary Principle, 53 Wash. & Lee L. Rev. 851 (1996). I think that much of 
what Cross says is convincing, but my emphasis here is quite different: I stress the cognitive foundations of 
the principle and urge not that the principle leads in perverse directions but that it offers no guidance at all.  

health  and  the  environment  even  from  remote  risks;  the  need  to  attend  to  unintended 

adverse  effects  of  technological  change;  and  the  need  to  ensure  that  wealthy  countries 

pay  their  fair  share  for  environmental  improvement  and  risk  reduction.  But  the 

precautionary principle is a crude way of protecting these goals, which should be pursued 

directly.  I  do  not  attempt  to  develop  any  particular  replacement  for  the  precautionary 

principle, but I do argue on behalf of wide viewscreens in the regulation of risks. 

 

In  making  these  claims,  I  will  be  challenging  an  idea  that  has  been  a  staple  of 
regulatory policy for several decades.5 Indeed, it has been claimed that the precautionary 

principle has become, or at least is becoming, a binding part of customary international 
law.6  In  the  mid-1970s,  German  environmental  policy  was  founded  on  the  basis  of 
Vorsorgeprinzip,  a  precursor  of  the  precautionary  principle.7  With  respect  to  risks, 

German policy has been described as seeing “precaution” as a highly interventionist idea, 
one that embodies “a loose and open-ended interpretation of precaution.”8 In the United 

States,  federal  courts,  without  using  the  term  explicitly,  have  built  in  a  notion  of 

precaution  in  some  important  cases,  allowing  or  requiring  regulation  on  the  basis  of 
conservative  assumptions.9  The  precautionary  principle  has  played  a  significant  role  in 

international documents, to the point where it has become ubiquitous. Variations on the 
notion  can  be  found  in  at  least  fourteen  international  documents.10  In  1982,  the  United 

                                                 
5  For  helpful  discussion,  see  David  Freestone  and  Ellen  Hey,  Origins  and  Development  of  the 
Precautionary  Principle,  in  The  Precautionary  Principle  and  International  Law  3  (David  Freestone  and 
Ellen  Hey  eds.  1994);  Jonathan  Wiener,  Precaution  in  a  Multirisk  World,  in  The  Risk  Assessment  of 
Environmental and Human Health Hazards (Dennis D. Paustenbach, ed., 2d ed., 2002, forthcoming).  
6  See  O.  McIntyre  and  T.  Mosedale,  The  Precautionary  Principle  as  a  Norm  of  Customary  International 
Law, 9 J Env Law 221 (1997); see generally Arie Trouwborst, Evolution and Status of the Precautionary 
Principle in International Law (2002). 
7 Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle 1, 1 (Julian 
Morris ed. 2001). 
8 See Interpreting the Precautionary Principle (T. O’Riordan and J. Cameron eds. 1994). 
9 See, e.g., American Trucking Association v. EPA, F.3d (DC Cir 2002); Lead Industries v. EPA, 647 F.2d 
1130 (DC Cir 1980). 
10  See  Indur  Goklany,  The  Precautionary  Principle  3  (2001).  Indeed  there  appears  to  be  a cascade effect 
here,  with  informational  and  reputational  influences  leading  to  many  casual  uses  of  the  precautionary 
principle,  to  the  point  where  a  failure  to  incorporate  the  principle  would  seem  to  be  a  radical  statement. 
Simply  because  the  precautionary  principle  has  been  used  so  often,  those  involved  in  international 
agreements are likely to believe that it is probably sensible to use it yet again. And because so many people 
identify  the  precautionary  principle  with  a  serious  commitment  to  environmental  protection,  see,  e.g., 
Protecting Public Health & the Environment, supra note, any nation that rejects the principle risks incurring 
international opprobrium. For a general treatment of informational cascades, in which decisions by others 

Nations  World  Charter  for  Nature  apparently  gave  the  first  international  recognition  to 

the principle, suggesting that when “potential adverse effects are not fully understood, the 
activities  should  not  proceed.”11  The  closing  Ministerial  Declaration  from  the  United 

Nations  Economic  Conference  for  Europe  in  1990  asserts,  “In  order  to  achieve 

sustainable  development,  policies  must  be  based  on  the  precautionary  principle.  .  .  . 

Where there are threats of serious or irreversible damage, lack of full scientific certainty 

should  not  be  used  as  a  reason  for  postponing  measures  to  prevent  environmental 
degradation.”12  

The  widely  publicized  Wingspread  Declaration, 

from  a  meeting  of 

environmentalists in 1998, goes further still: “When an activity raises threats of harm to 

human health or the environment, precautionary measures should be taken even if some 

cause  and  effect  relationships  are  not  established  scientifically.  In  this  context  the 
proponent of the activity, rather than the public, should bear the burden of proof.”13 The 

European Union treaty states that on the environment, EU policy “shall be based on the 
precautionary  principle.”14  Notwithstanding  official  American  ambivalence  about  the 
principle,15  there  are  unmistakable  echoes  of  the  principle  in  American  environmental 
law.16  The  precautionary  principle  has  received  a  high-profile  endorsement  in  the  New 

York Times Magazine, which listed the principle as one of the most important ideas of 
2001.17  In  February  2002,  the  precautionary  principle  was  explicitly  adopted  by  the 
European Commission, together with implementing guidelines.18 

 

 

                                                                                                                                                 
convey information about what it makes sense to do, see David Hirschleifer, The Blind Leading the Blind: 
Social Influence, Fads, and Informational Cascades, in The New Economics of Human Behavior 188, 189 
(Mariano Tommasi and Kathryn Ierulli eds 1995). On reputational pressures, see Timur Kuran, Public Lies, 
Private Truths (1996). 
11 Goklany, supra note, at 4. 
12 Id. at 5. 
13 Id. 
14 European Union Treaty, article 130R (1993), currently Article 174. 
15 See John Graham, The Role of Precaution and Risk Assessment in Risk Managament: An American’s 
View (2002), available at http://www.whitehouse.gov/omb/inforeg/eu_speech.html; Wiener, supra note. 
16 Seethe reference to an “adequate margin of safety” in the Clean Air Act, section 109, 42 USC 7409(b(1). 
17 The Year in Ideas: A to Z, New York Times, December 9, 2001, p. 92, column 2.  
18 http://europa.eu.int/comm/dgs/health_consumer/library/press/press38_en.html 

In  many  ways  the  precautionary  principle  seems  quite  sensible,  even  appealing. 

To justify regulation, a certainty of harm should not be required; a risk, even a low one, 

may  well  be  enough.  It  makes  sense  to  expend  resources  to  prevent  a  small  chance  of 

disaster; consider the high costs, pecuniary and otherwise, that are spent to reduce the risk 

of terrorist attack. On reasonable assumptions, these costs are worth incurring even if the 

probability of  harm, in individual cases or even in the aggregate, is relatively low. The 

precautionary principle might well be seen as a plea for a kind of regulatory insurance. 

Certainly  the  principle  might  do  some  real-world  good,  spurring  them  to  attend  to 

neglected  problems.  Nonetheless,  I  will  be  urging  that  the  principle  cannot  be  fully 

defended  in  these  ways,  simply  because  risks  are  on  all  sides  of  social  situations.  Any 

effort  to  be  universally  precautionary  will  be  paralyzing,  forbidding  every  imaginable 

step, including no step at all. 

B. Precautions and Rationality 

But if the precautionary principle, taken in a strong form, is unhelpful, in a way 

literally senseless, how can we account for its extraordinary influence, and indeed for the 

widespread belief that it can and should guide regulatory judgments? I have mentioned its 

possible pragmatic value. And undoubtedly the principle is invoked strategically by self-

interested  political  actors,  with  European  farmers,  for  example,  invoking  the  idea  of 

precaution to stifle American competitors, who are far more likely to rely on genetically 
modified  crops.19  But  apart  from  this  point,  I  suggest  that  an  understanding  of  human 

rationality and cognition provides five useful clues.  

1.  Loss aversion. The precautionary principle often seems appealing because of loss 

aversion.  The  central  point  here  is  that  people  dislike  losses  far  more  than  they 
like corresponding gains.20 The result is that out-of-pocket costs, or deterioration 

from the status quo, seem much worse than opportunity costs, or benefits lost as a 

result of continuing the status quo. In the context of risks, people tend to focus on 

                                                 
19 See Timur Kuran and Cass R. Sunstein, Availability Cascades and Risk Regulation, 51 Stan L Rev 683 
(1999). 
20 See Richard Thaler, Quasi-Rational Economics (1995). 

 

 

 

the  losses  that  are  associated  with  some  activity  or  hazard,  and  to  disregard  the 

gains  that  might  be  associated  with  that  activity  or  hazard.  The  precautionary 

principle often becomes operational only because of loss aversion, as people take 

precautions  against  potential  losses  from  the  status  quo,  but  neglect  potential 

benefits  that  would  be  unmistakable  gains.  A  closely  related  point  is  that 

unfamiliar risks produce far more concern than familiar ones, even if the latter are 

statistically  larger; and the precautionary principle,  in  practice,  is  much affected 

by this fact.  

2.  The  myth  of  a  benevolent  nature.  Loss  aversion  is  often  accompanied  by  a 
mistaken  belief  that  nature  is  essentially  benign,21  leading  people  to  think  that 

safety  and  health  are  generally  at  risk  only  or  mostly  as  a  result  of  human 

intervention. A belief in the relative safety of nature and the relative risk of new 

technologies often informs the precautionary principle. 

3.  The availability heuristic. It is well known that people focus on some risks simply 
because they are cognitively “available,” whereas other risks are not.22 When the 

precautionary  principle  seems  to  require  stringent  controls  on  one  risk,  even 

though  other  risks  are  in  the  vicinity,  the  availability  heuristic  is  a  common 

reason. And when the availability heuristic is at work, certain hazards will stand 
out whether or not they are not statistically large.  23 The hazards associated with 

heat  waves,  for  example,  receive  little  public  attention,  while  the  hazards 
associated with air travel are a significant source of public concern24; one reason 

is that the latter hazards come readily to mind.  

4.  Probability neglect. People are sometimes prone to neglect the probability that a 
bad  outcome  will  occur;  they  focus  instead  on  the  outcome  itself.25  The 

precautionary principle often embodies a form of probability neglect. At least this 

is so when people invoke the precautionary principle to favor stringent controls on 

                                                 
21 See generally James P. Collman, Naturally Dangerous (2001). 
22  Amos  Tversky  and  Daniel  Kahneman,  Judgment  Under  Uncertainty:  Heuristics  and  Biases,  in  Daniel 
Kahneman, Paul Slovic, and Amos Tversky, Judgment Under Uncertainty: Heuristics and Biases 3, 11-14 
(1982). 
23 Paul Slovic, The Perception of Risk 40 (2000). 
24 See Eric Klinenberg, Heat Wave: A Social Autopsy of Disaster in Chicago (2002).  
25  Yuval  Rottenstreich  and  Christopher  Hsee,  Money,  Kisses,  and  Electric  Shocks:  On  the  Affective 
Psychology of Risk, 12 Psych Science 185, 188 (2001). 

a low-probability risk, when the consequence of those very controls is to give rise 
to new risks of equal or greater probability.26 

5.  System neglect. The precautionary principle often reflects a general neglect of the 
systemic effects of regulation.27 When a single problem is placed in view, it can 

be  difficult  to  see  the  full  consequences  of  legal  interventions.  Sometimes  the 

precautionary  principle  has  the  appearance  of  being  workable  only  because  a 

subset  of  the  relevant  effects  are  “on  screen”—and  hence  there  seems  to  be  no 

need  to  take  precautions  against  other  possible  adverse  effects,  also  involving 

health  and  safety,  that  do  not  register.  An  important  aspect  of  system  neglect  is 

tradeoff neglect, one source of the conflict between experts and ordinary people in 
thinking about risks.28 When experts disagree with ordinary people about risks, it 

is sometimes because experts look at both the benefits and the harms associated 

with  the  relevant  practice,  whereas  ordinary  people  are  paying  attention  to  the 
harms  but  not  the  benefits.29  I  suggest  that  the  precautionary  principle  seems 

appealing, to ordinary people, in large part for the same reason. 

 

One  of  my  major  goals  is  show  that  the  precautionary  principle  can  be  made 

workable  only  through  routes  of  this  kind.  An  understanding  of  behavioral  economics 

simultaneously  sheds  light  on  the  operation  of  the  principle,  explains  its  otherwise 

puzzling appeal, and suggests why it should be abandoned or at least substantially recast. 

Indeed, such an understanding provides a better understanding of the uses and pitfalls of 

the old adage, “better safe than sorry,” which is subject to many of the same objections as 

the  precautionary  principle.  I  do  not  attempt  to  identify  a  competing  principle  for 

adoption  by  sensible  regulators.  But  I  do  urge  that  such  regulators  should  use  a  wide 

rather  than  narrow  viewscreen—and  that  as  applied,  the  precautionary  principle  is 

defective  precisely  because  it  runs  afoul  of  this  idea.  To  be  sure,  many  of  those  who 

endorse  the  principle  seek  to  protect  against  neglect  of  the  future,  disregard  of  the 

                                                 
26 In some cases, this is a reasonable reading of the evidence governing genetically modified food. See Alan 
McHughen, Pandora’s Picnic Basket 230-42 (2000); note in particular the evidence of harms from organic 
foods, discussed in id. 
27 See Dietrich Dorner, The Logic of Failure 6-42 (1996). 
28 The conflict is treated in Paul Slovic, The Perception of Risk (2000). 
29 See Howard Margolis, Dealing With Risk (1996). 

 

 

 

 

interests  of  those  suffering  from  the  greatest  deprivation,  and  impossible  demands  for 

unambiguous evidence from regulators. But as we shall see, the precautionary principle is 

a  crude  and  sometimes  perverse  way  of  promoting  those  goals,  which  can  be  obtained 

through other, better routes. A major purpose of this Essay is to suggest the need to use 

more direct effective strategies to pursue the salutary goals of risk regulation. 

This Article comes in four parts. Part I briefly traces the nature and the appeal of 

the  precautionary  principle.  Part  II  explains  why  the  principle  is  paralyzing,  with 

particular reference to the issues raised by arsenic, global warming, nuclear power, and 

genetic engineering of food. Part III suggests that the apparent sense of the principle is 

best  understood  in  light  of  the  behavioral  points  just  mentioned.  Part  IV  is  a  brief 

conclusion, in the form of a plea for wider viewscreens. 

II. The Precautionary Principle: Definition and Appeal 

I  have  said  that  the  precautionary  principle  enjoys  widespread  international 
support.30 But what does the principle mean or require? There are numerous definitions, 
and  they  are  not  compatible  with  one  another.31  We  can  imagine  a  continuum  of 

understandings. At one extreme are weak versions to which no reasonable person could 

object;  at  the  other  extreme  are  strong  versions  that  would  appear  to  call  for  a 

fundamental rethinking of regulatory policy.  

The  most  cautious  and  weak  versions  suggest,  quite  sensibly,  that  a  lack  of 

decisive  evidence  of  harm  should  not  be  a  ground  for  refusing  to  regulate.  Regulation 

might be justified even if we cannot establish a definite connection between, for example, 

low-level exposures to certain carcinogens and adverse effects on human health. Thus the 

1992 Rio Declaration states, “Where there are threats of serious or irreversible damage, 

lack of full scientific certainty shall not be used as a reason for postponing cost-effective 

                                                 
30 See Arie Trouwborst, Evolution and Status of the Precautionary Principle in International Law (2002). 
31 See Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle, supra, 
at 1-19; Wiener, supra note. 

measures  to  prevent  environmental  degradation.”32  The  Ministerial  Declaration  of  the 

Second International Conference on the Protection of the North Sea, held in London in 

1987, is in the same vein: “Accepting that in order to protect the North Sea from possibly 

damaging  effects  of  the  most  dangerous  substances,  a  precautionary  principle  is 

necessary  which  may  require  action  to  control  inputs  of  such  substances  even  before  a 
causal link has been established by absolutely clear scientific evidence.”33 Similarly, the 

United  Nations  Framework  Convention  on  Climate  Change  offers  cautious  language: 

“Where there are threats of serious or irreversible damage, lack of full scientific certainty 

should not be used as a reason for postponing [regulatory] measures, taking into account 

that policies and measures to deal with climate change should be cost-effective so as to 
ensure global benefits at the lowest possible cost.”34  

 

 

 The  Wingspread  Declaration  goes  somewhat  further:  “When  an  activity  raises 

threats  of  harm  to  human  health  or  the  environment,  precautionary  measures  should  be 

taken even if some cause and effect relationships are not fully established scientifically. 

In this context the proponent of an activity, rather than the public, should bear the burden 
of  proof.”35  The  first  sentence  just  quoted  is  a  mildly  more  aggressive  version  of  the 

statement  from  the  Rio  Declaration.  It  is  more  aggressive  because  it  is  not  limited  to 

threats of serious or irreversible damage. But in reversing the burden of proof, the second 
sentence goes further still.36 Of course everything depends on what those with the burden 

of proof must show in particular.  

In  Europe,  the  precautionary  principle  is  understood  in  a  still  stronger  way, 
suggesting  that  it  is  important  to  build  “a  margin  of  safety  into  all  decision  making.”37 

According  to  one  definition,  the  precautionary  principle  means  “that  action  should  be 

taken to correct a problem as soon as there is evidence that harm may occur, not after the 

                                                 
32 Quoted in Bjorn Lomborg The Skeptical Environmentalist 347 (2001). 
33 Quoted in Rethinking Risk and the Precautionary Principle 3, Julian Morris ed. (2000). 
34 See Goklany, supra note, at 6. 
35 See http://www.monitor.net/rachel/r586.html 
36 See the discussion in Wiener, supra note; David Pearce, The Preconditions for Achieving Consensus in 
the  Context  of  Technological  Risk,  in  Technological  Risk:  Its  Perception  and  Handling  in  the  European 
Community (M. Dierkes et al. eds 1980). 
37 See Bjorn Lomborg The Skeptical Environmentalist 348 (2001). 

harm  has  already  occurred.”38  In  a  comparably  strong  version,  it  is  said  that  “the 

precautionary  principle  mandates  that  when  there  is  a  risk  of  significant  health  or 

environmental  damage  to  others  or  to  future  generations,  and  when  there  is  scientific 

uncertainty  as  to  the  nature  of  that  damage  or  the  likelihood  of  the  risk,  then  decisions 

should  be  made  so  as  to  prevent  such  activities  from  being  conducted  unless  and  until 
scientific evidence shows that the damage will not occur.”39 The Cartagena Protocol on 

Biosafety to the Convention on Biological Diversity, adopted in 2000, appears to adopt a 
strong  version  as  well.40  The  Final  Declaration  of  the  First  European  “Seas  At  Risk” 

conference says that if “the ‘worst case scenario’ for a certain activity is serious enough 

then even a small amount of doubt as to the safety of that activity is sufficient to stop it 
taking place.”41 

Professor Richard Stewart usefully distinguishes among four different versions of 
the  precautionary  principle,  capturing  both  weak  and  strong  types42;  I  paraphrase  his 

typology here: 

1. Nonpreclusion Precautionary Principle: Regulation should not be precluded by the 

absence of scientific uncertainty about activities that pose a risk of substantial harm. 

2. Margin of  Safety Precautionary  Principle: Regulation should include a margin of 

safety,  limiting  activities  below  the  level  at  which  adverse  effects  have  not  been 

found or predicted. 

3.  Best  Available  Technology  Precautionary  Principle:  Best  available  technology 

requirements should be imposed on activities that pose an uncertain potential to create 

substantial harm, unless those in favor of those activities can show that they present 

no appreciable risk. 

                                                 
38 http://www.logophilia.com/WordSpy/precautionaryprinciple.asp 
39  Testimony  of  Dr.  Brent  Blackwelder,  President,  Friends  of  the  Earth,  before  the  Senate  Appropriate 
Committee, Subcommittee on Labor, Health and Human Services (Jan. 24, 2002). 
40 See Goklany, supra note, at 6. 
41 Final Declaration of the First European “Seas At Risk” Conference, Annex 1, Copenhagen, 1994. 
42 Richard B. Stewart, Environmental Regulatory Decision Making Under Uncertainty, 20 Research in Law 
and Economics 71, 76 (2002). 

 

 

 

 

 

 

4.  Prohibitory  Precautionary  Principle:  Prohibitions  should  be  imposed  on  activities 

that have an uncertain potential to impose substantial harm, unless those in favor of 

those activities can show that they present no appreciable risk.  

 

This  account  shows  that  the  precautionary  principle  might  be  described  both  in 

terms  of  the  level  of  uncertainty  that  triggers  a  regulatory  response  and  in  terms  of  the 

tool  that  will  be  chosen  in  the  face  of  uncertainty  (as  in  the  case  of  technological 

requirements or prohibitions). With an appreciation of this point, we can easily imagine 

many  other  variations  on  these  themes.  For  example,  an  Information  Disclosure 

Precautionary  Principle  might  say  that  in  the  face  of  uncertainty,  those  who  subject 

people  to  potential  risks  must  disclose  relevant  information  to  those  so  subjected.  The 

debate over labeling genetically modified organism can be seen as a debate over this form 
of  the  precautionary  principle.43  For  every  regulatory  tool,  there  is  a  corresponding 
precautionary principle,44 with possible matches or mismatches between the problem that 
causes  for  precautions  and  the  chosen  tool.45  The  idea  of  “margin  of  safety”  can  be 

understood in multiple different ways, with a continuum from a small margin, designed 

to counteract likely risks, to a small one, designed to prevent worst cases. 

The official account in Europe is very much in favor of one or another version of 
the precautionary principle, with the European Commission having formally adopted it.46 

But  European  practice  is  far  more  complex,  with  the  precautionary  principle  being 
invoked against some risks but not against others.47 To take just one example, “Europe 

has  been  more  precautionary  about  hormones  in  beef,  while  the  US  has  been  more 
precautionary  about  mad  cow  disease  (BSE)  in  beef  and  blood  donations.”48  While 

                                                 
43 See Alan McHughen, Pandora’s Picnic Basket 201-29 (2000). 
44 For discussions of regulatory tools, see Stephen Breyer, Regulation and its Reform 36-183 (1982); Cass 
R. Sunstein, Risk and Reason 251-88 (2002). 
45 On mismatch, see Breyer, supra, at 191-96. 
46  European  Commission,  Communication  from  the  Commission  on  the  Precautionary  Principle,  COM 
(200)!, Brussels, 2 Feb. 2000 (available at  
http://europa.eu.int/comm/dgs/health_consumer/library/pub/pub7_en.pdf 
47  See  the illuminating discussion in Jonathan Wiener and Michael Rogers, Comparing Precaution in the 
United States and Europe, 5 J Risk Research 317 (2002). 
48 Id. at 323. 

European  nations  have  taken  a  highly  precautionary  approach  to  genetically  modified 
foods,49 the United States has been especially willing to control the risks associated with 
carcinogens in food additives.50 In the context of occupational risk, American law is far 
more  precautionary  than  Swedish  law.51  I  cannot  venture  a  survey  here,  but  it  is 

reasonable to speculate that in actual practice, nations cannot plausibly be ranked along 

some  continuum  of  precaution.  More  plausibly,  some  nations  are  precautionary  about 

some  risks  but  not  others,  and  a  general  adoption  of  the  precautionary  principle  will 
conceal  this  inevitable  fact.52  I  will  return  to  this  point  and  to  its  inevitability  below, 

because  it  is  closely  connected  to  my  central  claims  here.  Nonetheless,  the  mounting 

importance of the principle in Europe deserves close attention, if only because the idea of 

precaution is playing such a large role in public debates.  

 

I  have  suggested  that  the  weak  versions  of  the  precautionary  principle  are 

unobjectionable  and  important.  Every  day,  people  take  steps  (and  incur  costs)  to  avoid 

hazards that are far from certain. We do not walk in moderately dangerous areas at night; 

we exercise; we buy smoke detectors; we buckle our seatbelts; we might even avoid fatty 

foods. Sensible governments are willing to consider regulation of risks that, in individual 

cases or even in the aggregate, have a well under 100% chance of coming to fruition. The 

weak  versions  of  the  precautionary  principle  state  a  truism—uncontroversial  and 

necessary only to combat public confusion or the self-interested claims of private groups 

demanding  unambiguous  evidence  of  harm,  which  no  rational  society  requires.  This 

function  should  not  be  trivialized.  Nearly  a  fifth  of  Americans,  for  example,  recently 

agreed that “until we are sure that global warming is really a problem, we should not take 

                                                 
49  See  David  Vogel,  The  Regulation  of  GMOs  in  Europe  and  the  United  States:  A  Case-Study  of 
Contemporary  European  Regulatory  Politics  (Publication  of  the  Study  Group  on  Trade,  Science  and 
Genetically  Modified  Foods,  2001),  available  at  http://www.cfr.org/pubs/Victor_ModFood_Paper2.html; 
Symposium, Are the US and Europe Heading for a Food Fight Over Genetically Modified Food? (2001), 
available  at  http://pewagbiotech.org/events/1024/;  TonyGilland,  Precaution,  GM  Crops,  and  Farmland 
Birds, in Rethinking Risk and the Precautionary Principle 84, 84-88 (Julian Morris ed. 2001). 
50 See Richard Merrill, FDA's Implementation of the Delaney Clause: Repudiation of Congressional Choice 
or Reasoned Adaptation to Scientific Progress?, 5 Yale J. on Reg. 1 (1988). 
51  See  Steven  Kelman,  Regulating  America,  Regulating  Sweden:  A  Comparative  Study  of  Occupational 
Safety and Health Policy (1981). 
52 See Wiener and Rogers, supra note. 

any  steps  that  would  have  economic  costs.”53  Sometimes  people  do  seem  to  seek 

certainty  before  showing  a  willingness  to  expend  costs,  and  well-organized  private 

groups  like  to  exploit  this  fact.  Insofar  as  the  precautionary  principle  counteracts  the 

tendency to demand certainty, it should be approved. 

 

 

Because the weak versions are sensible, I will not discuss them here. Instead I will 

understand the principle in a strong way, to suggest that regulation is required whenever 

there  is  a  possible  risk  to  health,  safety,  or  the  environment,  even  if  the  supporting 

evidence is speculative and even if the economic costs of regulation are high. To avoid 

palpable  absurdity,  the  idea  of  “possible  risk”  will  be  understood  to  require  a  certain 

threshold of scientific plausibility. To support regulation, no one thinks that it is enough 

if  someone,  somewhere,  urges  that  a  risk  is  worth  taking  seriously.  But  under  the 

precautionary principle as I shall understand it, the threshold burden is minimal, and once 

it is met, there is something like a presumption in favor of stringent regulatory controls. I 

believe that this understanding of the precautionary principle fits with the understandings 
of  its  most  enthusiastic  proponents,54  and  that  with  relatively  modest  variations,  this 
understanding fits with many of the legal formulations as well.55 

Why might the precautionary principle, understood in this strong sense, have such 

widespread appeal? At first glance, the answer is simple, for the principle contains some 

important truth. Sometimes it  is much better to be safe than sorry. Certainly we should 

acknowledge that a small probability (say, 1 in 100,000) of a serious harm (say, 100,000 

deaths) deserves extremely serious attention. It is worthwhile to spend a lot of money to 

eliminate that risk. The fact that a danger is unlikely to materialize is hardly a decisive 

objection to regulatory controls. Now an economically oriented critic might observe that 

our  resources  are  limited  and  that  if  we  spend  large  amounts  of  resources  on  highly 

speculative  harms,  we  will  not  be  allocating  those  resources  wisely.  In  fact  this  is  the 

                                                 
53 See http://www.pipa.org/OnlineReports/GlobalWarming/buenos_aires.html#1 
54  See  the  essays  in  Protecting  Public  Health  &  the  Environment  :  Implementing  the  Precautionary 
Principle, Carolyn Raffensberger & Joel Tickner eds. (1999). 
55 See Lothar Gundling, The Status in International Law of the Principle of Precautionary Action, 5 Intl J. 
Estuarine and Coastal Law 23, 26 (1990). 

simplest  criticism  of  the  precautionary  principle.56  Unless  the  harm  would  be  truly 

catastrophic, a huge investment makes no sense for a harm that has a 1 in 1 billion chance 

of  occurring.  Taken  for  all  that  it  is  worth,  the  precautionary  principle  might  seem  to 

require  indefensibly  huge  expenditures,  exhausting  our  budget  well  before  the  menu  of 
options  could  be  thoroughly  consulted.57  If  we  take  costly  steps  to  address  all  risks, 

however  improbable  they  are,  we  will  quickly  impoverish  ourselves.  On  this  view,  the 
principle  “would  make  for  a  dim  future.”58  This  is  no  less  true  for  nations  than  for 

Some  version  of  this  argument  is  surely  convincing,  but  it  also  seems  to  be 
missing  something  about  human  cognition.59  In  some  contexts,  regulation  is  indeed  a 

form  of  insurance,  or  a  way  of  placing  special locks  on a door. Consider  the following 

individuals.  

 

 

choice. Would you rather have 

1.  A sure loss of $20, or 

2.  A 1% chance of losing $1980? 

 

In  terms  of  expected  value,  (b),  representing  a  statistical  loss  of  $19.80,  is  a  bit 
less bad than (a); but most people would gladly choose the sure loss of $20.60 People do 

not  like  to  run  a  small  risk  of  a  large  or  catastrophic  loss;  this  is  why  people  buy 

insurance  and  take  special  precautions  against  serious  harms,  even  in  circumstances  in 
which  an  analysis  of  expected  value  would  not  justify  these  steps.61  If  government 

follows the judgments of ordinary people, it will be risk-averse in this sense as well. The 

willingness  to  incur  sure  losses,  in  preference  to  low-probability  catastrophes  of  lower 

                                                 
56 See Graham, supra note. 
57 See Bjorn Lomborg, supra note, at 349.  
58 See Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle, supra, 
at 1, 17. 
59  See  Daniel  Kahneman  and  Amos  Tversky,  Prospect  Theory:  An  Analysis  of  Decision  Under  Risk,  in 
Choices, Values, and Frames 17 (Daniel Kahneman and Amos Tversky eds. 2001). 
60 Id. 
61 A lucid discussion, with applications to litigation, is Chris Guthrie, Framing Frivolous Litigation, 67 U. 
Chi. L. Rev. 163 (2000). 

 

 

 

 

 

expected value, helps explain decisions in a variety of domains, involving both law and 
politics, including foreign policy.62 

This  point  about  judgment  under  risk  might  seem  to  suggest  that  a  democratic 

society,  following  popular  views,  will  depart  from  the  predictions  of  expected  utility 
theory and even embody a form of risk aversion for low-probability catastrophes.63 The 

result  will  be  to  move  regulation  in  the  direction  suggested  by  the  precautionary 

principle. But prospect theory cannot provide a defense of the principle in its strong form. 

I now explain why this is so. 

1. 

Why the Precautionary Principle Is Paralyzing 

A. The Problem 

The  most  serious  problem  with  the  precautionary  principle  is  that  it  offers  no 

guidance—not that it is wrong, but that it forbids all courses of action, including inaction. 

To  understand  this  point,  it  will  be  useful  to  anchor  the  discussion  in  some  concrete 

problems: 

1.  One of the most controversial environmental issues faced in the first year of 
the Bush administration involved the regulation of arsenic.64 There is a serious 

dispute  over  the  precise  level  of  risks  posed  by  low  levels  of  arsenic  in 

drinking water, but on the “worst case” scenario, over one hundred lives might 

be lost each year as a result of the 50 part per billion standard that the Clinton 
Administration  sought  to  revise.65  At  the  same  time,  the  proposed  10  ppb 

                                                 
62  See  id;  Rose  McDermott,  Risk-Taking  in  International  Politics:  Prospect  Theory  in  American  Foreign 
Policy (1998). 
63 See Roger Noll and James Krier, Some Implications of Cognitive Psychology for Risk Regulation, 19 J. 
Legal Stud. 747 (1990). 
64 Robert K. Musil, Arsenic on Tap, N.Y. TIMES, Apr. 24, 2001, at A18. 
65 See Cass R. Sunstein, The Arithmetic of Arsenic, Geo. L. J. (forthcoming 2002). 

standard  would  cost  over  $200  million  each  year,  and  it  is  possible  that  it 
would save as few as six lives annually.66 

2.  Genetic  modification  of  food  has  become  a  widespread  practice.67  But  the 
risks  of  that  practice  are  not  known  with  precision.68  Some  people  fear  that 

genetic modification will result in serious ecological harm and large risks to 
human health.69 

3.  Scientists  are  not  in  accord  about  the  dangers  associated  with  global 
warming,70  but  there  is  general  agreement  that  global  warming  is  in  fact 
occurring.71 It is possible that global warming will produce, by 2100, a mean 
temperature  increase  of  4.5  degrees  C72;  that  it  will  result  in  well  over  $5 
trillion in annual monetized costs73; and that it will also produce a significant 

number  of  deaths  from  malaria.  The  Kyoto  Protocol  would  require  most 

industrialized  nations  to  reduce  greenhouse  gas  emissions  to  92%-94%  of 
1990 levels.74 

4.  Many  people  fear  nuclear  power,  on  the  ground  that  nuclear  power  plants 

raise  various  health  and  safety  issues,  including  some  possibility  of 
catastrophe.75 But if a nation does not rely on nuclear power, it is likely to rely 
instead  on  fossil  fuels,  and  in  particular  on  coal-fired  power  plants.76  Such 

plants  create  risks  of  their  own,  including  risks  associated  with  global 

warming. China, for example, has relied on nuclear energy in part as a way of 

reducing greenhouse gases and in part as a way of reducing other air pollution 
problems.77 

                                                 
66 See id, 
67 Alan McHughen, Pandora’s Picnic Basket (2001). 
68 See id. 
69 See Tony Gilland, Precaution, GM Crops and Farmland Birds, in Rethinking Risk and the Precautionary 
Principle, supra note, at 60. 
70 See Bjorn Lomborg, The Skeptical Environmentalist (2001). 
71 Id. 
72 Id. at 317. 
73 Id.  
74 See Robert Percival et al., Environmental Regulation 1141 (3d ed. 2000). 
75 See Robert Goodin, No Moral Nukes, 90 Ethics (1980). 
76 See Stephen Breyer, Vermont Yankee and the Courts' Role in the Nuclear Energy Controversy, 91 Harv 
L Rev 1833, 1835-36 (1978). 
77 See Note, Nuclear Energy: China's Approach Towards Addressing Global Warming, 12 Geo. Int'l Envtl. 
L. Rev. 493 (2000). Of course it is possible to urge that nations should reduce reliance on either coal-fired 

5.  There  is  a  possible  conflict  between  the  protection  of  marine  mammals  and 

military  exercises.  The  United  States  Navy,  for  example,  engages  in  many 

such exercises, and it is possible that marine mammals will be threatened as a 

result. Military activities in the oceans might well cause significant harm; but 

a decision to suspend those activities, in cases involving potential harm, might 
also endanger military preparedness.78 

 

In these cases, what kind of guidance is provided by the precautionary principle? 

It is tempting to say, as is in fact standard, that the principle calls for strong controls on 

arsenic,  on  genetic  engineering  of  food,  on  greenhouse  gases,  on  threats  to  marine 
mammals, and on nuclear power.79 In all of these cases, there is a possibility of serious 

harms,  and  no  authoritative  scientific  evidence  suggests  that  the  possibility  is  close  to 

zero. If the burden of proof is on the proponent of the activity or processes in question, 

the precautionary principle would seem to impose a burden of proof that cannot be met. 

Put  to  one  side  the  question  whether  the  precautionary  principle,  understood  to  compel 

stringent regulation in these cases, is sensible. Let us ask a more fundamental question: Is 

that more stringent regulation therefore compelled by the precautionary principle? 

 

The answer is that it is not. In some of these cases, it should be easy to see that in 

its own way, stringent regulation would actually run afoul of the precautionary principle. 

The  simplest  reason  is  that  such  regulation  might  well  deprive  society  of  significant 

benefits, and for that reason produce a large number of deaths that would otherwise not 

occur.  In  some  cases,  regulation  eliminates  the  “opportunity  benefits”  of  a  process  or 
activity,  and  thus  causes  preventable  deaths.80  If  this  is  so,  regulation  is  hardly 

precautionary.  The  most  familiar  cases  involve  the  “drug  lag,”  produced  by  a  highly 

                                                                                                                                                 
power  plants  or  nuclear  power,  and  move  instead  toward  environmentally  preferred  alternatives,  such  as 
solar power. For general discussion, see Godfrey Boyle, Renewable Energy: Power for Sustainable Future 
(1996);  Allan  Collinson,  Renewable  Energy  (1991);  Dan  E.  Arvizu,  Advanced  Energy  Technology  and 
Climate Change Policy Implications, 2 Fl. Coastal L.J. 435 (2001). But these alternatives pose problems of 
their own, involving feasibility and expense. See Lomborg, supra note, at 118-48. 
78 See Testimony of Vice Admiral Charles W. Moore, Deputy Chief of Naval Operations for Readiness and 
Logistics, before the Committee on House Resources, Subcommittee on Fisheries Conservation, Wildlife 
and Oceans (June 13, 2002). 
79 See http://www.inra.fr/Internet/Produits/dpenv/som-ec43.html. 
80 See Aaron Wildavsky, Searching for Safety (1994). 

precautionary approach to the introduction of new medicines and drugs into the market.81 

If  a  government  takes  such  an  approach,  it  might  protect  people  against  harms  from 

inadequately tested drugs; but it will also prevent people from receiving potential beneits 
from those very drugs.82 Is it “precautionary” to require extensive premarketing testing, 

or to do the opposite?  

 

 

Or consider the case of genetic modification of food. Many people believe that a 

failure to allow genetic modification might well result in numerous deaths, and a small 
probability of many more.83 The reason is that genetic modification holds out the promise 

of producing food that is both cheaper and healthier—resulting, for example, in “golden 
rice,” which might have large benefits in developing countries.84 Now the point is not that 

genetic  modification  will  definitely  have  those  benefits,  or  that  the  benefits  of  genetic 

modification  outweigh  the  risks.  The  point  is  only  that  if  the  precautionary  principle  is 

taken  literally,  it  is  offended  by  regulation  as  well  as  by  nonregulation.  So  too  for 

regulation  of  ground-level  ozone.  Such  regulation  does  seem  justified  by  the 

precautionary principle, for responsible people believe that low levels of ozone produce a 
range of health harms, including risks of death.85 But there is also evidence that ground-
level  ozone  produces  health  benefits,  by  reducing  risks  of  cataracts  and  skin  cancer.  86 

Because  the  precautionary  principle  calls  for  protection  when  causal  connections  are 

unclear,  it  would  appear  to  require,  with  respect  to  ground-level  ozone,  both  stringent 

regulation and no regulation at all. 

Sometimes regulation would violate the precautionary principle because it would 

give rise to substitute risks, in the form of hazards that materialize, or are increased, as a 

                                                 
81  See  Henry  Grabowski  and  John  Vernon,  The  Regulation  of  Pharmaceuticals  (1983);  John  Mendeloff, 
Decision  Analysis  and  FDA  Drug  Review:  A  Proposal  for  "Shadow"  Advisory  Committees  (2002), 
available at http://www.fplc.edu/RISK/vol6/summer/mendelof.htm. 
82 See sources cited in note 64 supra. 
83 Bill Lambrecht, Dinner at the New Gene Cafe : How Genetic Engineering Is Changing What We Eat, 
How We Live, and the Global Politics of Food (2001) (tracing but not endorsing the various objections). 
84 Id.  
85 See American Trucking Association v. EPA, F.3d (DC Cir 2002). 
86 American Trucking Association v. EPA, 173 F.3d 1027, 1052 (DC Cir 1999).  

result of regulation.87 Consider the case of nuclear power. It is reasonable to think that in 

light  of  current  options,  a  ban  on  nuclear  power  will  increase  dependence  on  fossil 
fuels,88 which contribute to global warming. If so, such a ban would seem to run afoul of 
the  precautionary  principle.  Or  consider  the  EPA’s  effort  to  ban  asbestos,89  a  ban  that 

might  well  seem  justified  or  even  compelled  by  the  precautionary  principle.  The 

difficulty, from the standpoint of that very principle, is that substitutes for asbestos also 
carry risks.90 Or return to possible risks to marine mammals from the United States Navy. 

Some  people  are  concerned  that  efforts  to  eliminate  those  risks  will  endanger  military 
preparedness,  if  only  because  of  administrative  barriers  to  training  exercises.91  In  these 

circumstances,  what  is  the  appropriate  approach,  according  to  the  precautionary 

principle? 

 

 

The problem is pervasive. In the case of arsenic, the Administrator of the EPA has 

expressed  concern  that  regulation,  by  virtue  of  its  cost,  will  lead  people  to  cease  using 

local  water  systems  and  to  rely  on  private  wells,  which  have  high  levels  of 
contamination.92  If  this  is  so,  stringent  arsenic  regulation  violates  the  precautionary 

principle,  no  less  than  less  stringent  regulation  does.  This  is  a  common  situation,  for 
opportunity benefits and substitute risks are the rule, not the exception.93 

                                                 
87 See the discussion of risk-related tradeoffs in John Graham and Jonathan Wiener, Risk vs. Risk (1985); 
Cass R. Sunstein, Health-Health Tradeoffs, in Cass R. Sunstein, Risk and Reason (forthcoming 2002). 
88 See Breyer, supra note. 
89 See Corrosion Proof Fittings v. EPA, 947 F.2d 1201 (5th Cir. 1991). 
90 Id. at  
91 See Testimony of Vice Admiral Charles W. Moore, supra note. 
92 “But we have seen instances, particularly in the West and Midwest, where arsenic is naturally occurring 
at up to 700 and more parts per billion, where the cost of remediation has forced water companies to close, 
leaving people with no way to get their water, save dig wells. And then they are getting water that’s even 
worse than what they were getting through the water company.” Interview by Robert Novak & Al Hunt, 
CNN Evans, Novak, Hunt & Shields, Cable News Network, with Christine Todd Whitman, Administrator, 
U.S. Environmental Protection Agency (Apr. 21, 2001). 
93 Consider the treatment of DDT in Goklany, supra note, at 13-27, and in particular the emphasis on the 
public health risks of banning DDT, in the form of increasing malaria risks, in id. at 15-18. Note also that 
some  regulation  will  have  ancillary  benefits,  by  reducing  risks  other  than  those  that  are  specifically 
targeted. For a valuable discussion, see Richard Revesz, U. Chi. L. Rev. (forthcoming 2002). 

It is possible to go much further. A great deal of evidence suggests the possibility 
that  an  expensive  regulation  can  have  adverse  effects  on  life  and  health.  94  To  be  sure, 
both the phenomenon and the underlying mechanisms are disputed.  95 It has been urged 
that  a  statistical  life  can  be  lost  for  every  expenditure  of  $7  million96;  it  has  also  been 
estimated that the requisite expenditure, for a loss of life, is $50 million97; and one of the 

most careful studies suggests a cutoff point, for a loss of life per regulatory expenditure, 
of $15 million.98 A striking study suggests that poor people are especially vulnerable to 

this  effect—that  a  regulation  that  reduces wealth for the poorest 20% of the population 

will  have  twice  as  large  a  mortality  effect  as  a  regulation  that  reduces  wealth  for  the 
wealthiest 20%.99 I do not mean to accept any particular amount here, or even to suggest 

that  there  has  been  an  unambiguous  demonstration  of  an  association  between  mortality 
and  regulatory  expenditures.100  The  only  point  is  that  reasonable  people  believe  in  that 

association.  It  follow  that  a  multimillion  dollar  expenditure  for  “precaution”  has—as  a 

worst  case  scenario—significant  adverse  health  effects,  with  an  expenditure  of  $200 

million as leading to perhaps as many as thirty to forty lives lost.  

 

This point makes the precautionary principle hard to implement not merely where 

regulation removes “opportunity benefits,” or introduces or increases substitute risks, but 

also  in  any  case  in  which  the  regulation  costs  a  significant  amount.  If  this  is  so,  the 

precautionary principle, for that very reason, seems to argue against many regulations. If 

the  precautionary  principle  argues  against  any  action  that  carries  a  small  risk  of 

significant  harm,  then  we  should  be  reluctant  to  spend  a  lot  of  money  to  reduce  risks, 
                                                 
94Ralph  Kenney,  Mortality  Risks  of  Induced  by  the  Costs  of  Regulation,  10  Risk  Analysis  147  (1990); 
Randall Lutter & John F. Morrall, III, Health-Health Analysis: A New Way to Evaluate Health and Safety 
Regulation, 8 J Risk & Uncertainty 43, 49 table 1 (1994).  
95See Randall Lutter & John F. Morrall, III, Health-Health Analysis: A New Way to Evaluate Health and 
Safety Regulation, 8 J Risk & Uncertainty 43, 49 table 1 (1994). 
96 See Keeney, supra note. 
97 See W. Kip Viscusi and Richard Zeckhauser, The Fatality and Injury Costs of Expenditures, 8 J Risk and 
Uncertainty 19 (1994). 
98  See  Robert  Hahn  et  al.,  Do  Federal  Regulations  Reduce  Mortality  (Washington,  DC:  American 
Enterprise Institute, 2000). 
99 See Kenneth Chapman and Govind Hariharan, Do Poor People Have a Stronger Relationship Between 
Income and Mortality Than the Rich? Implications of Panel Data for Health-Health Analysis, 12 J Risk & 
Uncertainty 51, 58-63 (1996). 
100 Paul R. Portney & Robert N. Stavins, Regulatory Review of Environmental Policy: The Potential Role 
of  Health-Health  Analysis,  8  J  Risk  &  Uncertainty  111,  118  (1994)  (arguing  that  adverse  health  effects 
from the cost of regulation are possible but unlikely). 

simply because those expenditures themselves carry risks. Here is the sense in which, the 

precautionary  principle,  taken  for  all  that  it  is  worth,  is  paralyzing:  It  stands  as  an 

obstacle to regulation and nonregulation, and to everything in between. To say this is not 

to  say  that  the  precautionary  principle  cannot  be  amended  in  a  way  that  removes  the 
problem.101  But  once  it  is  so  amended,  it  is  much  less  distinctive,  and  increasingly 
resembles an effort to weight the health benefits or regulation against the health costs,102 

or even to measure benefits against costs. I will return to this point below. 

It  is  now  easier  to  understand  the  earlier  suggestion  that  despite  its  formal 

enthusiasm  for 

the  precautionary  principle,  European  nations  are  not  “more 

precautionary”  than  the  United  States.  Jonathan  Wiener  and  Michael  Rogers  have 
demonstrated  this  point  empirically.103  It  would  be  most  valuable  to  attempt  to 

comparative  study,  to  see  which  nations  are  especially  precautionary  with  respect  to 

which risks, and also to explore changes over time. In the early twenty-first century, for 

example, the United States appears to take a highly precautionary approach to the risks 
associated  with  abandoned  hazardous  waste  dumps,104  terrorism,  and  the  provision  of 

universal  health  care,  but  not  to  take  a  highly  precautionary  approach  to  the  risks 
associated with global warming,105 indoor air pollution, poverty, poor diet, and obesity. 

What I have been urging is that the selectivity of precautions is not merely an empirical 

fact; it is a conceptual inevitability. Simply as a logical matter, no society can be highly 

precautionary with respect to all risks.  

B. Rejoinders, Adjustments, and Salutary Goals 

Is  there  anything  that  might  be  said,  at  this  stage,  by  proponents  of  the 

precautionary principle? There are several possibilities. 

 

 

 

 

                                                 
101 For various efforts, see Goklany, supra note, at 89-94; Wiener, supra note. 
102 See John Graham and Jonathan Wiener, Risk vs. Risk (1995). 
103 See Wiener and Rogers, supra note.  
104 See W. Kip Viscusi and James Hamilton, Calculating Risks (2000). 
105 For the current responses, see http://www.whitehouse.gov/news/releases/2002/02/climatechange.html 

1.  The  weak  version.  It  might  be  tempting  to  revert  to  the  weak  version  of  the 

principle—a version that is entirely unobjectionable. Alternatively, it might be urged that 

in many cases in which the principle is invoked, the risk at issue is the one that deserves 

the  most  sustained  attention.  In  the  context  of  global  warming,  for  example,  the 

precautionary  principle  might  be  triggered  on  the  ground  that  the  potential  risks  of 

warming are far greater than the risks associated with the reduction of greenhouse gases. 

But this  step points  toward a  sensible and  substantial refashioning of the principle, one 

that  ensures  that  low-probability  catastrophes  are  given  careful  attention,  and  that  the 

various risks at issue will be weighed and balanced in accordance with the facts.  

2..  Biases.  In  addition,  advocates  of  the  precautionary  principle  might  urge  that 

environmental  values  are  systematically  disregarded  in  the  regulatory  process,  or  not 
given  their  due,  and  hence  that  the  principle  helps  counteract  systematic  biases.106  A 
particular  problem  here  is  myopia107:  Perhaps  government  officials,  uninformed  by  the 

precautionary  principle,  would  fail  to  attend  to  risks  that  will  not  occur,  or  be  seen  to 

occur,  in  the  short-run.  Another  problem  is  that  people  tend  to  be  unrealistically 
optimistic.108 As a result, many low-level risks do not register at all. A related problem is 

that people tend to reduce cognitive dissonance, sometimes by treating risks as if they are 
tiny,  even  worth  ignoring.109  When  people  think  that  they  are  “safe,”  even  though  they 

face  a  statistical  risk,  they  might  well  be  responding  to  emotions,  seeking  to  avoid  the 

anxiety that comes from an understanding of the inevitability of risk.  

 

 

On this view, the principle can be defended pragmatically, if not theoretically, as 

a  way  of  emphasizing  the  importance  of  attending  to  issues,  especially  environmental 

issues,  that  might  otherwise  be  neglected.  In  some  settings,  the  pragmatic  defense  is 

undoubtedly  plausible,  and  the  precautionary  principle,  applied  with  a  narrow 

viewscreen, undoubtedly leads to some good results. But two problems remain. The first 

                                                 
106 See Richard B. Stewart, Regulation in a Liberal State: The Role of Noncommodity Values, 92 Yale LJ 
1537 (1983). 
107 See the treatment of hyberbolic discounting in Richard Thaler, Quasi-Rational Economics (1995). 
108 See Shelley Taylor, Positive Illusions 9-12 (1989). 
109  See  George  Akerlof  and  William  Dickens,  The  Economic  Consequences  of  Cognitive  Dissonance,  in 
George Akerlof, An Economic Theorist’s Book of Tales 123, 124-28 (1984).  

is that environmental values are sometimes on both sides of the controversy; consider the 

nuclear power controversy. The same is certainly true of health and safety, as shown by 

the  case  of  premarket  testing  of  pharmaceuticals.  The  second  is  that  even  when 

environmental  values  are  on  only  one  side,  the  interests  and  values  on  the  other  side 

might well be at a comparative disadvantage too; consider the potential beneficiaries of 

genetic modification of food. In short, a more modest and revised precautionary principle 

might  well  make  sense,  but  the  less  modest,  and  more  distinctive,  principle  is  hard  to 

defend. 

 

3.  Distribution.  It  is  also  possible  to  defend  the  precautionary  principle  on 

distributional  grounds.  The  Clean  Air  Act  takes  a  precautionary  approach,  requiring  an 
“adequate margin of safety” and hence regulation in the fact of scientific uncertainty.110 

At  the  same  time,  the  Clean  Air  Act  appears  to  be  giving  disproportionate  benefits  to 
poor  people  and  members  of  minority  groups.111  Aggressive  action  to  combat  climate 
change would be more beneficial to poor countries than to wealthy ones.112 This is partly 

because  wealthy  countries  are  better  able  to  adapt;  it  is  partly  because  agriculture, 

potentially  vulnerable  to  climate  change,  is  responsible  for  only  2%  of  the  economy  of 
wealthy nations, but 50% of the economy of poor nations113; it is partly because one of 

the most serious health risks posed by climate change consists of an increased incidence 
of malaria, a nonproblem for wealthy countries.114 In the context of global warming, at 

least, the precautionary principle might be invoked to prevent especially severe burdens 

on those in the worst position to bear them. 

 

Of  course  it  makes  sense  to  be  concerned  with  the  distribution  of  domestic  or 

international  risks.  The  problem  of  global  warming  owes  its  origin  to  the  actions  of 

wealthy  nations,  and  hence  it  makes  special  sense  to  ask  those  nations  to  bear  a 

disproportionate  cost  of  correction  if  poor  nations  are  likely  to  be  hit  hardest.  The 

                                                 
110 See 42 USC 7409(b(1); American Trucking Associations v. EPA, F.3d (March 26, 2002). 
111 See Matthew E. Kahn, The Beneficiaries of Clean Air Act Regulation, 24 Regulation 34 (2001). 
112  See,  e.g.,  Joseph  Aldy,  Peter  Orszag,  and  Joseph  Stiglitz,  Climate  Change:  An  Agenda  for  Gloval 
Collective Action (unpublished manuscript 2001); Lomborg, supra note, at 291-302.  
113 See id. 
114 See sources cited in note 87 supra.  

distributional  effects  of  global  warming  are  among  the  strongest  points  in  favor 
aggressive  regulation  of  greenhouse  gases.115  But  in  many  cases,  the  precautionary 

principle, as applied, would threaten to have unfortunate distributional effects. The case 

of genetic modification of food is an example; here the benefits are likely to be enjoyed 
by  poor  people,  not  the  wealthy.116  The  case  of  DDT  is  similar.  While  a  ban  on  DDT, 

supported  by  reference  to  the  precautionary  principle,  is  eminently  justified  in  wealthy 

nations,  such  a  ban  is  likely  to  have  bad  effects  in  at  least  some  poor  countries,  where 

DDT is the cheapest and most effective way of combating serious diseases, most notably 
malaria.117 Distributional issues should indeed be a part of a system of risk regulation, but 

the  precautionary  principle  is  a  crude,  indirect,  and  sometimes  perverse  way  of 

incorporating distributional concerns. 

 

4.  Risk  vs.  uncertainty.  A  more  subtle  point  is  possible.  Often  regulators,  and 

ordinary people, are acting in a situation of risk (where probabilities can be assigned to 

various  outcomes)  rather  than  uncertainty  (where  no  such  probabilities  can  be 
assigned).118  Thus  far  I  have  been  speaking  as  if  environmental  and  other  risk-related 

problems  involved  a  risks  of  ascertainable  probability—so  that  analysts  are  able  to  say 

that the risk of X number of deaths in Y percent, whereas the risk of 2X number of deaths 

is Y/n, and so forth. But we can imagine instances in which analysts cannot specify even 

a range of probability, and in which the extent of the harm is also not susceptible to even 
vague probabilistic prediction.119  

 

In a situation of uncertainty, when existing knowledge does not permit regulators 

to assign probabilities to outcomes, it is standard to follow the maximin principle: Choose 
the  policy  with  the  best  worst-case  outcome.120  Perhaps  the  precautionary  principle,  as 

                                                 
115  Note,  however,  that  if  the  concern  involves  poor  countries,  it  is  not  clear  that  global  warming  is  an 
especially  high  priority,  in  light  of  the  many  needs  of  those  countries,  needs  that  might  be  addressed  by 
wealthier nations. See Lomborg, supra note, at 322-23; Goklany, supra note, at 71-88.  
116 See Goklany, supra, at 55. 
117 Cass R. Sunstein, Risk and Reason (forthcoming 2002); Aaron Wildavsky, But Is It True? 61 (1995). 
118  Sere  Frank  H.  Knight,  Risk,  Uncertainty,  and  Profit  (1933);  Paul  Davidson,  Is  Probability  Theory 
Relevant  for  Uncertainty?  A  Post-Keynesian  Perspective,  13  Journal  of  Post-Keynesian  Economics  129 
(1991). 
119 See Stewart, supra note, at 73-74, 90-92. 
120 See Jon Elster, Explaining Technical Change 185-207 (1983), for a helpful discussion. 

applied,  is  a  form  of  the  maximin  principle,  asking  officials  to  identify  the  worst  case 

among  the  various  options,  and  to  select  that  option  whose  worst-case  is  least  bad. 

Perhaps  the  maximin  principle  would  support  many  proposed  applications  of  the 

precautionary  principle,  by,  for  example,  urging  aggressive  steps  to  combat  global 

warming.  

 

This is not an implausible suggestion; sometimes it is best to respond to the worst-

case  scenario,  as  some  governments  do  in  the  face  of  risks  to  national  security  (not 

excluding  those  risks  posed  by  terrorism).  But  the  response  faces  three  problems.  The 

first  is  that  the  precautionary  principle  is  not  the  maximin  principle,  and  if  the  latter 

principle  is  what  is  meant,  then  we  should  be  discussing  that  principle  directly,  and 

evaluating it against the alternatives. The precautionary principle obscures those issues. 

The  second  problem  is  that  so  defended,  the  principle  might  well  prevent  rational 

priority-setting,  simply  because  it  “leads  to  a  disproportionate  allocation  of  limited 

regulatory  priorities  to  those  activities  posing  relatively  more  uncertainty,  because  the 

worst  case  assumption  inflates  their  harm  value  relative  to  risks  that  are  better 
characterized.”121 The third problem is that risks that are now in the realm of uncertainty 

will often move, over time, into the realm of risk. Indeed, one of the principal goals of a 

well-functioning system of environmental protection is to acquire more information about 

potential hazards, information that includes an understanding of the probability of harm. 

In some circumstances, acquiring information is far better than responding to the worst-

case  scenario,  at  least  when  that  response  itself  creates  dangers  in  the  realm  of  both 
uncertainty and risk.122 

 

 

5.  Salutary  goals.  We  are  now  in  a  position  to  appreciate  some  of  the  goals  of 

those who invoke the precautionary principle. Serious environmental problems might be 

addressed too late, or not at all, simply because causal connections cannot be described 

with certainty. In the context of tobacco, for example, a serious public health movement 

                                                 
121 Stewart, supra note, at 97. 
122 See id. at 106-112. 

was muted simply by virtue of scientific doubt123—even though reasonable people take 

steps  to  reduce  likelihoods,  not  only  certainties,  of  adverse  effects.  The  precautionary 

principle  can  be  taken  as  a  reminder  not  to  require  proof.  To  the  extent  that  the 

precautionary  principle  is  a  reminder of obligations  to  the future, it  is entirely salutary. 

Those who invoke the principle undoubtedly are motivated, much of the time, by the goal 
of protecting the most vulnerable people against risks to their safety and health.124 On this 

view,  the  precautionary  principle  has  strong  moral  goals,  and  they  are  distributive  in 

character.  

Nothing I have said is meant to draw these goals into doubt. My claim is that the 

precautionary principle is a crude and sometimes perverse way of promoting the relevant 

goals—and that if it is taken seriously, it is paralyzing, and therefore not helpful at all. 

IV. The Operation of the Precautionary Principle: A Behavioral Account 

 
In  practice,  the  precautionary  principle  is  widely  thought  to  provide  concrete 
guidance.125 How can this be? I suggest that the principle becomes operational if and only 

if those who apply it wear blinders—only, that  is, if they focus on some aspects of the 

regulatory situation but downplay or disregard others. Consider, for example, those who 

think that the precautionary principle requires restrictions on genetic engineering of food; 

to have this belief, it is necessary to ignore the potential health benefits of the practice. Or 

consider those who think that the precautionary principle calls for stringent regulation of 

greenhouse  gases;  such  people  neglect  the  need  to  adopt  precautions  against  the  very 

risks  introduced  by  stringent  regulation.  In  the  same  vein,  those  who  invoke  the 

precautionary  principle  to  seek  regulation  of  human  cloning  neglect  the  possibility  that 
without therapeutic cloning, many people will die.126  

 

 

 

 

                                                 
123 See Robert Goodin, No Smoking (1985). 
124 See note 1 supra. 
125 See, e.g., Implementing the Precautionary Principle, supra note. 
126 See Testimony of Dr. Brent Blackwelder, supra note. 

But  these  points  simply  raise  an  additional  question:  Why  is  the  precautionary 

principle so influential? Why does it speak to so many people? I believe that much of the 

answer lies in an understanding of behavioral economics and cognitive psychology. Five 

points  are  especially  pertinent.  Taken  together,  they  help  explain  the  kinds  of  blinders 

that people wear when they use the precautionary principle to support concrete outcomes. 

The  points  help  show  the  sense  in  which  the  relevant  blinders  are  not  arbitrary  or 

coincidental. They have some unmistakable structure. 

 

 

A.  Loss Aversion and Familiarity 

 

1.  In  general.  People  tend  to  be  loss  averse,  which  means  that  a  loss  from  the 
status quo is seen as more undesirable than a gain is seen as desirable.127 To see how loss 

aversion works, consider some of the classic experiments, which involve the endowment 
effect.128  People  who  were  initially  endowed  with certain goods—such  as coffee mugs, 

chocolate  bars,  and  binoculars—valued  those  goods  far  more  than  those  who  were  not 
initially  endowed  with  them.  The  reason  for  the  endowment  effect  is  loss  aversion129: 

People  are  much  more  distressed  by  the  prospect  of  loss  than  they  are  pleased  by  the 

prospect  of  equivalent  gain.  Another  way  to  put  the  point  is  to  say  that  contrary  to 

economic theory, people do not value out-of-pocket costs and opportunity costs the same. 

Opportunity costs, as foregone gains, seem to be far less bad, on a per-dollar basis, than 

out-of-pocket costs. 

In  the  context  of  risk  regulation,  there  is  a  clear  implication:  People  will  be 

closely attuned to the losses produced by any newly introduced risk, or any aggravation 

of existing risks, but far less concerned with the benefits that are foregone as a result of 

                                                 
127  See  Richard  H.  Thaler,  The  Psychology  of  Choice  and  the  Assumptions  of  Economics,  in  Quasi 
Rational Economics 137, 143, Richard H. Thaler ed. (New York: Russell Sage Foundation, 1991) (arguing 
that  “losses  loom  larger  than  gains”);  Daniel  Kahneman,  Jack  L.  Knetsch,  &  Richard  H.  Thaler, 
Experimental Tests of the Endowment Effect and the Coase Theorem, 98 J. Pol. Econ. 1325, 1328 (1990); 
Colin Camerer, Individual Decision Making, in The Handbook of Experimental Economics 665-670, John 
H. Kagel & Alvin E. Roth, eds. (1995). 
128 See Richard Thaler, Quasi-Rational Economics (1993). 
129  Of  course  loss  aversion  itself  remains  to  be  explained.  For  relevant  discussion,  see  Cass  R.  Sunstein, 
Switching the Default Rule, NYU L Rev (forthcoming 2002). 

regulation.  I  believe  that  loss  aversion  helps  to  explain  what  makes  the  precautionary 

principle operational: The opportunity costs of regulation often register little or not at all, 

whereas  the  out-of-pocket  costs  of  the  activity  or  substance  in  question  are  entirely 
visible.  In  fact  this  is  a  form  of  status  quo  bias.130  The  status  quo  marks  the  baseline 

against which gains and losses are measured, and a loss from the status quo seems much 

more bad than a gain from the status quo seems good.  

 

 

If  loss  aversion  is  at  work,  we  would  predict  that  the  precautionary  principle 

would place a spotlight on the losses introduced by some risk, and downplay the benefits 

foregone  as  a  result  of  controls.  In  fact  this  is  what  we  have  observed  in  several 
contexts.131  Whenever  the  “opportunity  benefits”  are  off-screen,  this  will  be  the  reason 

that the precautionary principle appears to give guidance notwithstanding the objections I 

have  made.  At  the  same  time,  the  neglected  opportunity  benefits  present  a  devastating 

problem with the use of the precautionary principle. In the context of genetic engineering 
of  food,  this  is  very  much  the  situation.132  We  can  find  the  same  problem  when  the 
precautionary  principle  is  invoked  to  support  bans  on  nonreproductive  cloning.133  For 

many  people,  the  possible  harms  of  cloning  register  more  strongly  than  the  potential 

therapeutic benefits that would eliminated by a ban on the practice. 

Loss aversion is closely associated with another cognitive finding: People are far 

more willing to tolerate familiar risks than unfamiliar ones, even if they are statistically 
equivalent.134 The risks associated with driving do not occasion a great deal of concern, 

even though tens of thousands of people die from motor vehicle accidents each year. The 

relevant  risks  are  simply  seen  as  part  of  life.  By  contrast,  many  people  are  quite 

concerned  about  risks  that  appear  newer,  such  as  the  risks  associated  with  genetically 

modified foods, newly introduced chemicals, nuclear power plants, and terrorism. Part of 

the reason for the asymmetry may be a belief that with new risks, we are in the domain of 

                                                 
130 See Samuelson and Zeckhauser, Status Quo Bias, J. Risk & Uncertainty. 
131 See above. 
132 See Katherine Barrett and Gabriela Flora, Genetic Engineering and the Precautionary Principle (2000), 
available at http://www.npsas.org/GEPrecautionary.html 
133 See Testimony of Dr. Brent Blackwelder, supra note. 
134 See Paul Slovic, The Perception of Risk 140-143 (2000). 

uncertainty rather than risk, and hence it makes sense to be cautious when probabilities 

cannot  be  assigned.  But  the  individual  and  social  propensity  to  focus  on  new  risks 

outruns  that  sensible  propensity;  it  makes  the  precautionary  principle  operational  by 

emphasizing a subset of the hazards actually involved. 

 

 

B.  The Mythical Benevolence of Nature 

 

Sometimes  the  precautionary  principle  operates  by  incorporating  the  belief  that 

nature is essentially benign and that human intervention is likely to carry risks—as in the 

suggestion  that  the  precautionary  principle  calls  for  stringent  regulation  of  pesticides. 

This is a distinctive form of loss aversion. The idea is that any human intervention will 

create loss from the status quo, and that this loss should carry great weight, whereas the 

gains should be regarded with some suspicion or at least be taken as less weighty. Often 

lose  aversion  and  a  belief  in  nature’s  benevolence  march  hand-in-hand:  The  status  quo 

forms  the  baseline  or  reference  state  against  which  to  assess  deviations.  Processes  that 

interfere with nature seem, on the part of many, to be taken as troubling “degradation”—

whereas gains or improvements seem, other things being equal, far less significant. 

A belief in the benevolence of nature does seem to play a role in the operation of 

the precautionary principle, especially among those who see nature as harmonious or in 

balance. In fact many of those who endorse the principle seem to be especially concerned 

about  new  technologies.  Certainly  most  people  believe  that  natural  chemicals  are  more 
safe  than  man-made  chemicals.135  (Most  toxicologists  disagree.136)  On  this  view,  the 

principle  calls  for  caution  when  people  are  intervening  into  the  natural  world.  Here  of 

course  we  can  find  considerable  sense:  Nature  often  consists  of  systems,  and 

interventions  into  systems  can  cause  a  number  of  problems.  New  technologies  can 

produce unintended bad effects, if only because they interfere with systems. But there is a 

                                                 
135 See Paul Slovic, The Perception of Risk 291 (2000). 
136 See id. 

large problem with this understanding of the precautionary principle. What is natural may 
not be safe at all.137  

 

Consider, for example, the idea that there is a “balance of nature.” According to a 
recent account, this idea is “not true.”138 A scientific “revolution has shown that nature 
“is characterized by change, not constancy,”139 and that “natural ecological systems are 
dynamic,” with desirable changes being “those induced through human action.”140 In any 
case nature is often a realm of destruction, illness, killing, and death.141 Hence the claim 

cannot be that human activity is necessarily or systematically more destructive than what 
nature does. Nor is it clear that natural products are comparatively safe.142 Organic foods, 

favored by many people on grounds of safety and health and creating annual revenues of 

$4.5 billion in the United States alone, are “actually riskier to consume than food grown 
with synthetic chemicals.”143 If the precautionary principle is seen to raise doubts about 

pesticides, but not about organic foods, it is probably because the health risks that come 

with departures from “nature” register as especially troublesome. Of course some of the 

most  serious  risks  are  a  product  of  nature.  Tobacco  smoking  kills  400,000  Americans 

each  year;  the  precautionary  principle  might  be  (but  has  not  been)  directed  against  it. 

Nothing is more natural than exposure to sunlight, but such exposure is associated with 
skin cancer and other harms,144 producing serious health problems that have not been the 

occasion for invoking the precautionary principle. 

 

To say this is not to resolve specific issues, which depend on complex questions 
of value and fact.145 My only suggestion is that the false belief in a benevolence of nature 

                                                 
137 See James P. Collman, Naturally Dangerous (2001). 
138 See Botkin, Adjusting Law to Nature’s Discordant Harmonies, 7 Duke Env’l Law and Policy Forum 25, 
27 (1996). 
139 Id.  
140 Id. at 33. 
141 As elaborated in detail in John Stuart Mill, Nature, in Three Essays on Religion 3, 28-31 (1996). 
142 See Collman, supra note. 
143 Id. at 31. 
144 Id. at 199-201. 
145 For a helpful discussion of genetic modification of food and related issues, see McHughen, Pandora’s 
Picket Basket, supra note. 

 

 

help to explain why the precautionary principle is thought, quite incorrectly, to provide a 

great deal of analytical help. 

C.  The Availability Heuristic 

 

It is well-established that in thinking about risks, people rely on certain heuristics, 
or  rules  of  thumb,  which  serve  to  simply  their  inquiry.146  Of  these  rules  of  thumb,  the 

availability heuristic is most important for purposes of understanding the law relating to 
risks.147 The availability heuristic also helps illuminate the operation of the precautionary 

principle,  by  showing  why  some  hazards  will  be  on-screen  and  why  others  will  be 

neglected.  For  example,  “a  class  whose  instances  are  easily  retrieved  will  appear  more 
numerous  than  a  class  of  equal  frequency  whose  instances  are  less  retrievable.”148 

Tversky and Kahneman demonstrate the point with a simple study showing people a list 

of  well-known  people  of  both  sexes,  and  asking  them  whether  the  list  contains  more 

names  of  women  or  more  names  of  men.  In  lists  in  which  the  men  were  especially 

famous, people thought that the list had more names of men, whereas in lists in which the 
women were the more famous, people thought that the list had more names of women.149 

This is a point about how familiarity can affect the availability of instances. A risk 

that is familiar, like the risk associated with nuclear power, will be seen as more serious 
than a risk that is less familiar, like the risk associated with heat during the summer.150 

But salience is important as well. “For example, the impact of seeing a house burning on 

the subjective probability of such accidents is probably greater than the impact of reading 
about a fire in the local paper.”151 So too, recent events will have a greater impact than 

earlier ones. The point helps explain much risk-related behavior, including decisions to 

take precautions. For example, whether people will buy insurance for natural disasters is 

                                                 
146  See  Daniel  Kahneman,  Paul  Slovic,  and  Amos  Tversky,  Judgment  Under  Uncertainty:  Heuristics  and 
Biases (1982). 
147 See Amos Tversky and Daniel Kahneman, Judgment Under Uncertainty: Heuristics and Biases, in id. at 
3, 11-14. 
148 Id. at11. 
149 Id. 
150 See Eric Klinenberg, supra note. 
151 Id. 

greatly  affected  by  recent  experiences.152  If  floods  have  not  occurred  in  the  immediate 
past, people who live on flood plains are far less likely to purchase insurance.153 In the 

aftermath  of  an  earthquake,  insurance  for  earthquakes  rises  sharply—but  it  declines 
steadily from that point, as vivid memories recede.154 Note that the use of the availability 
heuristic,  in  these  contexts,  is  hardly  irrational.155  Both  insurance  and  precautionary 

measures can be expensive, and what has happened before seems, much of the time, to be 

the  best  available  guide  to  what  will  happen again.  The problem is that the availability 

heuristic can lead to serious errors, in terms of both excessive fear and neglect. 

 

 

The  availability  heuristic  helps  to  explains  the  operation  of  the  precautionary 

principle  for  a  simple  reason:  Sometimes  a  certain  risk,  said  to  call  for  precautions,  is 

cognitively available, whereas other risks, including the risks associated with regulation 

itself, are not. For example, it is easy to see that arsenic is potentially dangerous; arsenic 

is  well-known  as  a  poison,  forming  the  first  word  of  a  well-known  movie  about 
poisoning.156 By contrast, there is a relatively complex mental operation in the judgment 

that  arsenic  regulation  might  lead  people  to  use  less  safe  alternatives.  In  many  cases 

where the precautionary principle seems to offer guidance, the reason is that some of the 

relevant risks are available while others are barely visible. 

It is well-known that the availability heuristic affects risk judgments, and we can 

now  appreciate  the  relationship  between  that  heuristic  and  the  operation  of  the 

precautionary principle. But to say the least, the availability heuristic does not operate in 

                                                 
152 Paul Slovic, The Perception of Risk 40 (2000). 
153 Id. 
154 Id. 
155 Kahneman and Tversky emphasize that the heuristics they identify “are highly economical and usually 
effective,”  but  also  that  they  “lead  to  systematic  and  predictable  errors.”  See  Amos  Tversky  and  Daniel 
Kahneman,  Judgment  Under  Uncertainty:  Heuristics  and  Biases,  in  Judgment  and  Decision  Making:  A 
Interdisciplinary  Reader  38,  55  (Hal  Arkes  and  Kenneth  Hammond).  Gerd  Gigenzer,  among  others,  has 
emphasized  that  some  heuristics  can  work  extremely  well,  see  Gerd  Gigerenzer  et  al.,  Simple  Heuristics 
That Make Us Smart (1999); Gerd Gigerenzer, Adaptive Thinking: Rationality in the Real World (2000), 
and used this point as a rejoinder to those who stress the errors introduced by heuristics and biases. For a 
helpful recent discussion, see Kahneman and Frederick, supra note. I do not mean to take a stand on the 
resulting  debates.  Even  if  many  heuristics  mostly  work  well  in  daily  life,  a  sensible  government  can  do 
much better than to rely on them.  
156 Arsenic and Old Lace. 

a social vacuum.157 What is readily “available” to some individuals, groups, cultures, and 

even  nations  will  not  be  available  to  all.  In  part  because  of  the  use  of  the  availability 

heuristic,  the  precautionary  principle  does  not  call  for  bans  on  nuclear  power  plants  in 

France, which has not caused serious health risks in that nation despite its heavy reliance 
on  nuclear  energy.158  By  contrast,  the  Three  Mile  Island  incident  provoked  intense 
concerns  about  nuclear  power  plants  in  the  United  States159  and  helped  promote  the 

widespread  idea  that  a  precautionary  approach  would  discourage  reliance  on  nuclear 

power.  Many  of  those  who  favor  gun  control  legislation  have  “available”  a  set  of 

incidents  in  which  such  legislation  would  have  avoided  unnecessary  deaths;  many  of 

those  who  reject  such  legislation  are  alert  to  incidents  in  which  private  gun  ownership 
allowed people to fend off criminal violence.160 Much remains to be done to clarify the 

relationship  between  the  availability  heuristic  and  social  interactions,  including  the 

operations of the media and political officials. For present purposes, the key point is that 

the  availability  heuristic  often  underwrites  the  use  of  the  precautionary  principle,  by 

suggesting the importance of taking precautions against some, but hardly all, of the risks 

involved. 

 

 

D.  Probability Neglect 

The  availability  heuristic  can  produce  an  inaccurate  assessment  of  probability. 

But sometimes people will attempt little assessment of probability at all, especially when 
strong emotions are involved. 161 In such cases, large-scale variations in probabilities will 

matter  little—even  when  those  variations  unquestionably  should  matter.  The  point 

applies  to  hope  as  well  as  fear;  vivid  images  of  good  outcomes  will  crowd  out 
consideration of probability too.162 Lotteries are successful partly for this reason.163 But 

                                                 
157  See  Dan  Kahan  and  Donald  Braman,  More  Statistics,  Less  Persuasion:  A  Cultural  Theory  of  Risk 
Perception (unpublished manuscript 2002); Timur Kuran and Cass R. Sunstein, Availability Cascades and 
Risk Regulation, 51 Stan L Rev 683 (1999).  
158 See Kuran and Sunstein, supra note. 
159 See id. 
160 See Kahan and Braman, supra note. 
161  Yuval  Rottenstreich  and  Christopher  Hsee,  Money,  Kisses,  and  Electric  Shocks:  On  the  Affective 
Psychology of Probability Weighting, supra, at 176-88.  
162 See id. 
163 See Phillip Cook, Selling Hope (1993). 

for purposes of applying the precautionary principle, the topic is fear rather than hope. I 

suggest that sometimes the precautionary principle becomes workable because the issue 

of  probability  is  neglected,  and  people  focus  on  one  emotionally  gripping  outcome 

among a large set of possibilities. 

 

 

Probability  neglect  has  received  its  clearest  empirical  confirmation  in  a  striking 
study  of  people’s  willingness  to  pay  to  avoid  electric  shocks.164 The central purpose of 

the  study  was  to  test  the  relevance  of  probability  in  “affect  rich”  decisions.  One 

experiment investigated whether varying the probability of harm would matter more, or 

less, in settings that trigger strong emotions than in settings that seem relatively emotion-

free. In the “strong emotion” setting, participants were asked to imagine that they would 

participate  in  an  experiment  involving  some  chance  of  a  “short,  painful,  but  not 
dangerous electric shock.”165 In the relatively emotion-free setting, participants were told 

that the experiment entailed some chance of a $20 penalty. Participants were asked to say 

how much they would be willing to pay to avoid participating in the relevant experiment. 

Some  participants  were  told  that  there  was  a  1%  chance  of  receiving  the  bad  outcome 

(either the $20 loss or the electric shock); others were told that the chance was 99%; and 

still others were told that the chance was 100%.  

The  central  result  was  that  variations  in  probability  affected  those  facing  the 

relatively emotion-free injury, the $20 penalty, far more than they affected people facing 
the more emotionally evocative outcome of an electric shock.166 For the cash penalty, the 

difference between the median payment for a 1% chance and the median payment for a 

99% chance was predictably large and indeed consistent with the standard model: $1 to 
avoid a 1% chance, and $18 to avoid a 99% chance.167 For the electric shock, by contrast, 

the  difference  in  probability  made  little  difference  to  median  willingness  to  pay:  $7  to 
avoid  a  1%  chance,  and  $10  to  avoid  a  99%  chance!168  Apparently  people  will  pay  a 

                                                 
164  Yuval  Rottenstreich  and  Christopher  Hsee,  Money,  Kisses,  and  Electric  Shocks:  On  the  Affective 
Psychology of Probability Weighting, supra, at 176-88.  
165 Id. at 181. 
166 Id. 
167 Id. 
168 Id. 

significant amount to avoid a small probability of a hazard that is affectively-laden—and 

the amount that they will pay will not vary greatly with changes in probability. The point 

explains  “why  societal  concerns  about  hazards  such  as  nuclear  power  and  exposure  to 

extremely  small  amounts  of  toxic  chemicals  fail  to  recede  in  response  to  information 
about the very small probabilities of the feared consequences from such hazards.”169  

 

It  should  be  easy  to  the  connection  between  probability  neglect  and  the 

precautionary  principle.  If  probabilities  are  neglected,  especially  when  emotions  are 

engaged,  then  the  principle  will  operate  through  excessive  public  concern  with  certain 

low-probability  hazards.  Return  to  the  contrast  between  deaths  from  heat  waves  and 
deaths  from  airplane  crashes.170  The  latter  trigger  far  more  intense  public  attention,  in 

part  because  of  the  availability  heuristic,  but  in  part  because  for  some  people,  the 

outcome  itself  has  such  salience,  and  the  probability  much  less  so.  In  the  context  of 

genetic  modification  of  food  and  global  warming,  the  same  phenomenon  is  at  work, 

leading  people  to  think  that  the  precautionary  principle,  simply  applied,  calls  for 

aggressive regulatory controls. Note that I am not urging that such controls are a mistake; 

in  the  context  of  global  warming,  they  seem  to  be  warranted  by  the  facts.  My  claim  is 

only that the precautionary principle appears to give guidance in part because the issue of 

probability is neglected.  

 

For  purposes  of  understanding  the  operation  of  the  precautionary  principle,  it  is 

important to see that visualization or imagery matters a great deal to people’s reactions to 
risks.171 When an image of a bad outcome is easily accessible, people will become greatly 
concerned  about  a  risk,  holding  probability  constant.172  Consider  the  fact  that  when 

people  are  asked  how  much  they  will  pay  for  flight  insurance  for  losses  resulting  from 

“terrorism,” they will pay more than if they are asked how much they will pay for flight 

                                                 
169 See Paul Slovic et al., The Affect Heuristic, forthcoming in Intuitive Judgment: Heuristics and Biases 
(Tom Gilovich et al. eds, forthcoming), unpublished manuscript at 11. 
170 See Eric Klinenberg, supra note. 
171  See  Paul  Slovic  et  al.,  Violence  Risk  Assessment  and  Risk  Communication,  24  Law  and  Human 
Behavior 271 (2000). 
172 See Loewenstein et al., supra, at 275-76. 

insurance  from  all  causes.173  The  evident  explanation  for  this  peculiar  result  is  that  the 

word  “terrorism”  evokes  vivid  images  of  disaster,  thus  crowding  out  probability 

judgments. Note also that when people discuss a low-probability risk, their concern rises 

even  if  the  discussion  consists  mostly  of  apparently  trustworthy  assurances  that  the 
likelihood  of  harm  really  is  infinitesmal.174  The  reason  is  that  the  discussion  makes  it 

easier to visualize the risk and hence to fear it.  

 

Note  that  probability  neglect  does  not  involve  the  availability  heuristic.  That 

heuristic  leads  not  to  neglect  probability,  but  to  answer  the  question  of  probability  by 

substituting a hard question (what is the statistical risk?) with an easy question (do salient 
examples  readily  come  to  mind?).175  My  point  here  is  not  that  visualization  makes  an 

event seem more probable (though this is also often true), but that visualization makes the 

issue of probability less relevant or even irrelevant. In theory, the distinction between use 

of the availability heuristic and probability neglect should not be obscure. In practice, of 

course,  it  will  often  be  hard  to  know  whether  the  availability  heuristic  or  probability 

neglect is driving behavior. 

 

The most sensible conclusion is that with respect to risks of injury of harm, vivid 

images  and  concrete  pictures  of  disaster  can  “crowd  out”  other  kinds  of  thoughts, 

including the crucial thought that the probability of disaster is really small. “If someone is 

predisposed  to  be  worried,  degrees  of  unlikeliness  seem  to  provide  no  comfort,  unless 
one  can  prove  that  harm  is  absolutely  impossible,  which  itself  is  not  possible.”176 

Probability neglect, I suggest, often makes the precautionary principle seem sensible and 

workable.  Indeed,  the  precautionary  principle  often  embodies  a  form  of  probability 

neglect. When people focus on highly speculative risks associated with certain risks, it is 

often  because  of  intense  emotional  reactions  that  make  those  risks,  and  not  relevant 

others,  stand  out  from  the  background.  In  many  cases,  probability  neglect  and  loss 
                                                 
173  See  E.J.  Johnson  et  al.,  Framing,  Probability  Distortions,  and  Insurance  Decisions,  7  H.  Risk  and 
Uncertainty 35 (1993). 
174  See  A.S.  Alkahami  and  Paul  Slovic,  A  Psychological  Study  of  the  Inverse  Relationship  Bteween 
Perceived Risk and Perceived Benefit, 14 Risk Analysis 1086, 1094-94 (1994). 
175  See  Amos  Tversky  and  Daniel  Kahneman,  Availability:  A  Heuristic  for  Judging  Frequency  and 
Probability, 5 Cognitive Psychology 207 (1973). 
176 See Weingart, supra note 1, at 362. 

aversion march hand-in-hand. Potential losses, from the status quo, often trigger intense 

emotions, as potential gains do not; and when the precautionary principle is operating, the 
low-probability losses have far more salience than they deserve.177 

Nor  is  the  problem  of  probability  neglect  foreign  to  law.  In  many  contexts,  law 

seems  to  be  a  response,  in  part,  to  fear  of  bad  outcomes  without  close  attention  to  the 
question  of  probability—along  one  dimension,  the  precautionary  principle  in  action.178 

The  European  Community’s  ban  on  meat  products  treated  with  hormones  has  raised 
large-scale issues about the role of public fear in risk regulation.179 The Appellate Body 
of  the  World  Trade  Organization  ruled180  that  the  ban  ran  afoul  of  Article  5.1  of  the 
Agreement on Sanitary and Phytosanitary Measures (SPS Agreement),181 which requires 

members of the WTO to justify all health and safety regulations by reference to scientific 
risk  assessments.182  In  this  way,  the  Appellate  Body  rejected  the  EC’s  effort  to  defend 

itself  in  part  by  reference  to  consumer  fears  about  the  safety  of  beef  treated  with 
hormones.183 In this context, such fears were apparently real, but they neglected the issue 
of probability.184 

 

 

                                                 
177 With respect to global warming, this is the suggestion in Goklany, supra note, at 58-88, and Lomborg, 
supra note. 
178 See Sunstein, Probability Neglect, supra note, at  
179 For an illuminating discussion, see Howard Chang, Risk Regulation, Public Concerns, and the Hormone 
Dispute: Nothing to Fear Except Fear Itself? (unpublished manuscript 2002). 
180 Report of the Appellate Body, EC Measures Concerning Meat and Meat Products (Hormones), 
WT/DS48/AB/R  &  WT/DS48/AB/R,  Jan.  16,  1998  (adopted  Feb.  13,  1998),  available  in 
Westlaw, WTO-DEC file, 1998 WL 25520 [hereinafter Appellate Body]. 
181See id. at ¶ 208 (citing Agreement on the Application of Sanitary and Phytosanitary Measures 
art. 5.1, Apr. 15, 1994, annex 1A-4 to Final Act Embodying the Results of the Uruguay Round of 
Multilateral Trade Negotiations, 33 I.L.M. 1125 (1994) [hereinafter SPS Agreement]). 

182See  SPS  Agreement,  supra  note  ,  art.  5.1  (“Members  shall  ensure  that  their  sanitary  or 
phytosanitary  measures  are  based  on  an  assessment,  as  appropriate  to  the  circumstances,  of  the 
risks  to  human,  animal  or  plant  life  or  health,  taking  into  account  risk  assessment  techniques 
developed by the relevant international organizations.”). 

183See Michele D. Carter, Selling Science Under the SPS Agreement: Accommodating Consumer 
Preference in the Growth Hormones Controversy, 6 MINN. J. GLOBAL TRADE 625, 627 (1997). 

184 For discussion of the complex normative issues, see Chang, supra note. 

E.  System Neglect  

 

 

The fourth point is, in a way, the largest. My suggestion is that much of the time, 

and  with  respect  to  risks,  people  neglect  the  systemic  effect  of  one-shot  interventions. 

They tend to assume that a change in a social situation would alter the part at issue, but 

without  altering  other  parts.  System  neglect,  thus  understood,  includes  the  general 

phenomenon  of  tradeoff  neglect,  by  which  people  fail  to  see  the  frequent  need  to  way 
competing  variables  against  one  another.185  But  tradeoff  neglect  is  only  part  of  what  is 

involved here. When the precautionary principle gives guidance, and when it goes wrong, 

it is often because those who use it are falling victim to system neglect. 

 

The clearest evidence comes from the German psychologist Dietrich Dorner, who 

has  designed  some  fascinating  experiments  to  see  whether  people  can  reduce  social 
risks.186 Dorner’s experiments are run via computer. Participants are asked to reduce risks 

faced  by  the  inhabitants  of  some  region  of  the  world.  The  risks  may  involve  pollution, 

poverty,  poor  medical  care,  inadequate  fertilization  of  crops,  sick  cattle,  insufficient 

water, or excessive hunting and fishing. Through the magic of the computer, many policy 

initiatives are available—improved care of cattle, childhood immunization, drilling more 

wells). Participants are able to choose among them. Once particular initiatives are chosen, 

the computer projects, over short periods and then over decades, what is likely to happen 

in the region.  

In  these  experiments,  success  is  entirely  possible.  Some  initiatives  will  actually 

make for effective and enduring improvements. But many of the participants—even the 

most educated and professional—produce calamities. They do so because they fixate on 

isolated  problems  and  do  not  see  the  complex,  system-wide  effects  of  particular 

interventions. For example, they may appreciate the importance of increasing the number 

of cattle, but once they do that, they create a serious risk of overgrazing, and they fail to 

                                                 
185 See Howard Margolis, Dealing With Risk (1995). 
186 Dietrich Dorner, The Logic of Failure: Recognizing and Avoiding Error in Complex Situations (1996). 

anticipate that problem.187 They may understand full well the value of drilling more wells 

to provide water, but they do not anticipate the energy and environmental effects of the 

drilling, which then endangers the food supply. Only the rare participant is able to see a 

number  of  steps  down  the  road—to  understand  the  multiple  effects  of  one-shot 

interventions  into  the  system,  and  to  assess  a  wide  range  of  consequences  from  those 

interventions. The successful participants seem to take small, reversible steps, or to see 

the  full  set  of  effects  at  once,  and  thus  to  protect  themselves  against  major  blunders. 

When  people  are  not  successful,  it  is  because  they  fail  to  see  that  risks  are  parts  of 
systems.188 

How  would  the  precautionary  principle  operate  if  invoked  in  Dorner’s 

experiments? It should be easy to see that while the weaker version might provide some 

assistance,  the  stronger  versions  offer  no  help  at  all.  There  are  simply  too  many  risks 

against which one might take precautions. Precautions cannot be taken against all risks, 

not  for  the  important  but  less  interesting  reason  that  resources  are  limited,  but  simply 

because  efforts  to  redress  any  set  of  risks  might  produce  risks  of  their  own.  The  real 
world  of  risk  regulation  offers  many  analogues.189  To  the  extent  that  the  precautionary 

principle appears to offer guidance, it is often because adverse systemic effects, and the 

need to take precautions against them, are simply being neglected.  

 

 

Howard Margolis has used a related point to explain why experts have different 

risk judgments from ordinary people, and he has done so in a particular effort to explain 
why  and  when  ordinary  people  will  think,  “Better  safe  than  sorry.”190  Margolis  thus 

offers  some  cognitive  foundations  for  the  precautionary  principle,  without  explicitly 

discussing  the  idea.  Margolis’  goal  is  to  cast  light  on  some  apparent  anomalies  in 

ordinary  thinking  about  risks:  Why  do  people  believe  that  small  risks  from  pesticides 

should  be  regulated,  if  comparatively  small  risks from X-rays are quite tolerable? Why 

are people so concerned about the risks of nuclear power, when experts tend to believe 

                                                 
187 Id. at 6-11. 
188 For some real world analogues to Dorner’s experiments, see James Scott, Seeing Like A State (1999). 
189See Wiener, supra note. 
190 See Margolis, supra note. 

that the risks are quite low—lower, in fact, than the risks from competing energy sources, 

such as coal-fired power plants, which produce relatively little public objection?  

Margolis suggests that people are sometimes subject to a kind of optical illusion, 

in which they see the harms associated with some activity or process, but fail to see the 
benefits.  If  so,  they  will  tend  to  think,  “better  safe  they  sorry.”191  If  not,  they  will  see 

some “fungibility” between both harms and benefits, and engage in the kind of tradeoff 
analysis that is more typical for experts.192 Margolis offers a nice example to support this 
suggestion.193 The removal of asbestos from schools in New York City was initially quite 

popular,  indeed  demanded  by  parents,  even  though  experts  believed  that  the  risks  were 

statistically  small.  (As  it  happens,  the  risk  of  a  child  getting  cancer  from  asbestos 

insulation was about 1/3 the risk of being struck by lightning.) But when it emerged that 

the removal would cause schools to be closed for a period of weeks, and when the closing 

caused parents to become greatly inconvenienced, parental attitudes turned right around, 

and asbestos removal seemed like a really bad idea. When the costs of the removal came 

on-screen, parents thought much more like experts, and the risks of asbestos seemed well 

worth  tolerating:  Statistically  small,  and  on  balance  worth  incurring.  The  precautionary 

principle  often  operates  because  of  the  visibility  of  only  one  side  of  the  ledger,  so  that 

people think that parents in advance of asbestos removal, seeing the possibility of hazard 

without confronting the problems introducing by reducing it. 

 

 

For an especially vivid example, consider the apparent views of Americans in the 

late  1990s.  About  63  percent  of  Americans  agreed  with  the  statement:  “Protecting  the 

environment  is  so  important  that  requirements  and  standards  cannot  be  too  high  and 
continuing environmental improvements must be made regardless of cost.”194 In the same 

general  vein,  59  percent  supported  the  Kyoto  Treaty  on  global  warming,  with  only  21 
percent opposed.195 But in the same period, 52 percent of Americans said that they would 

                                                 
191 Id. at 75-81. 
192 Id. at 75-92. 
193 Id. at 124-28. 
194 See The Program on International Policy Attitudes, Americans on the Global Warming Treaty, available 
at http://www.pipa.org/OnlineReports/GlobalWarming/glob_warm_treaty.html at Box 15. 
195 Id. 

refuse to support the Kyoto Treaty on global warming if “it would cost an extra $50 per 
month  for  an  average  American  household.”196  In  fact  only  11  percent  of  Americans 
would support the Kyoto Treaty if the monthly expense were $100 or more.197 How can 

we  explain  strong  majority  support  for  “environmental  improvements  .  .  .  regardless  of 

cost”  and  strong  majority  rejection  of  environmental  improvements  when  the  cost  if 

high? The answer lies in the fact that people are not, in fact, willing to spend an infinite 

amount for environmental improvements, and that when the costs are squarely placed “on 

screen,” people begin to weigh both costs and benefits. 

 

There  are  many  other  examples.  People  seem  quite  concerned  about  the  risks 

associated with dioxin, a real candidate for use of the precautionary principle, but far less 

concerned about the statistically equivalent risks associated with aflatoxin, a carcinogen 
found in peanut butter.198 When aflatoxin does not trigger public concern, a large part of 

the reason is that the burdens of banning aflatoxin seem high and indeed intolerable; too 

many people would object to heavy regulation of peanut butter, a staple of school lunches 

and  many  diets  for  generations.  In  this  light  it  is  both  mildly  counterintuitive  and 

reasonable, for example, to predict that people would be willing to pay less, in terms of 

dollars and waiting time, to reduce low-probability risks of an airplane disaster if they are 
frequent  travellers.  An  intriguing  study  finds  exactly  that  effect.199  It  is  also  safe  to 

predict  that  if  people  were  told,  by  a  reliable  source,  that  eliminating  pesticides  would 

lead  to  serious  health  problems—for  example,  because  pesticide-free  fruits  and 
vegetables  carried  special  dangers200—the  perceived  risk  of  pesticides  would  decline 

dramatically, and it would be difficult to invoke the precautionary principle as a basis for 
stringent  regulation  of  pesticides.201  Indeed  I  predict  that  if  people  were  informed  that 

eliminating pesticides would lead to a significant cost in the price of applies and oranges, 
the perceived risk would go down as well.202 

                                                 
196 Id. at Box 16.  
197 Id.  
198 Id. at 136-37. 
199 See Matthew Harrington (unpublished manuscript). 
200 See the discussion of organic food in McHughen, supra note, at 232-37. 
201 Carolyn Raffensperger, The Precautionary Principle as Forecaring: Hopeful Work for the Environmental 
Health Movement (2000), available at http://www.biotech-info.net/forecaring.html 
202 For evidence of the general phenomenon, see Paul Slovic, The Perception of Risk (2000). 

 

 

 

The  conclusion  is  that  the  precautionary  principle  often  seems  helpful  because 

analysts are focussing on the “target” risk, and not on the systemic, risk-related effects of 

being precautionary, or even on the risk-related consequences of risk reduction. Rational 
regulators, of course, think about systems, not snapshots.203 And once we see that risks 

are inevitably parts of systems, the precautionary principle will become far less helpful. 

 

V. Toward Wider Viewscreens 

In  this  Article  I  have  argued  not  that  the  precautionary  principle  leads  in  the 

wrong directions, but that if it is taken for all that it is worth, it leads in no direction at all. 

The reason is that risks of one kind or another are on all sides of regulatory choices, and 

it  is  therefore  impossible,  in  most  real-world  cases,  to  avoid  running  afoul  of  the 

principle.  Frequently risk regulation creates  a  (speculative) risk  from  substitute risks or 

from  foregone  risk-reduction  opportunities.  And  because  of  the  (speculative)  mortality 

and morbidity effects of costly regulation, any regulation, if it is costly, threatens to run 

afoul of the precautionary principle. We have seen that both regulation and nonregulation 

seem  to  be  forbidden  in  cases  involving  nuclear  power,  arsenic,  global  warming,  and 

genetic  modification  of  food.  The  precautionary  principle  seems  to  offer  guidance  only 

because  people  blind  themselves  to  certain  aspects  of  the  risk  situation,  focusing  on  a 

mere subset of the hazards that are at stake. 

To  some  extent,  those  who  endorse  the  precautionary  principle  seem  to  be 

responding to salutary political or moral motivations that the principle might be thought 

to embody. Well-organized private groups sometimes demand conclusive proof of harm 

                                                 
203  There  might  seem  to  be  some  tension  between  the  plea  for  wide  viewscreens  and  my  (qualified) 
argument for a form of judicial minimalism, in Cass R. Sunstein, One Case At A Time (1999). But there is 
no tension. Minimalism is a form of incrementalism, arguing on behalf of “small steps” in part because of 
the risk that large-scale interventions into systems will have unanticipated adverse consequences. See id. at 
52-53.  Indeed,  Dorner  himself  suggests  that  small  steps  are  a  desirable  approach  to  the  risk  of  system 
neglect.  See  The  Logic  of  Failure,  supra,  at  166-81.  By  endorsing  a  wide  viewscreen,  I  do  not  mean  to 
challenge small steps, but instead to urge that in taking any step at all, officials should look at the range of 
likely consequences. Of course it is possible that a  full assessment of such consequences will be beyond 
existing capacities. In such cases simplifying devices might be helpful. See Goklany, supra note, at 9-10, 
for some suggestions.  

as  a  precondition  for  regulation;  the  demand  should  be  firmly  resisted,  because  a 

probability  of  harm  is,  under  many  circumstances,  a  sufficient  reason  to  act.  Both 

individuals  and  societies  have  a  tendency  to  neglect  the  future;  the  precautionary 

principle  might  be  understood  as  a  warning  against  that  form  of  neglect.  There  are 

extremely  good reasons to incorporate  distributional considerations into risk regulation, 

and the precautionary principle seems, some of the time, to be a way to protect the most 

disadvantaged  against  risks  of  illness,  accident,  and  death.  Sometimes  people  try  to 

reduce  dissonance  by  thinking  that  actual  risks  are  trivial;  the  precautionary  principle 

might  work  as  a  helpful  counterweight  to  this  mechanism.  The  problem  is  that  the 

precautionary  principle,  as  applied,  is  a  crude  and  sometimes  perverse  way  to  promote 

these  various  goals,  not  least  because  it  might  be,  and  has  been,  urged  in  situations  in 

which the principle threatens to injure future generations and to harm rather than to help 

those who are most disadvantaged. 

I  have  also  urged  that  the  precautionary  principle  can  be  made  operational  only 

because  of  identifiable  cognitive  mechanisms.  Often  loss  aversion  is  at  work.  The 

benefits  of  certain  practices  are  less  salient  than  the  costs,  simply  because  the  costs 

would,  along  an  important  dimension,  represent  a  deterioration  from  the  status  quo. 

When loss aversion is involved, it might be thought, wrongly, that natural processes are 

always  safer,  and  better  for  the  environment,  than  processes  that  involve  human 

intervention. Sometimes the precautionary principle works by exploiting the availability 

heuristic, because the risks that matter are cognitively accessible, whereas the risks that 

are  ignored  are  far  less  so.  Frequently  the  precautionary  principle  is  underwritten  by 

probability neglect. Highly speculative harms are emphasized by those who focus on the 

badness  of  the  relevant  outcomes,  rather  than  the  likelihood  that  they  will  occur.  Most 

generally,  the  precautionary  principle  sometimes  gives  an  illusion  of  guidance  because 

people  focus  on  the  immediate  risk  while  disregarding  the  systemic  effects  of  one-shot 

interventions, even though those interventions can give rise to risks of their own. 

 

 

I have not suggested any particular substitute for the precautionary principle.  

But  I  do  not  endorse  the  suggestion  of  Aaron  Wildavsky,  a  political  scientist  with  a 
special  interest  in  risk  regulation,  who  also  rejects  the  precautionary  principle.204  In 

Wildavsky’s view, the notion of “precaution” should be abandoned and replaced with a 

principle  of  “resilience,”  based  on  an  understanding  that  nature,  and  society,  are  quite 

able to incorporate even strong shocks, and that the ultimate dangers are therefore smaller 

than  we  are  likely  to  fear.  It  would  follow  from  the  “resilience”  principle  that  a  nation 

should  be  less  concerned  than  it  now  is  with  the  risks  associated  with  (for  example) 

arsenic, global warming, and destruction of the ozone layer. Unfortunately, the principle 

of  “resilience”  is  no  better  than  that  of  “precaution.”  Some  systems  are  resilient,  but 

many are not. Whether an ecosystem, or a society, is “resilent” cannot be decided in the 

abstract. In any case resilience is a matter of degree. Everything depends on the facts. The 

“resilience principle” should be understood as a heuristic, one that favors inaction in the 

face  of  possibly  damaging  technological  change.  Like  most  heuristics,  the  resilience 

principle  will  work  well  in  many  circumstances,  but  it  can  also  lead  to  systematic  and 
even deadly errors.205  

 

A better approach would acknowledge that a wide variety of adverse effects may 

come  from  inaction,  regulation,  and  everything  between.  Such  an  approach  would 
attempt  to  consider  all  of  those  adverse  effects,  not  simply  a  subset.206  When  existing 

knowledge does not allow clear assessments of the full range of adverse effects, such an 

approach would develop simplifying devices, helping to show the appropriate course of 
action in the face of uncertainty.207 Such an approach would pursue distributional goals 

                                                 
204 See Aaron Wildavsky, But Is It True? A Citizen’s Guide to Environmental Health and Safety Issues 433 
(1995). 
205 Cf. See Amos Tversky and Daniel Kahneman, Judgment Under Uncertainty: Heuristics and Biases, in 
Judgment  and  Decision  Making:  A  Interdisciplinary  Reader  38,  55  (Hal  Arkes  and  Kenneth Hammond). 
(emphasizing that heuristic can lead to systematic mistakes). The resilience principle might well be taken as 
a reflection of optimistic bias. See Neil Weinstein, Unrealistic Optimism About Future Life Events, 39 J. 
Personality and Soc Psych. 806 (1980); Shelly Taylor, Positive Illusions (1991). 
206 See Wiener, supra note; Cass R. Sunstein, Risk and Reason (forthcoming 2002). 
207  See  Goklany,  supra  note,  at  9-10.  Instead  of  advocating  full-fledged  balancing  of  relevant  variables, 
Goklany  proposes  that  regulators  look  at  a  list  of  criteria,  including  “the  human  mortality  criterion” 
(valuing human life over that of members of other species), “the immediacy criterion” (giving priority to 
immediate  threats),  “the  uncertainty  criterion”  (giving  priority  to  risks  with  a  higher  probability  of 
occurring),  and  “the  irreversibility  criterion”  (giving  priority  to  risks  that  are  likely  to  be  permanent  or 
persistent). Some of these criteria seem to me doubtful; a less immediate threat might, for example, deserve 
priority if its magnitude so suggests, and it is unclear that a small number of human lives deserve priority 

directly by, for example, requiring wealthy countries, major contributors to the problem 

of  global  warming,  to  pay  poor  countries  to  reduce  greenhouse  gases  or  to  prepare 

themselves  for  the  relevant  risks.  And  such  an  approach  would  attempt  to  counteract, 

rather than to embody, the various cognitive limitations that people face in thinking about 

risks.  An  appreciation  of  the  difficulties  with  the  precautionary  principle  suggests  the 

importance  of  overcoming  cognitive  limitations  by  ensuring  that  people  have  a  full, 

rather than limited, sense of what is at stake. The result should be to help with cognitive 

distortions and to produce sensible priority-setting. An effort to produce a fair accounting 

of  the  universe  of  dangers  should  also  help  to  diminish  the  danger  of  interest-group 

manipulation.  

 

To be sure, public alarm, even if ill-informed, is itself a harm, and it is likely to 
lead to additional harms, perhaps in the form of large-scale “ripple effects.”208 A sensible 

approach to risk will attempt to reduce public fear even if it is baseless. My goal here has 

been  not  to  deny  that  point,  but  to  explain  the  otherwise  puzzling  appeal  of  the 

precautionary principle and to isolate the strategies that help make it operational. At the 

individual  level,  these  strategies  are  hardly  senseless,  especially  for  people  who  lack 

much  information  or  who  do  the  best  they  can  by  focussing  on  only  one  aspect  of  the 
situation at hand.209 But for governments, the precautionary principle is not sensible, for 

the simple reason that once the viewscreen is widened, it become clear that the principle 

provides  no  guidance  at  all.  A  rational  system  of  risk  regulation  certainly  takes 

precautions. But it does not adopt the precautionary principle. 

 
 
 
 
 
 
                                                                                                                                                 
over a large number of lives of members of other species. But Goklany is correct to seek an approach that 
helps  in  making  decisions  under  uncertainty.  Wiener,  supra  note,  offers  some  valuable  suggestions, 
involving  in  partcular  the  need  to  ensure  “risk-superior  moves,”  meaning  approaches  that  reduce  overall 
risks.  (Unpublished  manuscript  at  16.)  The  problem  with  this  approach  is  that  sometimes  we  will  lack 
sufficient information to identify such moves, because regulation must proceed in the face of uncertainty 
rather than risk. See above.  
208 See the discussion of the social amplification of risk in Slovic, supra note. 
209 See Gerd Gigerenzer et al., Simple Heuristics That Make Us Smart (1999). 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Readers with comments may address them to: 
 
Cass R. Sunstein 
University of Chicago Law School 
1111 East 60th Street 
Chicago, IL 60637 
 

csunstei@midway.uchicago.edu 

Chicago Working Papers in Law and Economics 
 (Second Series) 

1. 

2. 

3. 
4. 
5. 

6. 
7. 
8. 

9. 

10. 

11. 
12. 
13. 

14. 
15. 

16. 

17. 

Willam M. Landes, Copyright Protection of Letters, Diaries, and Other 
Unbpublished Works:  An Economic Approach (July 1991) 
Richard A. Epstein, The Path to The T. J. Hooper: The Theory and History of 
Custom in the Law of Tort (August 1991) 
Cass R. Sunstein, On Property and Constitutionalism (September 1991) 
Richard A. Posner, Blackmail, Privacy, and Freedom of Contract (February 1992) 
Randal C. Picker, Security Interests, Misbehavior, and Common Pools (February 
1992) 
Tomas J. Philipson & Richard A. Posner, Optimal Regulation of AIDS (April 1992) 
Douglas G. Baird, Revisiting Auctions in Chapter 11 (April 1992) 
William M. Landes, Sequential versus Unitary Trials: An Economic Analysis (July 
1992) 
William M. Landes & Richard A. Posner, The Influence of Economics on Law: A 
Quantitative Study (August 1992) 
Alan O. Sykes, The Welfare Economics of Immigration Law: A Theoretical 
Survey With An Analysis of U.S. Policy (September 1992) 
Douglas G. Baird, 1992 Katz Lecture: Reconstructing Contracts (November 1992) 
Gary S. Becker, The Economic Way of Looking at Life (January 1993) 
J. Mark Ramseyer, Credibly Committing to Efficiency Wages: Cotton Spinning 
Cartels in Imperial Japan (March 1993) 
Cass R. Sunstein, Endogenous Preferences, Environmental Law (April 1993) 
Richard A. Posner, What Do Judges and Justices Maximize? (The Same Thing 
Everyone Else Does) (April 1993) 
Lucian Arye Bebchuk and Randal C. Picker, Bankruptcy Rules, Managerial 
Entrenchment, and Firm-Specific Human Capital (August 1993) 
J. Mark Ramseyer, Explicit Reasons for Implicit Contracts: The Legal Logic to the 
Japanese Main Bank System (August 1993) 

18.  William M. Landes and Richard A. Posner, The Economics of Anticipatory 

Adjudication (September 1993) 
Kenneth W. Dam, The Economic Underpinnings of Patent Law (September 1993) 
Alan O. Sykes, An Introduction to Regression Analysis (October 1993) 
Richard A. Epstein, The Ubiquity of the Benefit Principle (March 1994) 
Randal C. Picker, An Introduction to Game Theory and the Law (June 1994) 

19. 
20. 
21. 
22. 
23.  William M. Landes, Counterclaims: An Economic Analysis (June 1994) 
24. 

J. Mark Ramseyer, The Market for Children: Evidence from Early Modern Japan 
(August 1994) 
Robert H. Gertner and Geoffrey P. Miller, Settlement Escrows (August 1994) 
Kenneth W. Dam, Some Economic Considerations in the Intellectual Property 
Protection of Software (August 1994) 
Cass R. Sunstein, Rules and Rulelessness, (October 1994) 

25. 
26. 

27. 

28. 

29. 

30. 
31. 

32. 

33. 
34. 
35. 

36. 
37. 

38. 

46. 
47. 

48. 

50. 

David Friedman, More Justice for Less Money: A Step Beyond Cimino (December 
1994) 
Daniel Shaviro, Budget Deficits and the Intergenerational Distribution of Lifetime 
Consumption (January 1995) 
Douglas G. Baird, The Law and Economics of Contract Damages (February 1995) 
Daniel Kessler, Thomas Meites, and Geoffrey P. Miller, Explaining Deviations 
from the Fifty Percent Rule: A Multimodal Approach to the Selection of Cases for 
Litigation (March 1995) 
Geoffrey P. Miller, Das Kapital: Solvency Regulation of the American Business 
Enterprise (April 1995) 
Richard Craswell, Freedom of Contract (August 1995) 
J. Mark Ramseyer, Public Choice (November 1995) 
Kenneth W. Dam, Intellectual Property in an Age of Software and Biotechnology 
(November 1995) 
Cass R. Sunstein, Social Norms and Social Roles (January 1996) 
J. Mark Ramseyer and Eric B. Rasmusen, Judicial Independence in Civil Law 
Regimes: Econometrics from Japan (January 1996) 
Richard A. Epstein, Transaction Costs and Property Rights: Or Do Good Fences 
Make Good Neighbors? (March 1996) 
Cass R. Sunstein, The Cost-Benefit State (May 1996) 

41. 

39. 
40.  William M. Landes and Richard A. Posner, The Economics of Legal Disputes 
Over the Ownership of Works of Art and Other Collectibles (July 1996) 
John R. Lott, Jr. and David B. Mustard, Crime, Deterrence, and Right-to-Carry 
Concealed Handguns (August 1996) 
Cass R. Sunstein, Health-Health Tradeoffs (September 1996) 
G. Baird, The Hidden Virtues of Chapter 11: An Overview of the Law and 
Economics of Financially Distressed Firms (March 1997) 
Richard A. Posner, Community, Wealth, and Equality (March 1997) 

44. 
45.  William M. Landes, The Art of Law and Economics: An Autobiographical Essay 

42. 
43. 

(March 1997) 
Cass R. Sunstein, Behavioral Analysis of Law (April 1997) 
John R. Lott, Jr. and Kermit Daniel, Term Limits and Electoral Competitiveness: 
Evidence from California=s State Legislative Races (May 1997) 
Randal C. Picker, Simple Games in a Complex World: A Generative Approach to 
Richard A. Epstein, Contracts Small 
the Adoption of Norms (June 1997)49. 
and Contracts Large: Contract Law through the Lens of Laissez-Faire (August 
1997)  
Cass R. Sunstein, Daniel Kahneman, and David Schkade, Assessing Punitive 
Damages (with Notes on Cognition and Valuation in Law) (December 1997)  

51.  William M. Landes, Lawrence Lessig, and Michael E. Solimine, Judicial Influence: 
A Citation Analysis of Federal Courts of Appeals Judges (January 1998)  
John R. Lott, Jr., A Simple Explanation for Why Campaign Expenditures are 
Increasing: The Government is Getting Bigger (February 1998)  

52. 

61. 

62. 

57. 

55. 

56. 

58. 

54. 

53.  

59. 
60. 

Richard A. Posner, Values and Consequences: An Introduction to Economic 
Analysis of Law (March 1998)  
Denise DiPasquale and Edward L. Glaeser, Incentives and Social Capital: Are 
Homeowners Better Citizens? (April 1998)  
Christine Jolls, Cass R. Sunstein, and Richard Thaler, A Behavioral Approach to 
Law and Economics (May 1998) 
John R. Lott, Jr., Does a Helping Hand Put Others At Risk?: Affirmative Action, 
Police Departments, and Crime (May 1998) 
Cass R. Sunstein and Edna Ullmann-Margalit, Second-Order Decisions (June 
1998) 
Jonathan M. Karpoff and John R. Lott, Jr., Punitive Damages: Their Determinants, 
Effects on Firm Value, and the Impact of Supreme Court and Congressional 
Attempts to Limit Awards (July 1998) 
Kenneth W. Dam, Self-Help in the Digital Jungle (August 1998) 
John R. Lott, Jr., How Dramatically Did Women=s Suffrage Change the Size and 
Scope of Government? (September 1998) 
Kevin A. Kordana and Eric A. Posner, A Positive Theory of Chapter 11 (October 
1998) 
David A. Weisbach, Line Drawing, Doctrine, and Efficiency in the Tax Law 
(November 1998) 
Jack L. Goldsmith and Eric A. Posner, A Theory of Customary International Law 
(November 1998) 
John R. Lott, Jr., Public Schooling, Indoctrination, and Totalitarianism (December 
1998) 
Cass R. Sunstein, Private Broadcasters and the Public Interest: Notes Toward A 
AThird Way@ (January 1999) 
Richard A. Posner, An Economic Approach to the Law of Evidence (February 
1999) 
Yannis Bakos, Erik Brynjolfsson, Douglas Lichtman, Shared Information Goods 
(February 1999) 
Kenneth W. Dam, Intellectual Property and the Academic Enterprise (February 
1999) 
Gertrud M. Fremling and Richard A. Posner, Status Signaling and the Law, with 
Particular Application to Sexual Harassment (March 1999) 
Cass R. Sunstein, Must Formalism Be Defended Empirically? (March 1999)71.
 
Jonathan M. Karpoff, John R. Lott, Jr., and Graeme Rankine, 
Environmental Violations, Legal Penalties, and Reputation Costs (March 1999) 
72.  Matthew D. Adler and Eric A. Posner, Rethinking Cost-Benefit Analysis (April 

68. 

63. 

65. 

67. 

69. 

64. 

66. 

70. 

73. 

1999) 
John R. Lott, Jr. and William M. Landes, Multiple Victim Public Shooting, 
Bombings, and Right-to-Carry Concealed Handgun Laws: Contrasting Private 
and Public Law Enforcement (April 1999)  

74. 

75. 

77. 

78. 

79. 
80. 

81. 

82. 
83. 

84. 
85. 
86. 

87. 

89. 

90. 

91. 
92. 
93. 

94. 

95. 

96. 

Lisa Bernstein, The Questionable Empirical Basis of Article 2=s Incorporation 
Strategy: A Preliminary Study (May 1999) 
Richard A. Epstein, Deconstructing Privacy: and Putting It Back Together Again 
(May 1999) 

76.  William M. Landes, Winning the Art Lottery: The Economic Returns to the Ganz 

Collection (May 1999) 
Cass R. Sunstein, David Schkade, and Daniel Kahneman, Do People Want 
Optimal Deterrence? (June 1999) 
Tomas J. Philipson and Richard A. Posner, The Long-Run Growth in Obesity as a 
Function of Technological Change (June 1999) 
David A. Weisbach, Ironing Out the Flat Tax (August 1999) 
Eric A. Posner, A Theory of Contract Law under Conditions of Radical Judicial 
Error (August 1999) 
David Schkade, Cass R. Sunstein, and Daniel Kahneman, Are Juries Less Erratic 
than Individuals? Deliberation, Polarization, and Punitive Damages (September 
1999) 
Cass R. Sunstein, Nondelegation Canons (September 1999) 
Richard A. Posner, The Theory and Practice of Citations Analysis, with Special 
Reference to Law and Economics (September 1999) 
Randal C. Picker, Regulating Network Industries: A Look at Intel (October 1999) 
Cass R. Sunstein, Cognition and Cost-Benefit Analysis (October 1999) 
Douglas G. Baird and Edward R. Morrison, Optimal Timing and Legal 
Decisionmaking: The Case of the Liquidation Decision in Bankruptcy (October 
1999) 
Gertrud M. Fremling and Richard A. Posner, Market Signaling of Personal 
Characteristics (November 1999) 

Preferences Are Distorted (November 1999) 
Richard A. Posner, Orwell versus Huxley: Economics, Technology, Privacy, and 
Satire (November 1999) 
David A. Weisbach, Should the Tax Law Require Current Accrual of Interest on 
Derivative Financial Instruments? (December 1999) 
Cass R. Sunstein, The Law of Group Polarization (December 1999) 
Eric A. Posner, Agency Models in Law and Economics (January 2000) 
Karen Eggleston, Eric A. Posner, and Richard Zeckhauser, Simplicity and 
Complexity in Contracts (January 2000)  
Douglas G. Baird and Robert K. Rasmussen, Boyd=s Legacy and Blackstone=s 
Ghost (February 2000)  
David Schkade, Cass R. Sunstein, Daniel Kahneman, Deliberating about Dollars: 
The Severity Shift (February 2000) 
Richard A. Posner and Eric B. Rasmusen, Creating and Enforcing Norms, with 
Special Reference to Sanctions (March 2000) 

88.  Matthew D. Adler and Eric A. Posner, Implementing Cost-Benefit Analysis When 

97. 

98. 

99. 

Douglas Lichtman, Property Rights in Emerging Platform Technologies (April 
2000)  
Cass R. Sunstein and Edna Ullmann-Margalit, Solidarity in Consumption (May 
2000) 
David A. Weisbach, An Economic Analysis of Anti-Tax Avoidance Laws (May 
2000)  

100.  Cass R. Sunstein, Human Behavior and the Law of Work (June 2000)  
101.  William M. Landes and Richard A. Posner, Harmless Error (June 2000) 
102.  Robert H. Frank and Cass R. Sunstein, Cost-Benefit Analysis and Relative 

Position (August 2000)  
Eric A. Posner, Law and the Emotions (September 2000)  
103. 
104.  Cass R. Sunstein, Cost-Benefit Default Principles (October 2000)  
105. 

Jack Goldsmith and Alan Sykes,  The Dormant Commerce Clause and the 
Internet (November 2000) 

106.  Richard A. Posner, Antitrust in the New Economy (November 2000) 
107.  Douglas Lichtman, Scott Baker, and Kate Kraus, Strategic Disclosure in the Patent 

108. 

System (November 2000) 
Jack L. Goldsmith and Eric A. Posner, Moral and Legal Rhetoric in International 
Relations:  A Rational Choice Perspective (November 2000) 

109.  William Meadow and Cass R. Sunstein, Statistics, Not Experts (December 2000) 
110. 
111. 

Saul Levmore, Conjunction and Aggregation (December 2000) 
Saul Levmore, Puzzling Stock Options and Compensation Norms (December 
2000) 

112.  Richard A. Epstein and Alan O. Sykes, The Assault on Managed Care:  Vicarious 
Liability, Class Actions and the Patient=s Bill of Rights (December 2000) 
113.  William M. Landes, Copyright, Borrowed Images and Appropriation Art:  An 

Economic Approach (December 2000) 

114.  Cass R. Sunstein, Switching the Default Rule (January 2001) 
115.  George G. Triantis, Financial Contract Design in the World of Venture Capital 

(January 2001) 
Jack Goldsmith, Statutory Foreign Affairs Preemption (February 2001) 

116. 
117.  Richard Hynes and Eric A. Posner, The Law and Economics of Consumer 

Finance (February 2001) 

118.  Cass R. Sunstein, Academic Fads and Fashions (with Special Reference to Law) 

119. 

(March 2001) 
Eric A. Posner, Controlling Agencies with Cost-Benefit Analysis:  A Positive 
Political Theory Perspective (April 2001) 

120.  Douglas G. Baird, Does Bogart Still Get Scale?  Rights of Publicity in the Digital 

Age (April 2001) 

121.  Douglas G. Baird and Robert K. Rasmussen, Control Rights, Priority Rights and 
the Conceptual Foundations of Corporate Reorganization (April 2001) 

122.  David A. Weisbach, Ten Truths about Tax Shelters (May 2001) 

123.  William M. Landes, What Has the Visual Arts Rights Act of 1990 Accomplished? 

124.  Cass R. Sunstein, Social and Economic Rights?  Lessons from South Africa (May 

125.  Christopher Avery, Christine Jolls, Richard A. Posner, and Alvin E. Roth, The 

Market for Federal Judicial Law Clerks (June 2001)   

126.  Douglas G. Baird and Edward R. Morrison, Bankruptcy Decision Making (June 

(May 2001) 

2001) 

2001) 

127.  Cass R. Sunstein, Regulating Risks after ATA (June 2001) 
128.    Cass R. Sunstein, The Laws of Fear (June 2001) 
129.  Richard A. Epstein, In and Out of Public Solution:  The Hidden Perils of Property 

Transfer (July 2001) 

130.  Randal C. Picker, Pursuing a Remedy in Microsoft:  The Declining Need for 

Centralized Coordination in a Networked World (July 2001) 

131.    Cass R. Sunstein, Daniel Kahneman, David Schkade, and Ilana Ritov, Predictably 

132. 
133. 

Incoherent Judgments (July 2001) 
Eric A. Posner, Courts Should Not Enforce Government Contracts (August 2001) 
Lisa Bernstein, Private Commercial Law in the Cotton Industry:  Creating 
Cooperation through Rules, Norms, and Institutions (August 2001) 

134.  Richard A. Epstein, The Allocation of the Commons:Parking and Stopping on the 

Commons (August 2001) 

135.  Cass R. Sunstein, The Arithmetic of Arsenic (September 2001) 
136. 

Eric A. Posner, Richard Hynes, and Anup Malani, The Political Economy of 
Property Exemption Laws (September 2001) 
Eric A. Posner and George G. Triantis, Covenants Not to Compete from an 
Incomplete Contracts Perspective (September 2001) 

137. 

138.  Cass R. Sunstein, Probability Neglect:  Emptions, Worst Cases, and Law 

(November 2001) 

139.  Randall S. Kroszner and Philip E. Strahan, Throwing Good Money after Bad? 
Board Connections and Conflicts in Bank Lending (December 2001) 
140.  Alan O. Sykes, TRIPs, Pharmaceuticals, Developing Countries, and the Doha 

 

141. 

ASolution@ (February 2002) 
Edna Ullmann-Margalit and Cass R. Sunstein, Inequality and Indignation 
(February 2002) 

142.  Daniel N. Shaviro and David A. Weisbach, The Fifth Circuit Gets It Wrong in 

Compaq v. Commissioner (February 2002) (Published in Tax Notes, January 28, 
2002) 

143.  Warren F. Schwartz and Alan O. Sykes, The Economic Structure of Renegotiation 

and Dispute Resolution in the WTO/GATT System (March 2002, forthcoming 
Journal of Legal Studies 2002) 

144.  Richard A. Epstein, HIPAA on Privacy:  Its Unintended and Intended 

Consequences (March 2002, forthcoming Cato Journal, summer 2002) 

145.  David A. Weisbach, Thinking Ouside the Little Boxes (March 2002, forthcoming 

146. 

Texas Law Review) 
Eric A. Posner, Economic Analysis of Contract Law after Three Decades:  Success 
or Failure (March 2002) 

147.  Randal C. Picker, Copyright as Entry Policy:  The Case of Digital Distribution 

(April 2002, forthcoming The Antitrust Bulletin) 

148.  David A. Weisbach, Taxes and Torts in the Redistribution of Income (April 2002, 

Coase Lecture February 2002) 

149.  Cass R. Sunstein, Beyond the Precautionary Principle (April 2002, updated 

January 2003) 

 

