Which Risks First?

Cass R. Sunstein

Almost everyone agrees that in controlling risks, the United States does a poor job of setting priorities. Sometimes substantial resources are devoted to controlling small or even de minimis risks. Some serious problems receive little attention. Consider the following chart, showing dramatic disparities in amounts spent per life-year saved note especially the disparities in the environmental context:

Cost-Effectiveness of Selected Regulations
Cost per premature death averted ($ millions 199) Regulation Agency
Unvented Space Heater Ban CPSC
Aircraft Cabin Fire Protection Standard FAA
Auto Passive Restraint/Seat Belt Standards NHTSA
Steering Column Protection Standard NHTSA
Underground Construction Standards OSHA-S
Trihalomethane Drinking Water Standards EPA
Aircraft Seat Cushion Flammability Standard FAA
Alcohol and Drug Control Standards FRA
Auto Fuel-System Integrity Standard NHTSA
Standards for Servicing Auto Wheel Rims OSHA-S
Aircraft Floor Emergency Lighting Standard FAA
Concrete & Masonry Construction Standards OSHA-S
Crane Suspended Personnel Platform Standard OSHA-S
Passive Restraints for Trucks & Buses (Proposed) NHTSA
Side-Impact Standards for Autos (Dynamic) NHTSA
Children's Sleepwear Flammability Ban CPSC
Auto Side Door Support Standards NHTSA
Low Altitude Windshear Equipment & Training Standards FAA
Electrical Equipment Standards (Metal Mines) MSHA
Trenching and Excavation Standards OSHA-S
Traffic Alert and Collision Avoidance (TCAS) Systems FAA
Hazard Communication Standard OSHA-S
Side-Impact Standards for Trucks, Buses, and MPVs (Proposed) NHTSA
Grain Dust Explosion Prevention Standards OSHA-S
Rear Lap/Shoulder Belts for Autos NHTSA
Standards for Radionuclides in Uranium Mines EPA
Benzene NESHAP (Original: Fugitive Emissions) EPA
Ethylene Dibromide Drinking Water Standard EPA
Benzene NESHAP (Revised: Coke Byproducts) EPA
Asbestos Occupational Exposure Limit OSHA-H
Benzene Occupational Exposure Limit OSHA-H
Electrical Equipment Standards (Coal Mines) MSHA
Arsenic Emission Standards for Glass Plants EPA
Ethylene Oxide Occupational Exposure Limit OSHA-H
Arsenic/Copper NESHAP EPA
Hazardous Waste Listing for Petroleum Refining Sludge EPA
Cover/Move Uranium Mill Tailings (Inactive Sites) EPA
Benzene NESHAP (Revised: Transfer Operations) EPA
Cover/Move Uranium Mill Tailings (Active Sites) EPA
Acrylonitrile Occupational Exposure Limit OSHA-H
Coke Ovens Occupational Exposure Limit OSHA-H
Lockout/Tagout OSHA-S
Asbestos Occupational Exposure Limit OSHA-H
Arsenic Occupational Exposure Limit OSHA-H
Asbestos Ban EPA
Diethylstilbestrol (DES) Cattlefeed Ban FDA
Benzene NESHAP (Revised: Waste Operations) EPA
1,2 Dichloropropane Drinking Water Standard EPA
Hazardous Waste Land Disposal Ban (1st 3rd) EPA
Municipal Solid Waste Landfill Standards (Proposed) EPA
Formaldehyde Occupational Exposure Limit OSHA-H
Atrazine/Alachlor Drinking Water Standard EPA
Hazardous Waste Listing for Wood-Preserving Chemicals EPA

We should not read this evidence for more than it is worth. There is considerable uncertainty in the numbers. Environmental protection has many purposes in addition to the protection of human life, including prevention of adverse health effects short of mortality, aesthetic goals, recreational goals, and prevention of deaths and adverse health effects in animals and plants. These purposes should also be taken into account in deciding which risks are most serious. But we know enough to approve of the general consensus that better priority setting is a crucial task for the modern regulatory state. A recent study suggests that better allocations of existing expenditures could save an additional 60,000 lives at no increased cost, and that with better allocations, we could save the same number of lives we now save with $31 billion in annual savings.
We might even conclude that selective attention is the principal problem facing modern regulation. Too often government focuses on pieces or sides of a problem, failing to see that what is at work is a complex whole! (It is notable that the science of ecology and the discipline of economics are both fundamentally concerned with this fact.) Too often government fails to see that if it affects (or fails to affect) one aspect of an environmental problem, it will simultaneously affect other aspects as well, probably involving prices, employment, poverty, international trade, and other environmental problems. It is selective attention that, for example, produces the pervasive phenomenon of risk regulation that actually increases (some, or aggregate) risks. And it is selective attention that produces regulations that reduce certain environmental harms but in the process create a range of new and sometimes serious social problems. The problem of selective attention is aggravated by the role of the media, which quite generally focuses on sensationalistic pieces of problems, and by the role of powerful private groups, which can attempt to promote risk redistribution rather than risk reduction.
On all this there is general and growing agreement. There is, however, no similar consensus on what better priority-setting would specifically entail. If a government not suffering from selective attention attempts to address the worst risks first, what precisely will it do? Some people suggest that government should engage in priority-setting by consulting the criterion of private willingness to pay. Some people think that the government should try to maximize the number of total lives saved.' If one program would save one hundred lives, and another eighty, the government should (other things being equal) begin with the first program. But other people, referring to pervasive differences between lay and expert evaluations of risk, reject this idea. They say that lay people have more complex, "richer" judgments about which risks are worst and that these judgments should govern regulatory policy. On this view, there is a danger that expert judgments will hide controversial ideas about rationality behind a technocratic smokescreen.
In this Article, I reject both of these views. A basic assumption is that the American constitutional order is a republic, or a deliberative democracy, in which public representatives are not supposed merely to register existing judgments but "to refine and enlarge the public view." If the issue of risk regulation is seen in these terms, representatives should attend to reflective citizen judgments, but they should not treat those judgments uncritically or accept them regardless of the reasons offered on their behalf. Much less should they rely on private willingness to pay, which may reflect unrealistic optimism, ignorance, or confusion. And if we examine the reasons that underlie risk-related judgments, we will conclude that it would be obtuse to say that government should attempt to maximize the number of lives saved, no matter the source and nature of relevant risks. Lives are not fungible with lives it matters a great deal for what purpose and in what context lives are being put in danger. But it would also be odd to rely entirely on lay judgments, which are frequently based on confusion, ignorance, and selective attention. When those judgments are based on misunderstandings of the facts, they should play no role in policy.
I contend that government should attempt a three-step inquiry. First it should try to estimate decently-livable life-years saved, rather than total lives saved. Thus the first step in its analysis should be to see how much aggregate extension of decently-livable years can be brought about by different regulatory initiatives. The second step should incorporate lay judgments to the extent that these are based on reasonable judgments of value rather than factual error or selective attention. In this way, regulators should ask if regulatory priorities should be shifted from the aggregate measure by exploring whether there are important qualities in the context that call for a shift. The key questions here are:
-Is the risk inequitably distributed?
-Is it especially dreaded?
-Is it run involuntarily?
-How easily can it be controlled by those exposed?
Answers to these questions may call for an adjustment of the first-stage judgment. As we will see, however, the second two questions raise complex issues, for risks are not "voluntary or not" or "uncontrollable or not," but instead come with small or high costs of avoidance. The ordinary criterion of decently-livable life-years should be adjusted upward when the costs of risk avoidance are especially high, and adjusted downward when the costs of risk avoidance are especially low. The third step consists of an incorporation of effects short of mortality, including (but not limited to) morbidity, adverse effects on aesthetics and recreation, and mortality effects for plants and animals.
The discussion of defects in ordinary judgments about risk-unrealistic optimism, heuristics that produce error, and so forth-leads to a degree of skepticism about the criterion of "private willingness to pay," and I offer a few words against the economists' conventional approach. I also discuss institutional arrangements that might help both to ensure that government attacks the worst risks first and to ensure that technocratic and democratic goals are simultaneously promoted by government regulation.

I. PROBLEMS WITH WILLINGNESS TO PAY

Many economists attempt to respond to the question of how to engage in sensible priority-setting through the criterion of private willingness to pay ("W P"). There are several advantages to resolving environmental questions via this criterion. For one thing, WTP provides simultaneous information on costs and benefits. This is important because an emphasis on decently-livable life-years looks at the benefit side without looking at costs. To know how to proceed, it is of course important to know both. For another thing, WTP appears to have democratic virtues, since it allows risk regulation to be made by consulting actual public judgments. And there can be little doubt that use of WTP would produce more coherence and rationality than the crazy-quilt pattern we now observe.
Nonetheless, there are three serious problems with proceeding in this way. The first problem is that private willingness to pay may well reflect factual errors, and factual errors should not be a basis for regulatory policy. The second problem is that the available methods for measuring willingness to pay - contingent valuation methods and revealed preference methods - have serious defects. The third problem is that willingness to pay reflects a category mistake it sees government as a kind of "maximizing machine," attempting to aggregate private preferences. Although much can be gained by consulting private preferences, this is a misconception of government's duties.
The first problem - reflection of factual errors - is the simplest. People may be willing to pay a great deal to live far from a nuclear power plant but by itself, this fact does not mean that government should devote a great deal of money to ensure that nuclear power plants are located far from people. By contrast, people may not be willing to pay much to reduce risks from particulate matter but if particulate matter is a serious contributor to respiratory problems and asthma, the low willingness to pay should not be used for purposes of policy. As we will see, ordinary people frequently lack or misunderstand relevant information and rely on heuristics that produce large-scale mistakes. Those mistakes should not be incorporated into law.
Perhaps willingness to pay can be based not on factual judgments but on something more abstract, such as the willingness to pay for a statistical life if so, the factual errors need not be incorporated, and we can rely on the basic criterion. Certainly this idea would produce improvements upon the haphazard and irrational status quo. But it too raises serious problems. There is the initial problem of deciding between willingness to pay (how much a person would pay for environmental improvement) and willingness to accept (how much a person would have to be paid to permit environmental deterioration) the relevant numbers may be substantially different, and it will be necessary to choose between them. This may not be a fundamental objection perhaps the two numbers can set ceilings and floors, and that itself may be an advance. But many regulatory goods are not traded on markets, and hence "contingent valuation" methods must be used. Rather than looking at actual choices, these methods ask people hypothetical questions about how much they would be willing to pay to avoid certain harms or conditions. The most advanced methods involve lengthy interview sessions designed to provide information, give a sense of context, and allow discussion in a way that fosters deliberative results.
Much recent work with contingent valuation techniques has sought to elicit values for different states of health. In such studies, for example, people purport to be willing to pay a much greater amount to avert cancer deaths (from $1.5 million to $9.5 million) than unforeseen instant deaths (from $1 million to $5 million). More generally, this work generates tables like the following:

Mortality Values by Cause of Death
Cause of Death Value Estimates in million $ per statistical life
Unforeseen Instant Death Asthma/Bronchitis Heart Disease Emphysema Lung Cancer 

Similarly, these survey techniques purport to show that people value days of illness - from coughing spells, headaches, nausea, sinus congestion, and so forth - in diverse amounts.
Despite their apparent promise, contingent valuation methods have serious limitations. For one thing, it is difficult to believe that people answering hypothetical questions can assign meaningful dollar values to various possible health or other risks. The more context-sensitive the method attempts to become, the more its hypothetical nature becomes problematic, bordering on the fantastic. The leading practitioners of contingent valuation purport to discover that people are willing to pay $90 to have a day of relief from angina if they have had it for only one day, but $288 for ten days of relief if they have had angina for twenty days. It is hard to take these figures seriously. In economic terms, people have a difficult time assigning hypothetical dollar values to bundles of commodities they virtually never confront in everyday experience.
Moreover, the results of contingent valuation studies suggest that the answers do not show actual valuation of relevant commodities. A special problem is that of "indifference to quantity," reflected in the astonishing and devastating fact that people will give the same dollar number to save 2000, 20,000, and 200,000 birds - or the same number to save one, two, or three wilderness areas." Relatedly, the valuation of a resource is much affected by whether it is offered alone or with other goods. Willingness to pay for spotted owls drops significantly when people are asked to value the owl with and in comparison to other species. This evidence suggests that people may be purchasing moral satisfaction rather than stating their real valuation. It is pertinent in this connection that the order and number of questions seems crucial in determining valuation. When asked for their willingness to pay to preserve visibility in the Grand Canyon, people offer a number five times higher when this is the first question than when it is the third question.
Would it be better to look at actual choices and thus to rely on revealed preferences? Some imaginative and provocative approaches attempt to determine the "value of life" by assessing willingness to pay for risk reductions. The Office of Management and Budget has explicitly supported the willingness-to-pay criterion on the ground that it provides "an aggregate measure of what individuals are willing to forgo so as to enjoy a particular benefit." This approach appears to be prevalent in the agencies, where it results in a number of between $1 million and $8 million per life saved.
But there are several problems with willingness-to-pay approaches based on actual market transactions. As noted, market behavior may reflect a lack of information about risks or cognitive problems and motivational influences that lead to inaccurate judgments about the facts. To be sure, workers are sometimes informed of risk levels and they can demand a risk premium but to say the least, full information about workplace risks is rare, especially in light of the fact that some risks depend on complex causal mechanisms and take many years to come to fruition. There are possible motivational distortions as well. Wishful thinking and the desire to reduce cognitive dissonance - by thinking that you are not, in your daily work, exposing yourself to some cancer risk - may lead people to see risks as lower than they really are.
It is notable in this connection that people appear to be "risk optimists." They typically believe that they are less likely than other people to fall prey to social dangers. Thus the vast majority of drivers believe that they drive more safely than most drivers thus most homosexuals believe that they are less likely than others to get AIDS thus with respect to most hazards, people believe that they are at lower risk than the mean. I discuss this point in more detail below.
Finally, willingness to pay measures ignore the distinction between the valuations people express in private, market transactions and those that they express in democratic arenas. What people are prepared to pay as private consumers is often, and appropriately, different from what they think society (and they, as members of society) ought to pay to avoid certain risks. Much empirical evidence confirms this point for example, "people were, in fact, found on average to bid more for an improvement for everyone in the United States than for just themselves." Judgments made in the context of democratic choice are designed to elicit different motivations and different considerations from those made in market transactions. Through exchange of different perspectives, collective decision making, and social-regarding reasoning, democratic arenas produce distinctive valuations. Partly this is a product of social norms partly it is a product of the fact that in the democratic setting, people are aware of the fact that whatever they are doing, they are doing it together.
There is a further point, having to do with the phenomenon of "adaptive preferences." People may well adapt their conduct and even their desires to what has been available. Consider here the story of the fox and the sour grapes. The fox does not want the grapes because he considers them to be sour but his belief to this effect is based on the fact that the grapes are unavailable. It is therefore hard to justify their unavailability by reference to his preferences. In the environmental context, it might be hypothesized that the preference for environmental quality will be especially weak among people who have not been exposed to pristine areas, clean water, and clean air. If the point is right, it has important implications for positive and normative work.
Akerlof and Dickens have argued that workers are unwilling to confront the real magnitude of environmental risks faced in the workplace, because it is too distressing for them to do so. On this view, workers, having adapted their preferences and beliefs to a relatively risky status quo, attempt to reduce cognitive dissonance by concluding that the dangers are trivial. The claim is speculative and the relevant evidence is largely anecdotal. But there is some empirical support for the general view. Consider the fact that after the Three Mile Island nuclear power plant accident, it was the people who lived on Three Mile Island who, of all those polled, believed that the relevant risks were lowest.
If the general claim is right, it would follow that the demand for environmental legislation might be relatively low among people deprived of exposure to environmental quality, and this phenomenon would be attributable to adaptation of preferences to what is available. It is extremely difficult to test this hypothesis against more 'conventional alternatives stressing learning and rational choice under conditions of deprivation. We might, however, begin to investigate the demand for environmental protection across regions and across nations. It would be especially valuable to see how the demand for environmental quality changes over time, perhaps with exposure to pristine areas, perhaps with a social belief that the degradation of environmental amenities is not inevitable, perhaps with the rise of organizations solving collective action problems of various sorts.
As a normative matter, it might also follow that existing preferences, as expressed in consumption choices, are an uncertain basis for regulatory policy, since we cannot without circularity justify regulatory outcomes by reference to preferences that those outcomes have generated. Of course, it is right to insist that government should usually respect private choices, partly because of the frustration and resentment that are produced by efforts to bring about change, partly because of the constant risk of ignorance and bias on government's part. But if what I have said here is true, it will be necessary to rethink the underanalyzed and vexing issue of paternalism, in environmental law and elsewhere.

II. LIVES AND DECENTLY-LIVABLE LIFE YEARS

Let us put willingness to pay to one side and ask what government should attempt to maximize in regulating risks. This is a question of great theoretical interest but it also has considerable practical importance. Any answer should meet two constraints. First, it should be acceptable from the theoretical point of view. Second, it should be administrable, that is, it should be something that real-world officials can actually use. The two constraints are mutually checking. A theoretically excellent answer might be rejected because it is too complex or unwieldy, or because it imposes unrealistic informational demands on government. (Some forms of cost-benefit analysis, unaccompanied by constraints on what count as costs and benefits, run afoul of this objection.) A practically useful answer might be indefensible from the standpoint of theory.
In recent years, many observers and some regulators, seeking a practical answer to the question what they should maximize, have focused on numbers of lives saved They decide which risks to regulate first by exploring the aggregate number of lives at risk. Thus many agencies attempt to specify that number in the course of making regulatory choices. In the environmental context, this is a promising start. A program that saves one hundred lives seems better than a program that saves two lives. (Of course to get a full picture, we must add gains in terms of morbidity, aesthetics, recreational opportunities, and tourism as well.) If this is our standard, much progress might be made by attending to the number of lives in danger from various "preventable" risks:

Deaths from Preventable Risks in the U.S.
Risk Percent of Total Total Deaths Range Total Deaths Per Year
Tobacco Diet/Activity Alcohol Microbial Toxic Agents Firearms Sexual Behavior Motor Vehicles Illicit Drugs 

There is considerable crudeness, however, in the idea of "lives saved" as the. regulatory maximand. Of course no program "saves lives" at best it extends them. Compare two regulations. The first extends the lives of one hundred elderly people, but in doing so, it gives them five additional years, accompanied by considerable pain and distress. The second extends the lives of eighty children, and in doing so, it gives each of them a statistical likelihood of fifty or more years of life. The second policy seems preferable to the first along two important dimensions. First: Lives are certainly not fungible, but where regulatory resources are limited and where choices have to be made, it makes sense (other things being equal and as an administrable start) to save as many years as possible. Other things being equal, many years should be chosen over few. Second: If government has a choice between preserving lives in a way that ensures decently-livable years and preserving lives in a way that ensures a barely functional and extremely painful continued existence, it should choose the former. To someone who has a choice between death and five years of constant and considerable pain, the latter will probably seem a lot better but for government regulators, it is preferable to provide five good years rather than five difficult ones if there is a choice. We might conclude, then, that government agencies should shift their attention from "lives saved" to "decently-livable life-years saved."
Notably, the idea of decently-livable life-years is designed to set a floor, not to give some numerical amount to each such year in terms of its overall "quality." The floor might be defined in various ways I understand it to refer to basic functional capacity. Thus someone who has chronic asthma certainly can live a decently-livable life. Someone who is confined to a hospital cannot. It is easy to imagine borderline cases, and perhaps the floor should be moved up or down, but the notion should have a degree of simplicity and should allow administrators to put to one side some of the harder questions. It is a modest variation on the idea of life-years saved it subtracts from that amount the number of years saved that, because of some independent condition, are not decently-livable.
Along this dimension, the idea of decently-livable life-years is far simpler than its close cousin: quality-adjusted life-years. Its simplicity is in some ways a vice but also one of its virtues instead of adjusting life-years for quality, every life-year above a certain floor counts for no less and no more than one. Of course scientific information currently leaves doubts about how many life-years are at risk, and frequently the best that can be done is to specify a range. But this very point suggests that decently-livable life-years has another advantage over quality-adjusted life-years: it imposes a less severe cognitive demand on government. Specification of the "quality" of lives aided by regulation can be an extremely demanding task.
In addition to simplicity, the idea of decently-livable life-years has the advantage that it is less contentious, and properly so. It is controversial to suggest that people with a chronic problem (respiratory difficulties, for example) deserve less in the way of regulatory help than people without such a problem. To devote resources to those who are suffering no difficulties, at the expense of those who, while functional, have a health problem, is to raise hard questions of equity. It is far less controversial to say that the government will treat everyone above a certain floor the same. A shift from lives saved to life-years saved makes a good deal of sense and has a degree of simplicity but the notion of decently-livable life-years raises many questions. This is not a purely statistical inquiry it has evaluative dimensions. The best way to handle the resulting problems is to recognize that a judgment of policy is being made and to ensure that that judgment is made by people who are subject to appropriate constraints, informed about relevant facts, and politically accountable.
An especially controversial issue lurks in the background: it is possible that some lives might be considered not decently-livable because of unjust or highly disadvantageous social conditions. Desperately poor people, for example, may lack decent life prospects already, and a small incremental reduction in their health may seem to push them below the relevant "floor." For purposes of regulatory policy, this ought not to be counted. If it did count, regulatory policy would be devoted to the protection of those already well-off and to the neglect of those in desperate conditions thus one social injustice would be compounded by another. The question is whether the saved years meet a decent floor, and it should be stipulated that this criterion is met by lives filled with extreme difficulty because of social and economic deprivation alone.

III. WHAT SHOULD NOT COUNT

Social psychologists have uncovered a number of distinctive characteristics of ordinary human judgments about risks. Much of the remainder of this paper will be focused on those characteristics and on their role in regulatory policy. How, if at all, should the basic criterion of decently-livable life-years saved be qualified? Consider, for example, the following table, showing differences between expert and lay judgments about which risks are most serious:

Public EPA Experts 
Hazardous waste sites Medium-to-low
Exposure to worksite chemicals High
Industrial pollution of waterways Low
Nuclear accident radiation Not ranked
Radioactive waste Not ranked
Chemical leaks from underground storage tanks Medium-to-low
Pesticides High
Pollution from industrial accidents Medium-to-low
Water pollution from farm runoff Medium
Tap water contamination High
Industrial air pollution High
Ozone layer destruction High
Coastal water contamination Low
Sewage-plant water pollution Medium-to-low
Vehicle exhaust High
Oil spills Medium-to-low
Acid rain High
Water pollution from urban runoff Medium
Damaged wetlands Low
Genetic alteration Low
nonhazardous waste sites Medium-to-low
Greenhouse effect Low
Indoor air pollution High
xray radiation Not ranked
Indoor radon High
Microwave oven radiation Not ranked

In this section, I discuss judgments that should not, in my view, play a role in government regulation. The most general conclusion is simple: Ordinary judgments should not be controlling when they are based on factual errors. When human judgments depend on heuristics or "frames" that produce mistakes, regulators should not rely on them. But some of these judgments are not easy to characterize, and they raise some questions about the nature of rationality (from the normative point of view) in this context.

A. Invidious Judgments

It is predictable that some people will find risks of special concern when they disproportionately affect white people or heterosexuals risks that affect blacks and homosexuals may well be undervalued. Here, there is a judgment that distributional considerations properly enter into the calculus, and that some risks, because of their distribution, are properly neglected. As we will see, distributional decisions can play an appropriate role in regulatory policy. But where the relevant judgments are invidious, they do not belong. Of course, we can enter into reasonable debates about how to evaluate some judgments. The easiest cases involve a constitutional prohibition on distributional judgments, as for example in the prohibition on measures motivated by prejudice grounded in gender and race. But government might reasonably decide that certain judgments are unacceptable even if they are not unconstitutional.

B. Misunderstandings of Facts and the Role of Heuristics

People frequently misstate probabilities. If people are asked to rank various risks in terms of severity, they may well make factual blunders. Some of their judgments about "severity" undoubtedly turn on judgments about value." But it is safe to say that factual mistakes are often at work.

1. Self-serving bias, unrealistic optimism, and overconfidence.

People tend to think that risks are more likely to materialize for others. Thus, there is systematic overconfidence in risk judgments, as the vast majority of people believe that they are less likely than other people to be subject to automobile accidents, infection from AIDS, heart attacks, asthma, and many other health risks. In one survey, for example, 90 percent of automobile drivers considered themselves to be above-average drivers. In another survey, students asked to envision their future said that they were far less likely than their classmates to be fired from a job, to have a heart attack or to get cancer, to be divorced after a few years of marriage, or to have a drinking problem.
Reflecting illusions about their own practices, gay men appear systematically to. underestimate the chance that they will get AIDS, even though they do not lack information about AIDS risks in general. Older people similarly underestimate the likelihood that they will be in a car accident or contract major diseases. Unrealistic optimism appears to characterize people in most social categories." People systematically underestimate the extent to which they are at risk, and perceptions of relative invulnerability affect preventive health practices." Consider, for example, the following table, based on a random community-wide survey of attitudes toward health risks a number below 0 suggests a belief in above-average immunity from the relevant risk:

Comparative Risk Judgments for Health Problems and Other Hazards
Hazard Description Mean SD
Drug Addiction Drinking (alcohol) problem Attempting Suicide Asthma Poison Ivy rash Sunstroke Nervous breakdown Homicide victim Gallstone Deaf Pneumonia Lung Cancer Skin Cancer Cold Sores Senile Laryngitis Gum Disease Tooth decay Insomnia Ulcer Mugging Victim Diabetes Overweight 30 or more pounds Influenza (flu) Stroke Serious auto injury Heart attack Arthritis Falling and breaking a bone High blood pressure Cancer

Evidence of this kind much complicates the view that people often overstate low-probability events. It is true that people may think that low probability events have higher probability than they in fact do. But many individual agents think that they are peculiarly less susceptible to such events, which may mean that they err in the other direction.

2. Availability.

People tend to think that risks are more serious when an incident is readily called to mind or "available." If pervasive, the availability heuristic will produce systematic errors. Assessments of risk will be pervasively biased, in the sense that people will think that some risks (of a nuclear accident, for example) are high, whereas others (of a stroke, for example) are relatively low.

3. Anchoring.

Often people make probability judgments on the basis of an initial value, or "anchor," for which they make insufficient adjustments. The initial value may have an arbitrary or irrational source. When this is so, the probability assessment may go badly wrong. Thus, for example, people may think that the probability of getting AIDS is very low, or very high, and the anchor may not be readily revised.

4. Representativeness.

Judgments about probability are in large part judgments about whether some process A will bring about some event B. Under what circumstances will driving produce significant increases in air pollution or fatal accidents? When will airbags produce risks to children? Do disposable diapers cause pollution problems? In answering such questions, people ask about the extent to which A is representative of B in the sense that it resembles B. People tend to be insensitive to the sample size, to misunderstand the phenomenon of regression to the mean, to have excessive confidence in their own judgments, and to misunderstand the effect on probability of base-rate frequency." As result, people may systematically misunderstand risk levels.

5. "No comparison" conditions.

People have a hard time understanding and evaluating risks that they view in isolation from other risks. Problems emerge when a risk is taken to be much larger than it is, simply by virtue of the fact that it is not placed in context with other risks and events. Sometimes individual judgments, and even social. policies, may emerge because of this effect.

C. Probability-Related "Tastes"

Here we are dealing not with factual errors, but with "tastes" or preferences that lead people to favor certain approaches to risk. Probability-related tastes present harder questions for the policy analyst.

1. "All or nothing."

People greatly prefer the elimination of a risk over the diminution of a risk, even when the aggregate reduction is the same. Thus it appears that people would much rather see a risk of .001 reduced to zero than a risk of .002 reduced to .001. It is not clear whether this preference should be characterized as irrational. Perhaps people receive a great deal of peace of mind from an eliminated risk, and a risk of reduced probability still creates residual fear. Thus, people's judgments track their own understandings of their tastes. But for government regulators, this kind of taste should play little role in policy. It is rare for risks to be present or absent there are only different levels of risk. Levels of air pollution are not either safe or not safe they are more or less safe. This simple idea seems to be poorly understood by the public. Thus, the Clean Air Act speaks in terms of ensuring safe levels of air quality, a highly misleading way to set up the problem. The question is not whether air quality is or is not safe the question is whether it is sufficiently safe in light of all relevant variables. Even if people want the government to ensure safe levels of air quality because of "all or nothing" thinking, officials should focus on the right question, not the wrong one.

2. Ambiguity aversion.

A closely related "taste" is the avoidance of ambiguity. At least when they lack relevant knowledge, and know that they do, people prefer situations of uncertainty (defined as those in which probabilities can be assigned to outcomes) over situations of risk (defined as those in which probabilities cannot be assigned). Thus people are averse to situations of uncertain probability and try to avoid choices that place them in such situations. Often risk regulation is, of course, undertaken when probabilities cannot be assigned. If people are averse to ambiguities, they may produce an incoherent pattern of regulation, perhaps based on an illusory perception, related to all-or-nothing judgments, that some things are "safe" and others are "dangerous."

3. Status quo bias.

People evaluate situations largely in accordance with their relation to a reference point gains and losses from the reference point are crucial. An ordinary reference is the status quo, which produces status quo bias. The most dramatic example is loss aversion, in accordance with which people are made more unhappy by losses than they are made happy by equivalent gains. People would require a great deal to allow someone to subject them to a new risk they would pay a great deal less to prevent someone from subjecting them to an existing risk.
Should government indulge status quo bias, that is, should it impose special barriers to new risks, and be less concerned about old risks? In view of the dramatic number of existing and new risks and the ever-changing nature of any particular status quo, it is far from clear that it should. I take up this question in more detail below.

4. Selective fatalism.

Some risks produce a great deal of concern and disturbance regardless of their level some risks appear as "background noise" and do not create much concern even if their magnitude is high. Human beings are, in short, selectively fatalistic. We lack an account of why people adapt themselves to certain risks but not others undoubtedly the novelty of the risk matters, and people sometimes adapt themselves to risks that they cannot control. But it is hardly clear that policymakers should follow a selectively fatalistic population perhaps people are fatalistic about risks that are large and easily diminished, and perhaps they are the opposite of h  risks that are small and controllable only at high cost. What matters is the source of their fatalism. The most that might be said is that regulators should consider whether a risk comes with low or high costs of adaptation.

D. Summary

We may summarize this discussion of heuristics and judgments about their relevance in the following way:

Availability Representativeness Anchoring "All or Nothing" Unrealistic Optimism Isolation Effects Ambiguity Aversion Status Quo Bias Selective Fatalism

IV. WHAT SHOULD COUNT

Thus far I have been focusing on heuristic devices and other cognitive processes that lead people to misassess risks. Social psychologists have spent a great deal of time discussing these devices and processes. My basic claim has been that government should be aware of these tendencies to make factual errors and should be on guard against them.
Social psychologists have also, however, uncovered a quite different source of variation between lay and expert judgments of risk. In brief: Experts tend to focus on aggregate lives at stake. Ordinary people - on the now-conventional account - look at a range of more qualitative variables. They care not simply about number of lives at risk but also about whether the risk is equitably distributed, potentially catastrophic, controllable, voluntarily incurred, and so forth. Here is a compilation:

Influencing Factor Aggravating Mitigating
familiarity new old
personal control uncontrollable controllable
voluntariness involuntary voluntary
media attention focussed on by media ignored by media
equity unfairly distributed equitable distribution
children children at special risk children not at risk
future generations at risk not at risk
reversibility irreversible reversible
dreadedness especially dreaded not especially dreaded
identifiability of victims victims known victims not identifiable
accompanying benefits benefits clear benefits not visible
human or natural origin human origin created by nature
trust in applicable institutions lack of trust good deal of trust
timing of effects effects delayed effects immediate
understanding mechanisms or process not understood mechanism or process understood
past history major or minor accidents no past accidents

Which, if any, of these factors should play a role in regulatory policy? For simple democratic reasons, it might seem tempting to say that all of them should. But this would be a mistake. Sometimes it is hard to separate them from heuristics and factual errors media attention, for example, is closely connected with the availability heuristic, and we should not think that because the media are focused on a certain risk, government should gave that risk special attention too. (In fact, this is a pathology of regulatory policy.) Past history should be similarly understood it is a rough proxy for future probability, not a reliable guide to the future. So too with trust. If people do not trust an institution's assurances, they are thinking that the risk is more serious than they are being told. Some of these factors may be a result of framing effects or of a process of selective attention. And some of them are easily accounted under the "life-years saved" criterion. If children and future generations are at risk, for example, more life-years are at stake.
There is, moreover, a puzzle in the fact that people treat as quite serious death-risks that are microscopically small as a statistical matter, while risks that are statistically much larger are treated as "just a part of life." It is certainly possible that people's judgments about risk severity are partly a product of some of the more qualitative considerations listed above this idea leads to the widespread view that ordinary people have a "richer" rationality than do experts, since ordinary people look at the nature and causes of death, not simply at aggregate deaths at issue. But as Howard Margolis has shown, it is also possible that an apparently "rich" judgment that a certain risk is severe, or not severe, depends not on well-considered judgments of value, but instead on the absence of ordinary contextual cues, on heuristic devices that are not well-adapted to the particular context, or instead on a range of confusing or confused ideas that people cannot fully articulate. When people say, for example, that the risk of nuclear power is very serious, they may be responding to their intense visceral concern, possibly based on (uninformed) statistical judgments about likely lives at risk, and on their failure to see that that risk comes accompanied by a range of social benefits. The fact that nuclear power produces benefits as well as risks may not "register" on the viewscreen, and this may help produce a "high risk" judgment." And when people are asked what underlies that judgment, they may point to qualitative considerations that operate as after-the-fact explanations for the visceral concern, and that are not causes of that concern.
For automobile accidents, by contrast, people's uninformed statistical judgment may not lead to overestimates of risk or visceral judgments of intense concern, partly because people are well aware that automobile travel produces high benefits as well as costs. Thus, it is possible that a judgment that a certain risk of death is unusually bad is based on an intuitive balancing that prominently includes perceived lives at stake and the perceived presence of small or no benefits associated with the risk-producing activity. And when people are asked to'say why they believe that some risk is especially bad, their answers may not be truly explanatory, but instead rationalizations of more visceral judgments based on other grounds. In other words, the reasons given may not actually lie behind the judgments people are in fact not very good at giving subjective accounts of what underlies their judgments. All this raises the possibility that people's references to "control" and "involuntariness" may not explain the actual basis of their judgments. This possibility remains to be investigated and tested. For the moment, let us put this possibility to one side and assume that the psychological evidence does suggest that certain risks are perceived as bad very much for more qualitative reasons. The important question is which reasons justify a qualification of the basic criterion of decently-livable life-years. Here are the strongest candidates.

A. Dread

People seem to think that some risks are especially dreaded and that for this reason they deserve special attention. Deaths from cancer and AIDS fall in this category. There is nothing mysterious to this idea it need not be taken to suggest any special conception of rationality. The underlying point is probably that the relevant deaths are especially grueling and hence that there is a kind of "pain and suffering premium" on the relevant death: not merely a life lost, but a period of intense emotional and physical difficulty as well. This period of intense difficulty might produce "costs" for those with the illness and for friends and family members as well. Sudden, unanticipated deaths can  be dreaded too - consider the idea of dying in an airplane crash - but the relevant premium is lower because it lacks the same degree of suffering. The best way to handle this factor is to supplement the criterion of "decently-livable life-years" in such L way as to take account of the pain and suffering associated with certain deaths.

B. Distribution

Some risks are inequitably distributed. They might, for example, be concentrated among poor people or African-Americans, or instead among homosexuals. Consider, for example, the risk of lead paint poisoning suffered by inner city children, or the risk of AIDS faced disproportionately by African-Americans, poor people, and homosexuals. It is fully legitimate for citizens or for elected representatives to think that inequitably distributed risks deserve special attention from government, as a way of counteracting background injustice. If the distributional judgments are not. invidious, it makes sense to defer to democratic judgments on the point. Thus regulators should be permitted to give distributional weights to risks whose distributional incidence is especially troublesome. This point supports special efforts to control environmental risks like asthma, which are concentrated in the inner city, and also to prevent the spread of diseases like breast cancer, whose incidence is concentrated among women.

C. Voluntariness

It is clear that people perceive voluntarily incurred risks as less troublesome than involuntarily incurred risks. Consider, for example, diverse public reactions to airplane crashes and automobile crashes. Or consider the fact that tobacco is by far the largest source of preventable deaths in the United States. Why do we not devote much more of our regulatory effort to smoking? The reason seems to lie in a judgment that smoking is a voluntary activity and hence that the resulting deaths are less troublesome than are other sorts of death.
Many people have suggested that the lay judgment to accord greater weight to "involuntary" risks shows a richer conception of rationality and therefore deserves deference from government. But a simple reference to voluntariness, when taken to suggest something special about "lay rationality," raises many puzzles. Most important: How do we know when risk is voluntarily incurred? "Voluntariness" is not a simple question of fact, and it is not, in the cases we are discussing, an all-or-nothing matter. Consider the fact that airplane crashes are conventionally thought "involuntary" and automobile crashes more "voluntary." Certainly it would be possible to see the risks from air travel as voluntarily run certainly people have a choice about whether to fly, and when they do fly, they pay a certain amount for a certain package, including risks of various sorts. The same is true of automobile safety. The difference between the two risks is hardly so categorical as to justify an assessment that they provide poles of voluntariness and involuntariness. Indeed, it is not clear even what is meant by the suggestion that one is voluntary and the other is not.
To shed more light on the issue, let us consider three classes of cases. First, consider the question whether workers exposed to cancer risks are voluntarily or involuntarily so exposed. If workers do not know about such risks - if they lack relevant information - we seem to have an easy case of involuntariness. Thus it makes sense to say that risks are run involuntarily when the people running them do not know about them. Lack of information provides a legitimate case for a judgment of involuntary exposure to risk. Of course, information itself can be obtained at some cost, pecuniary or otherwise. We are thus dealing, in cases of this kind, with high costs of risk avoidance in the form of high costs of acquiring relevant information.
Second, suppose that people who are exposed to a certain risk are aware of the risk, but are not in a contractual relation with the risk-producer. It is easy to imagine that some victims of pollution are in this position. People in Los Angeles may well know that they face high levels of smog. Are they exposed involuntarily? If we conclude that they are, we may mean that a risk is incurred involuntarily when and in the sense that it is typically very expensive for people to avoid it - and when someone else is the cheapest cost avoider. Consider ordinary people subject to cancer risks from toxic air pollutants. Here a claim that the risk is faced "involuntarily" may mean that those who "run" the risk can reduce it only at very high cost, at least compared with those who "produce" the risk. (The quotation marks are necessary for obvious Coasian reasons.)
But turn now to a third class of cases, involving a wage package or contract that does include compensation for the relevant risks. Assuming that point, we might want to distinguish between two different possibilities. In a case of a high-level scientist, knowledgeable about relevant risks and involved in work that he finds rewarding, we might well conclude that we have a case of voluntariness. (In the same category can be found the case of an astronaut.) But we might not say the same about a low-level worker who does not like his work at all." But what distinguishes the two cases? If knowledge is present, or if the compensation package includes payment for the relevant risk, it is not clear how the two differ. It may be that the reason for running the risk seems in some way better or more worthy in the first case than in the second, but this is not a distinction along the dimension of voluntariness. Thus a judgment that a risk is run "involuntarily" is probably based on 1) a lack of knowledge of the risk, or, more accurately, high costs of obtaining information about the risk, 2) a belief that even if information is present, it would be very costly or difficult for people to avoid the risk, or 3) a belief that the risk is unaccompanied by benefits that people incurring the relevant risks find satisfactorily compensatory in some subjective sense, notwithstanding their belief that the contract is in some sense worth signing. It may seem hard to make sense of the third alternative what might be at work is a judgment that background inequalities are producing the relevant bargain, or a belief that workers are competing to their collective detriment, and an agreement not to compete would be in their best interests.
On this view, the question whether a risk is run voluntarily or not usually is not a categorical one but instead is a question of degree, associated with information, risk-reduction costs, and the existence or absence of accompanying benefits. Of course there are interesting background questions about why and when a risk "codes" as voluntary or involuntary undoubtedly the answer depends a great deal on heuristic devices and selective attention.
We might therefore conclude that whether a risk qualifies as involuntary raises many of the questions raised by the question whether government should regulate the market at all. A risk might be characterized as involuntarily run because affected people lack relevant information because the transaction costs of bargaining are high because the risks should be seen to amount to "externalities" because collective action problems make market outcomes unsatisfactory since, for example, workers are in a prisoner's dilemma best solved through law or because some motivational or cognitive defect makes successful solutions through markets unlikely. These, of course, are among the conventional grounds for regulation in the first instance. When a risk seems voluntary, and not worthy of substantial regulatory resources, the term "voluntary" is serving as a placeholder for an argument that there is no sufficient ground for government action, because the accompanying benefits are high or the risk-reduction costs are low, and because market arrangements take adequate account of these facts.
From this point we should conclude that a lay judgment that a risk is "voluntary" should not be decisive. A better understanding of what factors underlie and support that judgment should be used for purposes of regulatory policy. The basic criterion of decently-livable life-years might, then, be adjusted upward when those at risk lack relevant information or when the costs of risk-avoidance are especially high - or downward when those at risk have the information and when the costs of risk-avoidance are low.

D. Control

People find risks less acceptable if those risks do not seem to be within their control. Automobile accidents may seem less troublesome than airline disasters partly for this reason. People have a sense that they cannot control the latter, which are hence wholly involuntary, whereas they can control the former, which have a voluntary element. But it should be clear from the previous discussion that the question is not whether risks can be controlled, but how expensive it is for individuals to control them. People can control their subjection to airplane-related risks by refusing to fly in planes people can control their subjection to risks from coal-fired power plants by living in areas served by solar energy. The question is not whether a risk can be controlled or not, but at what cost it is controllable, and with what benefits. Individuals tend to "frame" risk control in "all or nothing" terms, depending on the particular temporal event on which they focus. But this is a similar form of selective attention. As with voluntariness, "controllability" is a conclusion more than it is an analytic tool. It is best to look at the factors that account for a judgment that a risk is not controllable.

E. Concluding Notes

I have suggested that many of the "qualitative" factors that underlie lay judgments about risk can be accounted for by the criterion of decently-livable life-years. Some of those factors cannot be incorporated in this way, and this conclusion requires a "stage two" adjustment of the basic criterion. Thus, dreaded risks should be treated differently, because of the problems associated with certain illnesses and deaths. Distributional weights can be given to risks that have disproportionate effects on disadvantaged people. Certain factors underlie lay judgments about voluntariness and control those factors should be specified and also might be given weights. Of course, numerical weights have their limitations and it is important for those assessing risk to be aware of the qualitative factors and judgments that underlie the numbers.

V. AT THE BORDERS

In this section I discuss some borderline cases: factors that may or may not justify a deviation from the basic criterion of decently-livable life-years.

A. Future Generations

Do risks deserve special attention when future generations are at risk? In one sense the answer is certainly yes: When future generations are at risk, more people are at risk. Of course, there are large questions about the appropriate discount rate. But it seems sensible to say that if a risk will be incurred by people not yet born, it deserves greater attention because its degree is to that extent greater. This claim is easily taken care of via the notion of decently-livable life-years.

B. Potentially Catastrophic

Some psychological studies suggest that people think that potentially catastrophic risks deserve special attention. People's fear of nuclear power, for example, might be attributed to an understanding that if things go wrong, things will go very, very wrong. Thus, low probability, high-danger risks might be treated as worse than their "actuarial value." A one-in-a-million risk of 10,000 deaths might seem worth more than a one-in-a-thousand risk of ten deaths, or a one-in-a-hundred risk of one death.
This judgment may depend on a refusal to see that all risks must be evaluated in probabilistic terms and that catastrophicness is simply a matter of degree.' Thus, when a low probability, high-danger risk enters the viewscreen, people may focus on the danger itself, may fail to see the low probability, and may fail as well to see that the risk may provide substantial benefits, including reduction in other risks. The special concern for "catastrophic" risks may actually reflect selective attention rather than reasonable underlying judgments of value. Or the special attention given to potential catastrophes may depend on a refusal to trust the officials who give assurances that the probability is low. If the lack of trust is justified, then the lay judgment deserves respect on the ground that the official statements may be or simply are false. But if we put that point to one side, the difficulty lies in discerning why a small risk of a huge disaster is worse than an actuarially equivalent large risk of a small disaster.

C. New Risks

It seems clear that people are especially hostile to new risks. Old risks tend to be taken for granted. Thus an additional risk of .001 percent may well be treated as more troubling than a removal of a risk of .002 percent. The point is connected with the well-known psychological phenomenon of loss aversion. Losses from the status quo are seen as more bad than (equivalent) gains from the status quo are seen as good.
At least as a general rule, and putting to one side the possibility that new risks may pose especially high costs of adaptation, government should probably refuse to treat new risks as especially troublesome. On reflection it is not at all clear why a new risk of a certain magnitude is worse than an old risk of the same magnitude. Perhaps it could be said that old risks are an inextricable part of a system of benefits and costs that have already been "coded" at the individual level. Thus, the environmental risks associated with coal-fired power plants are something to which people have (more or less) adjusted, and a dramatic switch from coal-fired power plants would force people to give up an energy source to which they are acclimated. The case of automobiles is perhaps the most vivid. But new risks often come with benefits as well, and there is no reason why these should not "code" too. The strongest argument in favor of more severe regulation of new risks would be that people have adjusted to old risks, and hence an old risk/new risk division nicely corresponds to the actual costs associated with adjustment. When this is so, it makes sense to treat new risks more severely. But the degree of the disparity, as described by lay judgments, reflects status quo bias in a way that is hard to defend in pragmatic terms.
The discussion thus far has implications for the positive theory of health and safety regulation. It suggests that some apparently odd patterns (see Table 1) may well reflect differences between lay and expert judgments about risk. In this section, I offer several examples.

A. Dread

We would expect greater resources to be devoted to risks that are especially dreaded. Thus government might well devote more resources to the AIDS crisis and to cancer prevention, partly because these deaths are so dreaded. With AIDS, there is the additional problem that the disease casts a pall over a wide range of sexual acts this would increase the public "demand" for AIDS-related research. Judge Posner has attributed the large amount of resources devoted to such research to interest-group power." But the qualitative nature of risks-producing particularly grim deaths - undoubtedly plays a role in funding decisions.

B. Availability

It is easy to predict that the availability heuristic would help create a kind of crazy-quilt pattern in regulation, with some events calling for stringent regulation and others calling for little or no regulation at all. The regulation would not be closely associated with actual risk levels. This is the pattern we observe. Studies of American government show extraordinary disparities in expenditures per life saved.'
The disparities are plausibly attributed at least in part to the availability heuristic. The dramatic difference between expert and public assessments of risk levels has something to do with this heuristic, and the difference maps closely onto actual differences in expenditures per life saved. The public demand for regulation therefore appears to be a product of the availability heuristic, which is itself endogenous to the nature and levels of public and private publicity. Thus, for example, there are enormous expenditures designed to counteract cancers in the workplace, and relatively low expenditures designed to prevent injuries from automobile accidents. The comparative overregulation of certain environmental risks may well be a product of the fact that those risks, when they come to fruition, are highly publicized. Through this route, too, we might be able to explain the otherwise inexplicably severe controls on nuclear power. We might also be able to explain the extraordinary safety of air travel as compared with other means of transportation.

C. Ambiguity Aversion

If people are averse to ambiguity, we might expect that political outcomes will avoid ambiguity and present risks in "all or nothing" terms. In fact, this is a pervasive phenomenon in environmental statutes, where administrators are entrusted with ensuring a "safe level" rather than with coping pragmatically amidst ambiguities of both fact and value.

D. Status Quo Bias

Samuelson and Zeckhauser have shown that the affinity for the status quo appears to affect such diverse forms of behavior as brand allegiance, choice of insurance plans, changing public policies, marketing techniques, and investment decisions. If this is correct, large consequences follow. We can predict that much governmental behavior in the environmental context will be a product of endowment effects. Private and public reactions to risks should reflect a status quo bias. Both supply and demand will be affected. Government regulation of new risks will predictably be more stringent than government regulation of (equivalent) old risks. This is so precisely because the public: demand for regulation will be a product of status quo bias.
This is in fact what we observe. It is a defining characteristic: of the current system of environmental controls. New risks are regulated far more stringently than old ones, even though this strategy sometimes creates extremely perverse results, by perpetuating the life of the especially severe old risks and thus damaging public health and safety. New stationary sources of air pollution must meet technological requirements not imposed on old sources new cars are regulated far more heavily than old ones. There are many other examples in the area of environmental regulation. Consider, for example, the controversial and probably irrational Prevention of Significant Deterioration ("PSD") program. The PSD program says roughly that states that met national ambient air quality standards in 1977 cannot suffer a deterioration in air quality, even if the air would remain very clean, and even if there are good reasons for allowing new development. The use of the 1977 benchmark seems puzzling and even senseless. There is no clear reason to conclude that the air cannot, become dirtier than it happened to be in 1977, so long as it is consistent with the other national benchmark standards in the Clean Air Act. Of course, there is good reason to ensure that some areas are pristine or have especially clean air. The PSD program is, however, ill-suited to achieving this goal, since the 1977 benchmark is so broad.
How, then, can we explain the existence of the PSD program, which seems hard to justify on public interest grounds? Certainly part of the explanation comes from public choice theory. Representatives in "clear air" states disproportionately opposed the program, and those in "dirty air" states disproportionately supported it, no doubt in order to prevent the exodus of revenue-producing, polluting companies to "clean air" states. 7" But the apparently broad appeal of the PSD program may owe a good deal as well to the endowment effect. The perception that air quality ought at least to stay where it is - that the government should prevent deterioration from the status quo - seems to have widespread appeal. This is so despite the fact that other things being equal, regulatory efforts to make the air cleaner than it now is often face strong political roadblocks. The asymmetry cannot be fully explained on public interest grounds, for prevention of deterioration can be far worse than actual improvements. It probably has a good deal to do with status quo bias and with the initial endowment reflected in air quality at the time the legislation was under consideration.
Or consider one of the most criticized features of the Clean Air and Clean Water Acts, the pervasive requirement that companies adopt the "best available technology" (BAT). This strategy has been challenged on the ground that there is at best an incidental relationship between cost-effective environmental policy and adoption of BAT. In principle, it seems unreasonable to require everyone to adopt the best available technology. Instead, government should allow companies a high degree of flexibility in achieving air quality goals. Some companies should switch to clean energy sources, rather than put expensive technology on dirty energy sources some companies should go out of business because once they pay the environmental costs, their activity is not worthwhile some companies should not use BAT at all, since they do business in regions in which adoption of expensive technology is not sensible in light of the variables at stake.
An interest-group explanation is not entirely implausible for BAT requirements. But the requirements can also be understood as an outgrowth of status quo bias. If the technological status quo is thought to be an appropriate benchmark for legal requirements, its use in environmental law may not be so puzzling. There may be general agreement that the technological status quo is the best and fairest foundation for environmental law, even if this view will not survive critical scrutiny.
It is notable too that it appears very difficult (though not impossible) to bring about even rational environmental regulation through tax increases - on, for example, polluting vehicles or gasoline. "Green taxes" are supported by strong justifications, but they are an almost invisible part of national environmental policy. Perhaps the difficulty can be attributed to the influence of the automobile industry but some leaders in the industry have actually favored gasoline taxes. The difficulty may well be understood in terms of the endowment effect, as that effect operates to define the public demand for regulation. The existing price of gasoline marks the status quo from which departures are measured. Government efforts to raise the price therefore meet strong resistance. Hence, the public is generally quite hostile to any effort to increase the price of gasoline.
By contrast, there are many popular regulatory requirements that ultimately raise the cost of energy and automobiles, but that do so mostly by affecting new sources. By almost any measure of social welfare, the direct tax approach would be preferable to the regulatory approach. I do not deny that there are many possible explanations for currently dysfunctional environmental policy. But a contributing factor may be that a tax or fee imposes highly visible losses as compared with the status quo, whereas the regulatory approach does no such thing.
Or consider the fact that subsidies to mass transit might well be an especially sensible and inexpensive environmental strategy. If automobiles are a major contributor to air pollution, an important goal is to reduce vehicle miles traveled, as well as (or instead of) improving pollution control devices on cars. This much seems clear from the fact that regulatory requirements have not succeeded in reducing aggregate automobile pollution levels, because the decrease in air pollution per mile traveled has been more than offset by increases in total car use. It follows that an imperative for environmental policy is to create incentives that will decrease the use of the underlying polluting activity. But this idea has played relatively little role in policy, especially in the area in which it makes most sense: government expenditures devoted to mass transit and highways.
Here too the political influence of the automobile industry is a plausible contributing factor. But status quo bias may play a large role as well. Because Americans have adapted their behavior to frequent use of the automobile, it is especially difficult to change their behavior in the direction of mass transit. This explanation helps to account for the remarkable comparative popularity in Europe of environmental strategies that do deter automobile use and promote mass transit. In Europe, people have not so deeply adapted their practices and preferences to automobile use. Social norms are thus a culprit here, and they are taken as given when they might be more changeable and fluid than we think.
The point is very general. Public policy often takes the status quo - including, very prominently, the existence of particular firms - as if it were a given. Laws that endanger current institutions are subject to special social scrutiny. To some extent, this is fully rational in light of the real costs of transition. But I hypothesize that a large part of the phenomenon is attributable to a bias in favor of the status quo that is far stronger than traditional theory would predict.

VII. RISKS NOT INVOLVING MORTALITY

What about risks that do not involve mortality? As I have noted, many risks, especially in the environmental area, are serious because of morbidity effects, harms to recreational opportunities and aesthetic values, and mortality and morbidity effects for plants and animals. Here, there seems to be no alternative but to try to specify the relevant adverse effects in both quantitative and qualitative terms - how many weeks of respiratory problems, how much in the way of damage to crops, how much and what kind of animal morbidity. These specifications might be translated into more commensurable units through some variation on the idea of quality-adjusted or disability-adjusted life years. That is, morbidity effects might be analyzed by seeing the extent to which the effects diminish ideal functional capacity. This idea imposes a large cognitive demand on government, and it may be best to rely on simplifying categories. It is possible that we would want to separate the mechanism used to identify the magnitude of the harm from that used for purposes of allocating resources the resource allocation judgment might depend, for reasons stated above, on distributional judgments calling for special attention to those who are systematically disadvantaged, lack much wealth, or are without access to relevant public services. I cannot discuss in this space the various possible refinements on the idea of quality-adjusted or disability-adjusted life years. Though the appropriate refinements are a large and important task for the future, we can begin to make progress in the less rigorous way suggested here - beginning with decently-livable life-years, adjusting the measure in the way suggested above, and adding various non-mortality effects in a relatively uniform way.
The effort to generate numbers to identify qualitative gains in human lives does not run afoul of some of the objections discussed above, since it does not treat some lives as more or less valuable than others because of preexisting conditions that do, not prevent basic functional capacity. The crucial task is to rank. various morbidity consequences against one another, so that comparisons can be made. Much the same thing can be said about recreational and aesthetic effects. Adverse consequences, should be ranked against one another, rather than viewed in isolation. And perhaps it will ultimately be possible to come up, with an aggregate number, summing the various components. that come under the general category of "regulatory benefits." The number ought not, however, to disguise the fact that its. ingredients are qualitatively diverse.

VIII. RISKS AND DESIGN

Thus far I have discussed matters of substance, but some of the most pressing questions are institutional. Current American institutions fail to promote either democratic or technocratic goals. The current system is insufficiently democratic in the sense that the pattern of risk regulation cannot be plausibly attributed to considered judgments of the American people. Thai pattern is more plausibly a combination of interest-group pressure, selective attention, sensationalistic media "scandals," and the "pollutant of the month" syndrome that plagues federal regulation. The current system is insufficiently technocratic be.. cause there is no general or coherent effort to bring the best scientific judgments to bear on risk-regulation. Of course science plays a large role but its role is episodic rather than global. Instead, American government has a highly fragmented system, with a proliferation of congressional committees reflecting various pathologies, and with a wide range of agencies not interacting with one another and operating pursuant to diverse statutory standards.
What possible remedies are there? Any answer must devote considerable attention to the question how to promote trust in government institutions. Here are four proposals:
1. Create a new congressional committee entrusted with the job of compiling information about risk levels and producing better priority-setting. A large problem for American government consists of the congressional committee structure, which ensures that comparative risk analysis will be rare, and which promotes a kind of balkanization of federal law. A straightforward remedy would consist of the creation of a new committee whose principal purpose would be to ensure good priority-setting. Such a committee would have authority over substantive statutes and also over the appropriations process. Its basic goal would be to engage in "risk ranking," to publicize misallocations, and to initiate corrective legislation. Such a committee should rely a great deal on current scientific findings. But it should be aware that value judgments play a legitimate role in deciding which risks are most serious. Thus the committee might adopt a presumption in favor of maximizing the number of decently-livable life-years, but allow adjustments when reasonable judgments of value so require. It would be an advantage to initiate the very process of deliberating about how to decide which risks are most serious. Such a process would alert legislators and perhaps the public to the problems in "safe or unsafe" thinking and to the need to engage in risk comparisons. 2. Strengthen the Office of Information and Regulatory Affairs ("OIRA"), to make sure that it has, and is known to have, the authority to ensure better priority-setting. Under Presidents Reagan and Bush, OIRA was understood as a kind of "cost-benefit" police officer, intervening in a fairly ad hoc way so as to ensure that grossly inefficient regulations would be reconsidered. Under President Clinton, this role appears to have diminished, notwithstanding the general interest in "reinventing government" so as to ensure greater attention to results rather than processes.
I suggest that OIRA might command far broader bipartisan support if its main role were seen as ensuring better priority-setting through maximizing the number of life-years saved through regulation. This role would call for more regulation in some areas and less regulation in others it would involve recommendations and policy guidance for both rulemaking and enforcement action. Of course OIRA could adjust the basic criterion with reference to the judgments of value discussed above. The basic point is that OIRA should not be seen solely as a brake on regulation. Sometimes it should be a spur. Its general goal should be to overcome some of the cognitive problems described above, which affect judgments at the individual level, the public "demand" for regulation, and the behavior of government officials themselves. 3. Use judicial doctrines so as to ensure "more good than harm". The judicial role in managing risk regulation is inevitably partial and modest. But courts do have power to invalidate the most extreme or ill-considered regulatory proposals or omissions. There has been a modest direction in favor of a "more good than harm" principle embodying a presumptive requirement that costs not be grossly disproportionate to benefits.
This idea is a way of overcoming the general problem of selective attention it is appropriately modest but also has considerable power. It entails at a minimum an interpretive principle allowing agencies to exempt de minimis risks, and perhaps requiring them to do so, on analogy to the old common law idea that absurdity in interpretation will be avoided. It also entails a principle that agencies should be permitted to engage in "health-health" analysis where they see fit, ensuring that regulations do not create health problems greater than those that they are intended to reduce. Finally, it entails a requirement that under the Administrative Procedure Act agencies should, under "arbitrary or capricious" review, make a plausible showing that a regulation will make things better rather than worse.
4. Create a new institution to publicize poor priority-setting and to focus attention on the most serious risks. Justice Breyer has suggested the creation of an elite corps of risk managers, versed in various disciplines and authorized to divert resources from small problems to large ones.  " Most ambitiously, then, the national government might move in the direction of a variation on the "Breyer group" to engage in the sort of analysis I have proposed here, and grant that group the authority to 1) publicize its findings about which risks are most severe, 2) require agencies to engage in similar priority-setting, 3) recommend changes in statutes or regulations, or appropriations, and perhaps 4) engage in some reallocating on its own.
5. The problem of trust, or technocracy vs. democracy. All of these proposals raise concerns along the dimension of trust, and it is important to ensure that risk regulation is not seen as a purely technocratic matter. A major goal of these (briefly sketched) proposals is indeed to strengthen the scientific underpinnings of regulation but there are important democratic goals as well. The most central point here is that the crazy-quilt pattern of current risk regulation cannot plausibly be seen as a good response to democratic convictions. Instead, that pattern reflects some combination of interest-group pressures, selective attention, strategic behavior on the part of politicians, and sensationalistic anecdotes on the part of the mass media. A movement toward better priority-setting (however this is conceived) should start with democratic as well as technocratic goals, and with a recognition that the status quo cannot reasonably be defended on democratic grounds.
Thus, institutional changes should attend to citizen judgments at both the "input" and "output" sides. At the level of "inputs," it is important to ensure that public officials have an understanding of people's actual concerns and the foundations for those concerns. Citizen panels have been used productively by some agencies with an eye toward this goal. At the level of "outputs," officials should not rest content with sensible regulations, but should have a continuing obligation to provide information and to engage in discussion about the grounds for regulation and the basis and legitimacy of any citizen concerns. The point is especially important in light of the fact that some groups of citizens may be less trusting than others, and distrust, once present, may accelerate.

CONCLUSION

I have made four basic claims in this essay. First, environmental regulation suffers above all from a problem of selective attention. No reasonable reading of reflective citizen judgments can account for the pattern we now observe, and an understanding of the systemic effects of regulation would much improve the process of priority-setting. Second, the foundation for regulatory policy should be the number of decently-livable life-years saved. Third, government should use expert judgments on that count as the foundation for analysis, and it should qualify those judgments in a limited way. More specifically, it should do so with reference to whether the risks at issue are especially dreaded, inequitably distributed, and controllable or voluntarily incurred by the individuals involved. The latter two factors point in essence to the costs of risk avoidance (including information costs). Numerical weights might be added to different assessments of these variables. Government should not use lay judgments to the extent that they reflect factual errors, even though those judgments do appear to play a role in any persuasive "positive" account of regulation. Fourth, institutional arrangements should be designed so as to allow government to make the relevant judgments in a rational manner.
This approach is in significant part a technocratic one it places a high premium on scientific judgments and on getting the numbers right. It rejects the view that those judgments are decisive, but it rejects even more firmly the view that ordinary lay judgments, regardless of their content and grounds, should play a central role in regulatory policy. Those judgments are too frequently the product of framing effects, heuristic devices, or confused factual claims often they are proxies for factors that can be better analyzed in other ways. By itself, the approach I am suggesting would not solve all of the problems raised by the question which risks should be treated first a large gap - on which I have offered just a few brief notes - consists in the problem of how to deal with environmental and other risks that do not involve human mortality. But the approach holds out some hope of combining substantive appeal with easy administrability, and thus stands as a promising place to start.

Karl N. Llewellyn Distinguished Service Professor of Jurisprudence, University of Chicago. I am grateful to Paul Slovic and Matthew Spitzer for valuable comments on an earlier draft.
Based on data from Office of Management and Budget, Budget of the United States Government Fiscal Year 1992 Pt 2, 370 Tbl  C-2 (GPO 1991). An important challenge to these data is Lisa Heinzerling, Regulatory Loss of Mythic Proportions, 107 Yale L J (forthcoming 1998).
Tammy O. Tengs, et al, Five-Hundred Life-Saving Interventions and Their Cost-Effectiveness, 15 Risk Analysis 369 (1995).
See Dietrich Dorner, The Logic of Failure: Why Things Go Wrong and What We Can Do to Make Them Right (Metropolitan 1996), for an intriguing discussion of computer simulations that highlight this problem.
See John D. Graham and Jonathan Baert Wiener, Risk versus Risk: Tradeoffs in Protecting the Environment (Harvard 1995)
See W. Kip Viscusi, Fatal Tradeoffs: Public and Private Responsibilities for Risk (Oxford 1992).
This is the tendency in Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation (Harvard 1993).
Federalist 10 (Madison), in Max Beloff, ed, The federalist (Basil Blackwell 2d ed 1987).
See, for example, W. Kip Viscusi, Fatal Tradeoffs: Public and Private Responsibilities for Risk (Oxford 1992).
I borrow in the next several paragraphs from Richard H. Pildes and Cass R. Sunstein, Reinventing the Regulatory State, 62 U Chi L Rev 1 (1995).
See Richard H. Thaler, Quasi Rational Economics 159-60, 167, 169 (Russel Sage 1993).
See George Tolley, Donald Kenkel, and Robert Fabian, eds, Valuing Health for Policy: An Economic Approach 290-94 (Chicago 1994); Symposium, Contingent Valuation, 8 J Econ Persp 3 (Fall 1994).
Tolley, Kenkel, and Fabian, eds, Valuing Health for Policy at 341-42 (cited in note 11).
Id at 342.
Id at 99.
Id at 89. The dollar figures are mean bid values, and relief means a "mild day."
See Peter A. Diamond and Jerry A. Hausman, Contingent Valuation: Is Some Number Better than No Number?, 8 J Econ Persp 45 (Fall 1994); Daniel Kahneman and liana Ritov, Determinants of Stated Willingness to Pay for Public Goods: A Study in the Headline Method, 9 J Risk & Uncertainty 5 (1994).
See Kahneman and Ritov, 9 J Risk & Uncertainty 5 (cited in note 16).
See id.
See Viscusi, Fatal Tradeoffs at 19-21 (cited in note 8).
See Office of Management and Budget, Regulatory Program of the United States Government, 1990-1991 (GPO 1992). The Administrative Conference reached a similar conclusion, though more cautiously. See Recommendations of the Administrative Conference Regarding Administrative Practice and Procedure and Correction, Recommendation No. 88-7, 53 Fed Reg 39585, 39586-87 (1988).
See Ted R. Miller, Willingness to Pay Comes of Age: Will the System Survive?, 83 Nw U L Rev 876, 886-89 (1989).
See Part III for further discussion.
See Elliott Aronson, The Social Animal (W. H. Freeman 7th ed 1995); George A. Akerlof and William T. Dickens, The Economic Consequences of Cognitive Dissonance, 72 Am Econ Rev 307, 307-08 (1982).
Tolley, Kenkel, and Fabian, eds, Valuing Health for Policy at 318 (cited in note 11). For detailed examination of the difference between individual and social perspectives on health problems, see the recent study of the external costs of smoking and drinking in Willard G. Manning, et al, The Costs of Poor Health Habits (Harvard 1991). See. also Willard G. Manning, et al, The Taxes of Sin: Do Smokers and Drinkers Pay Their Way?, 261 JAMA 1604 (1989).
See Cass R. Sunstein, Social Norms and Social Roles, 96 Colum L Rev 903 (1996).
See Jon Elster, Sour Grapes: Studies in the Subversion of Rationality (Cambridge
3).
Id at 109.
Amartya Sen has insisted on this general point in many places. See Amartya Sen, Commodities and Capabilities (North-Holland 1985); Amartya Sen, Inequality Reexamined (Harvard 1992).
See Akerlof and Dickens, 72 Am Econ Rev 307 (cited in note 23).
See Aronson, The Social Animal at 176-78 (cited in note 23). See also the discussion in Part III.B.1 of unrealistic optimism as a distorting factor. It is possible, of course, that the people who lived in this area were better informed.
This idea is emphasized in Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation (Harvard 1993).
J. Michael McGinnis and William H. Foege, Actual Causes of Death in the United States, 270 JAMA 2207, 2208 (1993).
The notion of decently livable life years is intended as an improvement on the highly influential standard proposed by Richard Zeckhauser and Donald Shepard, Where Now For Saving Lives, 40 L & Contemp Probs 5, 11-45 (Autumn 1976), which uses the notion of "quality-adjusted life years." For general discussion, see George Tolley, Donald Kenkel, and Robert Fabian, eds, Valuing Health for Policy: An Economic Approach 290-94 (Chicago 1994); George W. Torrance, Measurement of Health State Utilities. For Economic Appraisal: A Review, 5 J Health Econ 1 (1986). The notion of decently livable life-years is simpler than quality-adjusted life-years and for that reason is more easily administrable as well as less contentious.
See Zeckhauser and Shephard, 40 L & Contemp Probs 5 (cited in note 33).
See, for example, Daniel Kahneman and Amos Tversky, Judgment Under Uncertainty: Heuristics and Biases 3-20 (Cambridge 1990); Paul Slovic, et al, Regulation of Risk: A Psychological Perspective, in Roger G. Noll, ed, Regulatory Policy and the Social Sciences 241 (California 1985).
Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation 21 (Harvard 1993).
Of course, judgments of severity may well be based on values as well as facts, and here things are more complex. See discussion in Part V.
See Slovic, et al, Regulation of Risk (cited in note 35)
See Neil D. Weinstein, Optimistic Biases About Personal Risks, 246 Science 1232 (1989). Shelley E. Taylor, Positive Illusions 10-11 (Basic 1990).
Id at 33.
Laurie J. Bauman and Karolynn Siegel, Misperception Among Gay Men of the Risk for AIDS Associated With Their Sexual Behavior, 17 J Applied Soc Psych 329 (March 1987).
Id.
Id at 330-331.
Reprinted from Neil D. Weinstein, Unrealistic Optimism About Susceptibility to Health Problems: Conclusions from a Community-Wide Sample, 10 J Behav Med 481, 486 (1986).
See Kahneman and Tversky, Judgment Under Uncertainty at 11-14 (cited in note 35); W. Kip Viscusi, Fatal Tradeoffs: Public and Private Responsibilities for Risk (Oxford 1992).
See Kahneman and Tversky, Judgment Under Uncertainty at 14-18 (cited in note 35).
Id at 63-98.
See Donald A. Redelmeier, et al, Understanding Patients Decisions: Cognitive and Emotional Perspectives, 270 JAMA 72, 73 (1993).
See Marc K Landy, et al, The Environmental Protection Agency: Asking the Wrong Questions From Nixon to Clinton 310-34 (Oxford 1994).
See Craig R. Fox and Amos Tversky, Ambiguity Aversion and Comparative Ignorance, 110 Q J Econ 585 (1995).
See Paul Slovic, et al, Regulation of Risk: A Psychological Perspective, in Roger G. Noll, ed, Regulatory Policy and the Social Sciences 241 (California 1985); Howard Margolis, Dealing With Risk (Chicago 1996). Note that the discussion to follow qualifies the treatment in Richard H. Pildes and Cass R. Sunstein, Reinventing the Regulatory State, 62 U Chi L Rev 1 (1995), where notions like dreaded, involuntary, and uncontrollable were left unanalyzed.
Based on the discussion in Margolis, Dealing With Risk (cited in note 52)
Id.
I borrow here from the important discussion in Margolis, Dealing With Risk (cited in note 52)
See Ali S. Alhakami and Paul Slovic, A Psychological Study of the Inverse Relationship Between Perceived Risk and Perceived Benefit, 14 Risk Analysis 1085 (1994).
See Margolis, Dealing with Risk (cited in note 52)
See Elizabeth Anderson, Value in Ethics and Economics 196-203 (Harvard 1993).
See Robert H. Frank, Choosing the Right Pond: Human Behavior and the Quest for Status (Oxford 1983).
See Sarah Lichtenstein, et al, When Lives Are In Your Hands: Dilemmas of the Social Decision Maker, in Robin M. Hogarth, ed, Insights in Decision Making: A Tribute to Hillel J. Einhorn 91 (Chicago 1990).
See Richard H. Thaler, Quasi Rational Economics 159-60, 167, 169 (Russel Sage 1993)
See Thomas J. Philipson and Richard A. Posner, Private Choices and Public Health: The AIDS Epidemic in an Economic Perspective 194-206 (Harvard 1993).
See Table 1.
See Nancy L. Rose, Fear of Flying? Economic Analyses of Airline Safety, 6 J Econ Persp 75 (Spring 1992).
See Marc K. Landy, et al, The Environmental protection agency: Asking the Wrong Questions From Nixon to Clinton 310-34 (Oxford 1994).
William Samuelson and Richard Zeckhauser, Status Quo Bias in Decision Making, 1 J Risk & Uncertainty 7 (1988).
See Peter Huber, The Old-New Division in Risk Regulation, 69 Va L Rev 1025 (1983).
See Cass R. Sunstein, After the Rights Revolution: Reconceiving the Regulatory State 92 (Harvard 1990).
Clean Air Act, 42 USC  7470-92 (1994).
B. Peter Pashigian, Environmental Regulation: Whose Self-Interests are Being Protected?, in George J. Stigler, ed, Chicago Studies in Political Economy 498 (Chicago 1988).
See, for example in the Clean Air Act, 42 USC  7475 (1982) (preconstruction requirements); 42 USC  7411 (1982) (standards of performance for new stationary sources)
See Robert W. Crandall, Policy Watch: Corporate Average Fuel Economy Standards, 6 J Econ Persp 171 (Spring 1992).
Robert W. Crandall, Regulating the Automobile (Brookings 1986).
See Marcia D. Lowe, Shaping Cities, in Lester R. Brown, ed, State of the World, 1992: A Worldwatch Institute Report on Progress Toward a Sustainable Society 119 (W. W. Norton 1992).
A clearheaded discussion and criticism is found in Sudhir Anand and Kristina Hanson, Disability-Adjusted Life Years: A Critical Review, (Harvard School of Public Health, Working Paper No. 96.06, Sept 1995).
See Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation (Harvard 1993); Paul Slovic, et al, Regulation of Risk: A Psychological Perspective, in Roger G. Noll, ed, Regulatory Policy and the Social Sciences 241 (California 1985).
See Thomas 0. McGarrity, Reinventing Rationality: The Role of Regulatory Analysis in the Federal Bureaucracy (Cambridge 1991).
See Roger G. Noll and James E. Krier, Some Implications of Cognitive Psychology for Risk Regulation, 19 J Legal Stud 747 (1990); Cass R. Sunstein, Endogenous Preferences, Environmental Law, 22 J Legal Stud 217 (1993).
See Edward W. Warren and Gary E. Marchant, More Good Than Harm, 20 Ecology L Q 379 (1993); Howard Margolis, Dealing With Risk (Chicago 1996).
See, for example, Corrosion Proof Fittings v EPA, 947 F2d 1201 (5th Cir 1991).
See id; Cass R. Sunstein, Health-Health Tradeoffs, 63 U Chi L Rev 1533 (1996).
5 USC  551-59 (1994).
See Breyer, Breaking the Vicious Circle (cited in note 76).
See Richard H. Pildes and Cass R. Sunstein, Reinventing the Regulatory State, 62 U Chi L Rev 1 (1995), for citations and discussion.
See id.
