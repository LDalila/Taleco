University of Chicago Law School ersity
Cass R. Sunstein
Human cognition does not take place in a social vacuum. When a particular incident becomes cognitively "available," it is because of social influences. Individuals are especially averse to losses but how do we know whether we are facing a loss or instead a foregone gain? What is the status quo from which losses are measured? Social understandings provide the answer. Individuals often think and work in groups do group interactions aggravate or reduce some of the harmful effects of heuristics and biases?' If heuristics and biases sometimes lead people to make bad decisions, in a way that seems to justify paternalism, the flow of information is a crucial reason. Can anything be done-by individuals, government, or the law-to improve information flow and perhaps to ensure "debiasing" in the process? Or consider the fact that people care about fairness and are willing to punish, at their own expense, those who behave unfairly. How might social influences reduce or increase people's willingness to sacrifice their material self-interest for the sake of fairness?
My goal in this Essay is to suggest that we will have a far better understanding of the relationship between behavioral economics and law if we investigate the connection between behavioral findings and social influences. The real-world effects of heuristics and biases are very much a function of social pressures, including, but not limited to, the law. Wellorganized private groups, showing a working knowledge of behavioral economics and a willingness to exploit it for their benefit, play a central role here. But to say this is to get ahead of the story. Begin with an example.
A. Snipers
In fall 2002, a pair of snipers killed ten people in the Washington, D.C. area. The victims were randomly chosen. They included men and women,
Cass R. Sunstein*
But there is something very odd about the extraordinary effects of the snipers' actions. For people in the relevant area, the snipers caused a miniscule increase in risk. If there were five million people in the D.C. area, and if the snipers were going to kill one person every three days, the daily statistical risk of being shot was less than one in one million, and the weekly statistical risk was less than three in one million. These are trivial risks, far lower than the risks associated with many daily activities about which people do not express even the slightest concern. The daily risk, for example, was smaller than the risk of death from drinking thirty diet sodas with saccharin, from driving one hundred miles, from smoking two cigarettes, from ten airline trips, from living in a home with a smoker for two weeks, from living in Denver rather than Philadelphia for forty days, and from eating thirty-five slices of fresh bread.' It would be possible to quibble with my assessment of the statistical risk, and perhaps people, at the time, rationally thought that the risk was somewhat higher than I have suggested. But even if so, the real risk could not possibly have been sufficient to justify the high levels of anxiety and fear, which bordered, for many, on the edge of hysteria. Perhaps some of the defensive behavior was rational, given the fact that that behavior itself was not terribly costly. But the extent of alarm could not possibly be justified by the extent of the risk.
Why, then, did so many people in Washington feel fear and alter their behavior in the midst of the snipers' attacks? Behavioral economics suggests two principal accounts. First, people rely on the availability heuristic. Under the availability heuristic, people assess probabilities by asking whether examples readily come to mind.' Lacking statistical information, people substitute an easy question (Can I think of illustrations?) for a hard question (What realities do the data actually show?). It is hardly irrational to use the availability heuristic when reliable information is absent. But the availability heuristic can lead to significant mistakes. If an incident is readily available but statistically rare, the heuristic will lead to overestimation of risk if examples do not come to mind, but the statistical risk is high, the heuristic can give people an unjustified sense of security. Perhaps the fear of sniper attack, in the Washington area, arose from a misperception of probability, generated by the high salience of the few attacks and thus by the availability heuristic. '
This explanation seems to have considerable power. But there is another explanation. When strong emotions are triggered, people tend to focus on the worst case and not to think much about issues of probability at
such sites into a strong basis of concern.24 Availability thus varies over time. Some statistically large risks do not cause a great deal of fear. Why is this?
The question suggests what is missing from the behavioral account: an assessment of the social and cultural dimensions of judgment under uncerIn behavioral work, researchers usually investigate individuals' thinking through laboratory experiments in which subjects answer questions in isolation. To say the least, these experiments are highly illuminating, and they tell us a great deal about how people think and act in the real world. What I mean to emphasize here is that for every finding in behavioral economics, there is an accompanying set of social interactions, which greatly influence people's beliefs and judgments.
This is most obviously true for availability. In many cases of highvisibility, low-probability risks, including sniper attacks, shark attacks, and the kidnapping of young girls, the sources of availability are not obscure. The mass media focus on those risks people communicate their fear and concern to one another the widespread fear and concern increase media attention and the spiral continues until people move on. This account explains how the "risk of the month" syndrome stems from the interaction between availability and social influences. Much of the time, however, what is available and salient to some is not available and salient to all. For example, many people focus on cases in which the government neglected to regulate some environmental risk, with the consequence being widespread illness and death. To such people, the available incidents require strong precautions in the face of uncertainty. But many other people focus on cases in which the government overreacted to weak science, engaging in large expenditures for little gain in terms of health, safety, or environmental protection. To such people, the available incidents justify a measure of circumspection and restraint in the face of uncertainty. Which of these cases will be available and to whom?
In any case people have different predispositions. These predispositions play a large role in determining which of the numerous possibilities is salient. Availability helps to determine beliefs, to be sure, but beliefs help to determine availability as well. Both beliefs and availability are endogenous to one another. When social and cultural forces interact with salience to produce concern about one set of problems, but not another, predispositions are crucial. On this count, too, those interested in behavioral economics have said relatively little.
NORTHWESTERN UNIVERSITY LAW REVIEW
In order to predict behavior, to see how law can accomplish shared goals, and to analyze the legitimate role of paternalism in law, it is necessary to know something about how social forces interact with individual cognition. Indeed, law can sometimes amplify the relevant effects-as, for example, through a rapid, aggressive response to a salient risk, a response that makes the risk more salient still. If public officials focus on a risk, they can use the underlying cognitive processes to increase social concern.
While I focus throughout this Essay on the availability heuristic and on probability neglect, it should be easy to see that social influences amplify many other features of individual cognition. Alert politicians and wellorganized private groups can manipulate loss aversion. Anchoring greatly affects people's judgments in the face of uncertainty, people often seize on any number, or "anchor," that is available. But on which number will they anchor? Social influences, including those imposed by lawyers, play a large role in answering that question. Fairness matters, but the beliefs and actions of others greatly affect people's judgments about fairness.3 In emphasizing these points, I mean to suggest the importance of seeing various cognitive findings in the context of social dynamics, including selfconscious manipulations of the flow of information.
II.
In this Part, I briefly describe the availability heuristic and probability neglect and their relationship to risk-related law. I do so partly because they are important in their own right, and not much discussed in this Symposium, but mostly by way of preface for the discussion of social influences.
A. Availability
Begin with the availability heuristic. When presented with hard questions, people often ask themselves easier questions, which serve to simplify their inquiry. The answer to the easier questions operates as a heuristic or a rule of thumb. Of these rules of thumb, the availability heuristic is probably the most important for purposes of understanding law, and in particular, those aspects of law that involve both discrimination and social risks.
Thus, for example, "a class whose instances are easily retrieved will appear more numerous than a class of equal frequency whose instances are less retrievable. The point very much bears on private and public responses to risks, suggesting, for example, that people will be especially responsive to the dangers of AIDS, crime, earthquakes, and nuclear power plant accidents if examples are easy to recall.35 The point also explains some of the sources of discrimination on the basis of race, sex, age, and disability. If it is easy to bring to mind cases in which a female employee quit work to care for her family, sex discrimination is more likely so too if it is easy to think of cases in which African-American employees performed poorly.
In this way, familiarity can affect the availability of examples, but salience is important as well. "The impact of seeing a house burning on the subjective probability of such accidents is probably greater than the impact of reading about a fire in the local paper. Similarly, earlier events will have a smaller impact than later ones. This point helps explain much of human behavior. For example, whether people will buy insurance for natural disasters is greatly affected by recent experiences. If floods have not occurred in the immediate past, people who live on flood plains are far less likely to purchase insurance. In the aftermath of an earthquake, many more people buy insurance for earthquakes, but the number declines steadily from that point, as vivid memories recede. For purposes of law and regulation, the problem is that the availability heuristic can lead to serious errors of fact, in terms of both excessive controls on small risks that are cognitively available and insufficient controls on large risks that are not. Notice that the use of the availability heuristic in these contexts strongly suggests that the heuristics operate even when the stakes are large. And it is even possible that the use of the availability heuristic, in such contexts, is fully rational for people who lack statistical knowledge. Perhaps use of that heuristic is the best way of minimizing the sum of decision and error costs. But it seems less useful to debate the rationality of the availability heuristic than simply to observe that it has a significant effect on actual behavior.
What, in particular, produces availability? An interesting study attempts to test the effects of ease of imagery on perceived judgments of risk.42 The study asked subjects to read about an illness (Hyposcenia-B) that "was becoming increasingly prevalent" on the local campus. In one condition, the symptoms were concrete and easy to imagine: muscle aches, low energy, and frequent severe headaches. In another condition, the symptoms were vague and hard to imagine: an inflamed liver, a malfunctioning nervous system, and a vague sense of disorientation. Subjects under both conditions were asked both to imagine a three-week period in which they had the disease and to write a detailed description of what they imagined. After doing so, subjects were asked to assess, on a ten-point scale, their likelihood of contracting the disease. The basic finding was that likelihood judgments were very different in the two conditions, with easily imagined symptoms making people far more inclined to believe that they were likely to get the disease.
There are several implications for policy and law. The public demand for law should be much higher if people can easily imagine the harm in question-in such cases, the law might well reflect a kind of hysteria. But if the harm is difficult to imagine, we might well see a pattern of neglect. We would therefore predict that easily imaginable harms would lead to relatively greater private precautions and relatively greater governmental concern. Well-organized private groups should, and do, take advantage of this fact, attempting to publicize visible examples of harms to which they seek to draw attention.46 This point also offers implications about public informational campaigns. If the government wants people to take protective steps, it should provide information about symptoms in a vivid rather than statistical way, relying on examples that can later be brought to mind.
An understanding of the availability heuristic bears directly on the debate over paternalistic interventions. If people believe that some risks are much higher than they actually are and that other risks are much lower than they actually are, their behavior will not promote their welfare. People will take excessive precautions to avoid trivial risks and they will fail to protect themselves against genuine hazards. Government has a legitimate role to play here at a minimum, it should correct false beliefs. In some cases, government legiti-
mately responds to people's inability to process risk-related information by constraining their choices, at least when the constraint ensures that they will do what they would do if they were adequately informed. Here, as elsewhere, an understanding of bounded rationality undermines the dogmatic, nearly theological, antipaternalism of those who indulge strong assumptions about rationality, at least if social influences do not correct individual errors.
The availability heuristic can produce an inaccurate assessment of probability. But sometimes people will attempt to make little assessment of probability at all, especially when strong emotions are involved.4 In such cases, large-scale variations in probabilities matter little, even when those variations unquestionably should matter. The case of the sniper attacks is an example. The point applies to hope as well as fear vivid images of good outcomes will crowd out consideration of probability too.49 Lotteries are successful partly for this reason.
Probability neglect has received its most direct empirical confirmation in a striking study of people's willingness to pay to avoid electric shocks. The central purpose of the study was to test the relevance of probability in "affect rich" decisions. One experiment investigated whether varying the probability of harm would matter more, or less, in settings that trigger strong emotions than in settings that seem relatively emotion-free. In the relatively emotion-free setting, participants were told that the experiment entailed some chance of a $20 penalty. In the "strong emotion" setting, participants were asked to imagine that they would participate in an experiment involving some chance of a "short, painful, but not dangerous electric shock." 5' Participants were asked to say how much they would be willing to pay to avoid participating in the relevant experiment. Some participants were told that there was a 1% chance of receiving the bad outcome (either the $20 loss or the electric shock), others were told that the chance was 99%, and still others were told that the chance was 100%.
The key result was that variations in probability affected those facing the relatively emotion-free injury, the $20 penalty, far more than they affected people facing the more emotionally evocative outcome of an electric shock.52 For the cash penalty, the difference between the median payment for a 1% chance and the median payment for a 99% chance was predictably large and indeed broadly consistent with economic rationality: $1 to avoid
a 1% chance, and $18 to avoid a 99% chance.5 For the electric shock, by contrast, the difference in probability made little difference to median willingness to pay: $7 to avoid a 1% chance, and $10 to avoid a 99% chance.5 Apparently, people will pay a significant amount to avoid a small probability of a hazard that is affect laden-and the amount that they will pay will not vary greatly with changes in probability. My own study, involving arsenic, comes to a similar conclusion, suggesting that people are less sensitive to differences in probability when the risks are described in a way that triggers strong emotions. The point explains "why societal concerns about hazards such as nuclear power and exposure to extremely small amounts of toxic chemicals fail to recede in response to information about the very small probabilities of the feared consequences from such hazards.
An understanding of probability neglect casts new light on the finding that visualization or imagery matters a great deal to people's reactions to risks.5 When an image of a bad outcome is easily accessible: people will become greatly concerned about a risk, holding probability constant.58 Consider the fact that when people are asked how much they will pay for flight insurance for losses resulting from "terrorism," they will pay more than if they are asked how much they will pay for flight insurance to compensate for injury or monetary losses from all causes.5 The evident explanation for this peculiar result is that the word "terrorism" evokes vivid images of disaster, thus crowding out probability judgments. Note also that when people discuss a low-probability risk, their concern rises even if the discussion consists mostly of apparently trustworthy assurances that the likelihood of harm really is infinitesimal.60 The reason is that the discussion makes it easier to visualize the risk and hence to fear it.
Probability neglect does not involve the availability heuristic. That heuristic leads people not to neglect probability, but to answer the question of probability by replacing a hard question (What is the statistical risk?) with an easy question (Do salient examples readily come to mind?). 6' My suggestion here is
not that visualization makes an event seem more probable (though this is also true), but that visualization makes the issue of probability less relevant or even irrelevant. The most sensible conclusion is that with respect to risks of injury or harm, vivid images and concrete pictures of disaster can "crowd out" other kinds of thoughts, including the crucial thought that the probability of disaster is really small. "If someone is predisposed to be worried, degrees of unlikeliness seem to provide no comfort, unless one can prove that harm is absolutely impossible, which itself is not possible. When people focus on highly speculative risks, it is often because of intense emotional reactions that make those risks, and not relevant others, stand out from the background.
III.
All these points involve individual thinking about risks. But as I have stressed, there is an unresolved puzzle for those interested in the real-world effects of the availability heuristic and probability neglect: in many contexts, multiple images are literally available and potentially salient. "[N]ot all analogies within a person's repertoire are equal: for whatever reasons, some are more easily recalled than others. Consider the problem of gun violence. We can find cases in which the presence of guns led to many deaths and also cases in which the presence of guns allowed law-abiding citizens to protect themselves against criminals. Or consider the question of whether women, when facing a risk of sexual violence, increase or decrease their chances of escaping unscathed if they engage in aggressive selfdefense. In some cases, resistance prevented the assault. In other cases, resistance led to murder.65 In the face of conflicting instances, which cases are especially available? Even expert judgments appear to be driven by one or another set of available instances. But why should one or another kind of case be available?
Social influences are quite important here. Sometimes availability and salience spread through social bandwagons or cascades, in which apparently representative anecdotes and gripping examples move rapidly from one person to another.67 In fact, a process of this sort played a large role in the
Washington area sniper attacks, in the Love Canal scare, and in many other sets of social processes producing law.
Consider a stylized illustration. Andrew hears of a social event, which he finds to be revealing or illustrative. The event might involve crime, discrimination, environmental hazards, or threats to national security. Andrew tells Barry, who would be inclined to view the event as not terribly informative, but who comes to believe that the event does indeed reveal a great deal after seeing Andrew's reaction. Once Carol hears about the event from Andrew and Barry, she is likely to find it revealing as well. Deborah will then have to possess a great deal of private information to reject the shared opinion of Andrew, Barry, and Carol. Stylized, though it is, the example shows that once several people start to consider an example as probative, many people may come to be influenced by their opinion, giving rise to cascade effects.10 Nor is the example entirely unrealistic. Why do people purchase insurance against natural disasters? Much of the explanation comes from social interactions that follow vivid examples.
In the domain of social risks, availability cascades are responsible for many social beliefs. The point is amplified by the fact that fear-inducing accounts, with high emotional valence, are especially likely to spread.7 There is a general implication here. Because different social influences can be found in different communities, local variations are inevitable, with different examples becoming salient in each. One community might greatly fear abduction of young girls, and another might not, even though the statistical risk is the same in each. One community might fear shark attacks, and another might not, even though the likelihood of such an attack, in both places, is miniscule. Such variations might involve coincidence or small or random factors, rather than large-scale cultural differences.
Different judgments within different social groups, with different available examples, owe their origin to social processes of this sort. Indeed the different reactions to nuclear power in France and the United States can be explained in large part in this way. Or suppose that some groups concentrate on cases in which guns increased violence, while others focus on cases in which guns decreased violence. When this is so, availability cascades are a large part of the reason. "Many Germans believe that drinking
like-minded people, predisposed to show concern about some problem, are likely to show amplified use of that heuristic. And some evidence suggests that the use of the representativeness heuristic is aggravated in groups.82 Groups seem to be more confident than individuals, but the evidence conflicts on whether the greater confidence reflects overconfidence bias.83 The most comprehensive study suggests that "there can be no simple answer to the question, processes do not eliminate the use of heuristics. It remains to be seen whether and when they reduce or increase the resulting errors.85
B. Media, Interest Groups, and Politicians
Thus far the discussion has involved interactions among individuals, who are all treated as equals. But it should be clear that in the real world, some voices are more important than others, especially when availability and salience are involved. In particular, the behavior and preoccupations of the media play a large role. Many perceived "epidemics" are in reality no such thing, but instead a product of overwhelming media coverage of gripping, unrepresentative incidents.8 Attention to these unusual incidents is likely to ensure availability and salience, promoting an inaccurately high estimate of probability and at the same time some degree of probability neglect. And in the face of close media attention, the demand for legal responses will be significantly affected. In the context of the sniper attacks, intense media coverage was the central source of social fear, helping to ensure that large amounts of private and public resources were devoted to risk reduction.
A natural question, then, is why the media covers certain risks and not others. A good clue comes from the following suggestion:
Whatever the criticisms, the reign of terror is boosting ratings for cable news netist attacks. At the end of last week, Fox News Channel's average daily audience
Hence the media's coverage reflects its economic self-interest, at least in part. Gripping instances, whether or not representative, are likely to attract attention and to increase ratings. Often the result is to distort probability judgments. There can be a kind of vicious circle involving the availability heuristic and media incentives, with each aggravating the other, often to the
detriment of public understanding. Knowing the importance of media coverage, well-organized private groups-some entirely self-interested and others altruistic and pursuing a social cause-often work extremely hard to promote public attention to particular risks. A common tactic is to publicize an incident that might trigger both availability and salience. Of course terrorists themselves are the most extreme and vicious example, using high-visibility attacks to convince people that "they cannot be safe anywhere." But many illustrations are less objectionable and sometimes even benign. Consider the abandoned hazardous waste problem at Love Canal, used by environmental groups to promote hazardous waste cleanup,8 or the Exxon Valdez disaster, used by the Sierra Club and other environmental organizations to promote more stringent safeguards against oil spills. Showing at least a working knowledge of the availability heuristic and other behavioral findings, private groups seize on selected incidents and publicize them to make them generally salient to the public. With respect to tort reform, corporate advocates use extreme and unrepresentative cases of jury misconduct to suggest that significant protections are needed against jury overreaching.9 " In all of these examples, the use of particular instances might be necessary to move the public, and legislators, in the right directions. Certainly the social processes that interact with salience and availability can promote legal reform where it is needed. But there are no assurances here. Social influences might well lead people to exaggerate a problem or a probability, or to ignore the question of probability altogether.
Politicians engage in the same basic project. President Ronald Reagan was a master. Consider his influential discussion of the Chicago Welfare Queen, "a heavy woman driving a big white Cadillac and paying for thick steaks with wads of food stamps." By its very nature, the voice of an influential politician comes with amplifiers. When public officials are able to bring an incident before the public, a seemingly illustrative example is likely to spread far and wide. A legal enactment can itself promote availability if the law responds to the problems associated with hazardous waste dumps or "hate crimes," people might well come to see those problems as readily available. The terrorist attacks of September 11, 2001 would inevi-
When people are in a group that is predisposed in a particular direction, the salient examples will be quite different from those that are salient in a group with an opposite predisposition. Here group polarization is especially important.
More generally, different cultural orientations play a large role in determining what turns out to be available. The United States is highly diverse, and for some purposes, it is plausible to think of different regions and groups as having somewhat different cultures. Within the AfricanAmerican community, for example, the available instances are sometimes quite different from those that can be found within the White Across nations, the differences are even more striking, in part because different world-views play such a dominant role.97
I have emphasized the role of the availability heuristic and probability neglect, but social influences are connected with the real-world effects of many heuristics and biases and with the full range of findings in behavioral economics. Consider, for example, one of the sources of unpredictability in jury awards involving punitive damages or hard-to-monetize injuries: the absence of a "modulus" that would enable people to make sense of various "points" along the scale of dollars.98 When a company has engaged in serious misconduct, is the appropriate punishment $100,000, or $1,000,000, or $10,000,000? A jury's judgment is likely to depend on the modulus that is suggested by the most influential jurors. But where does that modulus, or any modulus, come from? The answer lies in social understandings. Sometimes a particular juror will have heard of a case in which a certain amount has been awarded, and that amount might turn out to serve as a modulus for the group.
Social influences are not limited to this phenomenon. In a process akin to group polarization, the dollar awards of juries turn out to be systematically higher than the predeliberation dollar awards of those juries' median juror. Dollar awards undergo a systematic "severity shift," ensuring that in many cases, awards are as high as, or even higher than, that of the highest individual before deliberation began. Thus social interactions have a predictable amplifying tendency on individual awards. An understanding of individual psychology would be insufficient to predict this outcome. It is necessary to examine social interactions as well. There is much to be learned about the relationship between such interactions and anchoring.
Or consider loss aversion. People are averse to losses but how do we know whether something will count as a loss? When will people see changes as losses? Often the answer depends not on simple facts, but on a range of contextual factors, including how the event is framed. The status quo is usually the reference point, so that losses are so defined when people are asked, or forced, to relinquish what they now have. But simply through inventive terminology, it is possible to manipulate the frame so as to make a change appear to be a loss rather than a gain, or vice versa. These manipulations occur socially-through the acts and deeds of other people and institutions. Consider a company that says "cash discount" rather than "credit card surcharge." Or consider a parent who says that for behavior X, rather than behavior Y, a child will be rewarded, as opposed to saying that for behavior Y, rather than behavior X, a child will be punished. Or consider familiar advertisements to the effect that "you cannot afford not to" use a certain product.
In the context of environmental regulation, it is easy to manipulate the reference point that people use to measures losses or gains. Thus policymakers might claim that they are trying to "restore" water or air quality as it was thirty years ago. If they make this claim, people are likely to be receptive they do not want air and water to be dirtier than they recently were. By contrast, a proposal to "improve" air or water quality will not be nearly so attractive. People's judgments are much affected by whether we are speaking of restoration or improvement.0 But how can we tell which is involved? The answer might be manipulated socially, simply by picking a "clean" year to which policymakers seek to return. There is a more general point. Because people are averse to losses from the status quo, policymakers have a great deal to gain by manipulating people's conception of what the status quo is, so that any changes do not seem to be a "loss" at all. If an apparent increase in tax rates can really be described as a return to tax rates in 1996, taxpayers are less likely to object. Such manipulations, inevitably social in character, will inevitably have large effects on assessments of legal alternatives.10
Or consider the finding of bounded self-interest, which behavioral economists and those interested in behavioral law and economics have stressed. Bounded self-interest refers to the fact that people are sometimes willing to sacrifice material self-interest in order to be fair and also to sacrifice material self-interest in order to punish unfairness. But what is the difference between individual behavior and behavior in groups? The issue has been studied in connection with the Dictator Game, used to explore
selfishness and altruism. In this game, a subject is told that she can allocate a sum of money, say $10, between herself and some stranger. The standard economic prediction is that most subjects will keep all or almost all of the money for themselves. But the standard prediction turns out to be wrong. Most people choose to keep somewhere between $6 and $8 and to share the rest. The question here, however, is how behavior in the Dictator Game is affected if people are placed in teams-if people decide in groups rather than individuals. Are groups more altruistic than individuals? The answer is that team members choose still more equal divisions.1 Once placed in groups, people show a significant shift toward greater generosity.
This result seems best explained by reference to a social norm, one that disfavors selfishness, even within a group that stands to benefit from it. If people are deliberating with others about how much money to give to charity, chances are good that the group will end up being less selfish than the median individual, simply because people do not want to appear to be greedy. People's concern for their reputation, along with their concern for their own self-conception, plays a large role. Of course the outcomes here, and the effects of group influence, would change if the team in the Dictator Game had some reason to be hostile to those who would benefit from their generosity. We can easily imagine a variation of the Dictator Game in which, for example, people of a relatively poor religious group are deciding how much to allocate to another religious group that is thought to be both hostile and far wealthier. In this variation, the social norm would likely favor greater selfishness.
My point, in short, is that fairness-related behavior is often a function of prevailing social influences. Consider a study of cooperative behavior, which tested the subjects' willingness to cooperate, varying only the name of the game. In one version, the game was called a Wall Street game in another, it was called a Community Game. The level of cooperative behavior was far higher in the latter version that in the former. Whether people will behave fairly, and act to their mutual advantage, is likely to depend on whether they think that they are playing Wall Street or Community and here social signals are crucial.
