University of Chicago Law School ersity
Cass R. Sunstein Timur Kuran
The purpose of this article is to identify a set of interlinked social mechanisms that have important, sometimes desirable, but at other times harmful effects on risk regulation. The harmful effects range from inconsistent health regulations to mass anxiety about foods with no scientifically confirmed health hazards. The underlying mechanisms help shape the production of law through their effects on legislators, administrative agencies, and courts.
The mechanisms presented below are mediated by the availability heuristic, a pervasive mental shortcut whereby the perceived likelihood of any given event is tied to the ease with which its occurrence can be brought to mind. Cognitive psychologists consider the availability heuristic to be a key determinant of individual judgment and perception. They have demonstrated that the probability assessments we make as individuals are frequently based on the ease with which we can think of relevant examples.' Our principal claim here is that this heuristic interacts with identifiable social mechanisms to generate availability cascades-social cascades, or simply cascades, through which expressed perceptions trigger chains of individual responses that make these perceptions appear increasingly plausible through their rising availability in public discourse. Availability cascades may be accompanied by counter-mechanisms that keep perceptions consistent with the relevant facts. Under certain circumstances, however, they generate persistent social availability errors-widespread mistaken beliefs grounded in interactions between the availability heuristic and the social mechanisms we describe.2 The resulting mass delusions may last indefinitely, and they may produce wasteful or even detrimental laws and policies.
An availability cascade subsumes two of the special cascades that have recently received considerable attention in the social sciences, though not in law: informational cascades and reputational cascades.' An informational
cascade occurs when people with incomplete personal information on a particular matter base their own beliefs on the apparent beliefs of others. To be more specific, suppose that the words and deeds of certain individuals give the impression that they accept a particular belief. In response to their communications, other individuals, who lack reliable information, may accept that belief simply by virtue of its acceptance by others. As long as members of the relevant group are heterogeneous along one or more dimensions (e.g., initial personal information, willingness to rely on others for information, timing of social contacts), the transformation of the distribution of beliefs can take the form of a cascade, known also as a bandwagon or snowballing process.4 Not every member of a society experiencing an informational cascade need be influenced those with considerable private information may remain unswayed. Under the right conditions, however, many or most of the society's members, potentially even all, will end up with essentially identical beliefs, which may well be fanciful.
Insofar as society is socially fragmented, it may exhibit local informational cascades. A local informational cascade is one limited, for example, to a geographical area, a demographic subgroup, or a core of activists who share a political objective. Local informational cascades are quite common and, as we shall see, potentially quite important.
Like an informational cascade, a reputational cascade is driven by interdependencies among individual choices. It differs, however, in the underlying personal motivations. In the case of a reputational cascade, individuals do not subject themselves to social influences because others may be more knowledgeable. Rather, the motivation is simply to earn social approval and avoid disapproval. In seeking to achieve their reputational objectives, people take to speaking and acting as if they share, or at least do not reject, what
they view as the dominant belief. Everyone has had the experience of modifying public statements or actions in order to win praise or avoid censure. If a particular perception of an event somehow appears to have become the social norm, people seeking to build or protect their reputations will begin endorsing it through their words and deeds, regardless of their actual thoughts. As in the informational case, the outcome may be the cleansing of deviant perceptions, arguments, and actions from public discourse. And just as informational cascades may be limited in their reach, there may exist local reputational cascades-self-reinforcing processes that reshape the public pronouncements of particular subgroups without affecting those of the broader group.
Reputational and informational cascades are not mutually exclusive. Ordinarily, they exhibit interactions and even feed on one The resulting composite process, which is generally triggered by a salient event, is what we are calling an availability
Social agents who understand the dynamics of availability cascades and seek to exploit their insights may be characterized as availability entrepreneurs. Located anywhere in the social system, including the government, the media, nonprofit organizations, the business sector, and even households, these entrepreneurs attempt to trigger availability cascades likely to advance their own agendas. They do so by fixing people's attention on specific problems, interpreting phenomena in particular ways, and attempting to raise the salience of certain information. For example, availability entrepreneurs acting on behalf of corporations focus on cases of strikingly large punitive damages awards as a means of building support for tort reform. Likewise, environmental organizations draw attention to apparent disasters (e.g., Love April 1999]
Canal, Chernobyl, Three Mile Island) to support their calls for tighter regulation.9 Such availability campaigns often produce social benefits by overcoming public torpor and fueling debates on long-festering though rarely articulated problems. These desirable effects can arise in domains as diverse as economic regulation, identity politics, and social customs. At the same time, availability campaigns sometimes do great harm by producing widespread availability errors.10 This danger points to the need for institutional safeguards to ensure better priority-setting and fuller use of scientific knowledge. Proper safeguards, which need not entail either "more" regulation or "less" regulation, can save both lives and dollars.
Offering recent examples of availability cascades that have resulted in socially harmful regulatory responses, we shall propose institutional reforms to insulate the government and the legal system against the political pressures generated by harmful cascades. Insofar as the reforms turn out to be effective, they would ensure that when government responds to political pressures, it does so because the underlying problems are serious. Although our proposals are developed with special reference to the tripartite governmental system of the United States, with minor modifications they can be applied to any democratic system. Our analytical framework and policy conclusions carry major implications for both populist and deliberative conceptions of democracy. A central theme in contemporary debates on democracy is that political judgments should reflect much more than a technocratic exercise these judgments should be based on the facts, to be sure, but also on people's reflective values, including their tolerance for uncertainty. The analysis below is followed by concrete proposals on how these objectives can be advanced.
All of our major illustrations involve availability cascades pertaining to the regulation of risks," a topic especially well-suited to exploring interactions between democracy and law. We hasten to point out, however, that the general framework can be applied to a wide variety of other areas. Among the diverse social transformations that exhibit striking examples of availability cascades are the rise and decline of McCarthyism the struggle for black civil rights the student rebellions of the 1960s the spread of affirmative action and the recent explosion of public opposition to it the rise of feminism, the anti-tax movement, and the religious right ongoing campaigns against pornography, hate speech, smoking, health maintenance organizations, and
the burning of black churches the spread of ethnic and religious separatism across the world the persistence and sudden fall of communism the global turn toward market-friendly government policies campaigns for safe sex the enforcement of Megan's Law, designed to inform a community when a convicted sex offender moves in and finally, the emergence of the Federalist Society at American law schools.
Legal scholars are now devoting considerable attention to the virtues and vices of rational actor models, including those of models that accommodate social influences. It will therefore be useful to specify at this juncture how our approach bears on various claims in the existing literature that, for all its diversity, falls under the rubric of "rational choice." There is nothing irrational about participating in an informational cascade. Often people have little information about the magnitude of a risk or the seriousness of an alleged social problem. They stand to gain from tuning into, and letting themselves be guided by, the signals of others. Although informational cascades may cause false beliefs to spread and strengthen, they are nonetheless consistent with individual rationality as the concept is generally understood. Indeed, models of this phenomenon are expressly based on the rational actor framework. They treat individuals as utility maximizers who weigh all their options.14 Nor is there anything irrational about being concerned with one's reputation or anything rational about being unconcerned. To lack an interest in protecting and improving one's reputation is not an indicator of rationality rather, it is a mark of sociopathy. Models of reputational cascades depart from the conventional economic model merely by recognizing that reputation is an ingredient of individual utility functions.
The only element of our analysis that challenges the conventional rational actor model is the role we attribute to the availability heuristic. Those who have investigated this heuristic tend to consider it a cognitive limitation or, to use alternative terminology, an indicator of quasi-rationality. They April 1999]
stress that the heuristic confirms the difficulties people face in processing information. But using the availability heuristic may be entirely rational from the standpoint of an imperfectly informed real agent. After all, the cognitive powers of a real agent, unlike those of the fictitious agents in conventional models, are limited. People who seek to minimize search and decision costs, and who look for reliable information about a particular risk, may do best to form their assessments according to what incidents come most readily to mind. It is true, however, that the availability heuristic can produce systematic and persistent misperceptions. It also appears that people resort to this heuristic more than they would if they were perfectly rational. But we do not need to pursue these points here. None of our analysis rides on the precise definition of what it means to be rational. What does matter is that we consider a society composed of boundedly rational individuals who benefit immensely from using cognitive rules of thumb.
This article contributes to the nascent field of behavioral analysis of law,17 which stresses the significance of both cognitive limitations and social influences. Steering clear of the most vexing controversies about the extent to which people are "rational," we explore how interactions between people's reliance on the availability heuristic and identifiable social mechanisms direct the transformation of laws and policies. The consequences can be socially disastrous, so we proceed to explore institutional reforms that may diminish the potential hazards.
Part I begins with an account of an availability cascade that has imposed immense costs on Americans, and it continues with shorter accounts of two additional cases. Forming the article s theoretical core, Parts II and HI provide a conceptual framework for studying availability cascades and identifying their social and legal consequences. Part IV draws implications for the regulation of risks within a democratic social order. Addressing the appropriate role of science, it also points to the possible disadvantages of basing laws and policies solely or mechanically on publicly expressed judgments. This Part also connects availability cascades with democratic aspirations, including the ideal of deliberative democracy. Our concrete policy suggestions are in Part V, which includes proposals to improve the workings of Congress, the courts, and the executive branch. Offering institutional de-
fenses of peer review and cost-benefit analysis, this Part also relates our theoretical argument to the matter of product disparagement laws, which received substantial media coverage through a suit brought by beef producers against talk-show host Oprah Winfrey. Finally, Part VI goes beyond the subject of risk regulation, touching on the broader social significance of availability cascades. April 1999]
We now present three examples of availability errors, which will form a background for the subsequent analysis. The first, which is the most detailed, will be particularly valuable in demonstrating the significance of availability cascades, including their potentially lasting influence on law and policy.',
A. Love Canal
Between 1942 and 1953, the Hooker Chemical Company filled Love Canal, an abandoned waterway that feeds into the Niagara River in New York State, with more than 21,000 tons of chemical waste. It then covered the waste with dirt and sold Love Canal to the Niagara Falls Board of Education for $1.20 The local government developed the area, turning it into a neighborhood of more than 200 houses.21 The neighborhood was settled in 1957, and the site of the old canal, which many of the new homes bordered, became a school and a playground.
After several years of unusually heavy precipitation, the canal overflowed its banks in In that year a commission responsible for monitoring the Great Lakes detected the insecticide Mirex in Lake Ontario fish, and the New York Department of Environmental Conservation identified Love Canal as a major source. When the local press began reporting that area residents were worried about the health effects of Love Canal, frighten-
ing tales spread quickly: children being burnt, omnipresent odors inducing nausea, undrinkable water, and black sludge everywhere.24 According to the front-page stories, residents feared that the buried chemicals had resurfaced, making their neighborhood unlivable.
At this stage, neither the state government nor the federal government attempted to reassure the residents about their neighborhood's safety, probably for fear that such efforts would only engender distrust and because they thought the anxieties would dissipate on their own. Taking the cautious route, government officials ordered a series of tests. These detected low levels of carcinogens in basements near the dump site, and in early 1978 the Environmental Protection Agency (EPA) confirmed the findings. The EPA also reported, however, that the observed toxicity was not at all threatening the water was safe to drink, and Lake Ontario was not alarmingly contaminated.26 Nevertheless, lawsuits kept the residents' complaints steadily in the news.
In June 1978, frightening stories in the Niagara Falls Gazette came to the attention of Lois Marie Gibbs, a housewife living in the area.2 Gibbs, who became president of the Love Canal Homeowners Association, played a key role in reinforcing fears of adverse health effects and mobilizing public attention. Indeed, she would eventually appear on national television programs and receive invitations to the state capitol and even the White House In brief, she served as a leading availability entrepreneur of the episode, which culminated in the passage of the Comprehensive Environmental Response, Compensation and Liability Act (CERCLA), generally known as the Superfund
Angered by claims in the Gazette, Gibbs organized a petition drive and started going door-to-door to mobilize protests, eventually developing "a set speech. Partly as a result of these efforts, the local residents held a meeting, and those who "hadn't attended the meeting heard what was going on by
word of mouth. Everybody was very curious. The local health department initially attempted to counter the campaign by referring to controlled studies that found no evidence of leukemia or even of low or fluctuating counts of white blood cells. But because the health department provided no interpretation of what the numbers meant, they "had no meaning" for the residents, and concerns did not dampen.34 "One woman, divorced and with three sick children, looked at the piece of paper with numbers and starting crying hysterically: 'No wonder my children are sick. Am I going to die? What's going to happen to my children?"' Notwithstanding the results of scientific investigations, she felt that "no one could answer. Her anxieties and fears came to be shared by the entire community, which united around the problem: "People who had been feuding because little Johnny hit little Billy were now talking to each other. They had air readings in common .... The word spread fast, and the community became close-knit. Everywhere you looked, there were people in little groups talking and wondering and worrying."
Responding to the outcry, New York State Health Commissioner Robert Whalen declared a public health emergency in the area in early August of 1978.33 Characterizing Love Canal as a "great and imminent peril," he urged area residents to stay out of their basements and to avoid eating anything from their gardens. He also sought the temporary relocation of twenty-five pregnant women and children under two years old, whereupon residents whom the plan would leave behind inquired why their own health should be treated as less important. Gibbs, now a widely recognized activist on the issue, was furious.
I jumped up and said to Commissioner Whalen: "If the dump will hurt pregthe rest of us!? What do you think you're doing?" Now very emotional, I said
"You can't do that! That would be murder!" She and her associates treated technical explanations as just "a bunch of baloney."'41 They also instructed residents to report to doctors and local officials any and all suspected health abnormalities. "Tell them everything," Gibbs exhorted, "If you had three pimples this time last month, and this time you have five-tell them!" April 1999]
A month later, in September 1978, Whalen published a report entitled Love Canal: Public Health Time Bomb, which described Love Canal as a "modem day disaster" that was "both profound and devastating. Other government officials either expressed agreement with Whalen's concerns or simply stood silent. Meanwhile, Governor Hugh Carey, who was in the midst of a close contest for re-election, was trying to be at least as responsive to the concerns as Whalen.44 The stakes for his political career were already obvious, and the residents would reinforce the point by screaming at him: "You're a murderer! You're killing our children!" In early August, he created a multi-agency Love Canal task force and promised state aid for the locality.46 And two weeks later he agreed that 239 of the families living closest to the canal would be relocated at state expense.4 The federal government, too, responded to the growing sense of crisis. The top official of the Federal Disaster Assistance Administration toured the area very visibly on August 5, 1978, and two days later President Jimmy Carter declared an emergency in the area.
Within a few days of Carter's declaration, scientists re-examining the evidence began signaling that the dangers were being overblown. Their findings prompted some government officials, including Carey, to tone down their statements.49 But fears would not dissipate. On the contrary, they intensified when certain new studies, presented before Congress in early 1979, pointed to sky-high rates of nervous breakdown, miscarriage, and various diseases of the urinary system in the Love Canal area.50 These data would be thoroughly discredited two years later some of the effects were evidently fictitious, and others were undoubtedly produced by panic but at the time the data were widely reported as scientifically sound.52 To call for caution in interpreting the data, even to question their validity, was to risk fierce and widespread criticism.53 Information that flowed rapidly among groups was heightening anxieties, and those who challenged the prevailing interpretations of Love Canal were being labeled as accessories to a heinous cover-up.
The title of an ABC television program on Love Canal is representative of the perceptions that now held currency nationwide: The Killing Ground.54 Similar programs followed. In October 1979, for instance, public television aired a documentary on toxic waste, with a long segment on Love Canal.5 Gibbs made every effort to keep the nation focused on Love Canal. "One day, we decided we'd take a child's coffin and an adult coffin to the state capitol ... . It was a way of keeping us in the news.
In January 1980 the Justice Department commissioned a study that found chromosomal abnormalities in eleven of thirty-six Love Canal residents. The study would eventually be discredited as scientifically flawed, but it was leaked to the press before peer review at the EPA, and in May the New York Times promptly gave it front-page coverage. The news media descended on Love Canal once again, painting the image of an ordinary American community mired in a swamp of carcinogenic wastes as the rest of the country just watched. A resident found to have chromosomal aberrations appeared on national television, sobbing that she "just wanted to be a housewife" as in the days before the poisons of Love Canal destroyed her idyllic life.5 In early 1980, at a time when Love Canal was prominently featured in network newscasts almost every day, Governor Carey established a blueribbon panel to review the scientific evidence. Remarkably, given the political climate, the panel endorsed none of the reports of serious health effects. However, its evaluation had no appreciable influence on subsequent events. In May of the same year, a group of Love Canal residents held two EPA officials hostage at the headquarters of the Homeowners Association.5 The next day President Carter ordered the relocation of an additional 700 families at a cost of at least $3 million.6 And soon thereafter, exploiting the President's need for his support in the Kennedy-Carter contest for that year's Democratic Presidential nomination, Carey obtained $15 million in federal assistance toward the purchase of new homes for the relocated residents.
The Love Canal "time bomb," as the press dubbed was not the original source of government concern about abandoned hazardous waste dumps. Even before the 1978 news blitz, the EPA had worked on drafting an ambitious new law to address contamination problems. But publicity about Love Canal was crucial to this law's passage in 1980. Love Canal, and its attendant publicity, was a watershed event that crystallized public concern about toxic waste sites. In that year, Time magazine made the topic of waste sites a cover story, and new network documentaries followed suit. Polls conducted at the time showed that all this publicity dramatically influenced the views of Americans about industrial wastes: Eighty percent favored prompt federal action to identify and clean up potentially hazardous abandoned waste sites.63 Congress responded quickly with the Superfund statute, which called for $1.6 billion in expenditures over five years.64
The perceptual and attitudinal transformation that occurred between 1978 and 1980 has proved enduring. Since that period, Americans have consistently ranked waste sites among the country's top environmental problems. In a highly publicized 1987 study, the EPA found that Americans rank hazardous waste sitesfirst among all environmental problems-above pesticides, acid rain, indoor air pollution, radioactive waste, water pollution, exposure to work site chemicals, tap-water contamination, and thinning of the ozone layer, among many others.65 This preeminence was confirmed by public opinion polls in 1987 and To this date, moreover, American presidents and serious presidential candidates of both major parties invoke abandoned waste dumps as a leading environmental problem. Congress has continued to spend vast sums on clean-up campaigns. By 1994 it had allo[Vol. 51:683
cated a total of $13.6 billion to the cause. Yet it remains unproven that the contamination of Love Canal, assuming it occurred, ever posed a significant risk to anyone. Peer-reviewed follow-up studies conducted by the New York State Department of Health uncovered no abnormal health trends among Love Canal residents, and this finding was supported by later analyses by the American Medical Association, the National Research Council, and the Centers for Disease Control and Prevention. Equally significant, no subsequent study discovered any link between the identified chromosome alterations and the contamination in question. An exhaustive 1982 study by the EPA, based on 6000 samples of soil, air, and groundwater from the evacuated area and other sampling regions, found "no evidence of environmental contamination" at Love Canal.69 And in the same year the Department of Health and Human Services found that the emergency zone was "as habitable as the control areas with which it was compared. A recent analysis of the data goes much further. Looking beyond Love Canal, it suggests that "hazardous waste sites pose an almost negligible risk to human health when compared with the many more fundamental risks we face.
Our challenge here is to explain the dogged persistence of calls to prevent "more Love Canals." In view of the billions spent on the Superfund program, the social significance of the analytical challenge should be clear. Had these resources been devoted to the prevention of other risks, there could have been major benefits as measured in, say, life-years saved. Approximately 400,000 Americans die each year as a result of tobacco use, 300,000 die from poor diet and insufficient exercise, and many thousands more die each year from other preventable causes.72 The scientific evidence is overwhelming that poor diet produces far more cancers than abandoned hazardous waste sites. Yet during the period of skyrocketing concern over Love Canal, poor diet and exercise received almost no attention as national problems, and cigarette smoking was addressed almost exclusively through April 1999]
public health warnings. Indeed, until quite recently governments devoted negligible resources to fighting these causes of death, with the exception of modest informational campaigns against smoking, which were undermined by generous subsidies to tobacco farmers. At much less than the cost of Superfund, tax incentives and informational campaigns to promote better diet and exercise could probably have saved tens of thousands of lives per year.
We do not mean to imply that choosing priorities is simply a technocratic matter, nor that informed democratic judgments should never depart from numerical criteria. The guiding principles of priority-setting should involve subtle qualitative considerations, which will be brought into our analysis in due course. Suffice it to say here that the priority accorded to abandoned waste dumps hardly reflects what one would call the informed judgment of the American citizenry.
[Vol. 51:683
B. Alar
In the interest of reaching the theoretical core of our argument expeditiously, our next two examples of availability cascades are more compressed than the foregoing account of the Love Canal episode. A salient phenomenon in American environmental politics is the "pollutant of the month" syndrome. The essence of this syndrome is that expressed concerns about a particular substance fuel growing anxieties, which then generate an irresistible demand for regulation. These anxieties remain in the headlines until they are bumped off by a new perceived hazard.73
In 1989, one such pollutant was Alar, a pesticide long used on apples. About one percent of Alar is composed of UDMH, a carcinogen. Alar's manufacturer, the Uniroyal Company, embarked on a two-year study of its effects, reaching the half-point of the investigation in January 1989. The preliminary results showed that in rats and mice exposed to moderate amounts of Alar, there is no change in the incidence of tumors.76 But they also indicated a greater incidence of tumors in rodents exposed to high levels of UDMH. On the basis of these tentative findings, the Natural Resources Defense Council (NRDC) made a series of extrapolations, interpreting the results as implying that between 4700 and 6200 preschool children, or about one out of every 4200 exposed to Alar, will develop cancer by age six.77 A
lawyer for the NRDC said, "If EPA doesn't think that the most potent cancer causing chemical in our food supply is grounds enough to declare it an imminent hazard and remove it from food, well, I don't know what kind of risk it takes then to declare an imminent chemical hazard.
The television show 60 Minutes publicized the allegation, presenting its report against a background consisting of a red apple overlaid with a skull and crossbones.79 Ed Bradley, the program's host, began the report as follows: "The most potent cancer-causing chemical in our food supply is a substance sprayed on apples to keep them on the trees longer and make them look better."8 The story received wide coverage in newspapers, magazines, talk shows, and television news programs. It also instigated a public outcry, complete with protests from many celebrities, including actress Meryl Streep, who founded an activist group called Mothers and Others for Pesticide Limits.81 The NRDC's self-conscious agenda was
to create so many repetitions of [its] message that average American consumers
(not just the policy elite in Washington) could not avoid hearing it-from many
different media outlets within a short time. The idea was for the 'story' to
achieve a life of its own, and continue for weeks and months to affect policy
and consumer
The EPA reviewed the evidence and interpretations, concluding that the risk was vastly exaggerated: one in 111,000 rather than one in 4200.83 However, by the time the EPA made its announcement, the demand for apples had plummeted. Apples and apple products had been removed from stores and widely banned from school lunchrooms. Many people were treating apples as a highly toxic substance that one must handle with great care, and only when absolutely necessary. Moreover, doctors and poisoncontrol centers were facing a deluge of calls from frightened parents. One caller asked "whether it was safer to pour apple juice down the drain or to take it to a toxic waste dump. In desperation, the nation's apple growers asked Uniroyal to withdraw Alar from the market. And before the year was out, but after the EPA announcement, Uniroyal agreed to stop domestic sales of Alar, evidently to avoid the costs of contested cancellation proceedings. The EPA itself joined the alarmist bandwagon by announcing that it would
seek revisions of pertinent laws and regulations to make it easier to ban chemicals suspected of being carcinogenic.
Furious about the whole episode, the apple growers brought product defamation suits against the NRDC and 60 Minutes. But the expenses associated with this suit constitute only a small fraction of the social costs generated by the hysteria over Aar's hazards. In Washington State alone, the harm to the apple industry included at least $125 million in losses in the key six-month period. The United States Department of Agriculture put aside $15 million to buy some of the surplus apples. For all these costs, it is not even clear that the withdrawal of Alar resulted in a net benefit to children's health. A regulatory strategy that makes apples more expensive will lower their consumption, producing adverse health effects that may swamp any benefits from eliminating Alar. These observations suggest that Alar's withdrawal may not have survived any form of cost-benefit analysis. In any case, the EPA's initial risk estimate has turned out to be too high. According to its subsequent analyses, only one in 250,000 children exposed to Alar will develop cancer-doubtless a nontrivial risk, but less than half the initial EPA figure, and lower than that of the NRDC by a factor of sixty.90 Thus a 1991 editorial in Science argues that "a clearly dubious report about possible carcinogenicity by a special interest group was hyped by a news organization without the most simple checks on its reliability or documentation." A United Nations panel, along with others who have investigated the data, found that even the EPA's revised figure is too high. Alar does not cause cancer in mice, it concluded, and it is not dangerous to people.
The process that drove the Alar scare provides another example of an availability campaign launched by availability entrepreneurs. The following account puts it dramatically:
and orchestrating its release to the media in so forceful a manner as to compel
ingly familiar: a few suggestive tests involving tiny quantities raised way
expanded further by statistical manipulation, extrapolated against huge populavictims.93 Once Aar became identified as a threat to social welfare and, in particular, the lives of helpless children, it became risky to urge restraint in interpreting the figures. No official, and certainly no politician, wants to develop a reputation for softness on matters vital to children's health. Nor, in the face of reports of danger to children, is any official eager to tell worried parents that they should patiently wait for more scientific research. If some doubters and dissenters shade their views or mute their voices in response to such reservations, the relative content of the publicly available information will obviously get distorted. Specifically, information pointing to danger will become ever more available, raising its plausibility in the eyes of the many people who use availability as a criterion for evaluating the validity of such information. In the process, moreover, the burden of justifying one's beliefs will shift increasingly toward dissenters. Thus, as the Aar cascade took off, the proponents of banning Aar could increasingly take for granted that their safety concerns would be treated with respect. For their part, the opponents had to carry an increasingly heavy burden of being suspected of insensitivity to human suffering.
With Alar off the market, apple growers were quick to find substitutes. These substitutes might well be equally effective against pests without having the minute adverse side-effects of Aar. But we have no scientific basis for ruling out the possibility of a serious mistake. The substitutes may someday be identified as serious hazards. In any case, even if future historians judge the Aar episode to have reached an acceptable or even happy ending, there are socially cheaper ways to bring about a substitution of industrial inputs. It should not be necessary to cause widespread panic or to disrupt production and consumption patterns for the sake of preventing a dubious or minor hazard.
C. TWA Flight 800 Mass demand for regulation can develop especially quickly in reaction to events that involve many deaths. An immediate public reaction to a particular event that makes millions of people simultaneously and independently detect a serious risk does not constitute an availability cascade. Indeed, the availability heuristic may come into play without cascade effects. Independent uses of the heuristic could have social effects-they could even produce law-but they would work on the outcome directly, without triggering reactions by others. Yet sometimes a single event will trigger a rapid availability cascade. A cascade is at work whenever some people's alarmist reactions instill fear in others, whose own reactions then sow fears in still more individuals.
A striking example of a quick availability cascade involves reactions to the 1996 crash of TWA flight 800, which killed all 230 people on board. With about ninety-five percent of the wreckage now recovered, the cause of the accident remains unknown, although none of the evidence implicates a bomb or a missile. Nevertheless, the public outcry that followed the crash quickly led to heightened security measures at airports all across the United States and to the formation of the White House Commission on Aviation, Safety, and Security.
There are indications that the relevant government officials did not believe that the crash resulted from terrorism but with wild rumors circulating, and with denials of terrorist activity seeming callous or reckless, they simply pretended to take the claims seriously when expressing themselves publicly. A mere forty-five days after its creation, the White House Commission proposed extensive additional safeguards against terrorism. And within a month of this initial report, President Clinton signed most of the Commission's recommendations into law. The direct cost to taxpayers was estimated to be $400 million per year.95 The total price tag, including all costs to consumers and producers, apparently exceeds an estimated $6 billion.96
Yet the new security measures may not save any lives. On the contrary, they may even cost lives. Having made airline travel more expensive and more cumbersome, these measures have reduced the relative attractiveness of flying. Flying, however, is far less dangerous than driving. In fact, air travel is now the safest mode of transportation.97 Between 1960 and 1995 the fatal
accident rate in commercial aviation dropped from 0.011 fatal accidents per million aircraft miles flown to 0.0005. 91 By making some people substitute car travel for air travel, then, the adopted measures may well increase, rather than decrease, the number of unnatural deaths.99
Additional examples from recent years include mass outcries over Agent Orange, asbestos in schools, and automobile airbags that endanger children.1°° Each of these cases has culminated in politically irresistible public demands for government action. Their common thread is that people tended to form their risk judgments largely, if not entirely, on the basis of information produced through a social process, rather than through personal experience or investigation. In each case, a public upheaval unfolded as vast numbers of players reacted to each other's actions and statements. And in each, the demand for swift, extensive, and costly government action came to be considered morally and socially desirable-even though, in most or all cases, the net benefit of the resulting regulations may well have been negative.
What explains widespread fixations on unthreatening waste dumps, nearly harmless chemicals, and unlikely causes of a tragic airplane crash, when for years on end far more serious health hazards, such as breast cancer, indoor air pollution, "junk food" consumption, and asthma in the inner city have commanded comparatively little attention? What do the episodes involving Love Canal, Mar, and TWA 800 reveal about the formation of social policies? Do the underlying cognitive and social mechanisms carry lessons for the social sciences or study of the law? To what extent do they complement, reformulate, or undermine accounts of legislation and regulation based on the currently fashionable variants of public choice theory? Finally, what implications do the mechanisms have for democratic theory?
At first blush, the episodes in question confirm an essential finding of cognitive psychology: as individuals, we are capable of developing and retaining beliefs that are scientifically unjustified and even unjustifiable. The basis for this finding bounded rationality. Because our cognitive limitations preclude us from thinking deeply about more than a small fraction of the issues that bear on our values, behavior, and welfare, we rely on mental shortcuts that leave us misinformed in many contexts, even seriously wrong. 104 The episodes are consistent also with one of the central themes of the public choice school, namely, that citizens of a large polity have incentives to remain "rationally ignorant."'05 Why should the residents of Love Canal, or the rest of us, devote time and effort to learning the full truth about the alleged contamination when as individuals we each have only one voice and one vote to influence policies that the choices of many millions will help shape? By the logic of rational ignorance, if activists such as Lois Marie Gibbs or the Natural Resources Defense Council are exerting massive efforts on a risk-related problem, this is because their extraordinary gifts, or special social circumstances, or unusual political resources, make them believe that they can overcome any obstacles to collective action. As ordinary individuals we cannot affect politics in any meaningful way by ourselves, so most of us opt to sit back and let activists shape public discourse. Accordingly, we become informed about issues only insofar as the learning process is costless, entertaining, or a matter of civic obligation.
It would be a mistake, however, to treat these episodes merely as additional manifestations of bounded rationality and rational ignorance. Both interpretations raise the question of why, in each case, millions of Americans fell victim to exactly the same delusion. People evidently formed their perceptions interdependently, with each individual's expressed perceptions helping to shape those of others. As a vivid case in point, the perceptions of the Love Canal residents took shape, in significant measure, through their frequent meetings and informal communications. Equally important, invoking bounded rationality or rational ignorance sidesteps the challenge of explaining why people came to believe what they did. By 1979, few mentally
competent Americans, and probably none living in the Love Canal region, were "rationally ignorant" about the canal's contamination. However severe their cognitive limitations, millions of Americans knew something, and what they knew was converging to generate an alarming view about the dangers of industrial wastes.
What Americans "knew" depended, in the first instance, on their predisposition to believe certain claims more readily than others. Our next task is to identify the cognitive mechanisms and biases that impinge on risk perceptions and preferences. Turning subsequently to the social processes at work, we will explore how these interact with psychological processes to fuel mass delusions that have large consequences for regulatory policy. April 1999"]
A. Cognitive Processes
Cognitive findings about risk perception are generally studied through laboratory experiments. Over the past quarter-century, cognitive psychologists have reported a bewildering array of findings, and the publication of new findings continues. These findings fall into several categories. The following is a summary of this increasingly complex literature, with an emphasis on what is critical for our purposes.
1. Biases and heuristics.
A number of experiments have identified systematic problems in the ways people receive, store, retrieve, and process information. A particularly relevant problem stems from the framing effect, whereby given data are evaluated differently depending on how they are framed. A striking example is that people are more eager to undergo treatment for an ailment when they hear that ninety percent of the patients treated five years ago are still alive than when they learn that ten percent of the treated patients have died. Other relevant experiments on probability assessments uncover an anchoring effect, by which an initial judgment or number, such as a preliminary guess of the probability of falling victim to terrorism, serves as a perceptual "anchor." The anchor influences the assessment reached after adjusting or updating in the light of new information. For example, if the initial figure is one in 10,000, the ultimate assessment will be lower than if the initial figure was one in 100. The anchoring effect helps explain damages awards made
by juries. It undoubtedly also contributes to perceptions of environmental risks consider the immense difficulty of persuading people who have heard that a waste site poses a huge danger to believe that it is actually safe. A highly relevant bias is the alarmist bias. When confronted with a range of information suggestive of probabilities, people searching for a residential community tend to focus on the most alarming situations that they might encounter.1 In other words, the worst possible scenarios loom large in people's minds, distorting their risk perceptions and their behaviors.
Much remains unknown about the mental processes responsible for these various effects. What is clear is that many errors result from the cognitive shortcuts, or heuristics, that we use in processing, information. The anchoring effect is an example of a distortion generated by a heuristic. Another key heuristic is the representativeness heuristic, a mental shortcut by which causes are treated as resembling their effects. "A person who follows this heuristic evaluates the probability of an uncertain event, or a sample, by the degree to which it is: (i) similar in essential properties to its parent population and (ii) reflects the salient feature of the process by which it was generated."112 For our purposes, the most critical heuristic is the availability heuristic, which involves estimating the probability of an event on the basis of how easily instances of it can be brought to mind. This heuristic can produce substantial distortions whenever certain alternatives are easier to imagine than others. Thus, a person may overestimate the incidence of AIDS simply because many of his acquaintances have the disease and he can easily think of AIDS cases. Alternatively, a person may underestimate the incidence of AIDS because he cannot think of anyone who is among its victims. An independent but closely related phenomenon involves salience and vividness: salient or vivid information makes a far greater impression than dry or statistical information.1
[Vol. 51:683
The availability heuristic can obviously produce judgmental mistakes with unfortunate behavioral consequences." The ease with which an event's occurrences can be recalled need not have any bearing on its actual frequency.11 Insofar as we estimate the incidence of a disease with the aid of the availability heuristic, we fail to compensate for special characteristics of our own knowledge, experience, memories, and acquaintances as a result, our judgments contain systematic errors that make us behave either too cautiously or not cautiously enough. Likewise, if alarmist information is more salient, and thus more readily recalled, we may end up exaggerating the gravity of certain risks.
It is undoubtedly true that in certain contexts cognitive heuristics will produce beneficial results while economizing on decision costs. But their redeeming features should not be overstated, for the results of the economizing can be very harmful.' Indeed, people systematically err in assessing the number of deaths due to particular risks. While underestimating dangers that are not highly publicized (heart disease, strokes, asthma), they grossly overestimate risks to which the media pay a great deal of attention (accidents, electrocution).'
2. Prospect theory.
Cognitive psychologists have also uncovered distinctive features of the value functions through which people evaluate risks and options." These findings cast serious doubt on expected utility theory, which provides the behavioral basis for vast segments of the contemporary social sciences.120 A key finding is the certainty effect. Because people attach intrinsic value to certainty, their well-being improves more when the probability of an adverse effect drops from 1.0% to zero than when it drops from 2.1% to differently, their utility changes exhibit a discontinuity at the point where the risk in question disappears. An equally striking finding is loss aversion,
which is the tendency to benefit less from a given gain than to be harmed by an equivalent loss. People experience less satisfaction from winning, say, a $100 prize than they feel dissatisfaction upon finding out that the prize has been cancelled. The disparity can be enormous.
Whether a particular change qualifies as a loss or a gain depends on the relevant reference point, which can be manipulated. Is a change in the risk associated with some environmental hazard a loss or a gain? The answer could well depend on whether the reference point is 1979 or 1999. Loss aversion thus implies that one can distort policy evaluations through framing effects. Like loss aversion, the certainty effect can be triggered by choosing an appropriate reference point. We will show later how the certainty effect and loss aversion connect with the availability heuristic to shape, and be shaped by, availability cascades.
3. The relative acceptability of risks.
Yet another set of findings involves the qualitative features that enhance or diminish the acceptability of risks.1 Most people are not functionaries seeking to maximize life-years through regulation. Interested as they are in leading meaningful, comfortable, balanced, and morally satisfying lives, they care about the qualitative differences among risks. These differences thus generate diverse acceptability effects that shape their pertinent preferences and values.
One particular acceptability effect is the controllability effect, which makes a given risk more tolerable insofar as it appears controllable. Risks associated with driving arouse less concern than those of flying, because people think that they have relatively more control over the former. Likewise, people treat the risks of mountain climbing as a negligible social problem insofar as they perceive those risks as controllable through equipment choice, path selection, or simply picking a different adventure. The control-
lability effect constitutes just one of the many ways in which lay evaluations differ from those of experts. In addition to controllability, ordinary people pay special attention to risks that are potentially catastrophic, likely to affect future generations, inequitably distributed, or involuntarily incurred. And they de-emphasize risks with natural origins or unidentifiable victims. The following table summarizes the major acceptability effects:12
Many of these acceptability effects require further analysis. The line between controllable and uncontrollable risks is usually one of degree, not of kind. Likewise, there is no sharp distinction between voluntary and involuntary risks. For our purposes, however, the basic point is that various characteristics of risks affect lay judgments about whether they call for public regulation. These characteristics go much beyond the actuarial tables used by policy experts.
4. Beyond individual psychology: the role of social influences.
All three of the reviewed classes of cognitive findings about risk perception-biases and heuristics, prospect theory, and acceptability of risks-have obvious importance, and they have started to receive considerable attention in studies of policy making and the law.1 But even collectively these findings leave major gaps. They say nothing about the social dimensions of information acquisition, retrieval, processing, and transmission, and they disregard the social mechanisms that shape risk judgments and preferences. In the typical laboratory experiment involving risk judgments or preferences, experimenters tightly control all sources of information, and subjects are kept from communicating with one another. Prevented from sharing information, the subjects solve problems and answer questions in isolation from others. By design, therefore, there are no interdependencies among individual responses.
Outside of laboratory settings, of course, people consult each other they learn from each other they influence one another's values they defer to each other they share sources of public information they try to mold each other's beliefs and values and their social interactions shape their knowledge, perceptions, and interpretations. In sum, social processes contribute to the evolution of risk perceptions and also to the formation and transformation of
relevant preferences. These processes interact with all of the biases, heuristics, and effects discussed above. April 1999]
B. Interactions Between Social and Cognitive Influences: The Centrality of
the Availability Heuristic
Let us consider a few cases in point. The frames through which individuals interpret a situation are generally formed socially. Their reference points for assessing gains and losses are generally given by popular conventions and communicated through conversation, not chosen by individuals autonomously. Anchors, which in principle can vary enormously across individuals, are in practice the product of social interactions and widely shared information flows. For example, a key anchor for a damages award will be the same for every member of a jury by virtue of the plaintiff s request.
In contexts involving risks, then, both perceptions of a risk and its acceptability are framed socially. Whether people feel in control of a risk and what they consider representative of it are both determined through their interactions with others. This is consistent with findings that perceptions and attitudes toward any given risk can vary greatly across cultures and in any given culture across time. Indeed, an objectively fixed danger can appear controllable in one decade but uncontrollable in another, and enormous in one country but negligible in another. During the Love Canal episode, residents heard stories from each other politicians fueled fears through statements sympathetic to the apparent concerns and the media reported such developments to the entire nation, compounding the fears of both the Love Canal residents and people who lived, or believed they might live, near other abandoned waste dumps. Perceptions and fears fed on each other. Thus, neither the information that individuals received and processed nor their consequent sensitivities were in any meaningful sense exogenous to the episode. Individual dispositions and attitudes were formed and transformed through an emphatically social process.
As with George Orwell's "equal animals" of which "some animals are more equal than others,"'1 one heuristic is more fundamental than the restat least in social contexts where people, lacking reliable information of their own, look to others for interpretations of events. In such contexts, information does not influence individual perceptions unless it becomes available in the public domain, so the availability heuristic necessarily interacts with all the other heuristics and biases. Insofar as people exchange information with one another, the availability of information determines the characteristics of framing, representativeness, anchoring, and reference points. Likewise,
availability influences perceptions of the risk traits listed in Table I. If public discourse tends to code all pollution as a loss relative to an imagined state of environmental purity, that imagined state will become the reference state, and the easy availability of this coding will influence how individuals frame their judgments about pollution. In this manner the availability heuristic will promote frames that trigger loss aversion. Naturally, no loss aversion will come into play if public discourse emphasizes the environment's cleanliness relative to the past or relative to another society. In brief, the availability heuristic rules the roost.
Risk judgments and preferences are formed through a circular social process. Identifiable social mechanisms govern the availability of information and through the mediation of the availability heuristic, this availability shapes, on the one hand, judgments about the magnitudes of various risks and, on the other, the acceptability of these risks. Simultaneously, the consequent individual actions and expressions affect the availability of information. There are thus two-way interactions between social outcomes and individual cognitive processes. These interactions form an availability cascade whenever individual uses of the availability heuristic increase the public availability of data pointing to a particular interpretation or conclusion, and this increase in availability then triggers reinforcing individual responses.
In contexts subject to availability cascades, the distribution of beliefs across the relevant population may entail multiple equilibria. In other words, the same objective information may be capable of sustaining different, even extremely different, belief patterns, depending on whether a cascade occurs and, if so, which of many possible cascades is initiated. One risk may gain salience, receive an enormous amount of attention, and become the object of tight regulation, while another risk, which experts deem equivalent, is treated as "part of normal life."
Against this background, it is not surprising that culturally and economically similar nations can display dramatically different reactions to identical risks. While nuclear power enjoys widespread acceptance in France, it arouses considerable fear in the United States. Another implication of multiple equilibria is that any given risk assessment may change suddenly and dramatically even in the absence of any major change in the relevant
scientific evidence. Over a short time, people convinced that their environment is perfectly livable may come to think, because everyone else seems to be getting alarmed, that it is replete with dreadful carcinogens. The opposite transformation is also possible. Entire nations may become convinced that their environment is essentially clean along one dimension or another, simply because this judgment is widely shared. And insofar as people lack independent means of judging a claim's validity, there is a danger that the beliefs generated by a cascade will be factually incorrect. Millions of individuals may develop erroneous beliefs simply by giving each other reasons to adopt and preserve them.
Availability cascades do not appear randomly. For one thing, activists choose which dangers to stress publicly. For another, if an availability cascade is to unfold, enough people must initially be receptive to it. Skillful availability entrepreneurs have insights into the sorts of events to which relevant segments of society are receptive. The underlying social conditions thus create what one might call an availability market-a market in which certain risks are possible foci of cascades. What this market ultimately selects will obviously change over time and place. In late-twentieth-century America, the perceived risks of nuclear power are far more likely to trigger an alarmist cascade than those from sugar consumption (because the inconvenience of major change is obvious), or lighting candles at the dinner table (because it is common knowledge that people generally rely on electricity for illumination). Outside of the immediate context of risk regulation, a claim that pornography constitutes a form of sex discrimination was more likely to be taken seriously in the aftermath of the civil rights movement than in earlier times, when discrimination did not enjoy widespread recognition as a national problem. 13s
The concept of an availability market suggests the possibility of competition among availability entrepreneurs. Advocates of putting a cap on punitive damages will point to egregious cases of excess, such as the awarding of millions in damages because of hot coffee spilled on someone's arm at a fast
food restaurant opponents of such a cap will refer to egregious cases of wrongdoing in which juries awarded relatively modest awards. Critics of environmental regulation will point to scares that resulted in massive waste, while advocates will highlight cases in which the nation responded too little too late. In explaining the outcome of such competition, the capture theory of regulation invokes the relative strengths of the competing interest groups, as measured, for instance, by capacity to raise funds and deliver votes. Without denying that relative strengths matter, our argument stresses that these need not be decisive. The objectively weaker side may triumph simply by exploiting the right cognitive biases, timing its campaigns skillfully, and pressuring the right social groups, thereby putting in motion an availability cascade in its favor. The side that succeeds in triggering a cascade favorable to its cause will then see the interdependent responses of ordinary individuals make its advantages grow explosively and its initial political weaknesses turn into irresistible strengths. After the cascade has run its course, the triumphant availability entrepreneurs will appear to command far greater resources than their defeated opponents. Yet this outcome would not have been predicted at the start. In fact, observers might have predicted the opposite outcome.
We shall distinguish between two components of an availability cascade: an informational component and a reputational component. The former works through genuine changes in people's beliefs. If individuals A, B, and C become convinced that Love Canal is spreading cancer, D, upon learning of this development, might believe the claim on the grounds that her friends cannot all be wrong. In believing something simply because many others consider it true, D would be compensating for her lack of reliable personal information. The reputational component of an availability cascade works through expressions of conviction, weakly or uncertainly held, possibly even feigned, that people produce in order to retain social approval and escape censure. Imagine that A and B suggest that Love Canal is dangerously contaminated and that C, although unconvinced by the claim, refrains from expressing his misgivings and endorses the alarmist position simply to avoid being charged with stupidity or callousness. In this illustration, the availability of information pointing to Love Canal's danger rises through misrepresentations motivated by perceived social pressures.
Extending the latter illustration, suppose that D comes onto the scene, finding that everyone who has spoken up about Love Canal appears alarmed. Unaware that one of the statements is untruthful, she becomes alarmed herself, even though she would have felt secure had she had access to C's unex[Vol. 51:683
April 1999] pressed reservations. This extension demonstrates how the reputational component of an availability cascade may support its informational component. Each component bolsters the availability of information pointing to serious danger. The next Part will develop these possibilities in greater detail.
An analysis of any mass upheaval that triggers political and legal responses to perceived risks must take account of two sets of influences: (1) social influences on the individual, and (2) individual influences on society.
The first set consists of the effects that social variables have on personal variables. The social variable of greatest interest here is public discourse, which is the ensemble of publicly expressed or conveyed sentiments, ideas, and information that individuals use as gauges of what others know and want. Policy initiatives and enactments, including steps taken by official agencies, are also relevant. Public discourse and other social variables influence three types of personal variables: people's risk judgments (perceptions of the prevailing risks they face), their risk preferences (orderings of alternative risks), and their risk-policy preferences, or simply their policy preferences (orderings of possible ways of regulating risks). The second set of influences runs the opposite way, from personal variables to social ones. It consists of the impact that individuals have on public discourse through their own personal transformations.
The two sets of influences thus form a circular process. Public discourse shapes individual risk judgments, risk preferences, and policy preferences and the reshaped personal variables then transform the public discourse that contributed to their own transformations.
In ordinary language, the term "public" is employed to connote both openness and collectiveness. It is the former sense that is relevant here. Unlike a "private" variable, a public variable is one that is generally visible. Strictly speaking, a private characteristic, such as a private perception of a chemical spill's risk, is known only to its bearer, although people close to the individual, including his relatives and close friends, may have good insight into what he is thinking and feeling. Because of its visibility, the transformation of a public variable can have sudden and direct effects on individual thoughts and dispositions. If a newspaper report suggests that a water supply is safe, thousands of readers may instantly feel reassured.
By contrast, the immediate effects of private variables are necessarily limited, although, as we shall see, they can have important effects over longer time spans, through less direct channels. If an official investigates scientific reports about a waste dump and becomes convinced that worries are unjustified, this knowledge itself will have no impact on the information available to alarmed residents. What will influence the perceptions of residents is what he says publicly. It is critical to recognize that the official's public pronouncements are manipulable. Indeed, they can diverge from the thoughts that he carries within his head and from the knowledge he conveys to a confidant. To avoid charges of insensitivity, even to avoid having to justify an unpopular position, he may make speeches and promote policies that convey deep concern about a waste spill that he actually considers harmless.
Just as an official may tailor his public pronouncements to protect his reputation, so, too, may the other individuals who contribute to public discourse and public activity. Let us distinguish, therefore, between the private and public variants of the variables that characterize individuals. A given resident of Love Canal has a private risk judgment and also a corresponding public risk judgment. Depending on the reputational costs and benefits associated with alternative public acts and expressions, the latter may differ from the former. In particular, the resident may convey an interpretation that under- or overstates what she would express privately. Likewise, in any given context the resident's private risk preference and private policy preference may differ from her corresponding public risk preference and public policy preference. Whenever she chooses to express different preferences from those that she holds in her own mind, she engages in a form of preference
falsification. And by misrepresenting her risk judgment in public, she engages in a form of knowledge falsification.
The distinction between private and public variables calls for a refinement to the circular process described above. People's public judgments and preferences influence both the private and the public variables of other individuals. But the mechanisms are separate. In the former case, the influence rests on the informational value of public words and deeds in the latter, it works through the generated reputational costs and benefits. As with any bidirectional relationship, one gains analytical clarity by focusing on each inference separately. We shall start with the transformation of private variables under the influence of public variables, then move onto the reverse influence. These analytical steps will prepare us for a fuller description of availability cascades, including the efforts that perceptive individuals undertake to exploit them.
A. The Social Construction of Risk Judgments and Preferences
Because it is costly.to gather pertinent information, individuals ordinarily seek to free ride on knowledge that is publicly available through sources ranging from gossip and rumors to scientific reports. Most risk judgments rest on little, if any, personal investigation they depend largely, if not wholly, on trust placed in the judgments of selected others. Consider Barbara Quimby, the Love Canal resident who sobbed before television cameras. Quimby had not analyzed water samples or studied their impurities.
STANFORD L4 WREVIEW Her fears were based entirely on the apparent perceptions of her acquaintances and reports in the mass media.144 That a belief is a product of social influences does not mean that it is weakly held, or superficial from the standpoint of its holder on the contrary, it may run very deep. The resident of a contaminated area may be entirely convinced that the pollution will kill anyone who stays in the area, even though her information comes from statistics, claims, and interpretations that she has done nothing to verify.
Most, though not all,1 personal risk judgments stem primarily from social influences rather than hardwiring. If most Americans consider industrial waste dumps to pose much greater dangers to themselves than the millions of deer that roam the nation's highways, the reason lies in public discourse, notably the content of the mass media. Whereas the electronic and print media are replete with reports of industrial waste dumps, they seldom pay attention to the traffic injuries and deaths caused by deer herds that have grown fifty-four-fold since the 1940s because of hunting restrictions, lack of predators, and abundant new habitat. As a consequence, many people who consider environmental contamination an omnipresent and devastating danger think of deer as the affectionate, harmless, and vulnerable animals portrayed by Walt Disney's moving fable Bambi.
A complicating factor is that communities typically harbor subcommunities whose members interact primarily among themselves. Depending on the context, a given subcommunity may discount, even ignore, information provided by outsiders. That the media as a whole are bombarding society with one particular interpretation of an event provides no guarantee, then, that every segment of society will take notice. Insofar as subcommunities live in isolation from the rest of society, the reach of an availability cascade will be limited. Yet subcommunities that resist a particular availability cascade may themselves produce internal, smaller-scale, local availability cascades. The very processes that we are outlining may account for the spread and persistence of views within subcommunities. And in principle, therefore, the private risk judgments within a given subcommunity may lie closer to the truth, however we choose to define it, than those dominant outside it.
Private risk judgments and risk preferences also have pre-social determinants. For example, most people are predisposed to fear snakes but not vi[Vol. 51:683
ruses. In the absence of social influences, they will take greater precautions against snakes that happen to be harmless than against potentially lethal health hazards. Nonetheless, even in such contexts socialization can make a huge difference. We can be educated, for example, to feel comfortable around reptiles. Likewise, we can learn to consider certain risks less tolerable than others that pose equivalent, if not greater, risks. We may learn, on the one hand, that it is unconscionable to allow deaths from waste sites that are by-products of our material prosperity, and on the other, that fatalities from collisions with deer are the sad but acceptable consequence of trespassing through deer country.149 Such learning conditions us to become less tolerant toward risks associated with industrial wastes than toward equivalent risks posed by deer.
All sources of basic socialization-parental upbringing, formal education, and culture--contribute to the formation of private risk judgments and risk preferences. For the purposes at hand, however, these influences can be treated as part of a fixed background. The availability cascades of greatest interest here run their course over periods too short for them to change appreciably. Especially relevant to the present discussion are the activities of the mass media. Media outlets have diverse and complex objectives, but it is clear that most newspapers, magazines, and television stations seek to enlarge their "audience."'' It is also clear that this goal generally causes them to emphasize dangers over security, give some risks more exposure than others, and treat certain risks as particularly serious. The media exercise these influences by controlling the prominence with which stories are pursued, by selecting, soliciting, and shaping the quotations used in developing storylines, and by selecting the facts reported to advance editorial purposes, among other mechanisms.'
To be sure, the media, especially the print media, feature various opinions on many issues, and on matters of risk they alone cannot account for an observed homogenization of individual knowledge or dispositions. But the diversity of opinion can be illusory because the editors of media outlets typi-
cally select commentators to construct a truncated distribution of views centered on policy positions of their own.152 During the Love Canal episode, the media did indeed exhibit differences over the best response. But the "moderate" commentaries-those at the ideological center-favored a massive cleanup, with most other opinions differing essentially in the details. And despite the appearance of open-ended debate, some risks may receive enormous attention, while others are neglected. The biases of any one newspaper may not matter, of course, if they are offset by opposite biases of other media outlets. But in the course of an availability cascade, one particular bias will spread across the media and grow.
Private risk judgments and preferences shape the corresponding private policy preferences, the orderings over alternative policy options that people privately favor. The greater the dangers individuals ascribe to industrial waste dumps, with all else constant, the more they will favor expenditures for cleanups. By the same token, the more intolerant they are of industrial pollution, again with all else constant, the more they will favor such expenditures. In sum, social influences shape the private policy preferences of individuals through two complementary channels: by shaping their perceptions of risks and by molding their attitudes toward sources of risk.
B. Informational Cascades
For the moment, let us abstract from the social pressures that cause people's private characteristics to diverge from their public characteristics. As an analytical step, we are thus assuming that no differences exist between private and public risk judgments, between private and public risk preferences, or between private and public policy preferences. Against this simplified background, consider the members of a society debating how to respond, if at all, to a toxic spill. As individuals, they all want to know what will be best for themselves, their families, and their communities. Generally, however, they will devote little time to examining the scientific evidence because, if nothing else, they would not know how to interpret such data without extensive study. Most of the community's members will form their private risk judgments, risk preferences, and policy preferences through very limited information. Moreover, the acquisition and processing of the readily available information will be shaped by one or more cognitive heuristics that economize on both mental effort and time. Suppose that large segments of the media are comparing the source of contamination to leaded gasoline, which was banned after a cost-benefit study showed it to be a highly toxic
pollutant. Individuals exposed to the media are more likely, holding all else fixed, to consider the contamination as representative of high-risk chemicals, with all the associations that follow. The key precondition for an erroneous informational cascade is thus that most citizens have little reliable information of their own about the claim in question.
Similarly, if the media begin touting tough new industrial regulations to prevent future waste leakages, with little attention to the downside, citizens will become sensitized to the benefits of tougher controls, without necessarily developing an awareness of the costs.1 The point is critical, for people display much less eagerness to obtain particular benefits when they gain awareness of the corresponding costs. Widely reported evidence of the risks associated with x-rays and automobile driving have generated limited behavioral responses because the huge costs of giving up these amenities are self-evident.' In cases where the costs are not as clear, the content of media coverage may have major consequences for people's understanding, by determining the relative availability of both the relevant data and their interpretation. Insofar as the availability heuristic shapes people's interpretations and desired policy responses, the media may lead people to exaggerate the dangers of the situation at hand, convince them that its elimination should receive priority, and make them discount the inconveniences that would accompany an elimination attempt. The opposite effects are possible too through neglect the media may breed ignorance about a genuine danger, thus dampening the demand for action.
A strictly informational cascade occurs when people start attaching credibility to a proposition P (e.g., a certain abandoned waste dump is dangerous) merely because other people seem to accept P. To recast an earlier illustration, suppose that Ames signals that he believes P. Barr, who would otherwise have major reservations, believes P because Ames appears to do so. Cotton, who would have dismissed the proposition as silly, begins taking it seriously upon discovering that not just Ames but both he and Barr are believers. Noticing that Ames, Barr, and Cotton all seem alarmed, Douglas then accepts P without further thought. When Entin learns that all of his friends believe P, he joins the pack of believers on the grounds that their shared understanding cannot be wrong.
Ordinarily, individuals differ in their preconceptions, the reliability of their personal sources of information, their openness to public discourse, and Ap-ril 1999]
their sensitivity to changes in the apparent views of others.15 These differences fulfill a further precondition of any cascade: heterogeneity in individual responsiveness to social signals. In the absence of variations, everyone would adjust simultaneously to new information, producing not an informational cascade but a sudden collective shift by independent actors. With a cascade, adjustments come at different times, with some individuals becoming convinced of a serious danger at the earliest sign of adverse health effects, but others remaining skeptical to varying degrees until more information becomes available.158 This is an important part of the process that drove the three episodes discussed above, though, as we shall see, not the whole story. In each of those cases many people lacked the means to form their own judgments, so they came to consider the alleged problem serious by accepting the dominant opinion. In the course of an informational cascade, the perceived validity of a claim grows progressively stronger with the number of apparent believers, and people's doubts weaken, possibly even disappear. In accepting a belief, each individual strengthens the case for acceptance, which results in additional acceptances that strengthen the case even further.159 The ultimate outcome can be a widely shared judgment based on little information. Although commonly held, the judgment can also be quite fragile, in the sense that it may shift as a result of small shocks. This is so precisely because it is based on little information.1
To be sure, this stylized logic oversimplifies the way that most individuals interpret public claims. Numbers alone do not give information validity. Among the other influential factors is credibility. If one hundred people are denying that the contamination of Love Canal poses a danger to human beings, and a spokesperson for the National Association of Chemical Manufacturers joins the chorus by releasing data consistent with the claim, most listeners will discount the data on the ground that his association has an enormous stake in making the contamination seem trivial. His statements might even kindle suspicions of a cover-up, making listeners more, rather than less, receptive to evidence of serious danger.1 In any case, people's preconceptions make them exhibit selective trust and mistrust. Some people are skeptical of governmental claims about risk others think that if a corpo-
ration makes a claim the opposite must be true still others are inclined to believe that environmental lobbies are in the business of creating unnecessary "scares." Individuals who trust one set of actors will sometimes mistrust another set, and almost any large population will contain a great deal of diversity on this front. Consequently, informational cascades generated by the availability heuristic may operate like wildfire within one subgroup without spreading within another. It follows that at any given time different subgroups may experience their own informational cascades. One subgroup may come to agree that the idea of global warming is a fraud, another that all pesticides pose a grave health hazard, still another that the U.S. government engineered the AIDS crisis, or even invented the AIDS virus, to destroy an ethnic minority.
Like the communicator's trustworthiness, the risk traits listed in Table I may affect the impact of any given communication. For example, a report that points to a familiar problem such as industrial pollution will ordinarily be more credible than one that draws attention to an unfamiliar problem, for example, the hazards of breathing the air of used book shops. As a rule, however, the greater the number of people who hold a particular interpretation of reality, the stronger is the perceived validity of that interpretation. April 1999]
C. The Distortion of Public Discourse Through Social Pressures
By abstracting from social pressures, the previous Part disregarded the possibility that people will misrepresent their thoughts in order to accommodate the perceived agendas of others. But only rarely are social pressures negligible, and purely informational cascades are the exception rather than the rule.
1. Expressive distortions. In practice, each public signal or communication will differ from its private counterpart insofar as people seek to protect or improve their social standing through preference and knowledge falsification. Depending on the apparent social pressures, a group of officials may endorse reports that Love Canal poses a huge threat to nearby residents, when they know of data that make the reports suspect and they may feign approval of a relocation plan even though they consider the step ludicrous. The first case of insincerity constitutes a case of knowledge falsification. It signals to others an exaggerated risk judgment, one that inflates the corresponding private perception. The second act provides a case of preference falsification, as it makes the support for relocation greater than one would find if officials were polled through a secret ballot. Simply because of reputational incentives people may echo a popular sentiment, even though they have not made up their minds and feel confused, or a popular judgment, even though they are clueless about its veracity. Plainly, all such forms of falsification were present in the Love Canal episode.
Knowledge and preference falsification are common because people want to be regarded and treated well and, equally important, this desire is common knowledge. These conditions provide individuals and groups opportunities to advance their agendas merely by expressing approval of their public supporters and disapproval of their public opponents. The granting of approval operates as a "subsidy" to supporters and that of disapproval as a "tax" on opponents. Insofar as some individuals' need for social approval outstrips their other needs-more precisely, "reputational utility"'16 looms large in total utility-they will tailor their expressed beliefs and conveyed dispositions to their audiences. A related means of earning the affection, support, and goodwill of a group is to help punish its enemies and reward its friends. Accordingly, a common form of preference falsification entails criticizing people whose expressions one likes, or at least does not dislike. For instance, a New Yorker aware of the lack of alarming scientific evidence may, in the interest of bolstering her reputation, intimate that an official who counsels calm should be removed from office for displaying lamentable "weakness on the environment." Through such actions, preference and knowledge falsification contribute to the very social pressures that produce and reproduce them.
Preference and knowledge falsification are sometimes undertaken merely to avoid having to explain oneself to an audience. If almost everyone appears to consider Love Canal a "killing ground," the few who counsel inaction will be expected to justify their expressed preferences at length. By
contrast, those who endorse a state of emergency will not be required to explain themselves. Because the burden of proof falls on themselves, skeptics may choose to keep quiet, or even to join the dominant chorus, simply to be left alone. Thus a precondition of a reputational cascade is widespread willingness to make behavioral or expressive adjustments in the interest of improving one's standing. April 1999]
2. Depth and width of a public consensus.
The social pressures created by sincere and insincere expressions reflect more than the sum of communicated preferences. All else equal, a rich person's public preference will impose more pressure than that of a poor person, because the former possesses more effective means to tax and subsidize. Likewise, the preference of a high bureaucrat will generally impose more pressure than that of a lowly clerk, because the former commands a greater capacity to confer or deny favors.16 Another relevant factor is the apparent "depth" of the communicated preference. For example, if five people insist, with great confidence and intensity, that failure to recycle one's aluminum cans constitutes a horrible crime against future generations, their statements may exert greater pressure than the mild concerns expressed by fifty others. By the same token, when five million people seem to believe a particular proposition, the very "width" of the belief will impose pressure.
From the individual's point of view, then, both the depth and the width of publicly conveyed convictions are relevant. A wide and apparently deep public consensus will create enormous reputational pressure, and it may also provide considerable information about the underlying private preferences. By contrast, a wide but shallow public consensus will impose modest pressure that private dissenters are likely to find easy to resist publicly, and it will generate less information about private preferences.
3. Social subdivisions and other complexities.
In actual societies, people face diverse audiences, not a single, monolithic audience whose members all tune in at the same time. To the extent that their audiences are separated from one another, they may vary their expressions from one to the next. Having endorsed a relocation decision before one audience, they may dodge the issue before another, and criticize the step before yet another. Such shifts in behavior are typically associated with politeness. In the unusually sensitive social domain of race relations, researchers find that many Americans of all backgrounds formulate their interview
responses differently, depending on the interviewer's perceived race.165 A related study shows that when asked to provide feedback to fellow students, many white students are relatively less critical of essays they believe to have been written by blacks than of those they believe to have been written by whites.1 Although several motives could be at work here, one is to avoid being judged hostile to blacks. The bias in question disappears and in some cases is reversed when evaluations are taken in settings that rule out crossracial communication. These findings suggest that when a person expresses different judgments or preferences before two separate audiences, both sets of expressions could be insincere. A graduate student asked about her opinions concerning a toxic spill could downplay what she considers to be the true danger before her skeptical advisors and then inflate the same danger before hungry reporters looking for a scientist to showcase as a paragon of incompetence.
Another complexity is that conformism, insofar as it is driven by the desire to be accepted and liked, often competes with the impulse to stand out and apart from the crowd, gain recognition, and (what is not the same thing) be oneself. Some people refrain from preference or knowledge falsification even when they thereby hurt their popularity. In addition, some people perceive general public opprobrium a subsidy rather than a tax, especially when it is accompanied by widespread approval, perhaps even a leadership role, within a dissident subcommunity. As we shall see, the boundaries of acceptable nonconformism can change through an availability cascade.
Both belief and preference falsification are matters of degree. The most extreme form is to assert exactly the opposite of what one thinks or wants, as
when a scientist convinced of the safety of Alar-treated apples pretends that they threaten children and expresses support for banning the production of Alar. Weaker forms include the suppression of doubt about a report's accuracy, the exaggeration of enthusiasm for a policy, and miscommunication of mild concern as intense fear, or vice versa. However, even such weak forms of falsification distort the content of public discourse. They do so by transforming both the substance of knowledge in the public domain and the social pressures that determine what is and is not acceptable to communicate publicly. April 1999]
4. Reputational insurance.
The pressures that promote untruthful expression need not be palpable at the time of an individual's expressive decision. Sometimes we refrain from speaking our minds in anticipation of social pressures for which no concrete evidence yet exists. For example, an official who considers a waste spill innocuous may shade her knowledge simply to avoid being perceived as "weak on the environment" in the event that the spill comes to be perceived as harmful. By falsifying her knowledge she buys reputational insurance, a measure of immunity against possible pressures from environmentalists. She also pays a price, of course, by forfeiting the opportunity to be known as one of the first officials to diagnose the spill correctly.
D. Reputational Cascades
We have already touched on the origins of the social pressures that create incentives for tailoring one's public expressions to social expectations. Where policies will create winners and losers, not everyone simply reacts to pressures. Ever alert to the mechanisms under consideration, some individuals take it upon themselves to shape the pressures in order to mold public discourse and control the policy selection process. Examples of such availability entrepreneurs include Lois Marie Gibbs in the case of Love Canal and members of the NRDC in the Alar case. Availability entrepreneurs actively encourage the statement of views favorable to these options and discourage the statement of unfavorable views. A precondition for a reputational cascade is thus the possibility of inducing splits between the private and public "selves" of a sufficient number of people. Such a split requires a willingness on the part of many citizens to shade their public expressions and tailor their public actions in the interest of protecting their social standing.
Once initiated by groups with a financial or ideological stake in policy control, social pressures may grow through the assistance of the broader population. For this reason, such groups confer reputational benefits on individuals who support particular positions and impose reputational costs on
those who oppose them. They make individuals seem altruistic or selfish, virtuous or vicious, depending on what preferences and beliefs they express. People ordinarily want to be perceived as standing on high moral ground, so in the presence of sufficiently strong pressures, they adjust their expressions accordingly. Suppose that questioning the wisdom of relocating the Love Canal residents is generally equated with obtuseness and cold-heartedness, and calling for further scientific study is construed as giving antienvironmentalist firms time to develop their defenses. Under these circumstances, residents, observers, and policy makers will all think twice before expressing misgivings about the dominant diagnoses or policies.
Earlier, in discussing informational cascades, we performed a thought experiment that abstracted from social pressures and, hence, the reputational consequences of people's expressive choices. Going to the opposite extreme, let us now suppose that the choices of individuals are driven entirely by efforts to protect their social standing. We are thus imagining that people's private judgments and preferences play no role at all in their expressive choices like puppets under a puppeteer's command, people express themselves simply to accommodate social pressures. If everyone was equally aware of the prevailing social pressures, interpreted threats and promises identically, and cared equally about maintaining a good reputation, they would do so in unison at the first hint that someone wanted them to support a particular agenda. In reality, all such factors vary across individuals. People differ, for instance, in the attention they pay to the news, the circles in which they move, the experiences they have had with taking unpopular positions, and the importance they attach to being admired and accepted. Such differences guarantee variations in responsiveness to social pressure.
Imagine, then, that when a waste spill is reported, joumalists seeking a career break that will make them famous, or politicians aiming to build up their pro-environmental credentials, take to denigrating the responsible industry. Sensing an opportunity to appear virtuous, the first people to witness this campaign participate in the denunciations. In so doing, they raise the volume of criticism, which makes additional people aware of the ongoing transformation in public discourse. The latter individuals join the chorus of criticism to build their own reputations, which raises the volume further, and in this manner the vilification campaign grows through a reputational cascade. The cascade completes its course when news of the campaign has reached everyone who cares sufficiently about maintaining a good reputation.
[Vol. 51:683
E. Socialization and Its Limits The personal motives that underlie a purely reputational cascade differ fundamentally from those of a purely informational one. In the reputational variant, a person asks himself, "How will my community think of me if I fail to endorse its dominant position?" And he then falls in line upon gaining awareness of the prevailing political mood. In the informational variant, a poorly informed individual seeks the truth by asking herself, "What is the dominant view within my society?" And she jumps on the bandwagon in motion by basing her views on those of others. In the former case individuals are motivated solely by social approval in the latter they want only to know the truth.
Of these pure types, the reputational variant presents an oversocialized view of human nature. Although certain individuals' expressions are sometimes ruled solely by reputational concerns, most people ordinarily balance these concerns against the desire to be truthful to others and to themselves. At the opposite extreme, a purely informational cascade presents an undersocialized conception of the individual. Only highly abnormal people convey knowledge and preferences without any regard for the possible effects on their reputations. A realistically socialized view of human nature will treat people as social beings who seek acceptance, as knowledge-seekers who are ready to learn from others, and also as expressive agents who develop their individualities by speaking their minds. To be sure, people differ from one another along these dimensions some care enormously about their reputations, while others care very little.
The balanced perspective offered here implies that when a possible risk, such as the contamination of a canal, is characterized as a dangerous problem or, alternatively, as no threat whatsoever, there will be two distinct influences on listeners. On the one hand, the characterization will shape their private risk judgments, risk preferences, and policy preferences. On the other, it will teach them something about the evolving political climate, thus shaping their perceptions of the reputational costs and benefits associated with the possible public expressions. The public counterparts of the foregoing variables-the judgments and preferences they choose to convey in soApril 1999]
cial settings-will reflect a combination of these two influences. When public discourse on the contamination undergoes a change, the transformation will partly reflect modifications in people's actual thoughts and dispositions, and partly their efforts to preserve or gain social status, by adjusting to perceived shifts in social pressures.
As noted earlier, these influences may counteract one another. When a claim of "no danger" comes from a notoriously unscrupulous yet politically powerful lobbyist, the source of the information may generate skepticism, making listeners less willing to endorse the lobbyist's claim. But it may also alert listeners to the reputational advantages earned by those who endorse the claim publicly, thus enhancing their willingness to do so. In the cases of greatest concern here, however, these influences are mutually supportive. The multiplicity of individual sources of information makes the claim hard to dismiss as the concoction of greedy trouble makers. The claim gains credibility even as it becomes increasingly prudent to endorse publicly.
[Vol. 51:683
F. The Self-Reinforcement ofAvailability
Both processes-interdependent responses driven by reputational motives as well as those fueled by informational motives-add to the availability of knowledge pointing to a danger. Astute individuals will sense that reputational incentives are breeding knowledge and preference falsification. If nothing else, involuntary "body language" will sometimes publicize thoughts and feelings that people are striving to keep private. But one can know that public communications are partly feigned and try to make allowances for the dissembling without discounting it sufficiently. The upshot is that knowledge and preference falsification can have lasting effects on how people actually think and feel.
To make a risk claim and the supportive data more available is to make information pointing to the absence of this risk less available. An availability cascade is necessarily accompanied, therefore, by an unavailability cascade that progressively frees public discourse of voices out of tune with the evolving chorus. This concurrent cascade makes it increasingly difficult for people with stated or unstated reservations about the developing public consensus to retain their misgivings. Making their private knowledge increasingly insecure, it weakens their resistance and making their private prefer-
ences seem increasingly unusual, it facilitates their participation in the evolving consensus.
Imagine a Love Canal resident who, when the story breaks, thinks that the press is over-reacting and that her neighbors are acting irrationally. At first, she is able to share her doubts and misgivings with other skeptical residents, and she notices skeptical commentaries and editorials in the press. But as the cascade unfolds, open skepticism becomes progressively less common. She runs into fewer neighbors prepared to express reservations and encounters fewer press accounts calling for caution. She begins wondering whether she has been blind to facts obvious to almost everyone else. If and when the combination of mounting social pressures and the transformation of her own thoughts makes her cross her threshold of resistance, she will join the availability cascade. Dissenting voices will then become fainter still, making it that much harder for the dwindling number of open skeptics to hold out as critics.
The reputational costs imposed on critics may, over time, lead to intellectual paralysis. Insofar as people refrain from expressing their doubts, uncertainties, and misgivings, public discourse will become impoverished, eventually making people whose perceptions depend on public discourse stop questioning what appears as the conventional wisdom. In other words, the unthinkable ideas of one period can turn into the unthought ideas of a later one. In one period, people with doubts do not speak out in the next, doubts have ceased to exist.
In the course of an availability cascade, the content of the discussions will generally involve many of the risk traits listed in Table I. Communications will address, for example, matters of equity, such as the unfairness of businesses endangering the safety of a middle-class community. They will establish a reference point against which the risk is to be measured. And they will categorize the risk by highlighting similarities with previous dangers. As increasing numbers of individuals appear to agree on the specifications for various acceptability traits, and these specifications become more available in public discourse, cognitive biases other than availability will come into play. For example, as a consensus begins to form that the episode
[Vol. 51:683 resembles a certain disaster of the past, the representativeness heuristic will start influencing people's interpretations.
As Love Canal became a top news story, many commentators likened the episode to an industrial Vietnam, noting that dioxin is one of the chemicals in Agent Orange, which American forces used in the Vietnam War. Others drew analogies to "Gypsy hauling" and "midnight dumping, which gave the impression that no one is safe from deadly chemicals, that "new Love Canals" could be unfolding in anyone's backyard while they were off guard.8 These images created an intellectual climate that hindered the maintenance of a feeling of security.
The anchoring effect also played a role. People who heard Love Canal characterized as a disaster akin to the Vietnam War, or as an official act of mass murder, tended to consider the risk more serious than dispassionate analysis of the scientific data would suggest. In other words, they underdiscounted the analogy, thus becoming overly alarmed by the revealed evidence. Certain newspapers reinforced this process through reports that the levels of dioxin were 250 to 5000 times greater than what the EPA considers safe. Such numerical anchors must have compounded any biases rooted in the anchoring effect.
G. Availability Campaigns Like all errors, availability errors can have significant social consequences. Typically, there are both losers and winners. Knowing this, pressure groups-some entirely self-interested, others committed to a social cause for altruistic reasons-seek to instigate availability cascades. Their chances of success are limited insofar as people have access to reliable information of their own. But even then their causes are not hopeless. Pressure groups can alter people's perceptions of their self-interest, or at least the expression of their needs, through measures to prevent frank discussion.
In the environmental context, a common tactic is to produce a headlinegrabbing uproar by dramatizing a problem. Recent examples of heavily publicized problems include, in addition to those already mentioned, the plight of the Giant Panda, which the World Wildlife Fund has highlighted, and the Exxon Valdez disaster, which the Sierra Club and other environmental organizations have exploited to promote more stringent safeguards against oil spills. Groups that would bear the costs of the requested policy measures, such as oil and shipping companies in the case of Exxon Valdez, respond in kind. In particular, they draw attention to the "boy who cried wolf' phenomenon in environmental politics and the "green-friendly" aspects of their operations. At least implicitly, the participants in these contests understand both the reputational and informational motives on which availability cascades feed.
We have described the instigators and manipulators of availability campaigns as availability entrepreneurs. Showing at least a working knowledge of the availability heuristic and other cognitive processes, these entrepreneurs seize on selected incidents and publicize them to make them generally salient to the masses. They also draw associations that trigger painful memories, as when environmentalists proclaim that operational nuclear reactors are setting the stage for "another Three Mile Island," or when they characterize a toxic spill as "a new Love Canal." The entrepreneurs who coin such phrases sometimes act strategically. In particular, they select their tactics in the hope of producing cascade effects beneficial to their causes. But many, perhaps most, consider their claims of danger more or less real. After all, they themselves are subject to the availability heuristic as much as everyone else, and the fact that they move in circles within which the claim seems to be believed may have convinced them about the existence of a tremendous risk. April 1999]
An anti-nuclear activist may believe passionately in the necessity of eliminating nuclear power because all her friends are themselves opponents of nuclear power, and they make the danger in question very salient to her.
A common method for triggering availability cascades is for a group to pass carefully sifted information to selected journalists, who then rush to release hot stories that justify the group's work. The information will often contain grains of truth, but it may also harbor biases, even outright fabrica-, tions. We saw an example in the spread of misleading information during the Alar episode. For another such example, consider that in the Christmas season the media typically feature stories about holiday suicides. These stories give the impression, and sometimes say explicitly, that the risk of suicide rises sharply during the holiday season for people living alone (who feel especially lonely), for the financially strapped (who realize that the presents they want to purchase lie beyond their reach), and for sundry other categories of troubled people. In fact, the suicide rate is not unusually high between Thanksgiving and New Year's, and in some years it lies slightly below the norm.185 There are two reasons why, nonetheless, this period sees a rush of suicide stories. First, the reporters who receive their information from suicide hotlines may not bother to check their facts. Second, and more critically, the hotlines have a stake in making "bad times" for emotional health coincide with "good times" for fundraising. The hotlines find it especially effective to appeal for funds around Christmas, which comes at the end of the tax year, a time when taxpayers develop greater awareness of tax deductions and, hence, are more willing to make charitable donations.18
Reports of suicides tend to fuel new suicides through processes akin to those we are discussing here. Through the availability heuristic, wellpublicized suicides foster an awareness of suicide as a way out of pain. They also reduce the stigma attached to suicide, especially when the victims are celebrities who evoke sympathy.8 But to identify certain adverse effects of publicizing the commonness of suicides hardly implies that the availability campaigns in question constitute cases of cynical, self-serving manipulation. Suicide hotlines are run by people with honorable goals: prevention of despair and preservation of life. Nor does our observation imply that the campaigns are counterproductive on the whole. The lives saved through funds raised may well outnumber those lost due to the added holiday-season publicity.
To generalize, even when cognitive deception is involved, availability cascades may serve a socially beneficial purpose. Indeed, the entrepreneurs who set them in motion may well be exploiting heuristic devices as a response to private ignorance and public apathy. As with anyone seeking to provide a public good, activists striving to lessen a social risk face familiar obstacles to collective action. Likewise, anyone seeking to reform the social norms associated with a risky activity, or even those pertaining to public discourse about the activity, must cope with difficult collective action problems of their own. Suppose that the social meaning of complaining about second-hand smoke is prissiness or petulance. If large numbers are harmed or bothered by second-hand smoke, social well-being may improve through changes in the relevant expressive norms and, ultimately, in the behavioral norms themselves. But the prevailing social meanings cannot be changed by any particular individual acting alone. For another illustration, suppose that, while the problem of global warming is serious, people trumpeting the gravity of global warming get treated as fanatics. Those who happen to believe the statement may seek refuge in preference and knowledge falsification, thus delaying the emergence of a critical mass for action. Availability entrepreneurs help to overcome collective action problems of this kind they play a decisive role in breaking insincere resistance to the removal of privately recognized social injustices, problems, and inefficiencies. In acting as manipulative salespeople, therefore, they sometimes perform vital social services.
H. Roles of the Media and Political Institutions
Whatever the merits of their campaigns, availability entrepreneurs make use of political institutions and the media to trigger cascades. In one common pattern, a special-interest group supplies information to members of Congress, who then hold hearings that enable the group to testify and publicize its mission. During the process, journalists help spread the group's message, partly through leaks they receive. Citizens join the fray through letters, phone calls, and participation in talk shows, thus heightening awareness of the identified problem, as happened in the Love Canal and Alar scares. Eventually, laws or regulations are adopted that give the instigating group fresh opportunities to provoke new uproars in order to strengthen the achieved general consciousness.1
The tasks of special-interest groups are facilitated by the willingness of journalists to accept and report claims fed to them by special-interest groups. If the mass media often report carelessly, an important reason is that few people realize the extent to which reporters rely on slanted press releases and strategic leaks. For exactly the same reason that there exists widespread rational ignorance on any social issue-the boundedness of human cognitive capabilities-ignorance is widespread about the sources of news bulletins. The typical citizen has no time to investigate whether a story about an environmental hazard or an industrial safety matter has come from a trade association, a fundraising operation, or a regional group that stands to benefit disproportionately from resources allocated to solving the problem. When they watch film clips on television, read statistics in the newspaper, or hear a radio interview, they frequently presume that the information reflects the findings of disinterested journalists. But often the media are simply using videotapes, audiotapes, and reports prepared by a party driven to enhance the availability of certain perceptions and viewpoints and expecting the consequent transformation to fuel a cascade.
The wide acceptance that falsehoods gain in the popular imagination can be traced partly, of course, to those who concoct and first report them. But another part of the responsibility falls on individuals who spread news that they hear, thus making it increasingly available to others.
IV. POPULIST FIRESTORMS AND DEMOCRATIC RISK REGULATION
Availability cascades create serious problems for democracy and raise important issues for democratic theory. They create a danger that apparently democratic outcomes will rest on misinformation and be unrepresentative, in any normatively attractive sense, of citizens' actual beliefs, desires, and judgments. In discussing the relation between availability cascades and democratic theory, our focus remains on risk regulation, although the implications derived in this Part of the article, like the remedies we shall propose in the next Part, have much broader relevance.
Above all, the argument thus far indicates that "public opinion" about the regulation of risks (the distribution of public policy preferences) constitutes a highly problematic basis for government policy. This is partly because publicly expressed demands for regulation are likely to conceal doubt, ambivalence, and concern. But the corresponding "private opinion" (the distribution of private policy preferences) may also constitute a poor foundation for policy, because availability cascades often spread falsehoods that overwhelm sound scientific reports.1
Our call for caution about populist firestorms evokes two time-honored themes of the American tradition of public law. The first involves the ideal of deliberative democracy, which elaborates on the principle of democratic judgment by insisting that policies be based on careful deliberation and reflection rather than on mechanical reactions to citizen preferences.1 A principal point of the original Constitution was to ensure that representatives "refine and enlarge" popular sentiment, rather than automatically translate it into law. The key institutions of the American system of government were designed to promote the desired filtering. The second and more modem theme is that policy choices should rest on sound knowledge of relevant evidence. In the context of risk regulation, this objective requires a measure of deference to the purely factual judgments of scientific experts.1 It also requires democratic policy makers to discount regulatory demands rooted in availability cascades based on false information, to pay special attention to trained experts who have had time to put claims in perspective, and to show initiative in responding to significant problems that the citizenry happens to be overlooking.
The deliberative ideal thus rejects, simultaneously, both the purely technocratic form of democracy, which seeks to derive policies solely from the judgments of technical experts, and the purely populist form. Proposing that the government need not respond to each and every risk-related claim that a majority might articulate, it invites government officials to be deliberative as well as responsive. By the same token, it insists that scientific evidence alone cannot dispose of policy questions. Sometimes the evidence
concerning a risk cannot be assessed without introducing contentious assumptions, as with the evaluative notion of "conservative assumptions."200 But even when the facts are easily identified and when perceptions do not depend on controversial assumptions, assessing the significance of perceived reality-or of the demonstrable factor-requires evaluative judgments that are better made democratically than by experts. In no way, then, does the deliberative ideal instruct governments to ignore the "popular will." On the contrary, it instructs governments to take the "popular will" seriously, both by attending to reflective judgments of value and by staying attuned to mechanisms that govern the construction of any "popular will."
Suppose, for example, that more lives can be saved by regulating bicycles than by regulating coal-fired power plants. It does not follow that the government should automatically accord priority to reducing the former source of risk. As studies on risk acceptability show, popular judgments may well depend on factors other than the life-years at stake. From a deliberative perspective, judgments about qualitative differences among risks can legitimately influence political decisionmaking and legal outcomes, provided they are reflective and can survive critical scrutiny.2 Specifically, such judgments should be based to the extent possible on an accurate understanding of the facts, including the range of scientific uncertainty. In sum, a deliberative democracy seeks not only to ensure the accuracy of risk judgments but also to weight these according to reflective risk preferences.
Some contemporary research on risk suggests that experts and ordinary people display "rival rationalities," with ordinary people focusing on a relatively "broader" set of variables. Insofar as ordinary people do display a richer rationality, their considerations should certainly influence regulatory policy. Yet what appears as a "richer" rationality often rests on the cognitive and communicative distortions highlighted in this article. The extent to which these distortions are significant in any particular context is an empirical matter. At the very least, however, the demand for risk regulation may be based on serious distortions. The phenomenon of availability cascades points, then, to the possibility of a large gap between any snapshot of the "popular will" and the appropriate judgments of a democratic government.
[Vol. 51:683
A. Resisting Availability Errors
The first and most basic implication of the foregoing analysis is that a representative government may justifiably question the private risk judgments and preferences that underlie people's public communications on
matters relating to risks. Where people learn about risks and become sensitized to them largely on the basis of the apparent understandings of others, availability errors may play important roles. Although rampant anxiety over a pesticide or an abandoned waste site could stem from a scientifically demonstrable reality of a danger, it could also reflect misperceptions grounded in an availability cascade. Therefore, a properly functioning government committed to people's well-being will not respond mechanically to expressions of anxiety. Rather than taking conveyed risk judgments and preferences as given, it will be open to the possibility of pervasive misperceptions. And where it finds misperceptions, it will endeavor to lessen public anxiety by correcting them.
Even where private opinion about a risk does not rest on misperceptions, there may exist a problem rooted in preference and knowledge falsification. Public opinion about the severity of a social risk, or about the appropriate government response, may be unrepresentative of the underlying private risk judgments and preferences. The words and deeds that shape public opinion and public discourse need not be entirely sincere. Private support for a particular agenda may be much weaker than the corresponding public support likewise, private judgments of the risk in question may be less severe than their public counterparts. In the absence of offsetting mechanisms, such distortions can have serious political consequences. Groups clamoring for quick and massive action to reduce a risk will exploit a favorable public opinion to advance their causes. Pointing to the overt support their cause draws from the media, they will extend their demands and make politicians bow to their wishes. In view of this logic, a government that abides by public opinion in mechanical fashion would be committing an availability error of its own.
To the extent it is desirable for policy responses to reflect private opinion, policy makers would do well to pay special attention to polling instruments that give respondents anonymity. Such surveys, unlike exercises that make public the responses of participants, and unlike the public statements of journalists and politicians, allow people to express unpopular views without fear of retaliation. To be sure, there are sometimes solid reasons to avoid
following even the dictates of private opinion. With respect to risk issues on which individuals are unlikely to be sufficiently informed to make good judgments, or where cognitive biases tend to produce distortions, the private opinion of an educated representative sample may be more valuable than that of the population as a whole. The point remains, however, that governments can protect their policies from serious availability distortions through mechanisms identifying some form of private opinion.2°
Each of our first two implications goes against an inclination common for more than half a century in neoclassical economics as well as its many cross-disciplinary derivatives, including the economic analysis of law: the tendency to equate people's choices with "revealed preferences" that the social system must accommodate in the interest of efficiency. Whatever the setting in which preferences are expressed, what they "reveal" depends on the stimuli responsible for their formation. A given distribution of public preferences may signal that the pertinent individuals have felt pressured to keep certain types of information to themselves. Alternatively, those preferences may point to people's lack of exposure to private knowledge whose uncensored circulation would have produced important influences. In and of themselves, people's words and deeds concerning risks tell us too little about what they truly know, what they sincerely want, and what influences have shaped their dispositions, attitudes, and sensitivities. From the knowledge that eighty percent of the American people support a massive program to clean up a waste site, one cannot legitimately infer that such a program would please even the majority. Nor should one infer that the program
[Vol. 51:683
would retain majority support if public discourse were unimpeded by reputational concerns.
As in any context involving interdependent decisionmaking, the outlined model admits multiple equilibria. Depending on initial reports of the pertinent data, the same set of human psychologies and the same objective facts can yield vastly different outcomes. If the reports paint a picture of minor contamination unlikely to harm the environment, anyone who sounds alarm bells will look foolish, and society will get little exposure to alarmist discourse. There will be no build-up of anxiety, and no outcry for massive government intervention. By contrast, if the initial reports raise the specter of an environmental disaster that has made an entire region unfit for human habitation, an availability cascade that favors massive intervention may gather momentum. And if a cascade is triggered, people with information suggesting the absence of a serious problem will increasingly resort to knowledge and preference falsification, causing the retreat of public opposition to a massive cleanup effort. The lack of public dissent may convince large numbers of previously content people that greedy industrialists are making earth unlivable. Apri 11999]
B. Social Influences on Cognitive Processes
Even in the absence of availability cascades, cognitive biases can have substantial effects on perceptions and decisions. Yet in exploiting a basic judgmental heuristic-the availability heuristic-availability cascades aggravate various cognitive biases, with socially costly consequences for regulatory policy.
Regardless of how public discourse evolves, certain heuristics will be used regularly, and certain biases will always be very common. Consider, once again, the fear of snakes. Many people fear even physically harmless snakes, probably because such fear provided evolutionary advantages to our distant ancestors who lived in environments where certain snakes posed lifethreatening dangers. This suggests that snake phobia (ophidiophobia) is innate and easily activated in environments teeming with reptiles.207 But to recognize a fear's innateness establishes neither the fixity of its intensity nor that of its expression. Social forces may aggravate any individual's snake phobia by giving salience to dangerous human encounters with snakes and exaggerating their commonness. Counteracting social forces may have a calming influence by suppressing information about dangerous encounters and reinforcing information about benign ones.
Like the fear of snakes, the fear of falling victim to human aggression is innate. But the perceived risk of, say, date rape on a particular campus, can be heightened by giving high publicity to a few crimes through dissemination campaigns or efforts to reward victims with special status. By the same logic, the perceived risk of rape can be lowered through measures that suppress information on crime. If women who claim to have been raped are treated as promiscuous whiners, many rapes will go unreported. To the extent that the resulting misperceptions make victims even less willing to report crimes, an availability cascade that reduces the perceived risk of rape will be put in
[Vol. 51:683
C. Undesirable Law and Policy
Another immediate implication is that public discourse on any given risk may produce scientifically unnecessary, ineffective, even counterproductive policies. This follows from the possibility of untruthful and uninformed public discourse. If people base their judgments on what other people say and do, and if the words and deeds of these others are weakly informed, public discourse will rest on flawed judgments. And if people who happen to possess information pointing to the unlikelihood of serious danger hide their doubts about the wisdom of committing massive resources to cleaning up harmless wastes, the supporters of the clean-up program will easily achieve their aims. Having won the political struggle, they will then see their empirically unsupportable claims of danger become the conventional wisdom.
A key element of the logic here is the malleability of risk judgments. Insofar as individual risk judgments develop interdependently, people may make one another believe in the omnipresence of enormous risks that are actually trivial. Many risks form a psychological burden,20 so such misperceptions can fuel widespread anxiety that the government tries to alleviate by diverting resources from programs addressing genuine, scientifically verifiable problems. A program to wipe out a minuscule risk cannot be particularly effective as measured by saved lives or health improvements in distorting economic decisions and lowering economic growth, it might even lower life spans. True, the regulations would foster comfort by making people feel that -something is being done about a risk they consider significant. But if the risk were imaginary, the regulations would only undo a psycho-
logical damage created by the very social process responsible for the prevailing fears. April 1999]
D. Enduring Harm
Like purely informational and purely reputational cascades, availability cascades eventually come to a stop. One reason is that some learning takes place independently of social forces, as when a person who accidentally drinks a glass of water from Love Canal senses, when he remains healthy, that the Canal's toxicity is exaggerated. Another reason is that the social approval obtainable through various forms of insincerity can come at the expense of intrinsic benefits. People who complain about actually harmless waste sites incur huge costs when the government orders their relocation. Their reputational benefits are accompanied by intrinsic inconveniences. The cascade comes to a stop when individuals have no net incentive to alter the preferences or judgments they convey to others. By definition, the stopping point forms an expressive equilibrium.
This brings us to yet another, particularly alarming implication. Once an expressive equilibrium is established, and a risk alleviation policy is in place, both the equilibrium and the associated policies may endure even if subsequent scientific evidence discredits the information that triggered the cascade responsible for their emergence. Part of the reason is that the equilibrium influences the subsequent evolution of knowledge about alternative risks. But another part is that it conditions people's reputational incentives. Consider individuals who, whether through study, experience, or exposure to dissent, develop doubts about the prevailing conventional wisdom. They will find that, by publicizing their views, they would make themselves unpopular without much chance of reshaping the substance of public discourse on their own. To influence that substance, they must overcome a collective action problem. By choosing to keep quiet, or even to pay lip service to the new conventional wisdom, they will contribute to preserving the prevailing public discourse and the associated misperceptions. The continuing fear of abandoned hazardous waste dumps offers a central case in point.
A related implication concerns the beliefs of generations too young to have experienced the availability cascade that resulted in the prevailing policies. The public discourse shaped by the cascade will contribute to the perceptions of new generations. Insofar as young generations form their beliefs on the basis of informational availability, what they learn will reflect the distortions of the prevailing public discourse. Even today, two decades after scientists found the alleged health hazards of Love Canal essentially unfounded, references to the region evoke thoughts of profit-hungry industrial bosses destroying a gorgeous countryside and risking the lives of helpless multitudes for the sake of their own enrichment. Many people who have
never been to the Niagara Falls region, even those not yet born when Love Canal made the headlines daily, know of the episode through a public discourse still controlled by an availability cascade that ran its course twenty years
E. Uncoordinated Law
A basic observation that undergirds the entire analysis has been that people's cognitive limitations make them compartmentalize their risks. Specifically, it makes them consider risks essentially in isolation from one another, rather than jointly and in a manner that permits the identification of tradeoffs. Because such compartmentalization is ubiquitous, risk regulations may show great variability across different risks, among different populations, and over time. Let us take up each of these implications in turn.
If availability cascades have taken off in some contexts but not in others, historical precedents will differ across compartmentalized risk issues. It follows that the policies adopted to deal with these risks may be grossly inconsistent. Our framework thus yields insights into data showing huge discrepancies across the cost-effectiveness of American regulations aimed at saving lives. At one extreme, the cost of regulations on steering columns and space heaters is only $100,000 per saved life. At the opposite extreme, that of regulations on certain carcinogens cost well over $10 million per saved life. Part of the explanation is that availability cascades can draw people's attention away from important risks and make them focus on trivial ones.
Another puzzle illuminated by this analysis is that observed wage differences across occupations typically differ dramatically from those predicted by the theory of compensating wage differentials. In its standard form, this theory states that riskier occupations will tend to pay more than safer
April 1999] ones. In reality, the relevant variables are not the risks of alternative occupations but their perceived risks. And these perceived risks may diverge from actual risks because of availability cascades that have distorted public knowledge. Society may end up compensating some workers for imagined risks while failing to compensate other workers for real risks. And the very perceptions responsible for these market outcomes pressure the government into imposing workplace regulations at odds with true risks.
If a single nation does not coordinate its risk regulations, such coordination can hardly be expected at the international level. Hence there may be huge variations in the policies that different nations bring to bear on a given risk.215 We have already touched on the startling contrast between the popularity and widespread reliance on nuclear power in France and its unpopularity and sharply limited use in the United States.216 Another remarkable cross-continental contrast concerns genetically altered food. As of 1998, consumers all across Europe are in open revolt over the prospect of a future where all fruits and vegetables come from genetically altered seeds.2 Prince Charles voiced a popular European sentiment when he declared that no genetically altered food would enter his mouth.21 "That takes mankind into realms that belong to God, and God alone," he explained.219 In Britain, vandalism against genetic testing sites has become so common that the government is striving to conceal their locations.22 In sharp contrast, American
consumers are for the time being fairly relaxed about genetic engineering, perhaps because most are unaware of how common this alteration procedure has
The possibility of variability over time in any country reflects the vulnerability of many cascade-generated equilibria. Because the public discourse that supports a given expressive equilibrium may rest substantially on preference and knowledge falsification, even an inherently minor shock may have huge repercussions. Specifically, by making hidden doubts surface and by giving exposure to unarticulated knowledge, the right shock will alter public discourse and cause the equilibrium to unravel. The unraveling may even cause both expressive and substantive fears to change sides, ushering in a dramatically different expressive equilibrium. As a case in point, a quartercentury ago few people considered second-hand smoke a health hazard. And members of this tiny minority could not ask smokers to move elsewhere without risking angry or condescending reactions. Now most Americans consider second-hand smoke harmful, and many seriously exaggerate the risk.222 Today it is smokers, the minority, who risk ostracism when they publicly assert that second-hand smoke is harmless. Likewise, only a few years ago, nonscientists showed little concern about the thinning of the ozone layer. Now most people seem alarmed. Each of these transformations occurred over periods much shorter than it took for the relevant scientific evidence to accumulate. Early on in the paper, we saw evidence of an even faster transformation. It took just a few months for Love Canal to heighten fears of industrial waste
[Vol. 51:683
Our analysis raises the possibility of large gains from institutional reforms. The motivation for such reforms is that availability cascades constitute a major, perhaps the leading, source of the risk-related scares that have cramped federal regulatory policy at both the legislative and executive levels, with high costs in terms of lives lost, lowered quality of life, and dollars wasted. Especially when they run their course quickly, cascades force governments to adopt expensive measures without careful consideration of the facts. The consequent rush to action need not pose a problem where the cascade draws attention to a major neglected risk and the proposed measures turn out to solve a genuine social problem as already mentioned above,
availability cascades can produce a lot of good. For the reasons discussed above, however, the mere fact that vast numbers of citizens are calling for the alleviation of a perceived risk, or that they are demanding a particular risk reduction program, provides no guarantee that even they would benefit from having the government sheepishly fall in line. It does not even mean that they truly desire the measures they are championing.
A. Passions and Constraints
Many features of the prevailing system of checks and balances offer protection against availability cascades. For example, the bicameral legislature prevents cascades within one chamber from creating legislation on their own. Still, as matters now stand, the American government is imperfectly equipped to provide meaningful resistance against social pressures grounded in misinformation. When there is an upsurge of interest in addressing a particular risk, the government loses its ability to set sensible priorities, undertake long-range planning, and enforce intertemporal consistency. It has been estimated that the American government could save an additional 60,000 lives per year at no additional cost or, alternatively, save the lives it currently does for as much as $31 billion less than it now spends.22 The reforms proposed in this Part would provide instruments for achieving such gains.
The notion of institutional safeguards against availability cascades is far from foreign to American history. Parts of the Federalist Papers show an awareness of cascades and their effects on public discourse.226 Many of the founding institutions can be understood as instruments designed to reduce dangers associated with cascades. In addition to the bicameral legislature, such instruments include national representation, federalism, and the executive veto to reopen and temper legislative debates. Numerous post-founding innovations fulfil related functions. Among them are specialized legislative committees, an appropriations committee to oversee the whole budget, and conference committees to resolve differences between legislative chambers. Individually and collectively, these structures provide opportunities for improving the accuracy of information used in policymaking, refining prioritysetting, identifying trade-offs, promoting deliberation, and reaching reasonable compromises among competing judgments and interests.
The measures proposed and defended below are meant to develop the existing system in the light of modem realities. One of our objectives is to strengthen the role of science in risk regulation-a role that several groups have tried to weaken.227 To this end, we seek to provide regulators with better insulation against sudden and intense mass calls for immediate action (partly to allow them to address significant risks that public opinion is ignoring). It bears repeating that people may legitimately find some risks less acceptable than others that are quantitatively identical. But these judgments should be made with reference to the best possible understanding of reality rather than mass hysteria.
Our most general goal is the attainment of "comprehensive rationality" in risk regulation. All too often the government focuses on problems in isolation from related problems, and political forces hinder sensible prioritysetting. Through institutional arrangements that amount to precommitment strategies, the making and implementation of laws can be shielded from myopic, ephemeral, or counterproductive social pressures.
None of our proposals will be described in minute detail. Our intention is simply to outline certain basic institutional reforms. We begin by addressing a recent initiative designed to make it costly for availability entrepreneurs to launch cascades that generate scientifically unjustified mass anxiety.
[Vol. 51:683
B. Product Defamation Laws The Texas lawsuit that pitted beef producers against television talk show host Oprah Winfrey229 brought into sharp relief one possible measure against harmful availability cascades: civil actions to deter individuals and groups from instigating or aggravating such cascades in the hope of profiting from the ensuing panic. Conscious of the potential advantages, twelve states have enacted product disparagement laws.23 As one might expect, many observers consider such laws to be constitutionally unacceptable devices designed to placate powerful economic actors intent on suppressing legitimate doubts about the safety of their products. But the underlying issues are more complicated. For one thing, it is unclear that all or most product disparagement laws violate the First Amendment. For another, their beneficiaries would hardly be limited to industries trying to block reports about the defects of their products. Just as ordinary libel law serves to discourage public falsehoods about individuals, product disparagement laws discourage false statements about products. In each case, the purpose is to prevent availability cascades from causing irreparable damage.
In their current form, food disparagement laws apply to perishable foods whose producers and sellers could be ruined by a cascade-induced plunge in demand. As a general rule, the laws are narrowly drawn, allowing compensatory damages only for spreading known falsehoods. They do not cover negligent falsehoods, even reckless ones. Nor are they reasonably interpreted to cover hyperbole or humor. Thus the thirty-second Honda commercial that referred to the emus raised in Texas as "the pork of the future" did not violate any food disparagement law even though it temporarily lowered the demand for emu meat. And Oprah Winfrey was acquitted of the charges brought by beef producers, apparently for lack of evidence that she said anything she knew to be
STANFORD LA WREVIEW When a product is "libeled," the news may spread rapidly, bringing harm to a wide range of people. The best (and constitutionally mandated) remedy for false speech, it is often said, is more speech. Ordinarily this is true. Yet when an availability cascade is under way, the liberty to counter false charges will not necessarily provide a corrective, and this is what product disparagement laws and ordinary libel laws acknowledge.
Indeed, predictable social forces may reinforce rather than dampen sensational charges. One such force involves the mass media. The typical newspaper, magazine, or television station incurs a large penalty whenever it falls behind its rivals in reporting "breaking news. Because a good relative position in the media hierarchy translates into disproportionately large profit differentials, a media outlet that exercises caution in reporting a frightening story may find itself at a huge, possibly irreversible, competitive disadvantage. Facing a prisoner's dilemma with respect to sensational stories, it has every reason to compete aggressively to report sensationalistic stories as rapidly as possible. Another social force that reinforces sensational changes consists of reputational pressures. Evolving reputational pressures can make it personally costly for individuals to defend a disparaged product. And the consequent individual reticence may contribute to the growth and spread of availability errors.
To the extent that they reach only intentional falsehoods, the product defamation laws appear consistent with the body of libel law currently applied to government officials and well-known figures. Under New York Times Co. v. Sullivan,236 it is constitutionally legitimate for states to require compensation for libelous statements that are intentionally false or made with reckless disregard for the truth. The rationale here is that the reputational interests of individuals are sufficiently strong to overcome the relatively weak free speech interests. If states can prohibit intentional or reckless falsehoods about people, perhaps they can also prohibit intentional falsehoods about products. This logic thus makes product disparagement laws seem constitutional.
[Vol. 51:683
Such a view might be challenged on the ground that products are not people. Only people have feelings that can be hurt and social positions that can be damaged, so perhaps states cannot legitimately base their product disparagement laws on the exceptionally strong interests traditionally used to support the law of libel. There is indeed a difference. But product disparagement laws do not protect products as such. When citizens are frightened through false statements about products, it is people who are genuinely injured, sometimes severely. In fact, the victims may greatly outnumber those in a typical libel case consider the multitudes of frightened parents and the many millions of dollars lost by apple growers as a result of the Alar episode.3 The shareholders of the relevant companies and their employees suffer, too, as do their customers and the anxieties caused by the knowledge of consumption risks produce a wide range of ancillary social harms. As a case in point, frightened parents, who had fed their children apples falsely described as dangerously carcinogenic, unnecessarily lost sleep-a large if difficult to measure social loss-and they had to have their children tested medically. States have strong reasons, then, to permit the imposition of compensatory damages for intentional falsehoods about products.
To identify certain advantages of product disparagement laws and to defend their constitutionality is not, of course, to prove that on balance they are beneficial or desirable. In principle, such laws could encourage frivolous rather than meritorious suits. Even more seriously, they could deter reports about genuine product hazards. Although it is highly desirable to allow broad-ranging debate about all potential risks, the mere possibility of a lawsuit may make knowledgeable people refrain from discussing real dangers, with the net result being more, not less, loss of life. The possibility of frivolous lawsuits might be attenuated by making plaintiffs liable for all court costs, including the attorneys' fees, in the event they lose. As for the risk of excessive deterrence, it can be reduced by maintaining a sharp line between the communication of intentional falsehoods and legitimate expressions of hyperbole, doubt, and concern. But each reservation constitutes an empirical claim to be tested by experience. We do not have a sufficient basis for knowing whether the existing laws are too broad. In the present state of knowledge, it appears at least as likely that product defamation laws would do more good than harm than the other way around. April 1999]
C. Congress
We now turn to the core institutions of the federal government. Congress is currently quite vulnerable to availability cascades, partly because its members feel compelled to respond to mass demands for legislation simply
to keep their seats, and partly because they have incentives to serve as availability entrepreneurs who work in concert with their constituents to further parochial agendas. As an institution, Congress is poorly equipped to place risks in comparative perspective. Its committee system keeps Congress highly balkanized and also increases its susceptibility to short-term pressures. Because activities of senators and representatives are carefully scrutinized by directly affected lobbies, committee members are often reluctant to publicize information, make statements, or take positions that can be used against them at election time. As a case in point, they rarely make public, let alone endorse, the monetary values that potential or actual policies ascribe to statistical lives. Nor do they talk candidly about trading lives for money. Committee members thus encourage citizens to cling to the idea that even a statistical human life is priceless. One consequence is that when an availability cascade fuels massive demand for acting on a matter under the committee's purview, the members of the committee quickly yield, and legislative action follows without any attempt at coordination with existing policies.239
1. Risk oversight.
A possible method for insulating Congress from such pressures is to create a risk regulation committee entrusted with compiling information about a wide range of risk levels and empowered to set priorities. This committee would have authority over both substantive statutes and the appropriations process. It would thus operate as a check on short-term pressures by putting particular concerns in a broader context. Its basic goal would be to rank risks, publicize misallocations, and initiate legislative corrections. In its ideal form, the committee would rely heavily on prevailing scientific knowledge. At the same time, it would recognize that risk judgments and preferences constitute legitimate considerations in the determination of priorities and selection of policies. Thus, its essential function would be to prevent myopic, unduly quick, and poorly reasoned responses, not to insulate risk regulation from evolving social values. Helping to slow down, limit, and possibly even prevent availability cascades, the committee's hearings would enable Congress to "strike when the iron is cold.
Like any government body, the risk regulation committee would most certainly become the target of well-organized lobbies intent on molding policies to their own advantage.2 But it should be possible to dampen the in-
centives for rent-seeking by guaranteeing that risks are put in a comparative light. The very act of comparing risks and publicizing the obtained rankings would provide a measure of protection against well-organized special interests. If the social costs of accommodating a particular lobby's demands gain widespread recognition, counter-lobbying might neutralize this lobby's political effectiveness.
2. Cost-benefit analysis.
Congress has debated a number of bills designed to require agencies to engage in cost-benefit analysis. The use of cost-benefit analysis as the basis for regulatory decisions has been highly controversial, partly because of conceptual and empirical obstacles to quantifying either costs or beneand partly because no agency is widely trusted to undertake a fair analysis. Although we cannot resolve these problems here, it is clear that availability cascades provide a new and distinct reason for some kind of costbenefit mandate, not as a way of obtaining an uncontroversial assessment of policy options, not as the foundation for every decision, and not because economic efficiency is the only legitimate ground for regulation, but as an instrument for producing relevant information and a common-sensical brake on measures that would do little good and possibly considerable harm.
Wherever some salient event might cause a cascade in favor of speedy regulation, there are good reasons to support mechanisms that help identify and quantify actual risks, and also for putting "on screen" the various possible disadvantages of attempting to curb them.245 Cost-benefit analysis might therefore serve as a check on ill-advised availability campaigns. Consider, for example, the very different implications of cost-benefit analysis for a lead phasedown (amply justified) and for eliminating asbestos (a decidedly mixed picture). An understanding of availability cascades certainly does not establish the usefulness of cost-benefit analysis the proof would lie in its implementation. Yet such an understanding offers a new basis for requiring cost-benefit analysis as a means of widening the viewscreens of political actors and containing availability errors.
D. The Executive Branch Other possible safeguards against harmful availability cascades would involve the executive branch, which is probably in the best position to analyze risks comprehensively. Unlike the courts, the executive branch is capable of taking a bird's eye view of the entire regulatory system and unlike Congress, it is already equipped with institutions designed to promote overall consistency. Obviously, measures adopted by the executive branch must be consistent with laws enacted by Congress in principle, therefore, the legislature has the power to undermine any executive initiative to place regulations on more rational footing. Yet the executive branch exercises a powerful influence on public opinion, and it has considerable power to act on its own.
The following are three complementary proposals, each of which can help prevent cascades driven by misperceptions.
1. Peer review.
Several recent bills would require executive agencies to use "peer review" as a means of corroborating the evidence that underlies the regulations they institute.248 Under peer review, agency proposals are subject to scrutiny by informed outsiders. Many agencies have already experimented with this procedure. The argument developed in this article provides systematic reasons for expanding the ongoing experiments.
The most critical function of peer review is to identify and correct misperceptions spread through availability cascades. While an availability cascade is in progress, and even after it has run its course, peer review can provide an important safeguard against policy responses that the facts do not justify. The Love Canal and Alar scares might have been contained at an early stage if the underlying claims had been subjected to peer review in a timely manner and the findings given wide publicity.
2. Risk Information Site on the World Wide Web. Among the reasons why people turn to nonexperts for information on various risks is that they lack easy access to statistically accurate and scientifically up-to-date judgments. This handicap limits their capacity to compare risks and develop sound understandings of dangers associated with, for example, air travel, automobile driving, poor diet, electromagnetic fields, and infrequent exercise. To be sure, most such information may be found in publications shelved in any good library or bookstore. Alas, people seeking to educate themselves might have to read dozens of books to make the necessary comparisons. In addition, they would first have to identify the appropriate sources and learn how to standardize disparate pieces of information. There exist large potential gains, then, from making the most current and scientifically most credible information easily accessible to the widest possible audience. In the computer age, the Internet may serve as the requisite medium.
We propose the creation of a central Risk Information Site (RIS) on the World Wide Web. This site would list various risks and identify the probabilities, or range of probabilities, associated with each of them. The technology of the web allows the nesting of multiple levels of detail. The most elementary level ought to be extremely simple to follow-simple enough, perhaps, for a high-school student to check the latest scientific knowledge on, say, the risks associated with Alar or Love Canal below this layer would lie progressively more sophisticated layers, each accessible at the click of a mouse. Where the scientific community is divided on a particular risk assessment, as it is on the thinning of the ozone layer, the RIS should make the substance of the controversy as clear as possible, allowing websurfers to review the opposing arguments. The proposed website could be designed and operated by a nongovernmental Risk Information Center (RIC), along the lines of Consumer Reports. It could even be a profit-oriented enterprise after all, there exist profit-driven credit bureaus that enjoy an exemplary reputation because they have a stake in their maintenance. Only if no nongovApril 1999]
ernmental entity is willing or able to undertake the task should the federal government take the lead, because a government-operated RIC would have a harder time rising above partisan politics and establishing its trustworthiness.
Counteracting the irrational attitudes and counterproductive policy demands caused by cognitive biases and distortions of public discourse, an RIS would help individuals form their risk preferences and judgments more rationally than is currently possible.2 The RIS would also offer information on how other countries are dealing with particular risks, thus alerting people to possible over- or under-reactions. It might allow parties to a controversy to make their case as well as rebut their opponents. Had an RIS existed during the Love Canal episode, both Lois Marie Gibbs and her skeptics within the scientific world might have been given opportunities to post evidence supporting their respective cases as well as their reasons for doubting the opposing account. Equally important, the proposed RIS would feature systematic information on possible discrepancies between public and private opinion on ongoing controversies. To this end, it would post controlled surveys that give people anonymity along with ones that deliberately do not. These surveys would serve to identify hidden currents of opinion and unarticulated insights, thus strengthening individual resistance to the biases of public discourse and the social pressures stemming from public opinion. An even more ambitious enterprise would be to include information about the objectives of all groups with a stake in regulating particular risks. One could also publicize analyses of their political strategies.
In a world in which highly trusted scientists quickly evaluate all perceived risks and post their findings in comprehensible form on a widely known website, availability errors of the kinds that motivated this article would be less likely to develop than they currently do. Were a news program to claim that apples carry a deadly poison, people could check the RIS to learn what is known about the identified risk. If scientific tests suggested an infinitesimal risk, fewer people would believe the claim, and no major cascade would follow. It is possible, of course, for credible tests to be nonexistent. In this event, the RIC, or possibly some other organization such as the one we will propose next, would immediately undertake new tests to evaluate the claim. If the claim proved groundless, a possibly costly cascade would be prevented without involving the courts.
Obviously, even the most elaborate RIS cannot prevent every potentially destructive availability cascade. For one thing, just as some car buyers would rather seek guidance from their acquaintances than from Consumer
Reports, many people would not consult the RIS. In addition, even highlyeducated people can be influenced by empirically baseless claims, and certain people have strong incentives to exploit this gullibility witness the numerous promoters of accounts involving flying saucers and alien abductions, and the millions of Americans who take these accounts seriously. Nevertheless, an RIS could certainly help at the margin. Insofar as the RIS makes a difference, it would limit the need for speech-restricting measures such as the food disparagement laws discussed above.
1999]
3. Office of Information and Regulatory Affairs.
In 1981, President Reagan created a new agency, an Office of Information and Regulatory Affairs (OIRA) within the Office of Management and Budget, to oversee risk regulation in an effort to ensure coordination and rationality. Since that time, the functions of OIRA have changed. Under Presidents Reagan and Bush, OIRA operated essentially as a "cost-benefit" monitor that intervened in an ad hoc way to force reconsideration of inefficient or excessive regulations President Clinton, who has taken steps of his own to "reinvent government"2 so as to ensure greater attention to results than to processes, has de-emphasized this particular function.2
In view of the dangers of availability (and unavailability) cascades, OIRA should be reinvigorated and its powers extended and strengthened. This measure would serve to deter unreasonable regulations. Specifically, the OIRA should have, and be known to have, authority over both prioritysetting and cost-benefit balancing. It should be committed to mitigating the most unfortunate effects of availability cascades, not only by keeping small risks from consuming huge resources, but also by ensuring that major risks receive attention. Where experts working under OIRA lacked confidence in risk judgments spreading through a cascade, they would conduct fact-finding exercises. And, depending on the results, they would publicize any inaccuracies in popular beliefs. Likewise, where a scientific study suggested that a particular risk judgment should be revised, OIRA would examine the study's methodology, check whether its results can be replicated, and disseminate its findings. OIRA's mission should also include the dissemination of systematic information about risks, including changes in what scientists know about particular risks and the methods for controlling them. Finally, it should con-
duct systematic comparisons with other countries in the interest of finding cross-country differences that might provide clues to misperceptions or policy flaws at home. OIRA could constitute one of the information sources for the RIS discussed above.
If it proves infeasible to redesign OIRA along the proposed lines, and its role remains very limited, one might establish an alternative institution to publicize the inconsistencies of the prevailing regulatory system and focus attention on the most serious risks. United States Supreme Court Justice Stephen Breyer has suggested assembling a multidisciplinary group of welltrained risk managers, which would be authorized to divert resources from small problems to large ones.25 Justice Breyer's suggestion is largely consistent with our discussion. A "Breyer Group" within the executive branch could undertake the types of analyses and educational activities we are proposing here. The group would have the authority to publicize its findings about the relative seriousness of risks, require agencies to seek consistency in setting their priorities, and recommend changes in statutes, regulations, and even appropriations. A Breyer Group might even be empowered to undertake certain resource reallocations on its own. Our difference from Justice Breyer, which is perhaps only one of emphasis, lies in our view that risk evaluation has nontechnical dimensions that may require democratically determined risk policies to diverge from the types of risk rankings currently fashionable in scholarly circles.2
[Vol. 51:683
E. Courts
Courts, too, have a role to play in preventing excessive reactions to availability cascades. Most naturally, they can undertake judicial review of administrative actions alleged to be "arbitrary" or "capricious" within the meaning of the Administrative Procedure Act (APA).2 The ban on arbitrary or capricious action is increasingly being understood as requiring agencies to produce plausible evidence that their actions produce "more good than harm. This notion appears to embody a presumptive requirement that costs not be grossly disproportionate to benefits. Thus, existing doc-
trine authorizes courts to invalidate the most extreme and the most poorly conceived regulatory proposals, at least if they are not required by statutes. Courts can hardly be expected to identify availability cascades or to invalidate regulatory initiatives merely for being products of cascades. But if regulators are required to demonstrate that their policies would plausibly make things better rather than worse, taking account of all relevant variables, we will have a potentially valuable safeguard against harmful cascades.
Ordinarily, the reach of the doctrine of "more good than harm" is limited. But in contexts in which an availability cascade produces a sudden outcry for costly action against an actually small but allegedly grave risk, this doctrine can provide courts considerable authority. At a minimum, it prohibits regulations that rest on unfounded perceptions about health Courts might also use the doctrine as an interpretive principle in dealing with ambiguous statutes specifically, the principle would allow agencies to exempt de minimis risks, and perhaps require them to do so, on analogy to the common law maxim that absurdity in interpretation will be avoided The doctrine of more good than harm entails a requirement that agencies be permitted to engage in "health-health" analysis where they see fit, ensuring that regulations do not create health problems more serious than those they are intended to alleviate.26 Certain policy responses to availability cascades will be found to fail health-health analysis.
Finally, the "more good than harm" doctrine entails a mandate that, under the APA, agencies undergoing arbitrariness review should make a plausible showing that a regulation's costs are not grossly disproportionate to its benefits. We have said that our analysis makes a cognitive case for costbenefit analysis as a safeguard against socially destructive availability cascades. If availability and unavailability cascades can divert attention from important questions, then a broader reason exists for thinking that some form of cost-benefit analysis can do some good.267
F. Summary: Revisiting the Cases By way of summary, let us explore how the availability cascades discussed early in the article might have fared had the relevant institutional reforms been in place. The proposals that followed the terrorism-related concerns involving TWA are probably the easiest to reconsider in this light. Most would not have survived cost-benefit analysis. Studies probably would have shown that, in encouraging driving by raising the cost of flying, the proposals would not have enhanced overall safety and might well have harmed Our reforms would have had the same function as an earlier use of cost-benefit analysis, which tested a proposal to make young airplane passengers fly in their own child safety seats.270 In that case, cost-benefit analysis revealed that such a restriction would cost rather than save lives (by encouraging driving), and this finding helped defeat the proposal.
The Alar case could have been subjected to an analogous test. Peer review and cost-benefit analysis would have revealed the NRDC report to be vastly exaggerated, helping to alleviate the rapidly spreading fears. Perhaps by the time official investigations were completed and their findings publicized, the rapid cascade would already have forced apple growers to cease using Alar. However, government officials, relying on information from OIRA and the proposed Risk Information Center,2 could have provided more forceful reassurances than they actually did. In the Love Canal case, a congressional risk oversight committee might well have restricted the size of Superfund. It could have shown that even if it is appropriate for the federal government to commit itself to cleaning abandoned hazardous waste dumps, devoting billions of taxpayer dollars to the cause was indefensible.
The reforms we advocate would thus have protected society against legislative misallocations while offering the executive branch a greater role in priority-setting. The government would have been able to reallocate resources earmarked for abandoned hazardous waste dumps to more serious risks such as cancer and asthma.
In this article, we have tried to substantiate the following claims: 1. In a broad array of contexts that call for risk judgments, individuals lack reliable or first-hand knowledge. In such contexts, they assess probabilities with the help of the availability heuristic. Insofar as this heuristic influences the information that individuals store, retrieve, and process, it interacts with all other judgmental heuristics and with all cognitive biases that distort their judgments.
2. The availability heuristic, which has been studied in isolation, is frequently amplified by socially shaped informational cues and reputational incentives. People often believe something because others appear to believe it or they feign conviction to avoid reputational harm.
3. The informational and reputational processes that shape public discourse ordinarily feed on one another. Under the right conditions, they generate availability cascades that spread and worsen misperceptions. As a result, the perceived collective wisdom may bear little, if any, relation to reality.
4. Availability entrepreneurs try to trigger availability cascades likely to advance their causes, and they work to extend those already in progress. Acting selfishly or altruistically, they focus attention on isolated events, select information to support their preferred interpretations, and make anyone who questions their objectives appear ignorant, duped, or depraved.
5. Insofar as the availability heuristic helps shape individual perceptions, public opinion about the relative magnitudes of risks will exhibit multiple expressive equilibria. This implies the possibility of sudden shifts in public discourse on any given matter (as with the eruption of mass anxiety over toxic waste sites in the 1970s), inconsistencies across contexts (as with the huge attention paid to the dangers of Alar when more significant sources of risk, such as poor diet and insufficient exercise, received little attention), and discrepancies across countries at any given time (as with policies with respect to nuclear power, which is considered a much more serious threat in the United States than in Europe).
6. Availability cascades should be an important element in the positive analysis of legislation and regulation. An emphasis on interest-group pressures alone, or the availability heuristic standing by itself, leaves important gaps in understanding.
7. Availability cascades that spread empirically baseless information create formidable political pressures in support of wasteful and counterproductive regulations. These pressures might be mitigated by equipping the political system with "circuit breakers" to slow availability cascades and encourage the reconsideration of the demands they spawn.
Without removing the right to select risk policies democratically, all three branches of government should be enabled to resist demands driven by misinformation about risks and to seek consistency among risk policies.
Our starting point has been that people often lack relevant knowledge, even with respect to matters of great importance to them, and even if their convictions are intensely held. On matters ranging from the health consequences of sugar and coffee consumption to the risks of automobile driving, nuclear power, global warming, asthma, and thinning of the ozone layer, each of us depends for information on what other people seem to know, even as others are relying at least partly on us. We have sought to show how the availability heuristic interacts with informational and reputational motivations to create pervasively held social judgments rooted in cascades.
Because people routinely use the availability heuristic in trying to make sense of reality, there is a danger of widespread and persistent misperceptions about risks. To be sure, an availability cascade that reshapes public discourse may be socially beneficial the transformation can draw overdue attention to neglected problems. But there is no guarantee that the effects will be beneficial socially damaging availability errors cannot be ruled out. A major challenge for any democratic system is to institute safeguards against harmful cascades. We have suggested that a modest but potentially appropriate response is to create disincentives against efforts to instigate mass scares by propagating knowing falsehoods. We have also suggested, less modestly, that each of the three branches of American government should be reformed in order to create protections against the adverse effects of availability cascades. Our analysis indicates that peer review and costbenefit analysis should be encouraged as checks against misperceptions rooted in interdependent learning and preference falsification.
Availability cascades are by no means new, but modem communications enable them to gather momentum and overwhelm governments far more rapidly than was possible in the past. Fortunately, the very technologies responsible for this transformation present new tools for lessening the potential dangers. Most promisingly, a trusted Risk Information Site on the World Wide Web could make the latest information on a wide variety of hazards instantly available to anyone with access to a computer. This site would educate people not only on the magnitudes and characteristics of particular risks but also on discrepancies between private and public opinion about relevant controversies.
A broader educational mission would be to disseminate information about the mechanics and implications of availability cascades. Insofar as people appreciate the mechanisms discussed here, they will know that public opinion can be both misinformed and deceptive. As Alexis de Tocqueville recognized, the notion that the majority is not necessarily right collides with one of the building blocks of modem democracy: the principle of majority
[Vol. 51:683
rule.274 To ascribe moral authority to numbers is to instruct individuals that if they are outnumbered they are likely to be wrong and deserving of criticism. It is also to signal to the majority that it has a moral right to intimidate dissenters. As compared with people socialized to believe in the virtues of majority rule, those who understand the mechanics and consequences of availability cascades will be more resistant to their informational and reputational signals.
Availability cascades can arise with respect to any issue on which large numbers of people have limited knowledge. Consider the controversy over reforming social welfare programs. Most Americans are uninformed about the details of these programs few people know the percentage of welfare recipients who live in cities and how long beneficiaries generally remain on welfare. Whatever the merits of tightening welfare eligibility requirements, activists on all sides of the controversy help shape public discourse both by disseminating biased information and by vilifying their opponents. President Reagan, a master at using modem technologies to exploit people's use of the availability heuristic, played a leading role in reorienting public discourse on welfare, above all through sharp anecdotes that made honest taxpayers consider the system unfair one such anecdote was the tale of the chauffeurdriven "welfare queen" who makes a fortune without working. President Reagan also succeeded in painting the supporters of welfare as "tax-andspend liberals" uninterested in promoting a sense of personal responsibilThe debate preceding the Gulf War of 1991 provides another instructive example from national politics. People on both sides of the debate recognized that their cause would benefit by framing the issue appropriately and exploiting the availability heuristic. Pro-interventionists sought to raise the availability of images of the Korean War, which is widely believed to have inhibited the spread of communism anti-interventionists reminded Americans of the Vietnam War, generally remembered as a death trap born out of miscalculation, ignorance, and self-serving exaggeration of the stakes inApril 1999]
The explosion of federal and state legislation to combat "hate crimes" offers another instructive example. This legislative campaign is being spearheaded by availability entrepreneurs who publicize major crimes against gays and ethnic minorities to paint a picture of a virulent "epidemic" of such crimes and to signal that the campaign's opponents show insensitivity to a horrible social problem.278 Their campaign for hate crimes legislation went into high gear in mid-1998 after a racially-motivated murder in Jasper, Texas. Proponents argued that this murder confirms the persistence of racial violence and the need for extraordinary measures to combat the problem. Opponents of such legislation sought to use the same tragedy to demonstrate the lack of a need for special legislation. Jasper united in condemnation of the crime, they noted, and the police quickly caught the suspects.
Salient news sometimes becomes the focus of availability campaigns designed to achieve political outcomes that would otherwise be unattainable. A coalition of celebrities used Princess Diana's death during a high-speed escape from tabloid journalists to make a case for stronger protections against invasions of their privacy. The leading availability entrepreneurs of this episode were the Screen Actors Guild and Senator Diane Feinstein they tried to capitalize on the sympathy that this tragic death evoked by publicizing the dark side of tabloid journalism and vilifying tabloid journalists in order to catalyze an availability cascade in favor of new restrictions on media activi-
There are also groups that work to potentially salient events capable of producing availability cascades inimical to their legislative agendas. In 1998, a group of Greek-Americans organized a campaign that induced a famous actor to give up the lead role in a high-budget film about the life of Mustafa Kemal Atatfirk, the founder of modem Turkey. Even though the period when Atatfirk held Turkey's presidency is remembered as the golden age of modem Turkish-Greek relations, the campaigners, who condemned Atatiirk for actions they perceived as evil, feared the film would depict him favorably. They also feared that a reverential portrayal in a major Hollywood production would improve popular feelings toward Turkey, which they considered a threat to Greek interests.2 One of their justifications was that the probable transformation of public opinion would alter the political bal-
ance in Washington with regard to laws and policies of interest to the two mother countries and their ethnic communities in the United States.2 Another was that the film would influence legislative battles raging in many state and local governments over guidelines for teaching history.
Availability cascades are relevant not only to routine legislative struggles but also to the making and exercise of constitutional law. Consider first the matter of constitutional design. The rules for constitution-making and constitution-amending provide safeguards against bad cascades. In particular, they call for extended deliberation to prevent rushed, myopic, or misinformed judgments. Proposed amendments succeed only by surviving a complex process of "peer review" by many people in various institutional settings.288 Like the rules that govern constitutional design, the checks and balances of the Constitution are designed to counteract the potentially destructive social forces that we have highlighted here.2 So understood, the prevailing constitutional limits to rapid decisionmaking hardly constitute undemocratic obstacles to implementation of the popular will. On the contrary, they are instruments to improve the workings of democracy in the light of the inescapable cognitive limitations of individual citizens and their susceptibility to social pressures.
The courts are not immune to the social mechanisms examined in this article. Judges are subject to the availability heuristic, vulnerable to informational biases, and responsive to reputational incentives. All this leaves them open to the influences of availability cascades.291 Occasionally, a single legal decision-for example, Dred Scott v. Sandford,292 Plessy v. Ferguson, Lochner v. New York,294 Brown v. Board of Education,29Roe v. April 1999]
Wade296 -comes to signal how an entire area of law should be understood. By virtue of the salience it acquires, it conveys a relatively simple moral or institutional lesson. For precisely this reason, individuals with strong views on a possible, pending, or actual legal decision try to show that it is, or could become, "another Lochner, .... another Brown," or "another Roe." Social struggles over the meaning of great legal cases should be understood in this light.
Brown was exceedingly controversial in the late 1950s and early 1960s, but its defenders put in motion an availability cascade that completed its course around Since that time, to say that Brown was misguided, or even to question its merits, has been to risk serious reputational damage, even ostracism from legal circles. Part of Brown's significance lies in its demonstrated power to trigger subsidiary availability cascades, such as those that have made discrimination on the basis of sex and alienage seem "like" racial segregation.
The evolution of the American legal community's understanding of Roe v. Wade offers an example of concurrent and competing local availability cascades. In principle, Roe may be treated as either "another Brown" or "another Lochner." Through the mutually reinforcing reputational and informational mechanisms discussed here, large segments of the legal community have come to perceive it as "another Lochner." Within these circles, a defense of Roe triggers reputational sanctions. These circles co-exist with others, within which one incurs reputational punishments for challenging rather than defending Roe. Within each of these rival camps, perceptual interdependencies are clearly at work. Their members consider Roe right or wrong partly, if not largely, on the basis of what their co-members generally seem to believe. As with Brown, the social forces at work have spillover effects in other areas. Roe's controversial status may have initiated a powerful availability cascade that predisposes judges not to extend constitutional protections to new rights claimed to be part of constitutionally protected privacy or liberty. It may even have helped make the Supreme Court less inclined to
treat the "right" to physician-assisted suicide as a constitutional right, lest the judgment create "another
Availability cascades can help or hinder the tasks of governance by shaping social norms and determining compliance levels. Behavioral research shows that changes in the availability of information about compliance with a prevailing norm often influence the extent to which it is followed. For instance, taxpayers are far more likely to comply with the prevailing tax laws if they believe that most people fulfil their tax obligations than if they think that noncompliance is widespread. Another example is the problem of drinking on college campuses. Students who "binge drink" tend to overestimate the number of binge drinkers when informed of the actual numbers, they are less likely to continue this self-destructive and socially harmful behavior.3 The tax evasion and binge drinking examples suggest that undesirable behaviors may be curbed simply by controlling the information available to the relevant actors, or alternatively, correcting the availability errors that contribute to the conduct. Each of these cases also shows that the availability of information about compliance levels affects behavior through two channels: by signaling what is socially acceptable and by providing clues as to one's own interests. Laws that have produced compliance with little or no enforcement, such as those that relegate smoking to designated areas and require people to clean up after their dog, have much to do with the informational and reputational mechanisms discussed above.3
Our arguments here constitute a challenge to both the economic analysis of law and branches of cognitive psychology that are beginning to influence legal scholarship.3 With few exceptions, economists have ignored critical interdependencies that govern people's preferences, choices, and beliefs even the public choice school, which focuses on the sources of legislation, typically neglects the interdependencies at the heart of our argument here. Yet, as we have emphasized, there is no inherent conflict between the rational actor framework and the mechanisms that this article has high-
