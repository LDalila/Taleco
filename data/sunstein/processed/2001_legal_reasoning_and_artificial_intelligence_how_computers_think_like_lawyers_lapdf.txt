Ashley, Kevin Branting, Karl Margolis, Howard and Sunstein, Cass R. (2001) "Legal Reasoning and Artificial Intelligence: How Computers "Think" Like Lawyers," The University of Chicago Law School Roundtable: Vol. 8: Iss. 1, Article 2. Available at: http://chicagounbound.uchicago.edu/roundtable/vol8/iss1/2
1. Ardficial intelligence
ing and show what you can do with them. Computational models of analytical legal reasoning are comprised of a knowledge representation and an inference mechanism. The knowledge representation captures some important aspects of legal knowledge. And the inference mechanisms are algorithms that enable a program to use those elements of legal knowledge that are represented in order to solve problems.
This is an idealized illustration of a computational model of legal reasoning. It comprises a knowledge representation and an inference mechanism. The knowledge representation is a conceptual hierarchy of legal information dealing with some particular type of legal claim. At the bottom level it relates cases and their facts to the elements of some legal claim and, ideally, ultimately to the legal policies and principles that underlie that legal claim. The algorithms of the inference mechanism use that information. For instance, the inference mechanism may take a problem situation and compare it to other cases in light of the other cases' analyses, draw inferences about how that problem should be decided, and generate arguments using the information in the computational model.
Now there are three general issues in designing these computational models.
Synposhim: Legal Reasoning and Arziftdal Intel'gence
Now that's an idealized model. This is about as close as I've come to realizing that type of computational model. This is a Factor Hierarchy that my student, Vincent Aleven, designed for the claim of trade secret misappropriation. At the top level are the elements of the claim. For example, is the information a trade secret? Is there a confidential relationship? Were improper means used? And for each of those there would be a Factor Hierarchy. I'm just showing you the Factor Hierarchy for one: Is the information a trade secret?
At the bottom level are the various factors, the stereotypical patterns of facts that strengthen or weaken a claim. For instance, here's Fl 5, factor 15: "unique product." It stands for a stereotypical fact pattern that one often sees in trade secret cases. The plaintiff's claim is stronger to the extent that its product is unique in the industry. It's relevant to the issue of whether that information is a trade secret in two different ways. It shows that the information is valuable. It also suggests that the information is not known in the industry. The Factor Hierarchy is a graph, that is to say any given factor on it can have more than one
Symposium: Legal Reasoning and Ar
parent and we'll come back to the significance of that in just a second.
VA-ere pltf. ad def. entered into a nondisclosure agennt [F4], p1tf. took nmsures tol ep its infrmaticu secret [F6], ard def. entered into an agement not to coopete vith pltf. [F13], plff. should in a claimof trade secrets misapptiation, as inthe ElcorCase.
!Ecor is distinguishable. It is strngr for ptff. than is the current problem In E/cor, pltf.'s prouct was uniqu or the ramdkt [15] and thef= e substantial sinrilarities beteenpltf.'s and def.'s products [F18]. Not so in ... [FI5] is not an inpotant distinction. InMBL def.'s access to pl.'s info enabled it to develop its product in less firm or at loer cost [8]. It follos that inboth cases, pl.'s info was valuable for pl.'s business [P104]. [P15] is an-aceddistincticn Shos that inEco, the info appaently was not knowv outside pl's business [F106], x~Ndeas in MBL, pL's info was known outside pl.'s business [F106]: P. disclosed its prauct info to outsiders [Flo] and pl.'s info was generally known in the industry [MO0].
One can use a computational model like this to generate legal arguments and even to generate alternative interpretations of cases. This is a sample argument that the CATO program generates for a problem called the MBL case.6 I don't want to get into the details here, but I just want you to see the structure of it. It starts with an argument by analogy (first row of Slide 3). CATO argues that the MBL case should have the same result as the Elcor case,7 that is, the plaintiff should win. And it elaborates an analogy in terms of the factors that the two cases share. Then the program switches hats and argues that Elcor is distinguishable from the MBL case (second row of Slide 3). It's now arguing on behalf of the defendant. It points out, among other things, that the product was unique in Elcor, that is to say that factor F15 applies. But that was a strength that one doesn't find in the MBL problem.
I would also like you to focus on the last two parts. Here, CATO downplays
the significance of that distinction on behalf of the plaintiff (third row of Slide 3). It argues that the fact that the product was unique in Elcor is not an important distinction. It argues that the reason that that factor matters is that it shows that the product is valuable, that it has value. That was abstract factor 104 in the Factor Hierarchy. CATO points out that in the MBL case, there was other evidence that the product was valuable. In other words, CATO is arguing, given the reason why the distinction matters, that these two cases are basically the same. In this last argument, CATO responds for the defendant, it switches hats again, and now it's emphasizing the significance of this distinction (fourth row of Slide 3). It's saying here that the reason that that factor matters is that it shows that the information was not known outside of the plaintiffs business. And it goes on to say that in MBL there's evidence that the information was generally known, and it points to some other factors in the MBL case. In other words, CATO is arguing that, given the real reason why the distinction matters, the two cases are really quite different. In other words, it's doing analogical reasoning here.
In downplaying and emphasizing this distinction, from where does the knowledge come about why these differences matter from a legal point of view? Well, it comes from the Factor Hierarchy (Slide 2). Let me just show you that again. In making this argument, downplaying and then emphasizing the distinction, CATO is working up from factor F15 on two alternative paths through that Factor Hierarchy. In arguing for the plaintiff that the cases are similar, it's drawing an analogy at the level of that abstract factor 104 that this information is valuable. In arguing that the cases are actually quite different, it's following a different path from F15 through 106 and making a connection to other facts in the MBL case, factor F10 and F20, and using that information to argue at an abstract level that these cases are really quite different. Now, CATO has algorithms that enable it to decide which paths to follow in this Factor Hierarchy and how high up to go in selecting an abstract way of characterizing the significance of the differences. Those are the algorithms. That's the inference mechanism.
We use this feature in a program that teaches law students basic argumentation skills. And my student Vincent Aleven, in his dissertation, evaluated the CATO program in a controlled experiment involving first-year legal writing students with some good results. Another practical application of it might be as a kind of brief writer's assistant. One could imagine having a specialized Factor Hierarchy and case database that's updated periodically with good coverage of a particular kind of claim and that would help associates in a law firm analyze claims and make arguments. So that's my first example of a computational model.
My student, Steffi Brdininghaus, is using a similar kind of computational
Symposium: Legal Reasoning andArhlfidalIntelligence
... ... ... ..... [ ..
SMILE uses a learning algorithm called ID31 to learn a decision tree for distinguishing the positive instances of sentences from the negative instances of a particular factor. On the right [of Slide 5] is a part of the decision tree that SMILE actually learned from the positive instances. It corresponds to a rule for classifying sentences. If the text of the sentence includes the term "unique," then conclude that factor F15 applies. Otherwise, if it contains "known" and "general," conclude factor F15 applies, and so forth. It may seem like a naive rule, but in an evaluation we showed that it does a pretty good job of distinguishing the sentences that are positive instances of a factor from those that are not.
F15 al:e
pat
info rut gffle
To refine the decision trees we need to get more mileage out of the examples. Steffi has focused on trying to make the examples more general. For instance, take a look at that first sentence [in Slide 5]. It actually said in the original "Innovative." That's the name of the plaintiff. "Innovative introduced evidence that Parl Brick," that's the name of the plaintiff's product, "was a unique prod-
[Plaintiff] intoduc evidence that
[plaintiff's product] was a unkiie
product in the induryr.
"It appeaim that onexmvld not orda
[plairtitrs prouct in any
I l other tha that of the
plaintiff."tan YJa&LmielU Xtiay
'qhe infonmtion in the diagnrn is
not generally knm to the public
nor to any of [the plaintiffs]
conipetitor" P
to mT2e Puxid
which are the result of the Board's exercise of these operationalization techniques, in effect, to bridge the gap between case facts and abstract principles.
Let me show you a little about how operationalizations link facts and abstract principles. [Slide 7] contains a list of the operationalizations that Bruce cataloged during his analysis. These are the Board's techniques for bridging the gap between the abstract codes and the specific fact situations. For instance, code instantiation is a kind of more concrete interpretation of a code in the context of a case. In essence, the Board links combinations of selected facts in the case to a code provision when they instantiate it. For instance, in one case, the Board instantiates that public safety code provision that I cited to you before. ["Engineers shall recognize that their primary obligation is to protect the safety, health, and welfare of the public.'] It was a case involving a building inspection. Basically, the Board said that once an engineer discovers that an apartment building, which he has been hired to inspect, presents a danger and he knows that the building authority should be informed, then he has an obligation to warn of the danger even though his client instructs him to withhold the infor-
Ethics ccde pinciples
operationalization knowledge. We called that "Non-Op SIROCCO.1
(his is a
shows the mean F-measure per method over all fifty-eight trial cases. We used two different kinds of experiments here.
The point I want to make to you now is that in both instances SIROCCO outperformed Non-Op SIROCCO and the differences were statistically significant. This difference is the contribution to retrieval effectiveness that comes from the Board's operationalizations. We were able to sort of bottle it, if you will, and take advantage of it in improving the program's ability to retrieve cases.
So, in conclusion, those are my three examples of computational models and what you can do with them. You can generate arguments with them and even generate alternative interpretations of the significance of important similarities or differences. You can use them to help a program learn to index cases automatically. And you can use them to conduct interesting empirical investigations of such phenomena as operationalizing principles.
Ii S 0.4-/
0 Exact Matching
10[ EXTENDED MG
0 NON-OP SIROCCO
0 INFORMED RANDOM
MARGOLIS: And we turn next to Karl Branting. KARL BRANTING: Thank you, Howard. So Kevin has presented several computational models of legal reasoning and how they can be used for analysis and for tutoring. It's my opinion that these models can be useful in jurisprudence for helping to evaluate alternative
by the public. Richard Susskind, in his book The Future of Lawp,14 terms this the latent market-all those people out there who can't afford lawyers. Three, the World Wide Web constitutes a kind of electronic infrastructure for the distribution of legal services. Four, legal expert systems constitute a new vehicle for marketing and distributing the expertise of lawyers. And five, funding limitations on governmental bodies, which we know are always short of money, are inevitably going to drive them to automate a larger and larger proportion of the services that they deliver.
So, in summary, I am suggesting that legal services can be viewed as a kind of commodity, for which the public is the consumer, attorneys are the producers, the World Wide Web is the highway, and legal expert systems are the vehides. And by decreasing distribution costs and increasing economies of scale, legal expert systems will inevitably lead to increased consumption of this commodity. Less efficient producers will inevitably be priced out of the market. So
14. Richard Susskind, The Fumure of Law (Oxford 2d ed 1998).
only going to be able to make a few comments in support of it. Let me start by making the observation that there are quite a few different participants in the legal system and, in my view, for each one of these participants there may be various different legal tasks each requiring a separate computational model. By the participants, I mean we have the members of the public, clients, attorneys, judges, clerks, legislators, all people who are participants in the overall process. Just for simplicity, let's hone in maybe on the most typical garden variety sort of legal problem solving episode that we might imagine, which is when an individual comes to consult an attorney about some legal problem.
What kinds of separate tasks does an attorney perform? Well, I claim that there is a whole series of them. The first one is what I call problem formulation. When a client explains a problem to an attorney, the attorney has to elicit the legally relevant facts, steer the client away from the legally irrelevant stuff (indignation and so forth), and the attorney needs to formulate the problem that is being posed by the client in terms of legally relevant concepts. The second step is retrieval. The attorney, the legal problem solver, needs to think of some legal authorities that are relevant to the problem that has been formulated in the first step. Next is what we might call problem analysis. This is determining what sort of legal consequences might follow from the application of the legal authorities to the facts as elicited by the attorney. Next is the task of prediction. That is, for each of the possible outcomes of some legal action, litigation for example, estimating the probability of those outcomes. What is the expected return on them? How much would it cost to go to trial on a certain issue? How much might you win? How likely are you to win? Other tasks are planning, deciding what sort of actions should be taken on behalf of the client's goals, document drafting, and others. I won't enumerate them all.
The character of each of these tasks is rather different from the others. Not all of these tasks are amenable to modeling, only a subset. But the subset that, in my view, is most amenable includes the task of retrieving authorities, the analysis task, the prediction task, and the document drafting task. I'll just hone in on those. So far, I am still trying to support my contention that there are models of legal reasoning that are adequate for routine tasks. Number one, retrieval, I'm not going to talk about. There is a long history of AI models doing it. But right now the dominant models, e.g., the LEXIS/Westlaw kind of model, don't use much in the way of Al. I won't talk about that one. Instead I'll start with analysis.
Analysis. That's the idea that if I have some well-defined facts and I have some well-defined authorities, can I derive some arguments from them? Well, I think that if the problem is sufficiently well posed, then there are a variety of different models for finding arguments for and against a different legal conclusion. The simplest and historically the oldest one simply maps legal rules onto computational rules or logical rules. Such systems are useful if the case facts are
Symposium: Legal Reasoning andArtfiallntelligence
something like the UCC15 is much more appropriate than a legal problem in-
probability of success or, more precisely, the expected return on the lawsuit. A third task is document drafting. As we all know, there is already a large commercial market for the very simplest document drafting systems. There are lots of sophisticated models of document drafting, including some based on state of the art linguistics and speech-act theory.
So in summary, I think that there is, at least for these three tasks-for document drafting, prediction, and analysis-a history of computational models. They vary widely in their flexibility and explanatory power and development costs. And moreover, the relative merits of these models are, of course, a matter of dispute among computer scientists and scholars of jurisprudence. But the fact is that, at least at the low end, executable models-legal expert systems-already exist.
So that was all on claim number one. My other claims will be briefer. Factor one, the claim that models exist. Two, the unmet need for legal services. I think I can just appeal to the familiar experience that we all have that attorney fees are quite expensive. As a result, individuals are frequently unable to afford answers to basic legal questions. The cost of getting an answer to a legal question is often greater than the value of the claim that the question applies to. Of course, that is not true of large institutions, but for ordinary citizens this tends to be the case. And these costs are exacerbated by uncertainty in the legal system, which is the result of the fact that the law is in a state of evolution and therefore unsettled, the delays of litigation, which are worse in some places than in others, and the overall lack of predictability in the process.
So far I've said there are good models. There is also an unmet demand for legal services. A third factor is the World Wide Web. The World Wide Web is a wonderful development for people in my area of study because it provides a uniform computer interface familiar to a very high proportion of litigants and attorneys. It largely eliminates the problem that we used to have in software distribution, that is, hardware inconsistencies and interface inconsistency and unfamiliarity. So even the most technology averse lawyer is likely to be familiar with web browsers, if only because he or she has seen his or her children using them. [Iaughter]
Claim number four, legal expert systems as a distribution mechanism for legal expertise. It is my observation that the economic motivation for the law firms that are most active in development of web-based legal expert systemssuch as London-based Linklaters, Sidney's Blake, Dawson & Waldren, Ernst & Young, and others -is that, well, first of all, that legal expert systems perform work that wouldn't otherwise be done by the firm. So the idea is that clearly you don't want to make an expert system that you market for less than the amount it would cost one of your own attorneys to perform the same work. But the motivation is that the legal expertise can be marketed to a larger number of consum-
activities that are not billable. In the firms that I mentioned earlier that have invested a great deal of effort in creating legal expert systems, for internal institutional reasons there is not a lot of internal pressure for the people involved to be billing hours constantly because there is this huge upfront cost in the time of legal experts that is only amortized over the lifetime of the use of the program.
And the last one is the rather difficult institutional barrier, the ill-defined standards for the unauthorized practice of law. I think that there is going to be litigation on this subject in increasing amounts, because there are many attorneys at the low end of the food chain that are going to be directly threatened, already are threatened, by these systems, who are going to find daims of unauthorized practice of law as a way of attempting to stanch this flood.
Let me conclude with some predictions concerning the effects on the legal community. I think that legal expert systems aren't going to reduce demand for high-end legal services. In fact, I think, to the contrary, it is going to improve the delivery of high-end legal services by automating some of the more routine aspects. As an example, there is a new product that uses natural language processing to do proofreading pretty effectively. And it is marketed by saying that this is a mechanism to retain associates who would otherwise get so discouraged at being kept up late proofreading documents over and over again that they would move to some other firm. Plausible or not, I don't know.
On the other hand, the providers of routine legal services are going to face increasing competition from legal expert systems. And I think, as I said, that solo practitioners are already under such pressure. It may be that a new field of legal information engineers is going to develop consisting of attorneys whose job is to organize information for electronic mass distribution. And finally, I think that interactions with low-level government functionaries will increasingly be replaced by simple web-based legal expert systems. Am I out of time?
MARGOLIS: Yes. [laughte]
BRANTING: Thank you. [applause]
CASS SUNSTEIN: This is extremely interesting material. A major question is: What can we learn about artificial intelligence and what can we learn about legal reasoning from bringing them into contact? That's what I'm going to try to say something about.
There's a weak version of the enthusiasm for artificial intelligence in lawweak meaning less ambitious-and that is that this is like really upscale LEXIS and Westlaw. It bears the same relationship to LEXIS and Westlaw as LEXIS and Westlaw bear to Shepard's. In this view, it's extremely helpful for lawyers, who can find a lot of cases quickly. Plug in a problem and they'll see lots of cases like it and potential similarities and differences. That seems to me a convincing claim. Kevin Ashley has demonstrated it. That's the weak version and I'm all for that.
Sympomium: Legal Reasoning andArtfiaallntelligence
The strong version, which both speakers actually endorsed, is that artificial intelligence as we now have it can engage in analogical reasoning or does engage in analogical reasoning. To phrase it a little more polemically than is probably fair, I'll say that's just a mistake because at the present state of the art artificial intelligence cannot engage in analogical reasoning or legal reasoning. They can't do it. And the view that they can do it, or are doing it, is based on a misunderstanding of what analogical reasoning is, one that disregards the inescapably evaluative or normative dimension to my claim that one case is "like" another case. To engage in analogical reasoning, to do it, there has to be an evaluative argument showing that this case is like that case. There has to be a principle, and at the current state of the art, artificial intelligence can't generate good principles, or principles at all. I'm hoping this will be helpful.
Suppose you have someone who's been fired by an employer, a copilot, say, for refusing to fly an airplane on the ground that it's not safe. The employer has fired the copilot, and the copilot wants his job back or wants some money. Let's suppose, to make it very simple, that we're in a jurisdiction in which one court has held that you can't fire someone for refusing to commit a crime and another court has held that you can fire someone for reporting that the bank for which he works hasn't engaged in advertising activity in low-income communities. This is a world with just three cases: the case at hand, one case the employee wins, another case the employee loses. What's to be done? This is a problem in analogical reasoning.
A going account of analogical reasoning is by Edward Levi,21 and the title of this subsection of my talk is "Levi's Mistake." What Levi suggested was, in engaging in analogical reasoning, judges ask which case is more similar to the case at hand or which case has more similarities to the case at hand. Is it dear that that's not a very helpful way of doing analogical reasoning in our pilot case? Is the pilot case more similar to the bank case or is it more similar to the crime case? To figure that out you can count similarities. But is that what you're going to do? It's not an exercise in counting. You have to do something else, and let's make a little amendment to Levi and say you can search for relevant similarities. Now that's helpful, or at least more helpful than counting for "more." You need to find relevant similarities and HYPO, the computer program, can do that, but that's not helpful enough. To know whether a similarity is relevant, you need to figure out the principle for which the first case stands, and the first case doesn't tell you that. Is the idea in the crime case that you can't fire someone for refusing to inflict harm on third parties? If so, then our pilot maybe is going to be okay. Or is the principle instead you can't fire someone for refusing to commit a crime? If so, then our pilot's in trouble.
The ideas of "relevant" similarities and "more" similarities are pretty much non-starters. You need to figure out what the principle is that links or separates
the various cases. Ronald Dworkin,22 maybe the subsequent generation's Levi, gave some help on this, a kind of clue. He says what you do when you're engaging in legal reasoning is you put the previous decision in the best constructive light. You try to make the best sense out of it. So Dworkin says analogy without theory is blind. An analogy is a way of stating a conclusion, not reaching one, and theory must do the real work, where theory is the principle that links cases or that separates them. The upshot of this is that in any case that's a real case, to figure out whether something's analogous to something else, you have to generate a principle by which the two cases get linked or separated. Lists of factors will be a start, better than Westlaw and LEXIS, but they won't be analogical reasoning. That's not what analogical reasoning is.
To make progress here, we shouldn't give up on artificial intelligence and its potential. A lot more can be done. Good reasoners are going to deal with our copilot case. Can our copilot be fired? Probably anyone in this room, given ten minutes, could figure out ways of thinking the copilot should win or ways of thinking the copilot should lose by reference to the previous cases, reporting on the bank's violations on one hand and the person refusing to commit a crime on the other hand. But how can we make better progress? One thing we might consider is empirical: What are the consequences if you give copilots a right not to fly planes that they see as dangerous? If they can't lose their jobs for that, you might ask, is that going to make people safer? If so, that's a point for the copilot. If copilots do get this right, if the right is given to them, is this going to make it very much harder to run airplanes? Is this going to decrease convenience and order for airplanes and passengers? Those are empirical questions, which Judge Posner, in the relevant case,23 thought relevant. He's surely right on that. To do the analogical job well, one thing to pursue is these empirical questionsnot empirical in the sense that Professor Ashley suggested, not about collecting cases and factors, but an empirical inquiry into the real world effects of one or another legal rule. There's no reason in principle that a computer can't be helpful with that.
If we're not going to get empirical, then what we'd want to do is square our judgment of principle about whether the copilot should win with the rest of the things we think in imaginable cases. Then we'd have to be very creative and go beyond the cases at hand, the precedents, and hypothesize lots of analogies and think what makes best sense of our system of labor law insofar as it bears on this. A lot of really good judges go that route. So far as I can tell from Professor Ashley's really quite outstanding book,24 HYPO isn't able to do that. What HYPO can do is come up with cases, and it can be pretty exhaustive in that, telling how they might be similar and how they might be different, but in a kind
Symposium: Legal Reasoning andArfidalIntelligence
the arguments are working with those reasons. In work that's being done by colleagues in Europe, Henry Prakken and Giovanni Sartor, they are representing values, principles that are at stake in cases, and those are being worked into the arguments as well. So at least these concepts, these normative concepts, are being worked into the arguments.
Now whether judgment is being applied is another question. But I will opt in favor of the weak AI approach. My game is, I think, to try to find ways in which representing knowledge drawn from our models of how we reason in law, how can that knowledge be applied to do a better job of doing those weak tasks, like retrieval of the right cases at the right time or, for the cases that are retrieved, highlighting what's interesting about them, what's useful about them in the context of an argument. My game is not to try to reproduce the hard tasks of legal reasoning so much as to try to use the knowledge of how we do the hard tasks of legal reasoning to try to build better tools to support those tasks.
We, I think, have been careful not to compare strengths of arguments in terms of numbers. In HYPO there was no comparison of numbers. It was comparisons of sets in terms of set overlap, which is quite a different thing. And we're also, many of us, very sensitive to any attempts to assign numerical weights to anything like principles or values or factors or whatever and to collapse pluses and minuses in that way. We tend to eschew that kind of thing. So I think that we are sensitive to these concerns. We're just gradually working our way upward into the more complicated kinds of arguments that Cass and Howard are talking about.
BRANTING: I guess I'd have several responses. First of all, the legal expert systems that I was describing would clearly all fall into the weak category. They are useful tools. They may be performing some functions other than just weighing arguments. For example, document drafting and prediction are somewhat different tasks. But I guess I would want to emphasize also that people who work in the field of artificial intelligence and law by and large are sensitive to the fact that analogical legal reasoning is not a mechanical process and that the current computational models don't do an adequate job including the evaluative factors that Professor Sunstein pointed to.
On the other hand, in my view, what artificial intelligence is about is really two things. One is making useful artifacts. But a second thing is self-knowledge. That is to say, for example, not that this is what you said, but to say that certain kinds of problem solving or certain kinds of analysis cannot be modeled is kind of a way of saying we can't know ourselves, we can't understand how we solve certain problems well enough to define it with a specificity that's required of a computer. So from my point of view, one of the benefits of this field is that the exercise of trying to formalize legal knowledge in a computer-executable fashion is it forces you to make explicit every piece of knowledge that goes into that decisionmaking and can sometimes make obvious the gaps. For example, some
Syposium: Legal Reasoning and Arifidal Intelligence
MARGOLIS: You wanted to add to that?
MARGOLIS: Do we have any questions? Yes, please.
tiffs lost and the white plaintiffs won? That model would never show anything like that. So that is just one example that what somebody's judgment is during the inputs-whether it is the person searching or applying the law or the person putting in the tools and items in the computer or database that makes it all work-is going to limit whatever is produced. We might be better off going back to paper and Shepardi#ng, because you have to look at a certain case and come to a judgment of whether or not it is worth seeing.
ASHLEY: I think that that is a very interesting observation. I have to worry about that a lot because I am building, among other things, tutoring systems to teach law students to make arguments with cases. And the fact is that if you model something and focus their attention on one thing, you cause them not to focus their attention on something else. In addition, it is very difficult, because no matter how smart my model is, the students are infinitely smarter. It is very difficult for my program to provide feedback because it is always possible that the student has caught something that the computer simply doesn't know about because it hasn't been modeled. And thus if it says, "No, that's wrong," that's a problem.
It is also a problem even with the graphics that one might use to represent an argument. I didn't show you an example of a claim lattice, but there are ways of graphically representing arguments. We find them useful. They focus your attention on one interesting aspect of an argument but, again, one loses touch with others. It is a design problem that I am constantly trying to finesse.
But as far as the missing of the certain factors that the law does not treat as relevant but really are relevant, that is something that I haven't addressed. I like to look at the work of people like Professor Ted Eisenberg25 at Cornell, who has done these interesting statistical models of large areas of case law. His students are doing something like my students are doing when they prepare summaries of cases. They go to the cases, they have a form that they fill out for all of the stereotypical facts, but they include the legally "irrelevant" ones as well as the legally relevant ones, to the extent that one can determine them. And then he does statistical analysis on it and comes up with very interesting things. It is a kind of work and a kind of analysis that has to be done as well as the sort of stuff that I am doing. So I agree with you and I try to work around it to the extent that I can.
Another question or comments from the other panelists?
I'd be happy to respond to that as well. The perspective that I have been taking is legal expert systems as a vehicle for the delivery of legal expertise. And the question which you have raised is not so much about the adequacy of the vehicle itself, but its content. And of course that is true, it is only going to have as much value as the value of the expertise that is put into it. As
Syposium: Legal Reasoning andArfidal Intelligence
raises interesting issues about what artificial intelligence can ultimately do and also about what legal reasoning really is. You know, there's a joke among the faculty that you could imagine a computer program-I bet someone could do it-that could write a law and economics article about any topic. Choose a topic and promptly it's the case that you take your favorite or least favorite methodology, and you could imagine a computer program that could do that. I think you're absolutely right that these programs can perform as well as or better than really busy people who don't have time to think a whole lot about what's the best principle to construct for an area of law.
One of the great parts of Professor Ashley's book talks about the relationship between HYPO's performance-HYPO is the computer program-and judicial performance. They're pretty close. That tells us a lot, actually, about the legal system. It shows us that in daily legal reasoning often what does happen is seizing on one or two relevant differences that have been established, not terribly reflectively, as being super salient. That tells us a lot about what our judges are doing. Posner's own opinion in the copilot case was pretty brief. My hunch is that a computer program could improve on it a lot, along one dimension certainly, and maybe in a couple of others. The dimension it could certainly improve on is that it would have access to and use a much larger universe of precedents. Judge Posner just used a couple. The computer could give him a whole lot more. And maybe it could refine the principle by forcing him to grapple with the analogies.
There are intuitive leaps that are involved in chess and in driving. My research assistant, who may be in the room here, found what some of you may not know, that a computer program can drive extremely long distances across the United States at sixty-three miles an hour on average while being able to navigate all but a very small percentage of miles. Now that small percentage is really important if you want to be safe, but it's a small percentage, and what ordinary people would call intuitive leaps for driving, computers can do that.
A lot of creativity in the law, even by people who are very busy, consists of giving a meaning to a case or series of cases that nobody has seen before. This is much more mundane than it sounds, but really thrilling moments in a lawyer's life are when you can create a new pattern out of preexisting materials. That's where creativity lies and in the last few years alone long established cases have been given exceedingly new meanings. Judge Posner, not so recently, but not ages ago, understood the common law as about promoting economic efficiency. No one thought that way before, and it gave a whole new meaning to a tremendous pattern of cases. For artificial intelligence really to take off in law, and this probably isn't short term, it would have to become capable of being a little like a literary critic reading a poem, not in the sense of making nonsense
Siposium: Legal Reasoning andArifldal nteligence
AUDIENCE: wondering if anything has been done with, say, models of statutory interpretation or constitutional interpretation?
ASHLEY: There has been a lot of work and a lot of progress in representing bodies of statutory rules in a computable way. There has not been very much progress in what we would call statutory interpretation. So, for instance, one sees in civil law jurisdictions people drawing inferences from the structure of the code, for instance, about the meaning of a statutory predicate. We haven't come close to that, I don't think, in AI and law. Also, we have not succeeded in representing the alternative policies that the legislature must have had in mind for a particular statutory provision and trying to look at a problem situation through the statute in light of these alternative policies, actually modeling that. We'd like to, but I don't believe we have yet.
