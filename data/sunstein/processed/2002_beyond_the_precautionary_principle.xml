<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:xlink="http://www.w3.org/1999/xlink"><script/>
  <front>
    <journal-meta/>
    <article-meta>
      <title-group>
        <article-title>Beyond the Precautionar y Principle</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Coase-Sandor Working Paper Series in Law</string-name>
          <email>unbound@law.uchicago.edu</email>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <contrib contrib-type="editor">
          <string-name>Recommended Citation</string-name>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>accepted for inclusion in Coase-Sandor Working Paper Series in Law and Economics by an authorized administrator of Chicago Unbound. For more information</institution>
          ,
          <addr-line>please contact</addr-line>
        </aff>
      </contrib-group>
      <pub-date>
        <year>2002</year>
      </pub-date>
      <abstract>
        <p>Follow this and additional works at: https://chicagounbound.uchicago.edu/law_and_economics</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>-</title>
      <p>Cass R. Sunstein, "Beyond the Precautionary Principle" ( John M. Olin Program in Law and Economics Working Paper No. 149,
2002).</p>
    </sec>
    <sec id="sec-2">
      <title>JOHN M. OLIN LAW &amp; ECONOMICS WORKING PAPER NO. 149 (2D SERIES)</title>
      <p>Beyond the Precautionary Principle</p>
      <p>Cass R. Sunstein</p>
    </sec>
    <sec id="sec-3">
      <title>THE LAW SCHOOL</title>
    </sec>
    <sec id="sec-4">
      <title>THE UNIVERSITY OF CHICAGO</title>
      <p>Updated January 2003
Preliminary draft 1/12/03
All rights reserved
The precautionary principle has been highly influential in legal systems all over the
world. In its strongest and most distinctive forms, the principle imposes a burden of proof
on those who create potential risks, and it requires regulation of activities even if it
cannot be shown that those activities are likely to produce significant harms. Taken in
this strong form, the precautionary principle should be rejected, not because it leads in
bad directions, but because it leads in no directions at all. The principle is literally
paralyzing— forbidding inaction, stringent regulation, and everything in between. The
reason is that in the relevant cases, every step, including inaction, creates a risk to
health, the environment, or both. This point raises a further puzzle. Why is the
precautionary principle widely seen to offer real guidance? The answer lies in
identifiable cognitive mechanisms emphasized by behavioral economists. In many cases,
loss aversion plays a large role, accompanied by a false belief that nature is benign.
Sometimes the availability heuristic is at work. Probability neglect plays a role as well.
Most often, those who use the precautionary principle fall victim to what might be called
“system neglect,” which involves a failure to attend to the systemic effects of regulation.
Examples are given from numerous areas, involving arsenic regulation, global warming
and the Kyoto Protocol, nuclear power, pharmaceutical regulation, cloning, pesticide
regulation, and genetic modification of food. The salutary moral and political goals of
the precautionary principle should be promoted through other, more effective methods.
* Karl N. Llewellyn Distinguished Service Professor of Jurisprudence, Law School and Department of
Political Science, University of Chicago. I am grateful to valuable comments from Peter Dorman, Jack
Knetsch, Saul Levmore, Eric Posner, Indra Spiecker, and Adrian Vermeule, and from participants in the
Midwest Faculty Seminar. I am also grateful to Martha Nussbaum for helpful discussions.</p>
      <sec id="sec-4-1">
        <title>I. Introduction</title>
        <p>All over the world, there is increasing interest in a simple idea for the regulation
of risk: In case of doubt, follow the precautionary principle.1 Avoid steps that will create
a risk of harm. Until safety is established, be cautious; do not require unambiguous
evidence. In a catchphrase: Better safe than sorry. In ordinary life, pleas of this kind seem
quite sensible, indeed a part of ordinary human rationality. People buy smoke alarms and
insurance. They wear seatbelts and motorcycle helmets, even if they are unlikely to be
involved in an accident. Shouldn’t the same approach be followed by rational regulators
as well? Many people believe so.2</p>
      </sec>
      <sec id="sec-4-2">
        <title>A. Problems With Precautions</title>
        <p>
          I aim to challenge the precautionary principle here, not because it leads in bad
directions, but because read for all that it is worth, it leads in no direction at all. The
principle threatens to be paralyzing, forbidding regulation, inaction, and every step in
between.3 To explain this problem very briefly, the precautionary principle provides help
only if we blind ourselves to many aspects of risk-related situations and focus on a
narrow subset of what is at stake.4 A significant part of my discussion will be devoted to
showing why this is so. I will also urge that the precautionary principle gives the (false)
appearance of being workable only because of identifiable cognitive mechanisms, which
lead people to have a narrow rather than wide viewscreen. With that narrow viewscreen,
it is possible to ignore, or to neglect, some of the risks that are actually at stake. I
emphasize that we have good reason to endorse the goals that motivate many people to
endorse the precautionary principle. These goals include the importance of protecting
1 See, for general discussion, Interpreting the Precautionary Principle (Tim O'Riordan and James Cameron
eds. 2002); Protecting Public Health &amp; the Environment: Implementing the Precautionary Principle
(Carolyn Raffensberger &amp; Joel Tickner eds. 1999).
2 See the account of widespread international support below.
3 For criticisms that also emphasize the range of risks at stake, but without stressing the paralyzing quality
of the principle, see Wiener, supra note; Indur Goklany, The Precautionary Principle (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
4 For discussion of the possibly perverse effects of the precautionary principle, see Frank B. Cross,
Paradoxical Perils of the Precautionary Principle, 53 Wash. &amp; Lee L. Rev. 851 (1996). I think that much of
what Cross says is convincing, but my emphasis here is quite different: I stress the cognitive foundations of
the principle and urge not that the principle leads in perverse directions but that it offers no guidance at all.
health and the environment even from remote risks; the need to attend to unintended
adverse effects of technological change; and the need to ensure that wealthy countries
pay their fair share for environmental improvement and risk reduction. But the
precautionary principle is a crude way of protecting these goals, which should be pursued
directly. I do not attempt to develop any particular replacement for the precautionary
principle, but I do argue on behalf of wide viewscreens in the regulation of risks.
        </p>
        <p>In making these claims, I will be challenging an idea that has been a staple of
regulatory policy for several decades.5 Indeed, it has been claimed that the precautionary
principle has become, or at least is becoming, a binding part of customary international
law.6 In the mid-1970s, German environmental policy was founded on the basis of</p>
        <sec id="sec-4-2-1">
          <title>Vorsorgeprinzip, a precursor of the precautionary principle.7</title>
          <p>
            With respect to risks,
German policy has been described as seeing “precaution” as a highly interventionist idea,
one that embodies “a loose and open-ended interpretation of precaution.”8 In the United
States, federal courts, without using the term explicitly, have built in a notion of
precaution in some important cases, allowing or requiring regulation on the basis of
conservative assumptions.9 The precautionary principle has played a significant role in
international documents, to the point where it has become ubiquitous. Variations on the
notion can be found in at least fourteen international documents.10 In 1982, the United
5 For helpful discussion, see David Freestone and Ellen Hey, Origins and Development of the
Precautionary Principle, in The Precautionary Principle and International Law 3 (David Freestone and
Ellen Hey eds. 1994); Jonathan Wiener, Precaution in a Multirisk World, in The Risk Assessment of
Environmental and Human Health Hazards (Dennis D. Paustenbach, ed., 2d ed., 2002, forthcoming).
6 See O. McIntyre and T. Mosedale, The Precautionary Principle as a Norm of Customary International
Law, 9 J Env Law 221 (1997); see generally Arie Trouwborst, Evolution and Status of the Precautionary
Principle in International Law (2002).
7 Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle 1, 1 (Julian
Morris ed. 2001).
8 See Interpreting the Precautionary Principle (T. O’Riordan and J. Cameron eds. 1994).
9 See, e.g., American Trucking Association v. EPA, F.3d (DC Cir 2002); Lead Industries v. EPA, 647 F.2d
1130 (DC Cir 1980).
10 See Indur Goklany, The Precautionary Principle 3 (
            <xref ref-type="bibr" rid="ref1">2001</xref>
            ). Indeed there appears to be a cascade effect
here, with informational and reputational influences leading to many casual uses of the precautionary
principle, to the point where a failure to incorporate the principle would seem to be a radical statement.
Simply because the precautionary principle has been used so often, those involved in international
agreements are likely to believe that it is probably sensible to use it yet again. And because so many people
identify the precautionary principle with a serious commitment to environmental protection, see, e.g.,
Protecting Public Health &amp; the Environment, supra note, any nation that rejects the principle risks incurring
international opprobrium. For a general treatment of informational cascades, in which decisions by others
Nations World Charter for Nature apparently gave the first international recognition to
the principle, suggesting that when “potential adverse effects are not fully understood, the
activities should not proceed.”11 The closing Ministerial Declaration from the United
Nations Economic Conference for Europe in 1990 asserts, “In order to achieve
sustainable development, policies must be based on the precautionary principle. . . .
Where there are threats of serious or irreversible damage, lack of full scientific certainty
should not be used as a reason for postponing measures to prevent environmental
degradation.”12
          </p>
          <p>The
widely
publicized</p>
          <p>Wingspread</p>
          <p>Declaration, from
a
meeting
of
environmentalists in 1998, goes further still: “When an activity raises threats of harm to
human health or the environment, precautionary measures should be taken even if some
cause and effect relationships are not established scientifically. In this context the
proponent of the activity, rather than the public, should bear the burden of proof.”13 The
European Union treaty states that on the environment, EU policy “shall be based on the
precautionary principle.”14 Notwithstanding official American ambivalence about the
principle,15 there are unmistakable echoes of the principle in American environmental
law.16 The precautionary principle has received a high-profile endorsement in the New
York Times Magazine, which listed the principle as one of the most important ideas of</p>
        </sec>
        <sec id="sec-4-2-2">
          <title>European Commission, together with implementing guidelines.18</title>
          <p>convey information about what it makes sense to do, see David Hirschleifer, The Blind Leading the Blind:
Social Influence, Fads, and Informational Cascades, in The New Economics of Human Behavior 188, 189
(Mariano Tommasi and Kathryn Ierulli eds 1995). On reputational pressures, see Timur Kuran, Public Lies,
Private Truths (1996).
11 Goklany, supra note, at 4.
12 Id. at 5.
13 Id.
14 European Union Treaty, article 130R (1993), currently Article 174.
15 See John Graham, The Role of Precaution and Risk Assessment in Risk Managament: An American’s
View (2002), available at http://www.whitehouse.gov/omb/inforeg/eu_speech.html; Wiener, supra note.
16 Seethe reference to an “adequate margin of safety” in the Clean Air Act, section 109, 42 USC 7409(b(1).
17 The Year in Ideas: A to Z, New York Times, December 9, 2001, p. 92, column 2.
18 http://europa.eu.int/comm/dgs/health_consumer/library/press/press38_en.html</p>
          <p>In many ways the precautionary principle seems quite sensible, even appealing.
To justify regulation, a certainty of harm should not be required; a risk, even a low one,
may well be enough. It makes sense to expend resources to prevent a small chance of
disaster; consider the high costs, pecuniary and otherwise, that are spent to reduce the risk
of terrorist attack. On reasonable assumptions, these costs are worth incurring even if the
probability of harm, in individual cases or even in the aggregate, is relatively low. The
precautionary principle might well be seen as a plea for a kind of regulatory insurance.
Certainly the principle might do some real-world good, spurring them to attend to
neglected problems. Nonetheless, I will be urging that the principle cannot be fully
defended in these ways, simply because risks are on all sides of social situations. Any
effort to be universally precautionary will be paralyzing, forbidding every imaginable
step, including no step at all.</p>
        </sec>
      </sec>
      <sec id="sec-4-3">
        <title>B. Precautions and Rationality</title>
        <p>But if the precautionary principle, taken in a strong form, is unhelpful, in a way
literally senseless, how can we account for its extraordinary influence, and indeed for the
widespread belief that it can and should guide regulatory judgments? I have mentioned its
possible pragmatic value. And undoubtedly the principle is invoked strategically by
selfinterested political actors, with European farmers, for example, invoking the idea of
precaution to stifle American competitors, who are far more likely to rely on genetically
modified crops.19 But apart from this point, I suggest that an understanding of human
rationality and cognition provides five useful clues.</p>
        <p>1. Loss aversion. The precautionary principle often seems appealing because of loss
aversion. The central point here is that people dislike losses far more than they
like corresponding gains.20 The result is that out-of-pocket costs, or deterioration
from the status quo, seem much worse than opportunity costs, or benefits lost as a
result of continuing the status quo. In the context of risks, people tend to focus on
19 See Timur Kuran and Cass R. Sunstein, Availability Cascades and Risk Regulation, 51 Stan L Rev 683
(1999).
20 See Richard Thaler, Quasi-Rational Economics (1995).</p>
        <p>
          the losses that are associated with some activity or hazard, and to disregard the
gains that might be associated with that activity or hazard. The precautionary
principle often becomes operational only because of loss aversion, as people take
precautions against potential losses from the status quo, but neglect potential
benefits that would be unmistakable gains. A closely related point is that
unfamiliar risks produce far more concern than familiar ones, even if the latter are
statistically larger; and the precautionary principle, in practice, is much affected
by this fact.
2. The myth of a benevolent nature. Loss aversion is often accompanied by a
mistaken belief that nature is essentially benign,21 leading people to think that
safety and health are generally at risk only or mostly as a result of human
intervention. A belief in the relative safety of nature and the relative risk of new
technologies often informs the precautionary principle.
3. The availability heuristic. It is well known that people focus on some risks simply
because they are cognitively “available,” whereas other risks are not.22 When the
precautionary principle seems to require stringent controls on one risk, even
though other risks are in the vicinity, the availability heuristic is a common
reason. And when the availability heuristic is at work, certain hazards will stand
out whether or not they are not statistically large. 23 The hazards associated with
heat waves, for example, receive little public attention, while the hazards
associated with air travel are a significant source of public concern24; one reason
is that the latter hazards come readily to mind.
4. Probability neglect. People are sometimes prone to neglect the probability that a
bad outcome will occur; they focus instead on the outcome itself.25 The
precautionary principle often embodies a form of probability neglect. At least this
is so when people invoke the precautionary principle to favor stringent controls on
21 See generally James P. Collman, Naturally Dangerous (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
22 Amos Tversky and Daniel Kahneman, Judgment Under Uncertainty: Heuristics and Biases, in Daniel
Kahneman, Paul Slovic, and Amos Tversky, Judgment Under Uncertainty: Heuristics and Biases 3, 11-14
(1982).
23 Paul Slovic, The Perception of Risk 40 (2000).
24 See Eric Klinenberg, Heat Wave: A Social Autopsy of Disaster in Chicago (2002).
25 Yuval Rottenstreich and Christopher Hsee, Money, Kisses, and Electric Shocks: On the Affective
Psychology of Risk, 12 Psych Science 185, 188 (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
        </p>
        <p>a low-probability risk, when the consequence of those very controls is to give rise
to new risks of equal or greater probability.26
5. System neglect. The precautionary principle often reflects a general neglect of the
systemic effects of regulation.27 When a single problem is placed in view, it can
be difficult to see the full consequences of legal interventions. Sometimes the
precautionary principle has the appearance of being workable only because a
subset of the relevant effects are “on screen”—and hence there seems to be no
need to take precautions against other possible adverse effects, also involving
health and safety, that do not register. An important aspect of system neglect is
tradeoff neglect, one source of the conflict between experts and ordinary people in
thinking about risks.28 When experts disagree with ordinary people about risks, it
is sometimes because experts look at both the benefits and the harms associated
with the relevant practice, whereas ordinary people are paying attention to the
harms but not the benefits.29 I suggest that the precautionary principle seems
appealing, to ordinary people, in large part for the same reason.</p>
        <p>One of my major goals is show that the precautionary principle can be made
workable only through routes of this kind. An understanding of behavioral economics
simultaneously sheds light on the operation of the principle, explains its otherwise
puzzling appeal, and suggests why it should be abandoned or at least substantially recast.
Indeed, such an understanding provides a better understanding of the uses and pitfalls of
the old adage, “better safe than sorry,” which is subject to many of the same objections as
the precautionary principle. I do not attempt to identify a competing principle for
adoption by sensible regulators. But I do urge that such regulators should use a wide
rather than narrow viewscreen—and that as applied, the precautionary principle is
defective precisely because it runs afoul of this idea. To be sure, many of those who
endorse the principle seek to protect against neglect of the future, disregard of the
26 In some cases, this is a reasonable reading of the evidence governing genetically modified food. See Alan
McHughen, Pandora’s Picnic Basket 230-42 (2000); note in particular the evidence of harms from organic
foods, discussed in id.
27 See Dietrich Dorner, The Logic of Failure 6-42 (1996).
28 The conflict is treated in Paul Slovic, The Perception of Risk (2000).
29 See Howard Margolis, Dealing With Risk (1996).
interests of those suffering from the greatest deprivation, and impossible demands for
unambiguous evidence from regulators. But as we shall see, the precautionary principle is
a crude and sometimes perverse way of promoting those goals, which can be obtained
through other, better routes. A major purpose of this Essay is to suggest the need to use
more direct effective strategies to pursue the salutary goals of risk regulation.</p>
        <p>This Article comes in four parts. Part I briefly traces the nature and the appeal of
the precautionary principle. Part II explains why the principle is paralyzing, with
particular reference to the issues raised by arsenic, global warming, nuclear power, and
genetic engineering of food. Part III suggests that the apparent sense of the principle is
best understood in light of the behavioral points just mentioned. Part IV is a brief
conclusion, in the form of a plea for wider viewscreens.</p>
      </sec>
      <sec id="sec-4-4">
        <title>II. The Precautionary Principle: Definition and Appeal</title>
        <p>I have said that the precautionary principle enjoys widespread international
support.30 But what does the principle mean or require? There are numerous definitions,
and they are not compatible with one another.31 We can imagine a continuum of
understandings. At one extreme are weak versions to which no reasonable person could
object; at the other extreme are strong versions that would appear to call for a
fundamental rethinking of regulatory policy.</p>
        <p>The most cautious and weak versions suggest, quite sensibly, that a lack of
decisive evidence of harm should not be a ground for refusing to regulate. Regulation
might be justified even if we cannot establish a definite connection between, for example,
low-level exposures to certain carcinogens and adverse effects on human health. Thus the
1992 Rio Declaration states, “Where there are threats of serious or irreversible damage,
lack of full scientific certainty shall not be used as a reason for postponing cost-effective
30 See Arie Trouwborst, Evolution and Status of the Precautionary Principle in International Law (2002).
31 See Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle, supra,
at 1-19; Wiener, supra note.
measures to prevent environmental degradation.”32 The Ministerial Declaration of the
Second International Conference on the Protection of the North Sea, held in London in
1987, is in the same vein: “Accepting that in order to protect the North Sea from possibly
damaging effects of the most dangerous substances, a precautionary principle is
necessary which may require action to control inputs of such substances even before a
causal link has been established by absolutely clear scientific evidence.”33 Similarly, the
United Nations Framework Convention on Climate Change offers cautious language:
“Where there are threats of serious or irreversible damage, lack of full scientific certainty
should not be used as a reason for postponing [regulatory] measures, taking into account
that policies and measures to deal with climate change should be cost-effective so as to
ensure global benefits at the lowest possible cost.”34</p>
        <p>The Wingspread Declaration goes somewhat further: “When an activity raises
threats of harm to human health or the environment, precautionary measures should be
taken even if some cause and effect relationships are not fully established scientifically.
In this context the proponent of an activity, rather than the public, should bear the burden
of proof.”35 The first sentence just quoted is a mildly more aggressive version of the
statement from the Rio Declaration. It is more aggressive because it is not limited to
threats of serious or irreversible damage. But in reversing the burden of proof, the second
sentence goes further still.36 Of course everything depends on what those with the burden
of proof must show in particular.</p>
        <p>
          In Europe, the precautionary principle is understood in a still stronger way,
suggesting that it is important to build “a margin of safety into all decision making.”37
According to one definition, the precautionary principle means “that action should be
taken to correct a problem as soon as there is evidence that harm may occur, not after the
32 Quoted in Bjorn Lomborg The Skeptical Environmentalist 347 (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
33 Quoted in Rethinking Risk and the Precautionary Principle 3, Julian Morris ed. (2000).
34 See Goklany, supra note, at 6.
35 See http://www.monitor.net/rachel/r586.html
36 See the discussion in Wiener, supra note; David Pearce, The Preconditions for Achieving Consensus in
the Context of Technological Risk, in Technological Risk: Its Perception and Handling in the European
Community (M. Dierkes et al. eds 1980).
37 See Bjorn Lomborg The Skeptical Environmentalist 348 (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
harm has already occurred.”38 In a comparably strong version, it is said that “the
precautionary principle mandates that when there is a risk of significant health or
environmental damage to others or to future generations, and when there is scientific
uncertainty as to the nature of that damage or the likelihood of the risk, then decisions
should be made so as to prevent such activities from being conducted unless and until
scientific evidence shows that the damage will not occur.”39 The Cartagena Protocol on
Biosafety to the Convention on Biological Diversity, adopted in 2000, appears to adopt a
strong version as well.40 The Final Declaration of the First European “Seas At Risk”
conference says that if “the ‘worst case scenario’ for a certain activity is serious enough
then even a small amount of doubt as to the safety of that activity is sufficient to stop it
taking place.”41
typology here:
        </p>
        <p>Professor Richard Stewart usefully distinguishes among four different versions of
the precautionary principle, capturing both weak and strong types42; I paraphrase his
1. Nonpreclusion Precautionary Principle: Regulation should not be precluded by the
absence of scientific uncertainty about activities that pose a risk of substantial harm.
2. Margin of Safety Precautionary Principle: Regulation should include a margin of
safety, limiting activities below the level at which adverse effects have not been
found or predicted.
3. Best Available Technology Precautionary Principle: Best available technology
requirements should be imposed on activities that pose an uncertain potential to create
substantial harm, unless those in favor of those activities can show that they present
no appreciable risk.
38 http://www.logophilia.com/WordSpy/precautionaryprinciple.asp
39 Testimony of Dr. Brent Blackwelder, President, Friends of the Earth, before the Senate Appropriate
Committee, Subcommittee on Labor, Health and Human Services (Jan. 24, 2002).
40 See Goklany, supra note, at 6.
41 Final Declaration of the First European “Seas At Risk” Conference, Annex 1, Copenhagen, 1994.
42 Richard B. Stewart, Environmental Regulatory Decision Making Under Uncertainty, 20 Research in Law
and Economics 71, 76 (2002).</p>
        <p>4. Prohibitory Precautionary Principle: Prohibitions should be imposed on activities
that have an uncertain potential to impose substantial harm, unless those in favor of
those activities can show that they present no appreciable risk.</p>
        <p>This account shows that the precautionary principle might be described both in
terms of the level of uncertainty that triggers a regulatory response and in terms of the
tool that will be chosen in the face of uncertainty (as in the case of technological
requirements or prohibitions). With an appreciation of this point, we can easily imagine
many other variations on these themes. For example, an Information Disclosure
Precautionary Principle might say that in the face of uncertainty, those who subject
people to potential risks must disclose relevant information to those so subjected. The
debate over labeling genetically modified organism can be seen as a debate over this form
of the precautionary principle.43 For every regulatory tool, there is a corresponding
precautionary principle,44 with possible matches or mismatches between the problem that
causes for precautions and the chosen tool.45 The idea of “margin of safety” can be
understood in multiple different ways, with a continuum from a small margin, designed
to counteract likely risks, to a small one, designed to prevent worst cases.</p>
        <p>The official account in Europe is very much in favor of one or another version of
the precautionary principle, with the European Commission having formally adopted it.46
But European practice is far more complex, with the precautionary principle being
invoked against some risks but not against others.47 To take just one example, “Europe
has been more precautionary about hormones in beef, while the US has been more
precautionary about mad cow disease (BSE) in beef and blood donations.”48 While
43 See Alan McHughen, Pandora’s Picnic Basket 201-29 (2000).
44 For discussions of regulatory tools, see Stephen Breyer, Regulation and its Reform 36-183 (1982); Cass
R. Sunstein, Risk and Reason 251-88 (2002).
45 On mismatch, see Breyer, supra, at 191-96.
46 European Commission, Communication from the Commission on the Precautionary Principle, COM
(200)!, Brussels, 2 Feb. 2000 (available at
http://europa.eu.int/comm/dgs/health_consumer/library/pub/pub7_en.pdf
47 See the illuminating discussion in Jonathan Wiener and Michael Rogers, Comparing Precaution in the
United States and Europe, 5 J Risk Research 317 (2002).
48 Id. at 323.</p>
        <p>European nations have taken a highly precautionary approach to genetically modified
foods,49 the United States has been especially willing to control the risks associated with
carcinogens in food additives.50 In the context of occupational risk, American law is far
more precautionary than Swedish law.51 I cannot venture a survey here, but it is
reasonable to speculate that in actual practice, nations cannot plausibly be ranked along
some continuum of precaution. More plausibly, some nations are precautionary about
some risks but not others, and a general adoption of the precautionary principle will
conceal this inevitable fact.52 I will return to this point and to its inevitability below,
because it is closely connected to my central claims here. Nonetheless, the mounting
importance of the principle in Europe deserves close attention, if only because the idea of
precaution is playing such a large role in public debates.</p>
        <p>
          I have suggested that the weak versions of the precautionary principle are
unobjectionable and important. Every day, people take steps (and incur costs) to avoid
hazards that are far from certain. We do not walk in moderately dangerous areas at night;
we exercise; we buy smoke detectors; we buckle our seatbelts; we might even avoid fatty
foods. Sensible governments are willing to consider regulation of risks that, in individual
cases or even in the aggregate, have a well under 100% chance of coming to fruition. The
weak versions of the precautionary principle state a truism—uncontroversial and
necessary only to combat public confusion or the self-interested claims of private groups
demanding unambiguous evidence of harm, which no rational society requires. This
function should not be trivialized. Nearly a fifth of Americans, for example, recently
agreed that “until we are sure that global warming is really a problem, we should not take
49 See David Vogel, The Regulation of GMOs in Europe and the United States: A Case-Study of
Contemporary European Regulatory Politics (Publication of the Study Group on Trade, Science and
Genetically Modified Foods, 2001), available at http://www.cfr.org/pubs/Victor_ModFood_Paper2.html;
Symposium, Are the US and Europe Heading for a Food Fight Over Genetically Modified Food? (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ),
available at http://pewagbiotech.org/events/1024/; TonyGilland, Precaution, GM Crops, and Farmland
Birds, in Rethinking Risk and the Precautionary Principle 84, 84-88 (Julian Morris ed. 2001).
50 See Richard Merrill, FDA's Implementation of the Delaney Clause: Repudiation of Congressional Choice
or Reasoned Adaptation to Scientific Progress?, 5 Yale J. on Reg. 1 (1988).
51 See Steven Kelman, Regulating America, Regulating Sweden: A Comparative Study of Occupational
Safety and Health Policy (1981).
52 See Wiener and Rogers, supra note.
any steps that would have economic costs.”53 Sometimes people do seem to seek
certainty before showing a willingness to expend costs, and well-organized private
groups like to exploit this fact. Insofar as the precautionary principle counteracts the
tendency to demand certainty, it should be approved.
        </p>
        <p>Because the weak versions are sensible, I will not discuss them here. Instead I will
understand the principle in a strong way, to suggest that regulation is required whenever
there is a possible risk to health, safety, or the environment, even if the supporting
evidence is speculative and even if the economic costs of regulation are high. To avoid
palpable absurdity, the idea of “possible risk” will be understood to require a certain
threshold of scientific plausibility. To support regulation, no one thinks that it is enough
if someone, somewhere, urges that a risk is worth taking seriously. But under the
precautionary principle as I shall understand it, the threshold burden is minimal, and once
it is met, there is something like a presumption in favor of stringent regulatory controls. I
believe that this understanding of the precautionary principle fits with the understandings
of its most enthusiastic proponents,54 and that with relatively modest variations, this
understanding fits with many of the legal formulations as well.55</p>
        <p>Why might the precautionary principle, understood in this strong sense, have such
widespread appeal? At first glance, the answer is simple, for the principle contains some
important truth. Sometimes it is much better to be safe than sorry. Certainly we should
acknowledge that a small probability (say, 1 in 100,000) of a serious harm (say, 100,000
deaths) deserves extremely serious attention. It is worthwhile to spend a lot of money to
eliminate that risk. The fact that a danger is unlikely to materialize is hardly a decisive
objection to regulatory controls. Now an economically oriented critic might observe that
our resources are limited and that if we spend large amounts of resources on highly
speculative harms, we will not be allocating those resources wisely. In fact this is the
53 See http://www.pipa.org/OnlineReports/GlobalWarming/buenos_aires.html#1
54 See the essays in Protecting Public Health &amp; the Environment : Implementing the Precautionary
Principle, Carolyn Raffensberger &amp; Joel Tickner eds. (1999).
55 See Lothar Gundling, The Status in International Law of the Principle of Precautionary Action, 5 Intl J.
Estuarine and Coastal Law 23, 26 (1990).
simplest criticism of the precautionary principle.56 Unless the harm would be truly
catastrophic, a huge investment makes no sense for a harm that has a 1 in 1 billion chance
of occurring. Taken for all that it is worth, the precautionary principle might seem to
require indefensibly huge expenditures, exhausting our budget well before the menu of
options could be thoroughly consulted.57 If we take costly steps to address all risks,
however improbable they are, we will quickly impoverish ourselves. On this view, the
principle “would make for a dim future.”58 This is no less true for nations than for
individuals.</p>
        <p>Some version of this argument is surely convincing, but it also seems to be
missing something about human cognition.59 In some contexts, regulation is indeed a
form of insurance, or a way of placing special locks on a door. Consider the following
choice. Would you rather have
1. A sure loss of $20, or
2. A 1% chance of losing $1980?</p>
        <p>In terms of expected value, (b), representing a statistical loss of $19.80, is a bit
less bad than (a); but most people would gladly choose the sure loss of $20.60 People do
not like to run a small risk of a large or catastrophic loss; this is why people buy
insurance and take special precautions against serious harms, even in circumstances in
which an analysis of expected value would not justify these steps.61 If government
follows the judgments of ordinary people, it will be risk-averse in this sense as well. The
willingness to incur sure losses, in preference to low-probability catastrophes of lower
56 See Graham, supra note.
57 See Bjorn Lomborg, supra note, at 349.
58 See Julian Morris, Defining the Precautionary Principle, in Risk and the Precautionary Principle, supra,
at 1, 17.
59 See Daniel Kahneman and Amos Tversky, Prospect Theory: An Analysis of Decision Under Risk, in
Choices, Values, and Frames 17 (Daniel Kahneman and Amos Tversky eds. 2001).
60 Id.
61 A lucid discussion, with applications to litigation, is Chris Guthrie, Framing Frivolous Litigation, 67 U.
Chi. L. Rev. 163 (2000).
expected value, helps explain decisions in a variety of domains, involving both law and
politics, including foreign policy.62</p>
        <p>This point about judgment under risk might seem to suggest that a democratic
society, following popular views, will depart from the predictions of expected utility
theory and even embody a form of risk aversion for low-probability catastrophes.63 The
result will be to move regulation in the direction suggested by the precautionary
principle. But prospect theory cannot provide a defense of the principle in its strong form.
I now explain why this is so.</p>
      </sec>
      <sec id="sec-4-5">
        <title>Why the Precautionary Principle Is Paralyzing</title>
      </sec>
      <sec id="sec-4-6">
        <title>A. The Problem</title>
        <p>The most serious problem with the precautionary principle is that it offers no
guidance—not that it is wrong, but that it forbids all courses of action, including inaction.
To understand this point, it will be useful to anchor the discussion in some concrete
problems:
1. One of the most controversial environmental issues faced in the first year of
the Bush administration involved the regulation of arsenic.64 There is a serious
dispute over the precise level of risks posed by low levels of arsenic in
drinking water, but on the “worst case” scenario, over one hundred lives might
be lost each year as a result of the 50 part per billion standard that the Clinton
Administration sought to revise.65 At the same time, the proposed 10 ppb
62 See id; Rose McDermott, Risk-Taking in International Politics: Prospect Theory in American Foreign
Policy (1998).
63 See Roger Noll and James Krier, Some Implications of Cognitive Psychology for Risk Regulation, 19 J.
Legal Stud. 747 (1990).
64 Robert K. Musil, Arsenic on Tap, N.Y. TIMES, Apr. 24, 2001, at A18.
65 See Cass R. Sunstein, The Arithmetic of Arsenic, Geo. L. J. (forthcoming 2002).</p>
        <p>
          standard would cost over $200 million each year, and it is possible that it
would save as few as six lives annually.66
2. Genetic modification of food has become a widespread practice.67 But the
risks of that practice are not known with precision.68 Some people fear that
genetic modification will result in serious ecological harm and large risks to
human health.69
3. Scientists are not in accord about the dangers associated with global
warming,70 but there is general agreement that global warming is in fact
occurring.71 It is possible that global warming will produce, by 2100, a mean
temperature increase of 4.5 degrees C72; that it will result in well over $5
trillion in annual monetized costs73; and that it will also produce a significant
number of deaths from malaria. The Kyoto Protocol would require most
industrialized nations to reduce greenhouse gas emissions to 92%-94% of
1990 levels.74
4. Many people fear nuclear power, on the ground that nuclear power plants
raise various health and safety issues, including some possibility of
catastrophe.75 But if a nation does not rely on nuclear power, it is likely to rely
instead on fossil fuels, and in particular on coal-fired power plants.76 Such
plants create risks of their own, including risks associated with global
warming. China, for example, has relied on nuclear energy in part as a way of
reducing greenhouse gases and in part as a way of reducing other air pollution
problems.77
66 See id,
67 Alan McHughen, Pandora’s Picnic Basket (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
68 See id.
69 See Tony Gilland, Precaution, GM Crops and Farmland Birds, in Rethinking Risk and the Precautionary
Principle, supra note, at 60.
70 See Bjorn Lomborg, The Skeptical Environmentalist (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ).
71 Id.
72 Id. at 317.
73 Id.
74 See Robert Percival et al., Environmental Regulation 1141 (3d ed. 2000).
75 See Robert Goodin, No Moral Nukes, 90 Ethics (1980).
76 See Stephen Breyer, Vermont Yankee and the Courts' Role in the Nuclear Energy Controversy, 91 Harv
L Rev 1833, 1835-36 (1978).
77 See Note, Nuclear Energy: China's Approach Towards Addressing Global Warming, 12 Geo. Int'l Envtl.
L. Rev. 493 (2000). Of course it is possible to urge that nations should reduce reliance on either coal-fired
5. There is a possible conflict between the protection of marine mammals and
military exercises. The United States Navy, for example, engages in many
such exercises, and it is possible that marine mammals will be threatened as a
result. Military activities in the oceans might well cause significant harm; but
a decision to suspend those activities, in cases involving potential harm, might
also endanger military preparedness.78
        </p>
        <p>In these cases, what kind of guidance is provided by the precautionary principle?
It is tempting to say, as is in fact standard, that the principle calls for strong controls on
arsenic, on genetic engineering of food, on greenhouse gases, on threats to marine
mammals, and on nuclear power.79 In all of these cases, there is a possibility of serious
harms, and no authoritative scientific evidence suggests that the possibility is close to
zero. If the burden of proof is on the proponent of the activity or processes in question,
the precautionary principle would seem to impose a burden of proof that cannot be met.
Put to one side the question whether the precautionary principle, understood to compel
stringent regulation in these cases, is sensible. Let us ask a more fundamental question: Is
that more stringent regulation therefore compelled by the precautionary principle?</p>
        <p>
          The answer is that it is not. In some of these cases, it should be easy to see that in
its own way, stringent regulation would actually run afoul of the precautionary principle.
The simplest reason is that such regulation might well deprive society of significant
benefits, and for that reason produce a large number of deaths that would otherwise not
occur. In some cases, regulation eliminates the “opportunity benefits” of a process or
activity, and thus causes preventable deaths.80 If this is so, regulation is hardly
precautionary. The most familiar cases involve the “drug lag,” produced by a highly
power plants or nuclear power, and move instead toward environmentally preferred alternatives, such as
solar power. For general discussion, see Godfrey Boyle, Renewable Energy: Power for Sustainable Future
(1996); Allan Collinson, Renewable Energy (1991); Dan E. Arvizu, Advanced Energy Technology and
Climate Change Policy Implications, 2 Fl. Coastal L.J. 435 (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ). But these alternatives pose problems of
their own, involving feasibility and expense. See Lomborg, supra note, at 118-48.
78 See Testimony of Vice Admiral Charles W. Moore, Deputy Chief of Naval Operations for Readiness and
Logistics, before the Committee on House Resources, Subcommittee on Fisheries Conservation, Wildlife
and Oceans (June 13, 2002).
79 See http://www.inra.fr/Internet/Produits/dpenv/som-ec43.html.
80 See Aaron Wildavsky, Searching for Safety (1994).
precautionary approach to the introduction of new medicines and drugs into the market.81
If a government takes such an approach, it might protect people against harms from
inadequately tested drugs; but it will also prevent people from receiving potential beneits
from those very drugs.82 Is it “precautionary” to require extensive premarketing testing,
or to do the opposite?
        </p>
        <p>Or consider the case of genetic modification of food. Many people believe that a
failure to allow genetic modification might well result in numerous deaths, and a small
probability of many more.83 The reason is that genetic modification holds out the promise
of producing food that is both cheaper and healthier—resulting, for example, in “golden
rice,” which might have large benefits in developing countries.84 Now the point is not that
genetic modification will definitely have those benefits, or that the benefits of genetic
modification outweigh the risks. The point is only that if the precautionary principle is
taken literally, it is offended by regulation as well as by nonregulation. So too for
regulation of ground-level ozone. Such regulation does seem justified by the
precautionary principle, for responsible people believe that low levels of ozone produce a
range of health harms, including risks of death.85 But there is also evidence that
groundlevel ozone produces health benefits, by reducing risks of cataracts and skin cancer. 86
Because the precautionary principle calls for protection when causal connections are
unclear, it would appear to require, with respect to ground-level ozone, both stringent
regulation and no regulation at all.</p>
        <p>
          Sometimes regulation would violate the precautionary principle because it would
give rise to substitute risks, in the form of hazards that materialize, or are increased, as a
81 See Henry Grabowski and John Vernon, The Regulation of Pharmaceuticals (1983); John Mendeloff,
Decision Analysis and FDA Drug Review: A Proposal for "Shadow" Advisory Committees (2002),
available at http://www.fplc.edu/RISK/vol6/summer/mendelof.htm.
82 See sources cited in note 64 supra.
83 Bill Lambrecht, Dinner at the New Gene Cafe : How Genetic Engineering Is Changing What We Eat,
How We Live, and the Global Politics of Food (
          <xref ref-type="bibr" rid="ref1">2001</xref>
          ) (tracing but not endorsing the various objections).
84 Id.
greatly affected by recent experiences.152 If floods have not occurred in the immediate
past, people who live on flood plains are far less likely to purchase insurance.153 In the
aftermath of an earthquake, insurance for earthquakes rises sharply—but it declines
steadily from that point, as vivid memories recede.154 Note that the use of the availability
heuristic, in these contexts, is hardly irrational.155 Both insurance and precautionary
measures can be expensive, and what has happened before seems, much of the time, to be
the best available guide to what will happen again. The problem is that the availability
heuristic can lead to serious errors, in terms of both excessive fear and neglect.
        </p>
        <p>The availability heuristic helps to explains the operation of the precautionary
principle for a simple reason: Sometimes a certain risk, said to call for precautions, is
cognitively available, whereas other risks, including the risks associated with regulation
itself, are not. For example, it is easy to see that arsenic is potentially dangerous; arsenic
is well-known as a poison, forming the first word of a well-known movie about
poisoning.156 By contrast, there is a relatively complex mental operation in the judgment
that arsenic regulation might lead people to use less safe alternatives. In many cases
where the precautionary principle seems to offer guidance, the reason is that some of the
relevant risks are available while others are barely visible.</p>
        <p>It is well-known that the availability heuristic affects risk judgments, and we can
now appreciate the relationship between that heuristic and the operation of the
precautionary principle. But to say the least, the availability heuristic does not operate in
152 Paul Slovic, The Perception of Risk 40 (2000).
153 Id.
154 Id.
155 Kahneman and Tversky emphasize that the heuristics they identify “are highly economical and usually
effective,” but also that they “lead to systematic and predictable errors.” See Amos Tversky and Daniel
Kahneman, Judgment Under Uncertainty: Heuristics and Biases, in Judgment and Decision Making: A
Interdisciplinary Reader 38, 55 (Hal Arkes and Kenneth Hammond). Gerd Gigenzer, among others, has
emphasized that some heuristics can work extremely well, see Gerd Gigerenzer et al., Simple Heuristics
That Make Us Smart (1999); Gerd Gigerenzer, Adaptive Thinking: Rationality in the Real World (2000),
and used this point as a rejoinder to those who stress the errors introduced by heuristics and biases. For a
helpful recent discussion, see Kahneman and Frederick, supra note. I do not mean to take a stand on the
resulting debates. Even if many heuristics mostly work well in daily life, a sensible government can do
much better than to rely on them.
156 Arsenic and Old Lace.
a social vacuum.157 What is readily “available” to some individuals, groups, cultures, and
even nations will not be available to all. In part because of the use of the availability
heuristic, the precautionary principle does not call for bans on nuclear power plants in
France, which has not caused serious health risks in that nation despite its heavy reliance
on nuclear energy.158 By contrast, the Three Mile Island incident provoked intense
concerns about nuclear power plants in the United States159 and helped promote the
widespread idea that a precautionary approach would discourage reliance on nuclear
power. Many of those who favor gun control legislation have “available” a set of
incidents in which such legislation would have avoided unnecessary deaths; many of
those who reject such legislation are alert to incidents in which private gun ownership
allowed people to fend off criminal violence.160 Much remains to be done to clarify the
relationship between the availability heuristic and social interactions, including the
operations of the media and political officials. For present purposes, the key point is that
the availability heuristic often underwrites the use of the precautionary principle, by
suggesting the importance of taking precautions against some, but hardly all, of the risks
involved.</p>
      </sec>
      <sec id="sec-4-7">
        <title>D. Probability Neglect</title>
        <p>The availability heuristic can produce an inaccurate assessment of probability.
But sometimes people will attempt little assessment of probability at all, especially when
strong emotions are involved. 161 In such cases, large-scale variations in probabilities will
matter little—even when those variations unquestionably should matter. The point
applies to hope as well as fear; vivid images of good outcomes will crowd out
consideration of probability too.162 Lotteries are successful partly for this reason.163 But
157 See Dan Kahan and Donald Braman, More Statistics, Less Persuasion: A Cultural Theory of Risk
Perception (unpublished manuscript 2002); Timur Kuran and Cass R. Sunstein, Availability Cascades and
Risk Regulation, 51 Stan L Rev 683 (1999).
158 See Kuran and Sunstein, supra note.
159 See id.
160 See Kahan and Braman, supra note.
161 Yuval Rottenstreich and Christopher Hsee, Money, Kisses, and Electric Shocks: On the Affective
Psychology of Probability Weighting, supra, at 176-88.
162 See id.
163 See Phillip Cook, Selling Hope (1993).
for purposes of applying the precautionary principle, the topic is fear rather than hope. I
suggest that sometimes the precautionary principle becomes workable because the issue
of probability is neglected, and people focus on one emotionally gripping outcome
among a large set of possibilities.</p>
        <p>Probability neglect has received its clearest empirical confirmation in a striking
study of people’s willingness to pay to avoid electric shocks.164 The central purpose of
the study was to test the relevance of probability in “affect rich” decisions. One
experiment investigated whether varying the probability of harm would matter more, or
less, in settings that trigger strong emotions than in settings that seem relatively
emotionfree. In the “strong emotion” setting, participants were asked to imagine that they would
participate in an experiment involving some chance of a “short, painful, but not
dangerous electric shock.”165 In the relatively emotion-free setting, participants were told
that the experiment entailed some chance of a $20 penalty. Participants were asked to say
how much they would be willing to pay to avoid participating in the relevant experiment.
Some participants were told that there was a 1% chance of receiving the bad outcome
(either the $20 loss or the electric shock); others were told that the chance was 99%; and
still others were told that the chance was 100%.</p>
        <p>The central result was that variations in probability affected those facing the
relatively emotion-free injury, the $20 penalty, far more than they affected people facing
the more emotionally evocative outcome of an electric shock.166 For the cash penalty, the
difference between the median payment for a 1% chance and the median payment for a
99% chance was predictably large and indeed consistent with the standard model: $1 to
avoid a 1% chance, and $18 to avoid a 99% chance.167 For the electric shock, by contrast,
the difference in probability made little difference to median willingness to pay: $7 to
avoid a 1% chance, and $10 to avoid a 99% chance!168 Apparently people will pay a
164 Yuval Rottenstreich and Christopher Hsee, Money, Kisses, and Electric Shocks: On the Affective
Psychology of Probability Weighting, supra, at 176-88.
165 Id. at 181.
166 Id.
167 Id.
168 Id.
significant amount to avoid a small probability of a hazard that is affectively-laden—and
the amount that they will pay will not vary greatly with changes in probability. The point
explains “why societal concerns about hazards such as nuclear power and exposure to
extremely small amounts of toxic chemicals fail to recede in response to information
about the very small probabilities of the feared consequences from such hazards.”169</p>
        <p>It should be easy to the connection between probability neglect and the
precautionary principle. If probabilities are neglected, especially when emotions are
engaged, then the principle will operate through excessive public concern with certain
low-probability hazards. Return to the contrast between deaths from heat waves and
deaths from airplane crashes.170 The latter trigger far more intense public attention, in
part because of the availability heuristic, but in part because for some people, the
outcome itself has such salience, and the probability much less so. In the context of
genetic modification of food and global warming, the same phenomenon is at work,
leading people to think that the precautionary principle, simply applied, calls for
aggressive regulatory controls. Note that I am not urging that such controls are a mistake;
in the context of global warming, they seem to be warranted by the facts. My claim is
only that the precautionary principle appears to give guidance in part because the issue of
probability is neglected.</p>
        <p>For purposes of understanding the operation of the precautionary principle, it is
important to see that visualization or imagery matters a great deal to people’s reactions to
risks.171 When an image of a bad outcome is easily accessible, people will become greatly
concerned about a risk, holding probability constant.172 Consider the fact that when
people are asked how much they will pay for flight insurance for losses resulting from
“terrorism,” they will pay more than if they are asked how much they will pay for flight
169 See Paul Slovic et al., The Affect Heuristic, forthcoming in Intuitive Judgment: Heuristics and Biases
(Tom Gilovich et al. eds, forthcoming), unpublished manuscript at 11.
170 See Eric Klinenberg, supra note.
171 See Paul Slovic et al., Violence Risk Assessment and Risk Communication, 24 Law and Human
Behavior 271 (2000).
172 See Loewenstein et al., supra, at 275-76.
insurance from all causes.173 The evident explanation for this peculiar result is that the
word “terrorism” evokes vivid images of disaster, thus crowding out probability
judgments. Note also that when people discuss a low-probability risk, their concern rises
even if the discussion consists mostly of apparently trustworthy assurances that the
likelihood of harm really is infinitesmal.174 The reason is that the discussion makes it
easier to visualize the risk and hence to fear it.</p>
        <p>Note that probability neglect does not involve the availability heuristic. That
heuristic leads not to neglect probability, but to answer the question of probability by
substituting a hard question (what is the statistical risk?) with an easy question (do salient
examples readily come to mind?).175 My point here is not that visualization makes an
event seem more probable (though this is also often true), but that visualization makes the
issue of probability less relevant or even irrelevant. In theory, the distinction between use
of the availability heuristic and probability neglect should not be obscure. In practice, of
course, it will often be hard to know whether the availability heuristic or probability
neglect is driving behavior.</p>
        <p>The most sensible conclusion is that with respect to risks of injury of harm, vivid
images and concrete pictures of disaster can “crowd out” other kinds of thoughts,
including the crucial thought that the probability of disaster is really small. “If someone is
predisposed to be worried, degrees of unlikeliness seem to provide no comfort, unless
one can prove that harm is absolutely impossible, which itself is not possible.”176
Probability neglect, I suggest, often makes the precautionary principle seem sensible and
workable. Indeed, the precautionary principle often embodies a form of probability
neglect. When people focus on highly speculative risks associated with certain risks, it is
often because of intense emotional reactions that make those risks, and not relevant
others, stand out from the background. In many cases, probability neglect and loss
173 See E.J. Johnson et al., Framing, Probability Distortions, and Insurance Decisions, 7 H. Risk and
Uncertainty 35 (1993).
174 See A.S. Alkahami and Paul Slovic, A Psychological Study of the Inverse Relationship Bteween
Perceived Risk and Perceived Benefit, 14 Risk Analysis 1086, 1094-94 (1994).
175 See Amos Tversky and Daniel Kahneman, Availability: A Heuristic for Judging Frequency and
Probability, 5 Cognitive Psychology 207 (1973).
176 See Weingart, supra note 1, at 362.
aversion march hand-in-hand. Potential losses, from the status quo, often trigger intense
emotions, as potential gains do not; and when the precautionary principle is operating, the
low-probability losses have far more salience than they deserve.177</p>
        <p>Nor is the problem of probability neglect foreign to law. In many contexts, law
seems to be a response, in part, to fear of bad outcomes without close attention to the
question of probability—along one dimension, the precautionary principle in action.178
The European Community’s ban on meat products treated with hormones has raised
large-scale issues about the role of public fear in risk regulation.179 The Appellate Body
of the World Trade Organization ruled180 that the ban ran afoul of Article 5.1 of the
Agreement on Sanitary and Phytosanitary Measures (SPS Agreement),181 which requires
members of the WTO to justify all health and safety regulations by reference to scientific
risk assessments.182 In this way, the Appellate Body rejected the EC’s effort to defend
itself in part by reference to consumer fears about the safety of beef treated with
hormones.183 In this context, such fears were apparently real, but they neglected the issue
of probability.184
177 With respect to global warming, this is the suggestion in Goklany, supra note, at 58-88, and Lomborg,
supra note.
178 See Sunstein, Probability Neglect, supra note, at
179 For an illuminating discussion, see Howard Chang, Risk Regulation, Public Concerns, and the Hormone
Dispute: Nothing to Fear Except Fear Itself? (unpublished manuscript 2002).
180 Report of the Appellate Body, EC Measures Concerning Meat and Meat Products (Hormones),
WT/DS48/AB/R &amp; WT/DS48/AB/R, Jan. 16, 1998 (adopted Feb. 13, 1998), available in
Westlaw, WTO-DEC file, 1998 WL 25520 [hereinafter Appellate Body].
181See id. at ¶ 208 (citing Agreement on the Application of Sanitary and Phytosanitary Measures
art. 5.1, Apr. 15, 1994, annex 1A-4 to Final Act Embodying the Results of the Uruguay Round of
Multilateral Trade Negotiations, 33 I.L.M. 1125 (1994) [hereinafter SPS Agreement]).
182See SPS Agreement, supra note , art. 5.1 (“Members shall ensure that their sanitary or
phytosanitary measures are based on an assessment, as appropriate to the circumstances, of the
risks to human, animal or plant life or health, taking into account risk assessment techniques
developed by the relevant international organizations.”).
183See Michele D. Carter, Selling Science Under the SPS Agreement: Accommodating Consumer
Preference in the Growth Hormones Controversy, 6 MINN. J. GLOBAL TRADE 625, 627 (1997).
184 For discussion of the complex normative issues, see Chang, supra note.</p>
      </sec>
      <sec id="sec-4-8">
        <title>E. System Neglect</title>
        <p>The fourth point is, in a way, the largest. My suggestion is that much of the time,
and with respect to risks, people neglect the systemic effect of one-shot interventions.
They tend to assume that a change in a social situation would alter the part at issue, but
without altering other parts. System neglect, thus understood, includes the general
phenomenon of tradeoff neglect, by which people fail to see the frequent need to way
competing variables against one another.185 But tradeoff neglect is only part of what is
involved here. When the precautionary principle gives guidance, and when it goes wrong,
it is often because those who use it are falling victim to system neglect.</p>
        <p>The clearest evidence comes from the German psychologist Dietrich Dorner, who
has designed some fascinating experiments to see whether people can reduce social
risks.186 Dorner’s experiments are run via computer. Participants are asked to reduce risks
faced by the inhabitants of some region of the world. The risks may involve pollution,
poverty, poor medical care, inadequate fertilization of crops, sick cattle, insufficient
water, or excessive hunting and fishing. Through the magic of the computer, many policy
initiatives are available—improved care of cattle, childhood immunization, drilling more
wells). Participants are able to choose among them. Once particular initiatives are chosen,
the computer projects, over short periods and then over decades, what is likely to happen
in the region.</p>
        <p>In these experiments, success is entirely possible. Some initiatives will actually
make for effective and enduring improvements. But many of the participants—even the
most educated and professional—produce calamities. They do so because they fixate on
isolated problems and do not see the complex, system-wide effects of particular
interventions. For example, they may appreciate the importance of increasing the number
of cattle, but once they do that, they create a serious risk of overgrazing, and they fail to
185 See Howard Margolis, Dealing With Risk (1995).
186 Dietrich Dorner, The Logic of Failure: Recognizing and Avoiding Error in Complex Situations (1996).
anticipate that problem.187 They may understand full well the value of drilling more wells
to provide water, but they do not anticipate the energy and environmental effects of the
drilling, which then endangers the food supply. Only the rare participant is able to see a
number of steps down the road—to understand the multiple effects of one-shot
interventions into the system, and to assess a wide range of consequences from those
interventions. The successful participants seem to take small, reversible steps, or to see
the full set of effects at once, and thus to protect themselves against major blunders.
When people are not successful, it is because they fail to see that risks are parts of
systems.188</p>
        <p>How would the precautionary principle operate if invoked in Dorner’s
experiments? It should be easy to see that while the weaker version might provide some
assistance, the stronger versions offer no help at all. There are simply too many risks
against which one might take precautions. Precautions cannot be taken against all risks,
not for the important but less interesting reason that resources are limited, but simply
because efforts to redress any set of risks might produce risks of their own. The real
world of risk regulation offers many analogues.189 To the extent that the precautionary
principle appears to offer guidance, it is often because adverse systemic effects, and the
need to take precautions against them, are simply being neglected.</p>
        <p>Howard Margolis has used a related point to explain why experts have different
risk judgments from ordinary people, and he has done so in a particular effort to explain
why and when ordinary people will think, “Better safe than sorry.”190 Margolis thus
offers some cognitive foundations for the precautionary principle, without explicitly
discussing the idea. Margolis’ goal is to cast light on some apparent anomalies in
ordinary thinking about risks: Why do people believe that small risks from pesticides
should be regulated, if comparatively small risks from X-rays are quite tolerable? Why
are people so concerned about the risks of nuclear power, when experts tend to believe
187 Id. at 6-11.
188 For some real world analogues to Dorner’s experiments, see James Scott, Seeing Like A State (1999).
189See Wiener, supra note.
190 See Margolis, supra note.
that the risks are quite low—lower, in fact, than the risks from competing energy sources,
such as coal-fired power plants, which produce relatively little public objection?</p>
        <p>Margolis suggests that people are sometimes subject to a kind of optical illusion,
in which they see the harms associated with some activity or process, but fail to see the
benefits. If so, they will tend to think, “better safe they sorry.”191 If not, they will see
some “fungibility” between both harms and benefits, and engage in the kind of tradeoff
analysis that is more typical for experts.192 Margolis offers a nice example to support this
suggestion.193 The removal of asbestos from schools in New York City was initially quite
popular, indeed demanded by parents, even though experts believed that the risks were
statistically small. (As it happens, the risk of a child getting cancer from asbestos
insulation was about 1/3 the risk of being struck by lightning.) But when it emerged that
the removal would cause schools to be closed for a period of weeks, and when the closing
caused parents to become greatly inconvenienced, parental attitudes turned right around,
and asbestos removal seemed like a really bad idea. When the costs of the removal came
on-screen, parents thought much more like experts, and the risks of asbestos seemed well
worth tolerating: Statistically small, and on balance worth incurring. The precautionary
principle often operates because of the visibility of only one side of the ledger, so that
people think that parents in advance of asbestos removal, seeing the possibility of hazard
without confronting the problems introducing by reducing it.</p>
        <p>For an especially vivid example, consider the apparent views of Americans in the
late 1990s. About 63 percent of Americans agreed with the statement: “Protecting the
environment is so important that requirements and standards cannot be too high and
continuing environmental improvements must be made regardless of cost.”194 In the same
general vein, 59 percent supported the Kyoto Treaty on global warming, with only 21
percent opposed.195 But in the same period, 52 percent of Americans said that they would
191 Id. at 75-81.
192 Id. at 75-92.
193 Id. at 124-28.
194 See The Program on International Policy Attitudes, Americans on the Global Warming Treaty, available
at http://www.pipa.org/OnlineReports/GlobalWarming/glob_warm_treaty.html at Box 15.
195 Id.
refuse to support the Kyoto Treaty on global warming if “it would cost an extra $50 per
month for an average American household.”196 In fact only 11 percent of Americans
would support the Kyoto Treaty if the monthly expense were $100 or more.197 How can
we explain strong majority support for “environmental improvements . . . regardless of
cost” and strong majority rejection of environmental improvements when the cost if
high? The answer lies in the fact that people are not, in fact, willing to spend an infinite
amount for environmental improvements, and that when the costs are squarely placed “on
screen,” people begin to weigh both costs and benefits.</p>
        <p>There are many other examples. People seem quite concerned about the risks
associated with dioxin, a real candidate for use of the precautionary principle, but far less
concerned about the statistically equivalent risks associated with aflatoxin, a carcinogen
found in peanut butter.198 When aflatoxin does not trigger public concern, a large part of
the reason is that the burdens of banning aflatoxin seem high and indeed intolerable; too
many people would object to heavy regulation of peanut butter, a staple of school lunches
and many diets for generations. In this light it is both mildly counterintuitive and
reasonable, for example, to predict that people would be willing to pay less, in terms of
dollars and waiting time, to reduce low-probability risks of an airplane disaster if they are
frequent travellers. An intriguing study finds exactly that effect.199 It is also safe to
predict that if people were told, by a reliable source, that eliminating pesticides would
lead to serious health problems—for example, because pesticide-free fruits and
vegetables carried special dangers200—the perceived risk of pesticides would decline
dramatically, and it would be difficult to invoke the precautionary principle as a basis for
stringent regulation of pesticides.201 Indeed I predict that if people were informed that
eliminating pesticides would lead to a significant cost in the price of applies and oranges,
the perceived risk would go down as well.202
196 Id. at Box 16.
197 Id.
198 Id. at 136-37.
199 See Matthew Harrington (unpublished manuscript).
200 See the discussion of organic food in McHughen, supra note, at 232-37.
201 Carolyn Raffensperger, The Precautionary Principle as Forecaring: Hopeful Work for the Environmental
Health Movement (2000), available at http://www.biotech-info.net/forecaring.html
202 For evidence of the general phenomenon, see Paul Slovic, The Perception of Risk (2000).</p>
        <p>The conclusion is that the precautionary principle often seems helpful because
analysts are focussing on the “target” risk, and not on the systemic, risk-related effects of
being precautionary, or even on the risk-related consequences of risk reduction. Rational
regulators, of course, think about systems, not snapshots.203 And once we see that risks
are inevitably parts of systems, the precautionary principle will become far less helpful.</p>
      </sec>
      <sec id="sec-4-9">
        <title>V. Toward Wider Viewscreens</title>
        <p>In this Article I have argued not that the precautionary principle leads in the
wrong directions, but that if it is taken for all that it is worth, it leads in no direction at all.
The reason is that risks of one kind or another are on all sides of regulatory choices, and
it is therefore impossible, in most real-world cases, to avoid running afoul of the
principle. Frequently risk regulation creates a (speculative) risk from substitute risks or
from foregone risk-reduction opportunities. And because of the (speculative) mortality
and morbidity effects of costly regulation, any regulation, if it is costly, threatens to run
afoul of the precautionary principle. We have seen that both regulation and nonregulation
seem to be forbidden in cases involving nuclear power, arsenic, global warming, and
genetic modification of food. The precautionary principle seems to offer guidance only
because people blind themselves to certain aspects of the risk situation, focusing on a
mere subset of the hazards that are at stake.</p>
        <p>To some extent, those who endorse the precautionary principle seem to be
responding to salutary political or moral motivations that the principle might be thought
to embody. Well-organized private groups sometimes demand conclusive proof of harm
203 There might seem to be some tension between the plea for wide viewscreens and my (qualified)
argument for a form of judicial minimalism, in Cass R. Sunstein, One Case At A Time (1999). But there is
no tension. Minimalism is a form of incrementalism, arguing on behalf of “small steps” in part because of
the risk that large-scale interventions into systems will have unanticipated adverse consequences. See id. at
52-53. Indeed, Dorner himself suggests that small steps are a desirable approach to the risk of system
neglect. See The Logic of Failure, supra, at 166-81. By endorsing a wide viewscreen, I do not mean to
challenge small steps, but instead to urge that in taking any step at all, officials should look at the range of
likely consequences. Of course it is possible that a full assessment of such consequences will be beyond
existing capacities. In such cases simplifying devices might be helpful. See Goklany, supra note, at 9-10,
for some suggestions.
as a precondition for regulation; the demand should be firmly resisted, because a
probability of harm is, under many circumstances, a sufficient reason to act. Both
individuals and societies have a tendency to neglect the future; the precautionary
principle might be understood as a warning against that form of neglect. There are
extremely good reasons to incorporate distributional considerations into risk regulation,
and the precautionary principle seems, some of the time, to be a way to protect the most
disadvantaged against risks of illness, accident, and death. Sometimes people try to
reduce dissonance by thinking that actual risks are trivial; the precautionary principle
might work as a helpful counterweight to this mechanism. The problem is that the
precautionary principle, as applied, is a crude and sometimes perverse way to promote
these various goals, not least because it might be, and has been, urged in situations in
which the principle threatens to injure future generations and to harm rather than to help
those who are most disadvantaged.</p>
        <p>I have also urged that the precautionary principle can be made operational only
because of identifiable cognitive mechanisms. Often loss aversion is at work. The
benefits of certain practices are less salient than the costs, simply because the costs
would, along an important dimension, represent a deterioration from the status quo.
When loss aversion is involved, it might be thought, wrongly, that natural processes are
always safer, and better for the environment, than processes that involve human
intervention. Sometimes the precautionary principle works by exploiting the availability
heuristic, because the risks that matter are cognitively accessible, whereas the risks that
are ignored are far less so. Frequently the precautionary principle is underwritten by
probability neglect. Highly speculative harms are emphasized by those who focus on the
badness of the relevant outcomes, rather than the likelihood that they will occur. Most
generally, the precautionary principle sometimes gives an illusion of guidance because
people focus on the immediate risk while disregarding the systemic effects of one-shot
interventions, even though those interventions can give rise to risks of their own.</p>
        <p>I have not suggested any particular substitute for the precautionary principle.
But I do not endorse the suggestion of Aaron Wildavsky, a political scientist with a
special interest in risk regulation, who also rejects the precautionary principle.204 In
Wildavsky’s view, the notion of “precaution” should be abandoned and replaced with a
principle of “resilience,” based on an understanding that nature, and society, are quite
able to incorporate even strong shocks, and that the ultimate dangers are therefore smaller
than we are likely to fear. It would follow from the “resilience” principle that a nation
should be less concerned than it now is with the risks associated with (for example)
arsenic, global warming, and destruction of the ozone layer. Unfortunately, the principle
of “resilience” is no better than that of “precaution.” Some systems are resilient, but
many are not. Whether an ecosystem, or a society, is “resilent” cannot be decided in the
abstract. In any case resilience is a matter of degree. Everything depends on the facts. The
“resilience principle” should be understood as a heuristic, one that favors inaction in the
face of possibly damaging technological change. Like most heuristics, the resilience
principle will work well in many circumstances, but it can also lead to systematic and
even deadly errors.205</p>
        <p>A better approach would acknowledge that a wide variety of adverse effects may
come from inaction, regulation, and everything between. Such an approach would
attempt to consider all of those adverse effects, not simply a subset.206 When existing
knowledge does not allow clear assessments of the full range of adverse effects, such an
approach would develop simplifying devices, helping to show the appropriate course of
action in the face of uncertainty.207 Such an approach would pursue distributional goals
204 See Aaron Wildavsky, But Is It True? A Citizen’s Guide to Environmental Health and Safety Issues 433
(1995).
205 Cf. See Amos Tversky and Daniel Kahneman, Judgment Under Uncertainty: Heuristics and Biases, in
Judgment and Decision Making: A Interdisciplinary Reader 38, 55 (Hal Arkes and Kenneth Hammond).
(emphasizing that heuristic can lead to systematic mistakes). The resilience principle might well be taken as
a reflection of optimistic bias. See Neil Weinstein, Unrealistic Optimism About Future Life Events, 39 J.
Personality and Soc Psych. 806 (1980); Shelly Taylor, Positive Illusions (1991).
206 See Wiener, supra note; Cass R. Sunstein, Risk and Reason (forthcoming 2002).
207 See Goklany, supra note, at 9-10. Instead of advocating full-fledged balancing of relevant variables,
Goklany proposes that regulators look at a list of criteria, including “the human mortality criterion”
(valuing human life over that of members of other species), “the immediacy criterion” (giving priority to
immediate threats), “the uncertainty criterion” (giving priority to risks with a higher probability of
occurring), and “the irreversibility criterion” (giving priority to risks that are likely to be permanent or
persistent). Some of these criteria seem to me doubtful; a less immediate threat might, for example, deserve
priority if its magnitude so suggests, and it is unclear that a small number of human lives deserve priority
directly by, for example, requiring wealthy countries, major contributors to the problem
of global warming, to pay poor countries to reduce greenhouse gases or to prepare
themselves for the relevant risks. And such an approach would attempt to counteract,
rather than to embody, the various cognitive limitations that people face in thinking about
risks. An appreciation of the difficulties with the precautionary principle suggests the
importance of overcoming cognitive limitations by ensuring that people have a full,
rather than limited, sense of what is at stake. The result should be to help with cognitive
distortions and to produce sensible priority-setting. An effort to produce a fair accounting
of the universe of dangers should also help to diminish the danger of interest-group
manipulation.</p>
        <p>To be sure, public alarm, even if ill-informed, is itself a harm, and it is likely to
lead to additional harms, perhaps in the form of large-scale “ripple effects.”208 A sensible
approach to risk will attempt to reduce public fear even if it is baseless. My goal here has
been not to deny that point, but to explain the otherwise puzzling appeal of the
precautionary principle and to isolate the strategies that help make it operational. At the
individual level, these strategies are hardly senseless, especially for people who lack
much information or who do the best they can by focussing on only one aspect of the
situation at hand.209 But for governments, the precautionary principle is not sensible, for
the simple reason that once the viewscreen is widened, it become clear that the principle
provides no guidance at all. A rational system of risk regulation certainly takes
precautions. But it does not adopt the precautionary principle.
over a large number of lives of members of other species. But Goklany is correct to seek an approach that
helps in making decisions under uncertainty. Wiener, supra note, offers some valuable suggestions,
involving in partcular the need to ensure “risk-superior moves,” meaning approaches that reduce overall
risks. (Unpublished manuscript at 16.) The problem with this approach is that sometimes we will lack
sufficient information to identify such moves, because regulation must proceed in the face of uncertainty
rather than risk. See above.
208 See the discussion of the social amplification of risk in Slovic, supra note.
209 See Gerd Gigerenzer et al., Simple Heuristics That Make Us Smart (1999).</p>
        <p>Readers with comments may address them to:
10.
28.</p>
        <p>David Friedman, More Justice for Less Money: A Step Beyond Cimino (December
1994)
Daniel Shaviro, Budget Deficits and the Intergenerational Distribution of Lifetime
Consumption (January 1995)
Douglas G. Baird, The Law and Economics of Contract Damages (February 1995)
Daniel Kessler, Thomas Meites, and Geoffrey P. Miller, Explaining Deviations
from the Fifty Percent Rule: A Multimodal Approach to the Selection of Cases for
Litigation (March 1995)
Geoffrey P. Miller, Das Kapital: Solvency Regulation of the American Business
Enterprise (April 1995)
Richard Craswell, Freedom of Contract (August 1995)
J. Mark Ramseyer, Public Choice (November 1995)
Kenneth W. Dam, Intellectual Property in an Age of Software and Biotechnology
(November 1995)
Cass R. Sunstein, Social Norms and Social Roles (January 1996)
J. Mark Ramseyer and Eric B. Rasmusen, Judicial Independence in Civil Law
Regimes: Econometrics from Japan (January 1996)
Richard A. Epstein, Transaction Costs and Property Rights: Or Do Good Fences
Make Good Neighbors? (March 1996)
Cass R. Sunstein, The Cost-Benefit State (May 1996)
William M. Landes and Richard A. Posner, The Economics of Legal Disputes
Over the Ownership of Works of Art and Other Collectibles (July 1996)
John R. Lott, Jr. and David B. Mustard, Crime, Deterrence, and Right-to-Carry
Concealed Handguns (August 1996)
Cass R. Sunstein, Health-Health Tradeoffs (September 1996)
G. Baird, The Hidden Virtues of Chapter 11: An Overview of the Law and
Economics of Financially Distressed Firms (March 1997)
Richard A. Posner, Community, Wealth, and Equality (March 1997)
William M. Landes, The Art of Law and Economics: An Autobiographical Essay
(March 1997)
Cass R. Sunstein, Behavioral Analysis of Law (April 1997)
John R. Lott, Jr. and Kermit Daniel, Term Limits and Electoral Competitiveness:
Evidence from California=s State Legislative Races (May 1997)
Randal C. Picker, Simple Games in a Complex World: A Generative Approach to
the Adoption of Norms (June 1997)49. Richard A. Epstein, Contracts Small
and Contracts Large: Contract Law through the Lens of Laissez-Faire (August
1997)
Cass R. Sunstein, Daniel Kahneman, and David Schkade, Assessing Punitive
Damages (with Notes on Cognition and Valuation in Law) (December 1997)
William M. Landes, Lawrence Lessig, and Michael E. Solimine, Judicial Influence:
A Citation Analysis of Federal Courts of Appeals Judges (January 1998)
John R. Lott, Jr., A Simple Explanation for Why Campaign Expenditures are
Increasing: The Government is Getting Bigger (February 1998)</p>
        <p>Richard A. Posner, Values and Consequences: An Introduction to Economic
Analysis of Law (March 1998)
Denise DiPasquale and Edward L. Glaeser, Incentives and Social Capital: Are
Homeowners Better Citizens? (April 1998)
Christine Jolls, Cass R. Sunstein, and Richard Thaler, A Behavioral Approach to
Law and Economics (May 1998)
John R. Lott, Jr., Does a Helping Hand Put Others At Risk?: Affirmative Action,
Police Departments, and Crime (May 1998)
Cass R. Sunstein and Edna Ullmann-Margalit, Second-Order Decisions (June
1998)
Jonathan M. Karpoff and John R. Lott, Jr., Punitive Damages: Their Determinants,
Effects on Firm Value, and the Impact of Supreme Court and Congressional
Attempts to Limit Awards (July 1998)
Kenneth W. Dam, Self-Help in the Digital Jungle (August 1998)
John R. Lott, Jr., How Dramatically Did Women=s Suffrage Change the Size and
Scope of Government? (September 1998)
Kevin A. Kordana and Eric A. Posner, A Positive Theory of Chapter 11 (October
1998)
David A. Weisbach, Line Drawing, Doctrine, and Efficiency in the Tax Law
(November 1998)
Jack L. Goldsmith and Eric A. Posner, A Theory of Customary International Law
(November 1998)
John R. Lott, Jr., Public Schooling, Indoctrination, and Totalitarianism (December
1998)
Cass R. Sunstein, Private Broadcasters and the Public Interest: Notes Toward A
AThird Way@ (January 1999)
Richard A. Posner, An Economic Approach to the Law of Evidence (February
1999)
Yannis Bakos, Erik Brynjolfsson, Douglas Lichtman, Shared Information Goods
(February 1999)
Kenneth W. Dam, Intellectual Property and the Academic Enterprise (February
1999)
Gertrud M. Fremling and Richard A. Posner, Status Signaling and the Law, with
Particular Application to Sexual Harassment (March 1999)
Cass R. Sunstein, Must Formalism Be Defended Empirically? (March 1999)71.</p>
        <p>Jonathan M. Karpoff, John R. Lott, Jr., and Graeme Rankine,
Environmental Violations, Legal Penalties, and Reputation Costs (March 1999)
Matthew D. Adler and Eric A. Posner, Rethinking Cost-Benefit Analysis (April
1999)
John R. Lott, Jr. and William M. Landes, Multiple Victim Public Shooting,
Bombings, and Right-to-Carry Concealed Handgun Laws: Contrasting Private
and Public Law Enforcement (April 1999)</p>
        <p>Lisa Bernstein, The Questionable Empirical Basis of Article 2=s Incorporation
Strategy: A Preliminary Study (May 1999)
Richard A. Epstein, Deconstructing Privacy: and Putting It Back Together Again
(May 1999)
William M. Landes, Winning the Art Lottery: The Economic Returns to the Ganz
Collection (May 1999)
Cass R. Sunstein, David Schkade, and Daniel Kahneman, Do People Want
Optimal Deterrence? (June 1999)
Tomas J. Philipson and Richard A. Posner, The Long-Run Growth in Obesity as a
Function of Technological Change (June 1999)
David A. Weisbach, Ironing Out the Flat Tax (August 1999)
Eric A. Posner, A Theory of Contract Law under Conditions of Radical Judicial
Error (August 1999)
David Schkade, Cass R. Sunstein, and Daniel Kahneman, Are Juries Less Erratic
than Individuals? Deliberation, Polarization, and Punitive Damages (September
1999)
Cass R. Sunstein, Nondelegation Canons (September 1999)
Richard A. Posner, The Theory and Practice of Citations Analysis, with Special
Reference to Law and Economics (September 1999)
Randal C. Picker, Regulating Network Industries: A Look at Intel (October 1999)
Cass R. Sunstein, Cognition and Cost-Benefit Analysis (October 1999)
Douglas G. Baird and Edward R. Morrison, Optimal Timing and Legal
Decisionmaking: The Case of the Liquidation Decision in Bankruptcy (October
1999)
Gertrud M. Fremling and Richard A. Posner, Market Signaling of Personal
Characteristics (November 1999)
Matthew D. Adler and Eric A. Posner, Implementing Cost-Benefit Analysis When
Preferences Are Distorted (November 1999)
Richard A. Posner, Orwell versus Huxley: Economics, Technology, Privacy, and
Satire (November 1999)
David A. Weisbach, Should the Tax Law Require Current Accrual of Interest on
Derivative Financial Instruments? (December 1999)
Cass R. Sunstein, The Law of Group Polarization (December 1999)
Eric A. Posner, Agency Models in Law and Economics (January 2000)
Karen Eggleston, Eric A. Posner, and Richard Zeckhauser, Simplicity and
Complexity in Contracts (January 2000)
Douglas G. Baird and Robert K. Rasmussen, Boyd=s Legacy and Blackstone=s
Ghost (February 2000)
David Schkade, Cass R. Sunstein, Daniel Kahneman, Deliberating about Dollars:
The Severity Shift (February 2000)
Richard A. Posner and Eric B. Rasmusen, Creating and Enforcing Norms, with
Special Reference to Sanctions (March 2000)</p>
        <p>Douglas Lichtman, Property Rights in Emerging Platform Technologies (April
2000)
Cass R. Sunstein and Edna Ullmann-Margalit, Solidarity in Consumption (May
2000)
David A. Weisbach, An Economic Analysis of Anti-Tax Avoidance Laws (May
2000)
Cass R. Sunstein, Human Behavior and the Law of Work (June 2000)
William M. Landes and Richard A. Posner, Harmless Error (June 2000)
Robert H. Frank and Cass R. Sunstein, Cost-Benefit Analysis and Relative
Position (August 2000)
Eric A. Posner, Law and the Emotions (September 2000)
Cass R. Sunstein, Cost-Benefit Default Principles (October 2000)
Jack Goldsmith and Alan Sykes, The Dormant Commerce Clause and the
Internet (November 2000)
Richard A. Posner, Antitrust in the New Economy (November 2000)
Douglas Lichtman, Scott Baker, and Kate Kraus, Strategic Disclosure in the Patent
System (November 2000)
Jack L. Goldsmith and Eric A. Posner, Moral and Legal Rhetoric in International
Relations: A Rational Choice Perspective (November 2000)
William Meadow and Cass R. Sunstein, Statistics, Not Experts (December 2000)
Saul Levmore, Conjunction and Aggregation (December 2000)
Saul Levmore, Puzzling Stock Options and Compensation Norms (December
2000)
Richard A. Epstein and Alan O. Sykes, The Assault on Managed Care: Vicarious
Liability, Class Actions and the Patient=s Bill of Rights (December 2000)
William M. Landes, Copyright, Borrowed Images and Appropriation Art: An
Economic Approach (December 2000)
Cass R. Sunstein, Switching the Default Rule (January 2001)
George G. Triantis, Financial Contract Design in the World of Venture Capital
(January 2001)
Jack Goldsmith, Statutory Foreign Affairs Preemption (February 2001)
Richard Hynes and Eric A. Posner, The Law and Economics of Consumer
Finance (February 2001)
Cass R. Sunstein, Academic Fads and Fashions (with Special Reference to Law)
(March 2001)
Eric A. Posner, Controlling Agencies with Cost-Benefit Analysis: A Positive
Political Theory Perspective (April 2001)
Douglas G. Baird, Does Bogart Still Get Scale? Rights of Publicity in the Digital
Age (April 2001)
Douglas G. Baird and Robert K. Rasmussen, Control Rights, Priority Rights and
the Conceptual Foundations of Corporate Reorganization (April 2001)</p>
        <p>David A. Weisbach, Ten Truths about Tax Shelters (May 2001)</p>
        <p>William M. Landes, What Has the Visual Arts Rights Act of 1990 Accomplished?
(May 2001)
Cass R. Sunstein, Social and Economic Rights? Lessons from South Africa (May
2001)
Christopher Avery, Christine Jolls, Richard A. Posner, and Alvin E. Roth, The
Market for Federal Judicial Law Clerks (June 2001)
Douglas G. Baird and Edward R. Morrison, Bankruptcy Decision Making (June
2001)
Cass R. Sunstein, Regulating Risks after ATA (June 2001)
Cass R. Sunstein, The Laws of Fear (June 2001)
Richard A. Epstein, In and Out of Public Solution: The Hidden Perils of Property
Transfer (July 2001)
Randal C. Picker, Pursuing a Remedy in Microsoft: The Declining Need for
Centralized Coordination in a Networked World (July 2001)
Cass R. Sunstein, Daniel Kahneman, David Schkade, and Ilana Ritov, Predictably
Incoherent Judgments (July 2001)
Eric A. Posner, Courts Should Not Enforce Government Contracts (August 2001)
Lisa Bernstein, Private Commercial Law in the Cotton Industry: Creating
Cooperation through Rules, Norms, and Institutions (August 2001)
Richard A. Epstein, The Allocation of the Commons:Parking and Stopping on the
Commons (August 2001)
Cass R. Sunstein, The Arithmetic of Arsenic (September 2001)
Eric A. Posner, Richard Hynes, and Anup Malani, The Political Economy of
Property Exemption Laws (September 2001)
Eric A. Posner and George G. Triantis, Covenants Not to Compete from an
Incomplete Contracts Perspective (September 2001)
Cass R. Sunstein, Probability Neglect: Emptions, Worst Cases, and Law
(November 2001)
Randall S. Kroszner and Philip E. Strahan, Throwing Good Money after Bad?
Board Connections and Conflicts in Bank Lending (December 2001)
Alan O. Sykes, TRIPs, Pharmaceuticals, Developing Countries, and the Doha
ASolution@ (February 2002)
Edna Ullmann-Margalit and Cass R. Sunstein, Inequality and Indignation
(February 2002)
Daniel N. Shaviro and David A. Weisbach, The Fifth Circuit Gets It Wrong in
Compaq v. Commissioner (February 2002) (Published in Tax Notes, January 28,
2002)
Warren F. Schwartz and Alan O. Sykes, The Economic Structure of Renegotiation
and Dispute Resolution in the WTO/GATT System (March 2002, forthcoming
Journal of Legal Studies 2002)
Richard A. Epstein, HIPAA on Privacy: Its Unintended and Intended</p>
        <p>Consequences (March 2002, forthcoming Cato Journal, summer 2002)</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          <source>2001.17 In February</source>
          <year>2002</year>
          ,
          <article-title>the precautionary principle was explicitly adopted by the 1</article-title>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>