<?xml version="1.0" encoding="UTF-8"?>
<article xmlns:xlink="http://www.w3.org/1999/xlink"><script/>
  <front>
    <journal-meta/>
    <article-meta>
      <title-group>
        <article-title>Group Judgments: Deliberation, Statistical Means, and Information Markets</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Coase-Sandor Working Paper Series in Law</string-name>
          <email>unbound@law.uchicago.edu</email>
          <xref ref-type="aff" rid="aff0">0</xref>
          <xref ref-type="aff" rid="aff1">1</xref>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Cass R. Sunstein</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
          <xref ref-type="aff" rid="aff1">1</xref>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>Cass R. Sunstein, "Group Judgments: Deliberation, Statistical Means, and Information Markets", John M. Olin Program in Law and Economics Working Paper No.</institution>
          <addr-line>219, 2004</addr-line>
        </aff>
        <aff id="aff1">
          <label>1</label>
          <institution>Coase-Sandor Institute for Law and Economics</institution>
        </aff>
        <aff id="aff2">
          <label>2</label>
          <institution>accepted for inclusion in Coase-Sandor Working Paper Series in Law and Economics by an authorized administrator of Chicago Unbound. For more information</institution>
          ,
          <addr-line>please contact</addr-line>
        </aff>
      </contrib-group>
      <fpage>39</fpage>
      <lpage>80</lpage>
      <abstract>
        <p>Follow this and additional works at: https://chicagounbound.uchicago.edu/law_and_economics Part of the Law Commons Recommended Citation</p>
      </abstract>
    </article-meta>
  </front>
  <body>
    <sec id="sec-1">
      <title>-</title>
      <p>JOHN M. OLIN LAW &amp; ECONOMICS WORKING PAPER NO. 219
(2D SERIES)
Group Judgments: Deliberation, Statistical Means, and
Information Markets</p>
      <p>Cass R. Sunstein</p>
      <p>T H E L A W S C H O O L
T H E U N I V E R S I T Y O F C H I C A G O</p>
      <p>August 2004
(revised October 2004)
Preliminary draft 9/30/04
All rights reserved</p>
    </sec>
    <sec id="sec-2">
      <title>Group Judgments: Deliberation, Statistical Means, and Information Markets</title>
      <p>Cass R. Sunstein*
How can groups elicit and aggregate the information held by their individual members?
There are three possibilities. Groups might use the statistical mean of individual
judgments; they might encourage deliberation; or they might use information markets. In
both private and public institutions, deliberation is the standard way of proceeding; but
for two reasons, deliberating groups often fail to make good decisions. First, the
statements and acts of some group members convey relevant information, and that
information often leads other people not to disclose what they know. Second, social
pressures, imposed by some group members, often lead other group members to silence
themselves because of fear of disapproval and associated harms. As a result, deliberation
often produces a series of unfortunate results: the amplification of errors, hidden
profiles, cascade effects, and group polarization. A variety of steps should be taken to
ensure that deliberating groups obtain the information held by their members;
restructuring private incentives, in a way that increases disclosure, is the place to start.
Information markets have substantial advantages over group deliberation; such markets
count among the most intriguing institutional innovations of the last quarter-century and
should be used far more than they now are. One advantage of information markets is that
they tend to correct, rather than to amplify, the effects of individual errors. Another
advantage is that they create powerful incentives to disclose, rather than to conceal,
privately held information. Information markets thus provide the basis for a Hayekian
critique of many current celebrations of political deliberation. They also provide a
valuable heuristic for understanding how to make deliberation work better. These points
bear on discussion of normative issues, in which deliberation might also fail to improve
group thinking, and in which identifiable reforms could produce better outcomes.
Applications include the behavior of juries, multimember judicial panels, administrative
agencies, and congressional committees; analogies, also involving information
aggregation, include open source software, Internet “wikis,” and weblogs.
* Karl N. Llewellyn Distinguished Service of Jurisprudence, Law School and Department of Political
Science, University of Chicago. For valuable comments, I am grateful to Michael Abramowitz, Bruce
Ackerman, Ian Ayres, Bernard Harcourt, Saul Levmore, Douglas Lichtman, Richard Posner, and Adam
Samaha. I am also grateful to participants in workshops at Harvard Law School, the John F. Kennedy
School of Government at Harvard University, the University of Chicago Law School, and the Yale Law
School. A version of this paper was presented as the keynote lecture at a conference on Whither
Democracy? at Brandeis University, and I am grateful to participants for their suggestions and criticisms.
Many thanks also to Robert Park for extraordinary research assistance. Thanks above all to Reid Hastie, for
a great deal of patient help and tutoring.</p>
      <p>“Increased accuracy is a common justification for using groups, rather than
individuals, to make judgments. However, the empirical literature shows that groups
excel as judges only under limited conditions. . . . [G]roups performing tasks that involve
solutions that are not easily demonstrable tend to perform at the level of their average
members.”1</p>
      <p>“The presumption that Iraq had active WMD programs was so strong that formalized
[Intelligence Community] mechanisms established to challenge assumptions and ‘group
think,’ such as ‘red teams,’ ‘devil’s advocacy,’ and other types of alternative or
competitive analysis, were not utilized.”2</p>
      <p>“Sometimes important forecasts are made in traditional group meetings. This . . .
should be avoided because it does not use information efficiently. A structured approach
for combining independent forecasts is invariably more accurate.”3</p>
      <p>How can groups obtain the information that their members have? There are three
principal answers. First, groups might use the statistical mean (or median) of the
independent judgments of their members. Second, groups might ensure deliberation,
asking for the reasoned exchange of facts, ideas, and opinions. Third, groups might use
information markets, through which group members, or those outside of the group, “bet”
on their judgments about future events. Of course each of these methods can take diverse
forms; one of my principal goals here is to explore which forms are most likely to
produce good outcomes. The choice bears on the performance of many institutions
involved in law and politics, including juries, administrative agencies, congressional
committees, federal courts of appeals, and even the Supreme Court itself.</p>
      <p>Both private and public institutions usually prefer to make decisions through
deliberation. Generalizing from this fact, many people have paid a great deal of attention
to deliberative accounts of democracy itself. The theoretical foundations of deliberative
1 See Daniel Gigone and Reid Hastie, Proper Analysis of the Accuracy of Group Judgments, 121 Psych.
Bulletin 149 (1997).
2 Select Committee on Intelligence, United States Senate, Report of the U.S. Intelligence Community’s
Prewar Intelligence Assessments on Iraq, Conclusions, at 7.
3 J. Scott Armstrong, Combining Forecasts, in Principle of Forecasting 417, 433 (J. Scott Armstrong ed.
2001).
democracy have been elaborated in some detail,4 and increasing attention is being
devoted to methods for making democratic processes more deliberative. James Fishkin,
for example, has pioneered the idea of the “deliberative opinion poll,” by which people
are asked to deliberate together on public issues and to state their judgments only after
the deliberative process.5 Fishkin and Bruce Ackerman have gone so far as to suggest a
new national holiday, Deliberation Day, in which people are asked to congregate in
groups in order to discuss and debate important issues of public policy.6 Perhaps the
proposal is unrealistic; perhaps citizens as a whole should not be expected to deliberate
much in a liberal society.7 But even if this is true, leaders in the public and private sphere
might be urged to deliberate more than they now do, and many accounts of deliberative
democracy emphasis the importance of deliberation by representatives.8</p>
      <p>Why, exactly, is deliberation important or even desirable? A central answer must
be that deliberation will result in wiser judgments and better outcomes.9 But does
deliberation actually have this effect? The answer is by no means clear.10 Group members
may impose pressures on one another, leading to a consensus on falsehood rather than
truth. The idea of “groupthink,” coined and elaborated by Irving Janis, suggests the
possibility that groups will tend toward uniformity and censorship, thus failing to
combine information and enlarge the range of arguments.11</p>
      <sec id="sec-2-1">
        <title>Without structural</title>
        <p>protections, both private and public groups are likely to err, not in spite of deliberation
4 See Jurgen Habermas, Between Facts and Norms (1998); Amy Gutmann and Dennis Thompson,
Democracy and Disagreement (1999); Deliberative Democracy (Jon Elster ed. 1998). On the role of
deliberative democracy in the American framing, see William Bessette, The Mild Voice of Reason (1988).
5 See James Fishkin, The Voice of the People (2000).
6 See Bruce Ackerman and James Fishkin, Deliberation Day (2004).
7 See Richard A. Posner, Law, Pragmatism, and Democracy (2003).
8 See William Bessette, The Mild Voice of Reason (1996).
9 There are other possibilities, of course. Perhaps deliberation has educative effects or contributes to
individual self-development; perhaps it legitimates decisions or increases the likelihood that people will
acquiesce in then. See Thomas Tyler, Why People Obey the Law (1999). I am mostly putting these
arguments to one side here, and focusing on the possibility that deliberation will improve outcomes. As
noted below, however, deliberation tends to increase confidence and to decrease variance, even when it
does not increase accuracy; it follows that deliberation might be justified because of its legitimating effects
even when it fails to produce better outcomes. See pp. XX below.
10 See Gigone and Hastie, supra note; Garold Stasser and William Titus, Hidden Profiles: A Brief History,
14 Psych Inquiry 304 (2003); Robert MacCoun, Comparing Micro and Macro Rationality, in Judgments,
Decisions, and Public Policy (M.V. Rajeev Gowda and Jeffrey Fox eds. 2002).
11 See Irving Janis, Groupthink (2d ed. 1980).
but because of it. The use of statistical means, or of information markets, will often lead
to more accurate decisions.</p>
        <p>As an example of a failure of deliberation, consider the account in the 2004 report
of the Senate Select Committee on Intelligence, which explicitly accused the Central
Intelligence Agency (CIA) of groupthink, in which the agency’s predisposition to find a
serious threat from Iraq led it to fail to explore alternative possibilities or to obtain and
use the information that it actually held.12 In the Committee’s view, the CIA
“demonstrated several aspects of group think: examining few alternatives, selective
gathering of information, pressure to conform within the group or withhold criticism, and
collective rationalization.”13 Thus the agency showed a “tendency to reject information
that contradicted the presumption” that Iraq had weapons of mass destruction.14 Because
of that presumption, the agency failed to use its own formalized methods “to challenge
assumptions and ‘group think,’ such as ‘red teams,’ ‘devil’s advocacy,’ and other types of
alternative or competitive analysis.”15 Above all, the Committee’s conclusions emphasize
the CIA’s failure to elicit and aggregate information.</p>
        <p>This claim is a remarkable and even uncanny echo of one that followed the 2003
investigation of failures at NASA, stressing that agency’s similar failure to elicit
competing views, including those based on information held by agency employees.16 The
Columbia Accident Investigation Board explicitly attributed the accident to NASA’s
unfortunate culture, one that does too little to elicit information. In the Board’s words,
NASA lacks “checks and balances.”17 It pressures people to follow a “party line.”18 At
NASA, “it is difficult for minority and dissenting opinions to percolate up through the
agency’s hierarchy”19—even though, the Board contended, effective safety programs
require the encouragement of minority opinions and bad news.
12 Available at http://intelligence.senate.gov/.
13 Id., conclusions at 4.
14 Id. at 6.
15 Id. at 8.
16 Report of The Columbia Accident Investigation Board, available at
http://www.nasa.gov/columbia/home/CAIB_Vol1.html
17 Id. at 12.
18 Id. at 102.
19 Id. at 183.</p>
        <p>As we shall see, statistical means sometimes do at least as well as deliberation.
Information markets, which count among the most intriguing institutional innovations of
the last quarter-century, often do far better. To explain why deliberation fails, I explore
the consequences of two sets of influences on members of deliberating groups.20 The first
consists of informational influences, by which group members fail to disclose what they
know because of deference to the information publicly announced by others. The second
involves social pressures, which lead people to silence themselves in order not to face
reputational sanctions, such as the disapproval of relevant others. As a result of these
problems, groups often do not correct but instead amplify individual errors; emphasize
shared information at the expense of unshared information; fall victim to cascade effects;
and tend to end up in a more extreme position in line with the predeliberation tendencies
of their members.21 Even federal judges are vulnerable to the relevant pressures, as both
Republican and Democratic appointees show especially ideological voting when they are
sitting with other judges appointed by presidents of the same political party.22 Statistical
groups and information markets are far less susceptible to the pressures that make
deliberating groups err.</p>
        <p>Because of those pressures, deliberative processes often fail to achieve their
minimal goal of aggregating the information that the relevant deliberators actually have.
Indeed, such processes often fail to aggregate information even as they decrease variance,
and increase confidence, among their members.23 A confident, cohesive, error-prone
group is nothing to celebrate; on the contrary, it might be extremely dangerous both to
itself and to others.24 As we shall see, information markets often outperform both
statistical and deliberating groups, simply because they are so effective at pooling
20 I explore these mechanisms from a different direction in Cass R. Sunstein, Why Societies Need Dissent
(2003), but without attention to statistical groups and information markets, and without focusing on
amplification of errors, hidden profiles, and the common knowledge effect, which are major emphases
here.
21 This last possibility is emphasized in Roger Brown, Social Psychology: The Second Edition (1985);
Sunstein, supra note.
22 See Cass R. Sunstein, David Schkade, and Lisa Ellman, Ideological Voting on Federal Courts of
Appeals: A Preliminary Investigation, 90 Va L Rev 301 (2004); Cass R. Sunstein and David Schkade, All
the President’s Judges (unpublished manuscript 2004).
23 Chip Heath and Rich Gonzalez, Interaction With Others Increases Decision Confidence But Not
Decision Quality: Evidence against Information Collection Views of Interactive Decision Making, 61 Org
Behavior and Human Decision Processes 305 (1995).
24 See the comparison of democratic and nondemocratic regimes in Dominic Johnson, Overconfidence and
War: The Havoc and Glory of Positive Illusions 180-83 (2004).
information. Indeed, information markets realign private incentives in a way that makes
them exceptionally well-designed to reduce the problems that infect deliberating groups.
Such markets are worth investigating in part because they provide an illuminating route
by which to explore some characteristic defects in deliberative processes. If such
processes are to be improved, it might well be by building on the insights provided by the
large successes of information markets. In addition, such markets are worth investigating
in their own right, if only because they promise to provide a supplement to deliberation,
one that should improve social decisions.25 My goal, in short, is to mend deliberative
processes, not to end them. As we shall see, both social norms and institutional design
can go a long way toward reducing the problems that lead to deliberative blunders.</p>
        <p>To keep the analysis simple, my principal focus is not on controversial judgments
of value but on questions with demonstrably correct answers. An understanding of how
deliberation finds, and fails to find, those answers should have implications for its
potential and limitations with respect to normative questions as well. If, for example,
deliberation often fails in producing good answers to simple questions of fact, then it is
also likely to fail to produce good answers to disputed issues of value. The solution to
many such questions depends at least in part on resolution of factual issues; it is difficult
to take a stand on proposals to raise the minimum wage, to engage in preemptive war, or
to overrule Roe v. Wade26 without resolving several issues of fact. And even when
factual issues are not central, deliberation can, in principle, ensure more sensible
judgments.27 Unfortunately, however, the problems posed by informational pressure and
social influences apply in normative domains as well as elsewhere. I will therefore offer
some suggestions for how groups can reduce those problems through structural reforms.</p>
        <p>This Article comes in six parts. Part II explores a nondeliberative method for
aggregating privately-held information, one that simply takes the average of
predeliberation judgments. The resulting judgments of these “statistical groups” are
sometimes remarkably accurate, and they provide a useful benchmark for assessing
25 For an ambitious account, see Robin Hanson, Shall We Vote on Values, But Bet on Beliefs?
(unpublished manuscript 2003).
26 410 US 113 (1973).
27 This is the thesis of Fishkin, The Voice of the People, supra note.
deliberative judgments.28 An understanding of the judgments of statistical groups also
provides several clues about the usefulness and limitations of relying on the judgments of
groups in general. Part III explores the effects of informational pressures and social
influences, with an emphasis on amplification of errors, hidden profiles, cascade effects,
and group polarization. Part III also attempts to square some apparently conflicting
evidence about the performance of deliberating groups; it investigates the possibility that
some groups will do as well as or even better than their best members.</p>
        <p>Part IV investigates structural reforms that are intended to ensure that group
members reveal what they know—for example, by requiring anonymous statements of
beliefs before deliberation begins, by assigning specified roles to participants in
deliberation, and by structuring incentives to produce disclosure of privately held
information. Part V identifies and compares information markets, in which people bet on
the outcomes of events. Information markets have performed remarkably well in many
diverse domains. Because they restructure people’s incentives, overcome a collective
action problem faced by individual group members, and allow informed traders to play a
large role in setting “prices,” they have advantages over both statistical judgments and
deliberative judgments. They might well be used as a supplement to or even a
replacement for collective deliberation. Part VI briefly discusses how the analysis might
apply to normative questions.</p>
        <p>Suppose that there is a question about some disputed issue of fact. How many
home runs did Hank Aaron hit? When was Calvin Coolidge elected president? Will a
district court decision be reversed on appeal? Does a foreign country pose a serious threat
to national security? Is the United States likely to have difficulty in winning a particular
war? A great deal of evidence suggests that under certain conditions, a promising way to
answer such questions is this: Ask a large number of people and take the mean answer.29
When the relevant conditions are met, the mean answer, which we might describe as the
28 These are often described as the judgments of “statisticized groups.” See Irving Lorge et al., A Survey of
Studies Contrasting the Quality of Group Performance and Individual Performance, 1920-1957, 55 Psych
Bull 337, 344 (1958).
29 When groups are large, of course, the mean and the median will tend to converge.
group’s “statistical answer,”30 is often accurate, where accuracy is measured by reference
to objectively demonstrable fact.</p>
        <p>It is well-known that statistical answers from groups of sufficiently large sizes
tend to match the views of population-wide samples.31 This finding bears on issues as
diverse as the use of juries as a measure of community sentiment32 and the remarkable
success of Google, the search engine; Google is good at finding what a particular
searcher wants because it knows what most searchers want.33 But here the question is
what is true, not what populations think. Let us therefore explore how statistical groups
perform, partly because the answer is important and illuminating itself, and partly
because it provides a useful foundation for the assessment of both deliberating groups
and information markets.</p>
      </sec>
    </sec>
    <sec id="sec-3">
      <title>A. Evidence</title>
      <p>Many of the studies of statistical groups involve quantitative estimates. Consider a
few examples:
1. In an early study, Hazel Knight asked college students to estimate the temperature
of a classroom.34 Individual judgments ranged from 60 degrees to eighty-five
degrees; the statistical judgment of the group was 72.4 degrees, very close to the
actual temperature of 72 degrees. That judgment was better than that of 80% of
individual judgments.
2. Judging the numbers of beans in the jar, the group average is almost always better
than that of the vast majority of individual members. In one such experiment, a
group of fifty-six students was asked about a jar containing 850 beans; the group
estimate was 871, a better guess than all but one of students.35
30 See Janis, supra note.
31 See H.J. Eysenck, The Validity of Judgments As A Function of Number of Judges, 25 J. Exp Psych. 650
(1939).
32 For evidence and comments, see Cass R. Sunstein, Daniel Kahneman, and David Schkade, Assessing
Punitive Damages, 107 Yale L.J. 2071 (1998).
33 See Sergey Brin and Lawrence Page, The Anatomy of a Large-Scale Hypertextual Web Search Engine,
available at http://www-db.stanford.edu/
34 Lorge et al., supra note, at 342.
35 See James Surowiecki, The Wisdom of Crowds 5 (2004).
individuals.36
group members.37
3. Asking two hundred students to rank items by weight, one experimenter found
that the group’s estimate was 94 percent accurate—a figure excelled by only five
4. Asked to rank ten piles of buckshot, each only slightly different in size from the
others, the group’s guess was 94.5% accurate, far more so than that of almost all
5. The British scientist Francis Galton sought to draw lessons about collective
intelligence by examining a competition in which contestants attempted to judge
the weight of a fat ox at a regional fair in England. The ox weighed 1,198 pounds;
the average guess, from the 797 contestants, was 1,197 pounds.38</p>
      <p>If these findings can be generalized, many questions might plausibly be answered
not deliberatively, but simply by asking a large group of people and selecting the average
response. Imagine that a large company is attempting to project its sales for the following
year. Might it do best to poll its salespeople and to choose the average number on the
assumption that it is likely to be correct39? Or suppose that a company is deciding
whether to hire a new employee. Should it ask relevant personnel, not to deliberate, but
about their individual views on whether the employee’s performance is likely to meet a
certain level? Or turn to the legal context and suppose that the question is whether a case
should be settled. Ought a law firm to poll its lawyers about the expected outcome at
trial? Or consider the political domain and suppose that the question is whether a war
effort will go well by some identifiable standard. Should the President poll his advisers
and take the median answer? To answer these questions, we have to know why, in the
relevant studies, the median judgment is so accurate.
36 Kate Gordon, Group Judgments in the Field of Lifted Weights, 7 J Exp Psych 389 (1924); Kate Gordon,
Further Observations on Group Judgments of Lifted Weights, 1 J Psych 105 (1935-1936).
37 R. S. Bruce, Group Judgments in the Field of Lifted Weights and Visual Discrimination, 1 J Psych 117
(1935-1936).
38 See James Surowiecki, The Wisdom of Crowds (2004).
39 Some affirmative evidence can be found in J. Scott Armstrong, Combining Forecasts, in Principle of
Forecasting 417, 433 (J. Scott Armstrong ed. 2001).</p>
    </sec>
    <sec id="sec-4">
      <title>B. The Condorcet Jury Theorem</title>
      <p>The accuracy of judgments of statistical groups is best explained by reference to
the Condorcet Jury Theorem.40 To see how the Jury Theorem works, suppose that people
are answering a common question with two possible answers, one false and one true, and
that the average probability that each voter will answer correctly exceeds 50 percent. The
Jury Theorem holds that the probability of a correct answer, by a majority of the group,
increases toward certainty as the size of the group increases.41 The importance of the Jury
Theorem lies in the demonstration that groups are likely to do better than individuals, and
large groups better than small ones, if majority rule is used and if each person is more
likely than not to be correct. The last proviso is extremely important. Suppose that each
individual in a group is more likely to be wrong than right. If so, the likelihood that the
group will decide correctly falls to zero as the size of the group increases.</p>
      <p>In the context of statistical judgments, several of Condorcet’s stringent and
somewhat unrealistic assumptions are met. Indeed, the likelihood that they will be met is
higher with statistical groups than with deliberating ones. Condorcet assumed that people
would be unaffected by whether their votes would be decisive42; that people would not be
affected by one another’s votes; and that the probability that one group member would be
right would be statistically unrelated to the probability that another group member would
be right.43 The first two assumptions plainly hold for statistical groups. People do not
know what others are saying and hence they cannot be influenced by a belief that their
judgments will make the difference to that of the group. The third assumption may or
may not be violated. Those who have similar training, or who work closely together, will
be likely to see things in the same way,44 and those involved in statistical groups might
40 See William P. Bottom et al., Propagation of Individual Bias Through Group Judgment: Error in the
Treatment of Asymmetrically Informative Signals, 25 J Risk and Uncertainty 147 (2002).
41 The theorem is based on some simple arithmetic. Suppose, for example, that there is a three-person
group, in which each member has a 67% probability of bring right. The probability that a majority vote will
produce the correct answer is 74%.
42 William P. Bottom et al., Propagation of Individual Bias Through Group Judgment: Error in the
Treatment of Asymmetrically Informative Signals, 25 J Risk and Uncertainty 147, 153 (2002).
43 Id.
44 Id.
well meet these conditions. On the other hand, the Condorcet Jury Theorem has been
shown to be robust to violations of this third assumption.45</p>
      <p>To see why statistical groups perform well, consider the problems just described
and note that even if everyone in the group is not more than 50% likely to be right, the
Theorem’s predictions may well continue to hold. Suppose, for example, that 60% of
people are 51% likely to be right and that 40% of people are 50% likely to be right; or
that 45% of people are 40% likely to be right and that 55% of people are 65% likely to be
right; or even that 51% of people are 51% likely to be right and that 49% of people are
merely 50% likely to be right. Even under these conditions, the likelihood of a correct
answer will move toward 100% as the size of the group increases. It will not move as
quickly as it would if every group member were highly likely to be right, but it will
nonetheless move. We could imagine endless variations on these numbers. The point is
that even if a significant percentage of the group is not more likely to be right than
wrong, or even if many group members are more likely to be wrong than right, an
accurate result, from a sufficiently large group, can be expected.</p>
      <p>Of course most of the relevant judgments, in studies of statistical groups, do not
involve a binary choice; consider the question how many beans are in a jar, how many
pounds a given object weighs, or how well a certain product will sell in the following
year. But the answers to such questions are not analytically different from those in binary
choices. In answering the relevant questions, each person is effectively being asked to
answer a long series of binary questions—ten beans or a thousand beans, twenty beans or
five hundred beans, fifty beans or one hundred beans, and so on. If a sufficiently large
group is asked to answer such questions, and if most individual answers will be better
than random, the mean answer will be highly accurate. Of course the combination of
probabilities, for a series of binary results, might mean that things will turn out poorly. If
someone is 51% likely to answer each of two questions correctly, the probability that she
will answer both questions correctly is only slightly higher than 25%. But with large
groups, enough people are likely to make better-than-random guesses, on the questions
45 Id.
involved in certain quantitative judgments, that the average estimate will have a high
degree of accuracy.46</p>
      <p>But compare a situation in which if only 49% of the group is likely to be better
than random. If so, the likelihood of a mistake will move toward 100% under the same
condition. But for the number of beans in a jar, or the weight of an ox, most people are
not wholly at sea. The accuracy of the median judgment, for large groups, is simply an
application of the Condorcet Jury Theorem. And in certain circumstances, deliberating
groups will act in roughly the same way, aggregating their information to produce
remarkably accurate results.47</p>
    </sec>
    <sec id="sec-5">
      <title>C. Errors</title>
      <p>In this light, we can identify two situations in which the judgment of a statistical
group will be incorrect. The first are those in which group members show a systematic
bias. The second are those in which their answers are worse than random. The failures of
statistical judgments, in these circumstances, have strong implications for deliberation as
well.</p>
      <p>1. Bias. A systematic bias in one or another direction will create serious problems
for the group’s answers. If, for example, an experimenter “anchors” subjects on a
misleading number, the median will almost certainly be wrong. Suppose, for example,
that a jar contains 800 jelly beans, and the experimenter happens to say, quietly, “many
jars of jelly beans, though not necessarily this one, have 500 jelly beans,” or even, “I’m
asking this question to 250 people.”48 In either case, the low number will likely operate as
an anchor,49 and people’s answers will be systematically biased toward understating the
actual number, producing an unreliable mean. One study demonstrates more generally
46 On some of the technical complexities, see Christian List and Robert Goodin, Epistemic Democracy:
Generalizing the Condorcet Jury Theorem, 9 Journal of Political Philosophy 9 (2001). For a popular
illustration, consider the television show, Who Wants to be A Millionaire? In this show, contestants, when
stumped, are permitted to ask a personally appointed “expert” (a friend who is known to know a great deal)
or the studio audience. The studio audience significantly outperforms the expert. See Surowiecki, supra
note. The reason is that most audience members are more accurate than they would be if they guessed
randomly, and when this condition is met, large groups can be expected to do extremely well.
47 Bottom et al., supra note.
48 Even self-evidently arbitrary anchors have significant effects on people’s judgments. See Gretchen
Chapman and Eric Johnson, Incorporating the Irrelevant: Anchors in Judgments of Belief and Value, in
Heuristics and Biases: The Psychology of Intuitive Judgment 120 (Thomas Gilovich et al. eds. 2002).
49 See id.
that a group’s statistical estimate is likely to be erroneous “when the material is
unfamiliar, distorted in a way such that all individuals are prone to make similar errors of
estimation.”50 The error-producing effects of anchors are simply a special case of this
general point. Anchors are undoubtedly at work in deliberating groups as well, although
in theory deliberation might reduce their effects. And anchors have significant effects
within the legal system. For example, the plaintiff’s demand is likely to affect damage
awards for harms that are difficult to monetize, and groups are no less subject to those
effects than individuals.51 Even judges have been found to be subject to irrelevant
anchors,52 and there is every reason to believe that multimember courts would be at least
as vulnerable to them as individual judges are.53</p>
      <p>2. Random or worse. Suppose that people are asked not about the number of jelly
beans in a jar, but about the number of atoms in a jelly bean. On that question, people’s
answers are hopelessly ill-informed, and there is no reason at all to trust their judgments.
Consider a small-scale study at the University of Chicago Law School, one that strongly
supports this conclusion. A number of faculty members were asked the weight, in
pounds, of the fuel that powers space shuttles. The actual answer is 4 million pounds. The
median response was 200,000; the mean was 55,790,555 (because of one outlier
choice)—both wildly inaccurate. In a binary choice, of course, people’s answers will be
worse than random only if they are unaware of how little they know; if they know that
they are likely to be wrong, they should choose randomly, which gives them a 50%
probability of being right. But sometimes people think they know more than they do, and
many tasks do not involve binary choices at all. Statistical groups will err if confusion
and ignorance are so widespread that individual’s answers are worse than random. Here
too there are evident applications to many contexts in law and politics.
50 Lorge et al., supra note, at 346.
51 See Chapman and Johnson, supra note; Reid Hastie et al., Do Plaintiffs’ Requests and Plaintiffs’
Identities Matter?, in Cass R. Sunstein et al., Punitive Damages: How Juries Decide 62 (2002).
52 Chris Guthrie, Jeffrey Rachlinski, and Andrew Wistrich, Inside the Judicial Mind, 86 Corn L Rev 777
(2001).
53See Norbert Kerr et al., Bias in Judgment: Comparing Individuals and Groups, 103 Psych. Rev. 687
(1996).</p>
    </sec>
    <sec id="sec-6">
      <title>D. Statistical Answers and Experts</title>
      <p>Should statistical means be used more than they now are? Do statistical means
outperform experts? Everything depends on the competence of the experts. If we could
find real experts on the weight of oxen or on how to count jelly beans, and if we
understand expertise to be the ability to make accurate assessments, then experts would
by stipulation do better than statistical means. Suppose, for example, that a deliberating
group of lawyers is trying to decide how many Supreme Court decisions have invalidated
a state or federal law, or the number of lines in Antigone, or the weight of the most recent
winner of the Kentucky Derby. Would it make any sense to poll the lawyers individually
and to assume that the mean response is accurate? The studies outlined above suggest that
if the group is large enough, the mean answer will be at least good.54 But there are many
ways to do far better.</p>
      <p>For many factual questions, of course, a little research would be sufficient to
identify the correct answers. But for some factual issues, even significant research is
inconclusive, and it is best to consult experts. And if experts are available, it would make
sense to obtain a statistical answer from them, rather than to select one or a few. If
experts are likely to be right, a statistical group of experts should have the same
advantage over individual experts as a statistical group of ordinary people has over
ordinary individuals. In fact a great deal of evidence supports this claim.55 In a series of
thirty comparisons, statistical groups of experts had 12.5% fewer errors on forecasting
tasks involving such diverse issues as company earnings, cattle and chicken prices, real
and nominal GNP, survival of patients, and housing starts.56 For example, statistical
groups of experts significantly outperformed individual experts in predicting the annual
earnings of firms; changes in the American economy; and annual peek rainfall runoff in
eight different countries.57 The implication is straightforward: “Organizations often call
on the best expert they can find to make important forecasts. They should avoid this
54 I conducted such a poll with faculty at the University of Chicago Law School, who did fairly well in
estimating the weight of the horse who won the Kentucky Derby, fairly badly in estimating the number of
lines in Antigone—and horrendously with the number of Supreme Court invalidations of state and federal
law!
55 See J. Scott Armstrong, Combining Forecasts, in Principles of Forecasting 416 (2001).
56 Id. at 428.
57 Id. at 430-31.
practice, and instead combine forecasts from a number of experts.”58 For political polling,
it has become standard practice to combine a set of poll results and to rely on the mean or
median, rather than to select one or two.59</p>
      <p>Consider in this regard the Copenhagen Consensus, designed to inform policy
judgments about global risks.60 The Copenhagen Consensus was obtained for a series of
possible interventions, involving climate change, water and sanitation, hunger and
malnutrition, free trade, and communicable diseases, among others. A number of experts
were asked about the best way to promote global welfare, and particularly the welfare of
developing countries, assuming that $50 billion were made available. The experts ranked
the possible projects, producing an overall ranking (reflecting the mean rankings of the
experts taken as a whole).61 I do not mean to suggest that the results of this particular
exercise are correct; everything depends on whether the relevant experts were in a
position to offer reliable answers on the questions at hand. But if statistical means are a
good way to aggregate knowledge when ordinary people know something of relevance,
then they are also a good way to aggregate knowledge from experts.</p>
    </sec>
    <sec id="sec-7">
      <title>III. Deliberating Groups</title>
      <p>Although the judgments of statistical groups can be quite accurate, it is easy to
imagine that a deliberating group would be much better. In principle, a deliberating group
should do well even when its members are error-prone. Deliberation, in the form of an
exchange of information and reasons, might well bring them into line. If many group
members give answers that are worse than random, perhaps other group members can
show them how they have erred. If individuals have been manipulated in their private
judgments, perhaps deliberation will undo the effects of the manipulation.62 If individual
members have anchored on a misleading value, perhaps deliberation will expose the
anchor as such.
58 Id. at 433.
59 See, e.g., Sam Wang, Electoral College Meta-Analysis (2004), available at
http://synapse.princeton.edu/~sam/pollcalc.html
60 See http://www.copenhagenconsensus.com/.
61 See id.
62 See Ackerman and Fishkin, supra note.</p>
      <p>To make the analysis tractable, let us focus on how deliberating groups might be
able to solve factual questions or cognitive puzzles that have correct solutions. The latter
are often questions of instrumental rationality, posing a question about the right strategy
for achieving agreed-upon goals. Results in these domains provide a good test of when
and whether deliberating groups perform well. To the extent that such groups do badly in
answering questions with objectively correct answers, we have reason to suspect that they
will also do badly in answering questions for which there is no consensus on truth or
validity.</p>
    </sec>
    <sec id="sec-8">
      <title>A. Mechanisms and Realities</title>
      <p>1. Possibilities. If groups perform better than their average member, we can
imagine three principal mechanisms by which the improvement occurs.</p>
      <p>Groups as equivalent to their best members. One or more group members will
often know the right answer, and other group members might well become
convinced of this fact. For this reason groups might perform toward or at the level
of their best members. If some or many members suffer from ignorance, or from a
form of bias that leads to error, other group members might correct them.
Suppose, for example, that a panel of judges is trying to recall relevant Supreme
Court decisions in a somewhat specialized area. If one of the judges is actually
aware of those decisions, the group will be made aware of them too. Or suppose
that a group of military officials is attempting to assess the strengths and
weaknesses of a potential enemy in some part of the world. If one of them is a
specialist, all of them can learn what the specialist knows. Many deliberating
groups contain at least one expert on the question at hand; if group members listen
to the expert, they will do at least as well as she does. For these reasons,
deliberation might correct individual errors, rather than propagating them, in a
way that allows convergence on the judgment of the most accurate group
member.</p>
      <p>The whole as the sum of the parts: aggregating information. Deliberation could
aggregate existing information, in a way that leads the group as a whole to know
more than any individual member does. Suppose that the group contains no
experts on the question at issue, but that relevant information is dispersed among
group members, so that the group is potentially expert even if its members are not.
Or suppose that the group contains a number of experts, but that each member is
puzzled about how to solve a particular problem. Deliberation might elicit the
relevant information and allow the group to make a sensible judgment. Almost
everyone has had the experience of being a part of a group that ended up with a
solution that went beyond what any individual member could have produced on
her own. In this process, the whole is equal to the sum of the parts—and the sum
of the parts is what is sought.</p>
      <p>Beyond the sum of the parts: synergy. The give-and-take of group discussion
might sift information and perspectives in a way that leads the group to a good
solution to a problem, one in which the whole is actually more than the sum of
their parts. In such cases, deliberation is, at the very least, an ambitious form of
information aggregation, one in which the exchange of views leads to a creative
answer or solution. And in fact, groups sometimes do outperform their best
members.63
2. Variance, confidence, and legitimacy. To what extent do these mechanisms
work in practice? Two points are clear. First, deliberation usually reduces variance.64
After talking with together, group members tend to come into accord with one another.65
Statistical groups thus show far more diversity of opinion than deliberating groups.
Second, group members tend to become far more confident of their judgments after they
speak with one another. 66 A significant effect of group interactions is a greater sense that
one’s post-deliberation conclusion is correct—whether or not it actually is. Corroboration
by others increases confidence in one’s judgments.67 It follows that that members of
deliberating groups will usually converge on a position on which group members have a
great deal of confidence. This is not disturbing if that position is also likely to be
63 See Gigone and Hastie, supra note.
64 See Roger Brown, Social Psychology: The Second Edition 206-07 (1985).
65 Id.
66 See Chip Heath and Rich Gonzalez, Interaction With Others Increases Decision Confidence But Not
Decision Quality: Evidence against Information Collection Views of Interactive Decision Making, 61 Org
Behavior and Human Decision Processes 305 (1995).
67 See Robert Baron et al., Social Corroboration and Opinion Extremity, 32 J Experimental Soc. Psych. 537
(1996).
correct—but if it is not, then many group members will end up sharing a view in which
they firmly believe, but which turns out to be wrong (a most unfortunate and sometimes
quite dangerous situation68).</p>
      <p>If the purpose of deliberation is not to produce accurate outcomes, then it might
be especially important to know that deliberation ensures less variance and higher
confidence. Suppose that a key goal of deliberation is to promote a sense of legitimacy—
a belief, by group members, that they have been able to participate in the process and a
belief, by all concerned, that the decision is acceptable on its merits. Because deliberation
decreases variance and increases confidence in the outcome, it might be favored even if
produces errors. There are complex tradeoffs among the relevant variables here. If
deliberation significantly increases confidence and legitimacy, then it might be desirable
even if the decision is slightly worse—at least if little turns on slight differences in the
quality of the outcome. Perhaps what most matters is that group members accept the
decision, not that the decision be correct. On the other hand, an increase in legitimacy
might not be so important if the decision is leading the group into a serious blunder. For
many decisions, a key goal of deliberation is to improve choices. And if deliberation has
that effect while also increasing legitimacy, so much the better.</p>
      <p>3. Accuracy. Unfortunately, there is no systematic evidence that deliberating
groups will usually succeed in aggregating the information that their members have. With
respect to questions with definite answers, deliberating groups tend to do about as well as
or slightly better than their average member, but not as well as their best members.69
Hence it is false to say that group members usually end up deferring to their internal
specialists. Truth does not win out; the most that can be said is that under some
conditions, the group will converge on the truth if the truth begins with “at least some
initial support” within the group when the task has “a demonstrably correct answer
according to a broadly shared normative framework (e.g., deductive logic).”70 Note here
that when groups outperform most of their individual members, it is generally because
the issue is one on which a particular answer can be shown, to the satisfaction of all or
68 See Dominic Johnson, Overconfidence and War, supra note.
69 See Gigone and Hastie, supra note; Reid Hastie, Experimental Evidence of Group Accuracy, in
Information Pooling and Group Decision Making 129 (Bernard Grofman and Guillermo Owen et al. eds.
1983).
70 MacCoun, supra note (manuscript at 5).
orders rather than choosing their own prices, a small group of “marginal traders” trade
frequently and post limit orders.249 As we shall see, it is these traders who have the
greatest effect on prices.</p>
      <p>As a predictor, the Iowa Electronic Markets have produced extraordinarily
accurate judgments. Almost all of the time, they have done better than professional
polling organizations.250 In the week before the last four elections, the predictions in the
Iowa market have shown an average absolute error of just 1.5 percentage points, a
significant improvement over the 2.1 percentage point error in the final Gallop polls.251
The IEM have proved accurate not only on election eve but only in long forecasting
horizons, both in absolute terms and also when compared to alternative forecasting
systems.252 Nor are such markets limited to the United States. In other nations,
universities are operating similar markets; examples include the University of British
Columbia Election stock market, involving Canada,253 and Vienna University of
Technology, operating the Austrian Electronic Market.254 Although the relevant districts
are quite small, Australian bookmakers have shown a high degree of accuracy in
predicting district-level races.255</p>
      <p>3. Other information markets: Hollywood, weather, and beyond. Outside of the
political context, consider the Hollywood Stock Exchange, in which people predict Oscar
nominees and winners (as well as opening weekend box office successes). For the
Hollywood Stock Exchange, the level of accuracy has been impressive. “HSX offers
good predictions of a film’s gross receipts before release and, relatively speaking, even
better predictions after opening weekend - when a large number of traders have some
information in the form of (or at least the possibility of) observing the finished film on
screen, along with audience reactions. Apparently, studios have begun relying on these
estimates to structure the distribution of their films.”256 The market has proved at least
249 Id. at 99-100.
250 See Wolfers and Zitzewitz, supra note, at 112.
251 Id.
252 See Joyce Berg et al., Accuracy and Forecast Standard Error of Prediction Markets (July 2003 working
paper).
253 http://esm.ubc.ca/
254 http://ebweb.tuwien.ac.at/apsm/
255 Justin Wolfers and Andrew Leigh, Three Tools for Forecasting Federal Elections: Lessons from 2001,
37 Australian Journal of Political Science 223 (2002).
256 Levmore, supra note.
equal to expert panels in predicting Oscar winners, with (for example) correct predictions
of thirty-five of forty Oscar nominees in 2002.257</p>
      <p>The futures market for oranges does a better job predicting weather in Florida
than the National Weather Service.258 A large prediction market, producing a typical
event turnover in the hundreds of millions of dollars and run by the Deutsche Bank and
Goldman Sacks, involves the likelihood that economic data released later in the week will
show specific values259; the market performs at least as well as the consensus forecasts of
a survey of about fifty professional forecasters.260 Wagers at race tracks consistently
outperform horse-racing experts in predicting winners.261 Companies have started to use
internal prediction markets to answer relevant questions, including likely sales in specific
periods.262 The level of accuracy here is also high—far better, in fact, than what would
emerge from statistical means or deliberation, where excessive optimism can cause
serious problems.263</p>
      <p>For example, Hewlett Packard (HP) and the California Institute of Technology
initiated a project to study experimental markets as an information aggregation
mechanism involving product sales.264 The experimenters chose twelve people who
worked in different parts of HP’s business operation. Because of its small size, the market
was a very “thin” one, meaning that there were few participants and that the market was
far less liquid than the much “thicker” Iowa Electronic Markets. Participants were chosen
with the thought that each could contribute information from his department in buying
and selling the relevant futures, which were tied to sales and bonuses for executives
(which, in turn, are closely tied to profits). The markets were organized so that that
securities existed for intervals of sales. For example, one security would pay off if sales
were between one and ten printers; another would pay off if sales were between 10 and
20. In most of the experiments, the possible range of sales was divided into ten intervals
257 David Pennock et al., The Real Power of Artificial Markets, 291 Science 987 (2001).
258 R. Roll, Orange Juice and Weather, 74 Am. Econ. Rev. 861 (1984).
259 See www.economicderivatives.com
260 See Wolfers and Zitzewitz, supra note, at 114.
261 Id.
262 See Charles Plott, Markets as Information Gathering Tools, 67 Southern Economic J. 1 (2000).
263 Id.
264 K. Chen and C. Plott, Information Aggregation Mechanisms: Concept, Design, and Implementation for
a Sales Forecasting Problem; working paper; available online at
http://www.hpl.hp.com/personal/KayYut_Chen/paper/ms020408.pdf
of equal size. On the basis the prices of each security, the experimenters could guess how
many units HP would sell that month. Information markets were expected to have large
potential advantages over internal projections. Those involved in sales have an incentive
to understate projected outcomes, so as to ensure that they do not fall short of
expectations; this bias, or a competing bias in favor of excessive optimism, might well be
reduced through market incentives.</p>
      <p>The results showed that the
markets’ predictions
were a considerable
improvement over HP’s official forecasts. In no fewer six of the eight markets for which
official forecasts were available, the market prediction was significantly closer to the
actual outcome than the official forecast265—and this was despite “anecdotal evidence”
that the markets’ activities were included as inputs in generating the official forecast.266</p>
      <p>In fact information markets are springing up all over the Internet, allowing people
to make bets on the likely outcomes of sports, entertainment, finance, and political
events. In fact we can find actual or proposed prediction markets about any number of
questions: Will gas prices reach $3 per gallon? Will cellular life be found on Mars? Will
Osama Bin Laden be captured by a certain date? Will small pox return to the United
States?</p>
      <sec id="sec-8-1">
        <title>Will there be a sequel to</title>
      </sec>
      <sec id="sec-8-2">
        <title>Master and Commander?</title>
      </sec>
      <sec id="sec-8-3">
        <title>Will the Federal</title>
        <p>Communications Commission be abolished? These and other questions are being asked
on information markets. Consider the following list:</p>
      </sec>
      <sec id="sec-8-4">
        <title>Hollywood Stock Exchange— http://www.hsx.com</title>
        <p>Austrian Electronic Markets—http://ebweb.tuwien.ac.at/apsm/
University of British Columbia Election Stock Market--http://esm.ubc.ca/
Iowa Electronic Markets—http://www.biz.uiowa.edu/iem/
Foresight Exchange—http://www.ideosphere.com/fx/
Tradesports—http://www.tradesports.com
Centrebet-- http://www.centrebet.com/
News Futures—http://us.newsfutures.com/home/home.html
Probability Sports—http://www.probabilitysports.com
Economic Derivatives—http://www.economicderivatives.com
Wahlstreet—German political futures market;
http://tagesspiegel.wahlstreet.de/share/home/home.html
265 Id. at 12.
266 Id. at 5.
4. Aggregating information through markets. All in all, prediction markets have
been spectacularly successful in terms of the aggregate accuracy of the resulting “prices.”
Why is this? Note that they do not rely on the median or average judgment of a randomly
selected group of people. They are genuine markets. Those who participate are
selfselected. They must believe that they have relevant information; it is costly for them to
“vote,” and they ought not to be expected to do so unless they have something to gain.267
In addition, votes are not weighted equally. If people want to invest a few dollars, they
are permitted to do so, but they can invest a great deal more if they are confident of their
answer.268 Intensity of belief is captured in prices.269</p>
        <p>There is a further point. People are permitted to buy and sell shares on a
continuing basis. “Unlike polls or expert panels in which participants are asked for their
independent opinions, each trader in the market sees the net effects of the beliefs of all
other traders, and the time series changes in those beliefs. This makes the market more
than a static, one-time prediction but rather a dynamic system that can respond
instantaneously to the arrival of new information.”270 Moreover, a correct answer is
rewarded and an incorrect one is punished. Hence investors have a strong incentive to be
right. In these circumstances, accurate answers can emerge even if only a small
percentage of participants have good information. In the Iowa Electronic Markets, for
example, it turns out that 85% of the traders do not seem to be particularly wise.271 They
hold onto their shares for a long period and then simply accept someone else’s prices.
The predictions of the market are driven by the other 15%—frequent traders who post
their offers rather than accepting those made by other people. To work well, prediction
markets do not require accurate judgments by anything like the
majority of
267 Note that some markets involve real rather than virtual money. Newsfutures, for example, uses virtual
currency that can be redeemed for monthly prizes (such as appliances); Foresight Exchange and the
Hollywood Stock Exchange use “virtual currency,” so that people do not earn real money, but instead
attempt to enhance their reputation and their self-image. Note in this regard that Foreign Exchange lists
publicly the “top ten investors by score,” see http://www.ideosphere.com/fx/
268 Some markets, however, impose limits on permissible investments; the IEM is an example, with a
ceiling of $500. Note also that some markets, like the Hollywood Stock Exchange, do not involve real
dollars; it is noteworthy that successful predictions are found even in such markets.
269 See note supra.
270 Berg et al., supra note.
271 See id.
participants.272 In this sense, information markets are very different from the ordinary
judgments of deliberating groups. The resulting prices do not amplify or even perpetuate
cognitive errors; on the contrary, they correct them, because shrewd traders are able to
invest in a way that corrects for even widespread errors.273</p>
        <p>Of course information markets involve a measure of deliberation. Individual
investors are likely to have deliberated with others before they invest. In some such
markets, investors undoubtedly act as “teams,” pooling resources after deliberating
together about what to do. The point is that ultimate decisions come not from asking
group members to come up with a mutually agreeable conclusion, but by reference to the
price signal, which will have aggregated a great deal of diverse information. It is for this
reason that information markets outperform deliberative processes.</p>
        <p>How might institutions take advantage of information markets? It is possible to
imagine both internal and public varieties. An internal market would be limited to people
within the relevant organization. As we have seen, Hewlitt-Packard has used such a
market to predict sales, and the Department of Defense proposed an internal Policy
Analysis Market as part of its abandoned initiative on geopolitical events.274 An external
market would permit public investment by people outside of the institution for which
predictions are being made. In either case, the outcome of the market might well be more
accurate than the outcome of deliberation, in which errors might arise and be propagated
or even amplified as a result of discussion. (For companies, optimistic bias is an obvious
risk,275 one that information markets should reduce.) An organization might rely on an
internal market if it seeks to keep the results private or if it believes that an aggregation of
information held within the organization will be sufficiently accurate. One risk of an
internal market is that it might be too “thin,” simply because most institutions will have
272 The same is of course true of ordinary markets. For a good overview, see Andrei Shleifer, Inefficient
Markets (2000).
273 As noted below, this is not inevitable. We could easily imagine a market in which cognitive problems
are reflected in prices; indeed, this appears to happen with ordinary stock markets. See Robert Shiller,
Irrational Exuberance (2001). In information markets, it is entirely possible to imagine booms or crashes,
produced by cognitive errors in combination with social influences. My point is not that this is impossible,
but that the track record of information markets, at least thus far, is exceptionally good.
274 See note supra.
275 See Daniel Kahneman and Dan Lovallo, Timid Choices and Bold Forecasts: A Cognitive Perspective on
Risk Taking, in Choices, Values and Frames 393 (Daniel Kahneman and Amos Tversky eds. 2000). For an
application to group decisions, see Johnson, Overconfidence and War, supra note.
few investors276; another is that members of the organization might suffer from a
systematic bias. Alternatively, an institution might create a public market, available to all,
believing that through this route it will obtain more accurate results. In either case, an
organization might use an information market instead of group deliberation, or at the very
least as an input into such deliberation.</p>
      </sec>
    </sec>
    <sec id="sec-9">
      <title>B. Failed Predictions?</title>
      <p>In what circumstances might information markets fail? To answer this question,
ordinary stock markets are the place to start. A primary concern is that information
markets, no less than ordinary ones, can be susceptible to manipulation by powerful
speculators. The only known attempt to manipulate an information market occurred
during the 2000 presidential election. A group of speculators attempted to manipulate the
Iowa Electronic Market by buying large volumes of futures in presidential candidate
Patrick Buchanan. The value of Buchanan shares did increase dramatically, but they fell
almost immediately when “well-informed traders . . . seized the opportunity to profit off
the manipulative traders.”277 Hence the Iowa market remained stable despite this
attempted manipulation. Perhaps other, more plausible efforts at manipulation would
succeed; but none has thus far.</p>
      <p>Another concern is that some of the cognitive biases that afflict individuals will
manifest themselves in prediction markets. Just as in group deliberation, investors in a
market might be subject to predictable heuristics and biases. The results here are
unequivocal: they are. For example, psychologists have found that people overestimate
the likelihood that their preferred candidate will win an election—a form of optimistic
bias.278 At a certain point in the 1980 campaign, for example, 87% of Jimmy Carter’s
supporters believed that he would win, while 80% of Ronald Reagan’s supporters
276 Note, however, that Hewlitt-Packard produced good predictions even in a thin market. On the successes
of thin markets, see Levmore, supra note.
277 Klarreich, Best Guess, Science News (Oct 18, 2003); available online at
http://www.sciencenews.org/articles/20031018/bob9.asp.
278 For an overview, see Christine Jolls, Behavioral Economics Analysis of Redistributive Legal Rules, 51
Vand. L. Rev. 1653 (1998)
believed that their candidate would win.279 Obviously, at least one side had overestimated
its candidate’s probability of victory at the relevant time.</p>
      <p>In the market context, IEM traders show the same bias. In 1988, for example,
Dukakis supporters were more likely to hold futures in the Massachusetts governor’s
illfated presidential bid than were supporters of George H.W. Bush.280 More strikingly still,
Dukakis supporters were more likely to view the candidates’ debates as helpful to the
Democratic candidate and accordingly bought significant additional futures in his
campaign after each debate.281 Bush supporters precisely showed the same pattern.
Traders thus exhibited the “assimilation-contrast” effect.282 People usually assimilate new
information in a way that confirms their view of the world, and those who invest in
information markets show the same bias.</p>
      <p>Nonetheless, the Iowa Electronic Markets were more accurate than polls in predicting
the outcome of the 1988 presidential election. Even three weeks before the election, the
market provided an almost-perfect guess about the candidates’ shares of the vote.283 How
is such accuracy possible when many traders showed identifiable biases? The answer lies
in the behavior of a small group of “marginal traders” who were far less susceptible to
these biases—the “marginal trader” hypothesis. According to this hypothesis, a small
group of active traders who are far less susceptible to the relevant biases have a
disproportionately large effect on aggregate market behavior. In trading election futures,
these traders did not show the same biases as their fellow traders and earned significant
profits at the expense of their quasi-rational colleagues.284 Thus, the biased behavior of
most traders did not affect the market price because the marginal traders were prepared to
take advantage of their blunders. If marginal traders are active and able to profit from the
279 D. Granberg and E. Brent, When Prophesy Bends: The Preference-Expectation Link in U.S. Presidential
Elections, 45 Journal of Social and Personality Psychology 477.
280 Forsythe, Rietz, and Ross at 94.
281 Id.
282 M. Sherif and C. Hovland, Social Judgment: Assimilation and Contrast Effects in Communication and
Attitude Change (1962).
283 J. Berg, F. Nelson, and T. Rietz, Accuracy and Forecast Standard Error of Prediction Markets, Working
draft; available online at: http://www.biz.uiowa.edu/faculty/trietz/papers/forecasting.pdf
284 Forsythe, Rietz, and Ross at 100. The term “quasi-rational” comes from Richard Thaler, Quasi-Rational
Economics (1987).
bounded rationality of other participants, then there will be no effect on the aggregate
market price.285</p>
      <p>Another bias that might be expected to affect information markets is the
“favoritelongshot” bias often seen in horse races. In horse-racing, heavy favorites tend to give
higher returns than other horses in the field, while longshots tend to offer lower than
expected returns.286 If the point generalizes, prediction markets might not be accurate
with respect to highly improbable events. The market should be expected to overestimate
the likelihood that such events will come to fruition; for example, Pat Buchanan futures
would be expected to be (and might well have been) overpriced even before the
attempted manipulation of the market. By contrast, an information market might
underestimate the probability of events that are highly likely to occur.287 But with respect
to existing prediction markets, there is little evidence of systematic errors in this vein.</p>
      <p>“Prediction bubbles” are also easy to imagine, with investors moving in a certain
direction with the belief that many other investors are doing the same. A temporary
upsurge in investment in the nomination of Hillary Rodham Clinton as 2004 Democratic
nominee might well have been a small bubble, with some investors thinking, not that she
would in fact be the nominee, but that others would invest in that judgment, thus inflating
the value of the investment. Crashes are possible as well. In any case informational
influences can certainly lead individuals to make foolish investments in any market,
including prediction markets.288 As information markets develop, significant individual
errors should be expected, and undoubtedly they will produce some errors in the price
signal.289</p>
      <p>In particular contexts, the imaginable problems take a different form. Consider the
problem of “terrorism futures.” It would be extremely valuable to aggregate privately
held information about the risk and location of any attack. But do likely investors actually
285 Compare the discussion in Schleifer, supra note.
286 See Richard Thaler and William Ziemba, Anomalies: Parimutual Betting Markets: Racetracks and
Lotteries, 2 J Econ Persp 161 (1988); see also C. Manski, Interpreting the Predictions of Prediction
Markets, unpublished; available online at
http://faculty.econ.nwu.edu/faculty/manski/prediction_markets.pdf
287 C. Wolfers and E. Zitzewitz, Prediction Markets, preliminary draft; available online at
http://facultygsb.stanford.edu/wolfers/Papers/Predictionmarkets.pdf
288 See Robert Schiller, Irrational Exuberance (2001).
289 Cf. id. (discussing such errors in the stock market).
possible helpful information? Thomas Rietz, a director of the Iowa Electronic Markets,
argued that terrorism and world events were fundamentally different from other contexts
in which markets have successfully predicted future events.290
When betting on
presidential elections, people can use ordinary information sources, along with their
network of friends, family, and co-workers, to form an opinion; but for most investors,
there are no such sources of information for terrorist activity. Another skeptic worried
that the market would allow the wealthy to “hedge” against the possibility of terrorist
activity, while ordinary Americans would remain vulnerable to this threat.291 In this view,
“terrorism futures” could operate as an insurance market that would not serve its purpose
of providing information. In any event government use of the resulting information could
be self-defeating, at least if the information were made public. Terrorists would know the
anticipated time and location of attacks, and also know that the government was aware of
this—which would make it most unlikely that the prediction would turn out to be
accurate. Where the event’s occurrence is endogenous to the outcome of the information
market, there is reason for skepticism about its likely performance, certainly if relevant
actors have much to lose if the market turns out to be correct.292</p>
      <p>But many policy issues, including those potentially involved in the now-defunct
Policy Analysis Market, did not have this feature. Consider, for example, the question
whether the Egyptian economy is likely to grow in the next year, or whether Yassir
Arafat will lead the Palestinian Authority at the end of 2005. Perhaps many investors will
lack a great deal of information on such questions, but it is most unlikely that the market
prediction will turn out to be self-defeating. Of course the Policy Analysis Market itself
raises many questions and doubts. The broader point is that in many domains,
information markets are extremely promising, and likely to outperform both statistical
means and the products of group deliberation.</p>
      <p>Of course it will not always be feasible to use information markets. A jury, for
example, could not enlist such markets to decide on questions of guilt or innocence; and
it is not easy to see how information markets could be used by judges. When the relevant
290 C. Biever and D. Carrington, Pentagon cancels futures market on terror, New Scientist Online,
http://www.newscientist.com/news/news.jsp?id=ns99994007
291 J. Stiglitz, Terrorism: There’s No Futures in It, L.A. Times, July 31, 2003 at ??; available at
http://www.commondreams.org/views03/0731-08.htm
292 See Richard Posner, Catastrophe: Risk and Response (forthcoming 2004).
groups are small, effective markets may be impossible to create, simply because of the
absence of significant numbers of investors.293 On the other hand, administrative agencies
might well enlist such markets to resolve a number of questions,294 and ambitious efforts
are underway to examine how government might enlist them to answer an array of
disputed questions.295 Of course information markets might suffer from a legitimacy
deficit, at least at the present time. Recall that deliberation increases confidence and
decreases variance; in many contexts, reliance on information markets might well breed
confusion and distrust.296 But at a minimum, such markets should be used, where
feasible, as an adjunct to deliberative processes.</p>
      <p>Deliberating groups are often asked to answer questions that are not purely
issues. Should cost-benefit analysis be the foundation of regulatory decisions? Should the
minimum wage be increased? Should capital punishment be permitted? Can the President
be impeached for lying under oath? Should Roe v. Wade be overruled? Should the
Constitution be interpreted to require states to reconsider same-sex marriages? When, if
ever, is theft morally acceptable?</p>
      <p>When people answer such questions, informational influences and social
pressures are likely to play a major role. One study demonstrates group polarization with
respect to outrage: When individuals are outraged about corporate misconduct, juries are
systematically more outraged than their median member.297 And in fact group discussion
often produces polarization on normative issues,298 in a way that strongly suggests the
presence of hidden profiles. It is on normative questions, above all, the groups end up at a
293 Note, however, that “thin” markets have proved remarkably accurate, see Levmore, supra note, and that
some small groups might encourage outsider investors.
294 See Michael Abramowicz, Information Markets, Administrative Decisionmaking, and Predictive
CostBenefit Analysis, 71 U Chi L Rev 933 (2004)
295 See Robert Hahn and Paul Tetlock, Using Information Markets to Improve Policy (2004), available at
http://aei-brookings.org/publications/abstract.php?pid=816
296 Recall the reaction to the Policy Analysis Market, outlined above.
297 See David Schkade et al., Deliberating About Dollars: The Severity Shift, 100 Colum L Rev 1139
(2000).
298 See Roger Brown, Social Psychology: The Second Edition (1985); Cass R. Sunstein, Why Societies
Need Dissent (2003).
more extreme point in line with their predeliberation tendencies. I have noted that in
many domains, federal judges are subject to group polarization, with both Democratic
and Republican appointees showing a tendency to extremism when they are sitting with
like-minded others.299</p>
      <p>It might be controversial to suggest that groups amplify individual errors, because
in the normative domain, we might not be able to say, with confidence, that one or
another view counts as an “error.” Skeptics about morality and law, rejecting the view
that moral and legal questions have correct answers, would insist that any shifts
introduced by deliberation cannot be said to be right or wrong. But if they are correct,
does deliberation have any point300? In any case skepticism is extremely hard to defend
for law or morality. We may bracket the debate over whether legal problems have
uniquely correct answers in hard cases301 while also agreeing that on multiple and diverse
views about legal reasoning, some conclusions are right and others are wrong.302 If
deliberation is often likely to lead people to err on questions of fact, it will also lead
participants in law to blunder on questions of law. Suppose, for example, that the
question is whether a regulatory agency has violated the statute that it is charged with
administering, or whether a particular voting scheme violates the equal protection
doctrine, or whether the impossibility doctrine relieves a contracting party of the duty to
perform. In all of these cases, groups are likely to err if their deliberations are not
structured in such a way as to overcome the risks of amplification of errors, hidden
profiles, cascade effects, and group polarization.</p>
      <p>In the moral domain, skepticism also runs into serious problems.303 Without
engaging the complex philosophical issues, we can simply note that many different views
299 See Cass R. Sunstein et al., Ideological Voting on Federal Courts of Appeals: A Preliminary Analysis,
90 Virginia Law Review301 (2004).
300 A possible answer would stress the legitimating functions of deliberation, see pp. X above, but for
deliberation to work, and even to legitimate, deliberators must believe that they are trying to make progress
on a disputed question, not simply to legitimate it. An effort to justify deliberation purely on the ground
that it is legitimating will tend to be self-defeating for the participants.
301 See Ronald Dworkin, Is There Really No Right Answer In Hard Cases?, in Ronald Dworkin, A Matter
of Principle 119 (1985).
302 This proposition follows, for example, from views as diverse as those expressed in Antonin Scalia, A
Matter of Interpretation (1999); Ronald Dworkin, Law’s Empire (1986); and Cass R. Sunstein, Legal
Reasoning and Political Conflict (1996).
303 For various perspectives, see John Rawls, A Theory of Justice (1971) (discussing the search for
reflective equilibrium); Bernard Williams, Interlude: Relativism, in Morality: An Introduction to Ethics
1about the nature of morality acknowledge the possibility of individual error—and that if
individual error does occur, group error will occur as well. As obvious examples,
consider the persistence of slavery and racial segregation. As a less obvious example,
consider the fact that people’s answers to many questions depend on how those questions
are framed. The framing of options affects judgments not only on factual questions but on
moral ones as well, including for example the disputed issue of moral obligations to
members of future generations.304 As noted, groups do not show less susceptibility to
framing effects than individuals,305 and hence groups will be vulnerable to framing for
questions of morality and law as well as for questions of fact.</p>
      <p>No information market could be helpful in answering normative questions, simply
because there is no way to establish whether a particular investor was correct; for
normative questions, predictions are not being made at all.306 And for such questions, it
might seem odd or perhaps even bizarre to rely on the judgments of statistical groups. To
be sure, democratic processes might be seen as an effort to settle moral and political
issues by seeking the mean view within the relevant population (views that are formed
after deliberation, at least much of the time). But to say the least, it is controversial to
claim that ordinarily moral and political questions are best answered by simply finding
the mean views of a population-wide sample. Is the morality of abortion, or capital
punishment, properly settled by asking for the average view of a group of, say, 1000
people? Is a legal question to be resolved by taking the median view of a large set of
people trained in the law? Ordinarily moral and legal answers are found by reference to
the reasons offered on behalf of competing positions, not by taking a poll.</p>
      <p>Note, however, that empirical questions are often a central component of good
answers to normative problems; many such problems cannot be resolved without
knowing something about the facts. The analysis of mistakes by deliberating groups
should apply in full force to the factual components of normative questions. Consider, for
example, the suggestion that the minimum wage should be increased. If minimum wage
37 (1972); David Brink, Moral Realism and the Foundations of Ethics (1989); Gilbert Harmon and Judith
Jarvis Thompson, Moral Relativism and Moral Objectivity (1996).
304 See Cass R. Sunstein, Moral Heuristics and Moral Framing, 88 Minn L Rev 1556 (2004).
305 See Kerr et al., supra note.
306 It might be tempting to say that the moral views of posterity provide the relevant test, but then the bet
would be on the moral views of posterity, not on what morality requires.
increases would significantly decrease employment, surely that is relevant to the decision
whether to support such increases; and it matters too whether minimum wage increases
would benefit poor people or mostly people who are not poor.307 To be sure, these are
empirical questions on which experts are almost certainly far better than deliberating
groups of ordinary people. The point is only that many normative questions cannot
sensibly be resolved without information about the actual effects of one or another
answer. When this is so, an understanding of the hazards of deliberation, and of how to
minimize those hazards, can be used constructively by groups that are attempting to
resolve normative questions.</p>
      <p>Of course consequences may not be the central part of some normative disputes.
Some people believe, for example, that capital punishment is morally unacceptable even
if it has a strong effect in deterring murders, and evaluative judgments of various kinds
can separate people even if they agree on the facts.308 But the more general point
nonetheless holds: Sometimes a certain view of the facts can bring diverse people into
line on normative issues, producing a single position despite disagreements on those
issues. To this extent, the analysis here applies to normative questions as well. Group
judgments on such questions will be distorted by the amplification of errors, hidden
profiles, cascade effects, and polarization. It is important to take steps, of the kind that I
have catalogued, to reduce those distortions.</p>
      <p>What about for purely normative issues, lacking any factual component? Here the
argument on behalf of group deliberation is not fundamentally different from what it is
elsewhere.309 Unless we are relativists or skeptics, we will agree that one point of
deliberation is to ensure that normative questions are correctly answered, that is, are
answered by reference to good reasons, even if we disagree about what they are. And if
this is so, then there is strong reason to be concerned, for normative questions no less
than empirical ones, that group judgments will be impaired by the mechanisms traced
here. The structural reforms have an equivalent role in the normative domain. We may
therefore take the simple cases I have emphasized, in which deliberation leads to palpable
307 For evidence, see Daniel Shaviro, The Minimum Wage, the Earned Income Tax Credit, and Optimal
Subsidy Policy, 64 U. Chi. L. Rev. 405, 450-51 (1997).
308 See Dan Kahan and Donald Braman, More Statistics, Less Persuasion: A Cultural Theory of Gun Risk
Perceptions, 151 U. Pa. L. Rev. 1052 (2003).
309 See Amy Gutmann and Dennis Thompson, Democracy and Disagreement (1999),
and demonstrable errors, to provide clear evidence of deliberative pathologies that are
likely to occur even when errors are neither palpable nor demonstrable. If a central goal is
to ensure that normative questions—in law, politics, and morality—are answered well,
then the prescriptions I have outlined deserve a place for numerous deliberating groups,
including those not centrally concerned with facts at all.</p>
    </sec>
    <sec id="sec-10">
      <title>Conclusion</title>
      <p>Groups often contain a great deal of information, and an important task is to elicit
and use the information that members actually have. Deliberation is generally thought to
be the best way of carrying out that task. But deliberative bodies are subject to serious
problems. Much of the time, informational influences and social pressures lead members
not to say what they know. As a result, groups tend to propagate and even to amplify
cognitive errors. They also emphasize shared information at the expense of unshared
information; hidden profiles are a result. Cascade effects and group polarization are
common.</p>
      <p>What can be done by way of response? At the very least, it should be possible to
structure deliberation so as to increase the likelihood that relevant information will
emerge. A norm in favor of critical thinking, and incentives to reward individuals for
good decisions by groups, can overcome some of the relevant pressures. Leaders should
take steps to encourage a wide range of views; to do this, leaders might be cautious about
expressing their own views at the outset and encourage reasons, rather than conclusions,
before the views of group members start to harden. Institutions might ensure anonymity
and private polling before deliberation; they might permit anonymous statements of final
conclusions; they might create strong incentives, economic and otherwise, to encourage
people to disclose what they know.</p>
      <p>Information markets have significant advantages over deliberative processes, and
in many contexts they might supplement or even replace those processes. Such markets
tend to correct rather than to amplify individual errors, above all because they allow
shrewd investors to take advantage of the mistakes made by others.310 Because
310 Note that this is an empirical claim, not a conceptual one. It is certainly possible for markets to
propagate individual errors. See Shiller, supra note.
information markets provide economic rewards for correct individual answers, they
realign incentives in a way that promotes disclosure. As a result, they are often more
accurate than the judgments of deliberating groups. To the extent feasible, many groups
would often do well to enlist information markets in arriving at their judgments, above all
because of the accuracy of the price signal.</p>
      <p>My emphasis throughout has been on the aggregation of information and the risk
that deliberating groups will err on instrumental questions and on issues of fact. But the
same risks arise in the normative domain, where informational influences and social
pressures also produce forms of self-silencing that are highly damaging to good
deliberation. In that domain as elsewhere, incentives make all the difference;
wellfunctioning groups take steps to ensure that on normative questions as on factual ones,
people feel free to disclose what they believe to be true.</p>
      <p>Readers with comments should address them to:
10.
216.
217.
218.</p>
    </sec>
  </body>
  <back>
    <ref-list/>
  </back>
</article>