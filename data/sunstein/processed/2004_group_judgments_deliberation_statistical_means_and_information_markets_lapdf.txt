Follow this and additional works at: https://chicagounbound.uchicago.edu/law_and_economics Part of the Law Commons
University of Chicago Law School
Coase-Sandor Working Paper Series in Law and Economics
Cass R. Sunstein
Coase-Sandor Institute for Law and Economics
JOHN M. OLIN LAW & ECONOMICS WORKING PAPER NO. 219
(2D SERIES)
Cass R. Sunstein
THE LAW SCHOOL THE UNIVERSITY OF CHICAGO
Group Judgments: Deliberation, Statistical Means, and Information Markets
Cass R. Sunstein*
How can groups elicit and aggregate the information held by their individual members? There are three possibilities. Groups might use the statistical mean of individual judgments they might encourage deliberation or they might use information markets. In both private and public institutions, deliberation is the standard way of proceeding but for two reasons, deliberating groups often fail to make good decisions. First, the statements and acts of some group members convey relevant information, and that information often leads other people not to disclose what they know. Second, social pressures, imposed by some group members, often lead other group members to silence themselves because of fear of disapproval and associated harms. As a result, deliberation often produces a series of unfortunate results: the amplification of errors, hidden profiles, cascade effects, and group polarization. A variety of steps should be taken to ensure that deliberating groups obtain the information held by their members restructuring private incentives, in a way that increases disclosure, is the place to start. Information markets have substantial advantages over group deliberation such markets count among the most intriguing institutional innovations of the last quarter-century and should be used far more than they now are. One advantage of information markets is that they tend to correct, rather than to amplify, the effects of individual errors. Another advantage is that they create powerful incentives to disclose, rather than to conceal, privately held information. Information markets thus provide the basis for a Hayekian critique of many current celebrations of political deliberation. They also provide a valuable heuristic for understanding how to make deliberation work better. These points bear on discussion of normative issues, in which deliberation might also fail to improve group thinking, and in which identifiable reforms could produce better outcomes. Applications include the behavior of juries, multimember judicial panels, administrative agencies, and congressional committees analogies, also involving information aggregation, include open source software, Internet ?wikis,? and weblogs.
Preliminary draft 9/30/04 All rights reserved
How can groups obtain the information that their members have? There are three principal answers. First, groups might use the statistical mean (or median) of the independent judgments of their members. Second, groups might ensure deliberation, asking for the reasoned exchange of facts, ideas, and opinions. Third, groups might use information markets, through which group members, or those outside of the group, ?bet? on their judgments about future events. Of course each of these methods can take diverse forms one of my principal goals here is to explore which forms are most likely to produce good outcomes. The choice bears on the performance of many institutions involved in law and politics, including juries, administrative agencies, congressional committees, federal courts of appeals, and even the Supreme Court itself.
Both private and public institutions usually prefer to make decisions through deliberation. Generalizing from this fact, many people have paid a great deal of attention to deliberative accounts of democracy itself. The theoretical foundations of deliberative
democracy have been elaborated in some detail,4 and increasing attention is being devoted to methods for making democratic processes more deliberative. James Fishkin, for example, has pioneered the idea of the ?deliberative opinion poll,? by which people are asked to deliberate together on public issues and to state their judgments only after the deliberative process.5 Fishkin and Bruce Ackerman have gone so far as to suggest a new national holiday, Deliberation Day, in which people are asked to congregate in groups in order to discuss and debate important issues of public policy.6 Perhaps the proposal is unrealistic perhaps citizens as a whole should not be expected to deliberate much in a liberal society.7 But even if this is true, leaders in the public and private sphere might be urged to deliberate more than they now do, and many accounts of deliberative democracy emphasis the importance of deliberation by representatives.8
Why, exactly, is deliberation important or even desirable? A central answer must be that deliberation will result in wiser judgments and better outcomes.9 But does deliberation actually have this effect? The answer is by no means clear.10 Group members may impose pressures on one another, leading to a consensus on falsehood rather than truth. The idea of ?groupthink,? coined and elaborated by Irving Janis, suggests the possibility that groups will tend toward uniformity and censorship, thus failing to combine information and enlarge the range of arguments.11 Without structural protections, both private and public groups are likely to err, not in spite of deliberation
but because of it. The use of statistical means, or of information markets, will often lead to more accurate decisions.
As an example of a failure of deliberation, consider the account in the 2004 report of the Senate Select Committee on Intelligence, which explicitly accused the Central Intelligence Agency (CIA) of groupthink, in which the agency?s predisposition to find a serious threat from Iraq led it to fail to explore alternative possibilities or to obtain and use the information that it actually held.12 In the Committee?s view, the CIA ?demonstrated several aspects of group think: examining few alternatives, selective gathering of information, pressure to conform within the group or withhold criticism, and collective rationalization.?13 Thus the agency showed a ?tendency to reject information that contradicted the presumption? that Iraq had weapons of mass destruction.14 Because of that presumption, the agency failed to use its own formalized methods ?to challenge assumptions and ?group think,? such as ?red teams,? ?devil?s advocacy,? and other types of alternative or competitive analysis.?15 Above all, the Committee?s conclusions emphasize the CIA?s failure to elicit and aggregate information.
This claim is a remarkable and even uncanny echo of one that followed the 2003 investigation of failures at NASA, stressing that agency?s similar failure to elicit competing views, including those based on information held by agency employees.16 The Columbia Accident Investigation Board explicitly attributed the accident to NASA?s unfortunate culture, one that does too little to elicit information. In the Board?s words, NASA lacks ?checks and balances.?17 It pressures people to follow a ?party line.?18 At NASA, ?it is difficult for minority and dissenting opinions to percolate up through the agency?s hierarchy?19?even though, the Board contended, effective safety programs require the encouragement of minority opinions and bad news.
As we shall see, statistical means sometimes do at least as well as deliberation. Information markets, which count among the most intriguing institutional innovations of the last quarter-century, often do far better. To explain why deliberation fails, I explore the consequences of two sets of influences on members of deliberating groups.20 The first consists of informational influences, by which group members fail to disclose what they know because of deference to the information publicly announced by others. The second involves social pressures, which lead people to silence themselves in order not to face reputational sanctions, such as the disapproval of relevant others. As a result of these problems, groups often do not correct but instead amplify individual errors emphasize shared information at the expense of unshared information fall victim to cascade effects and tend to end up in a more extreme position in line with the predeliberation tendencies of their members.21 Even federal judges are vulnerable to the relevant pressures, as both Republican and Democratic appointees show especially ideological voting when they are sitting with other judges appointed by presidents of the same political party.22 Statistical groups and information markets are far less susceptible to the pressures that make deliberating groups err.
Because of those pressures, deliberative processes often fail to achieve their minimal goal of aggregating the information that the relevant deliberators actually have. Indeed, such processes often fail to aggregate information even as they decrease variance, and increase confidence, among their members.23 A confident, cohesive, error-prone group is nothing to celebrate on the contrary, it might be extremely dangerous both to itself and to others.24 As we shall see, information markets often outperform both statistical and deliberating groups, simply because they are so effective at pooling
information. Indeed, information markets realign private incentives in a way that makes them exceptionally well-designed to reduce the problems that infect deliberating groups. Such markets are worth investigating in part because they provide an illuminating route by which to explore some characteristic defects in deliberative processes. If such processes are to be improved, it might well be by building on the insights provided by the large successes of information markets. In addition, such markets are worth investigating in their own right, if only because they promise to provide a supplement to deliberation, one that should improve social decisions.25 My goal, in short, is to mend deliberative processes, not to end them. As we shall see, both social norms and institutional design can go a long way toward reducing the problems that lead to deliberative blunders.
To keep the analysis simple, my principal focus is not on controversial judgments of value but on questions with demonstrably correct answers. An understanding of how deliberation finds, and fails to find, those answers should have implications for its potential and limitations with respect to normative questions as well. If, for example, deliberation often fails in producing good answers to simple questions of fact, then it is also likely to fail to produce good answers to disputed issues of value. The solution to many such questions depends at least in part on resolution of factual issues it is difficult to take a stand on proposals to raise the minimum wage, to engage in preemptive war, or to overrule Roe v. Wade26 without resolving several issues of fact. And even when factual issues are not central, deliberation can, in principle, ensure more sensible judgments.27 Unfortunately, however, the problems posed by informational pressure and social influences apply in normative domains as well as elsewhere. I will therefore offer some suggestions for how groups can reduce those problems through structural reforms.
This Article comes in six parts. Part II explores a nondeliberative method for aggregating privately-held information, one that simply takes the average of predeliberation judgments. The resulting judgments of these ?statistical groups? are sometimes remarkably accurate, and they provide a useful benchmark for assessing
deliberative judgments.28 An understanding of the judgments of statistical groups also provides several clues about the usefulness and limitations of relying on the judgments of groups in general. Part III explores the effects of informational pressures and social influences, with an emphasis on amplification of errors, hidden profiles, cascade effects, and group polarization. Part III also attempts to square some apparently conflicting evidence about the performance of deliberating groups it investigates the possibility that some groups will do as well as or even better than their best members.
Part IV investigates structural reforms that are intended to ensure that group members reveal what they know?for example, by requiring anonymous statements of beliefs before deliberation begins, by assigning specified roles to participants in deliberation, and by structuring incentives to produce disclosure of privately held information. Part V identifies and compares information markets, in which people bet on the outcomes of events. Information markets have performed remarkably well in many diverse domains. Because they restructure people?s incentives, overcome a collective action problem faced by individual group members, and allow informed traders to play a large role in setting ?prices,? they have advantages over both statistical judgments and deliberative judgments. They might well be used as a supplement to or even a replacement for collective deliberation. Part VI briefly discusses how the analysis might apply to normative questions.
Suppose that there is a question about some disputed issue of fact. How many home runs did Hank Aaron hit? When was Calvin Coolidge elected president? Will a district court decision be reversed on appeal? Does a foreign country pose a serious threat to national security? Is the United States likely to have difficulty in winning a particular war? A great deal of evidence suggests that under certain conditions, a promising way to answer such questions is this: Ask a large number of people and take the mean answer.29 When the relevant conditions are met, the mean answer, which we might describe as the
group?s ?statistical answer,?30 is often accurate, where accuracy is measured by reference to objectively demonstrable fact.
It is well-known that statistical answers from groups of sufficiently large sizes tend to match the views of population-wide samples.31 This finding bears on issues as diverse as the use of juries as a measure of community sentiment32 and the remarkable success of Google, the search engine Google is good at finding what a particular searcher wants because it knows what most searchers want.33 But here the question is what is true, not what populations think. Let us therefore explore how statistical groups perform, partly because the answer is important and illuminating itself, and partly because it provides a useful foundation for the assessment of both deliberating groups and information markets.
Many of the studies of statistical groups involve quantitative estimates. Consider a few examples:
1. In an early study, Hazel Knight asked college students to estimate the temperature
of a classroom.34 Individual judgments ranged from 60 degrees to eighty-five
degrees the statistical judgment of the group was 72.4 degrees, very close to the
actual temperature of 72 degrees. That judgment was better than that of 80% of
individual judgments.
2. Judging the numbers of beans in the jar, the group average is almost always better
than that of the vast majority of individual members. In one such experiment, a
group of fifty-six students was asked about a jar containing 850 beans the group
estimate was 871, a better guess than all but one of students.35
3. Asking two hundred students to rank items by weight, one experimenter found that the group?s estimate was 94 percent accurate?a figure excelled by only five individuals.36 4. Asked to rank ten piles of buckshot, each only slightly different in size from the
others, the group?s guess was 94.5% accurate, far more so than that of almost all
group members.37 5. The British scientist Francis Galton sought to draw lessons about collective
intelligence by examining a competition in which contestants attempted to judge
the weight of a fat ox at a regional fair in England. The ox weighed 1,198 pounds
the average guess, from the 797 contestants, was 1,197 pounds.38
If these findings can be generalized, many questions might plausibly be answered not deliberatively, but simply by asking a large group of people and selecting the average response. Imagine that a large company is attempting to project its sales for the following year. Might it do best to poll its salespeople and to choose the average number on the assumption that it is likely to be correct39? Or suppose that a company is deciding whether to hire a new employee. Should it ask relevant personnel, not to deliberate, but about their individual views on whether the employee?s performance is likely to meet a certain level? Or turn to the legal context and suppose that the question is whether a case should be settled. Ought a law firm to poll its lawyers about the expected outcome at trial? Or consider the political domain and suppose that the question is whether a war effort will go well by some identifiable standard. Should the President poll his advisers and take the median answer? To answer these questions, we have to know why, in the relevant studies, the median judgment is so accurate.
B. The Condorcet Jury Theorem
The accuracy of judgments of statistical groups is best explained by reference to the Condorcet Jury Theorem.40 To see how the Jury Theorem works, suppose that people are answering a common question with two possible answers, one false and one true, and that the average probability that each voter will answer correctly exceeds 50 percent. The Jury Theorem holds that the probability of a correct answer, by a majority of the group, increases toward certainty as the size of the group increases.41 The importance of the Jury Theorem lies in the demonstration that groups are likely to do better than individuals, and large groups better than small ones, if majority rule is used and if each person is more likely than not to be correct. The last proviso is extremely important. Suppose that each individual in a group is more likely to be wrong than right. If so, the likelihood that the group will decide correctly falls to zero as the size of the group increases.
In the context of statistical judgments, several of Condorcet?s stringent and somewhat unrealistic assumptions are met. Indeed, the likelihood that they will be met is higher with statistical groups than with deliberating ones. Condorcet assumed that people would be unaffected by whether their votes would be decisive42 that people would not be affected by one another?s votes and that the probability that one group member would be right would be statistically unrelated to the probability that another group member would be right.43 The first two assumptions plainly hold for statistical groups. People do not know what others are saying and hence they cannot be influenced by a belief that their judgments will make the difference to that of the group. The third assumption may or may not be violated. Those who have similar training, or who work closely together, will be likely to see things in the same way,44 and those involved in statistical groups might
well meet these conditions. On the other hand, the Condorcet Jury Theorem has been shown to be robust to violations of this third assumption.45
To see why statistical groups perform well, consider the problems just described and note that even if everyone in the group is not more than 50% likely to be right, the Theorem?s predictions may well continue to hold. Suppose, for example, that 60% of people are 51% likely to be right and that 40% of people are 50% likely to be right or that 45% of people are 40% likely to be right and that 55% of people are 65% likely to be right or even that 51% of people are 51% likely to be right and that 49% of people are merely 50% likely to be right. Even under these conditions, the likelihood of a correct answer will move toward 100% as the size of the group increases. It will not move as quickly as it would if every group member were highly likely to be right, but it will nonetheless move. We could imagine endless variations on these numbers. The point is that even if a significant percentage of the group is not more likely to be right than wrong, or even if many group members are more likely to be wrong than right, an accurate result, from a sufficiently large group, can be expected.
Of course most of the relevant judgments, in studies of statistical groups, do not involve a binary choice consider the question how many beans are in a jar, how many pounds a given object weighs, or how well a certain product will sell in the following year. But the answers to such questions are not analytically different from those in binary choices. In answering the relevant questions, each person is effectively being asked to answer a long series of binary questions?ten beans or a thousand beans, twenty beans or five hundred beans, fifty beans or one hundred beans, and so on. If a sufficiently large group is asked to answer such questions, and if most individual answers will be better than random, the mean answer will be highly accurate. Of course the combination of probabilities, for a series of binary results, might mean that things will turn out poorly. If someone is 51% likely to answer each of two questions correctly, the probability that she will answer both questions correctly is only slightly higher than 25%. But with large groups, enough people are likely to make better-than-random guesses, on the questions
involved in certain quantitative judgments, that the average estimate will have a high degree of accuracy.46
But compare a situation in which if only 49% of the group is likely to be better than random. If so, the likelihood of a mistake will move toward 100% under the same condition. But for the number of beans in a jar, or the weight of an ox, most people are not wholly at sea. The accuracy of the median judgment, for large groups, is simply an application of the Condorcet Jury Theorem. And in certain circumstances, deliberating groups will act in roughly the same way, aggregating their information to produce remarkably accurate results.47
In this light, we can identify two situations in which the judgment of a statistical group will be incorrect. The first are those in which group members show a systematic bias. The second are those in which their answers are worse than random. The failures of statistical judgments, in these circumstances, have strong implications for deliberation as well.
1. Bias. A systematic bias in one or another direction will create serious problems for the group?s answers. If, for example, an experimenter ?anchors? subjects on a misleading number, the median will almost certainly be wrong. Suppose, for example, that a jar contains 800 jelly beans, and the experimenter happens to say, quietly, ?many jars of jelly beans, though not necessarily this one, have 500 jelly beans,? or even, ?I?m asking this question to 250 people.?48 In either case, the low number will likely operate as an anchor,49 and people?s answers will be systematically biased toward understating the actual number, producing an unreliable mean. One study demonstrates more generally
that a group?s statistical estimate is likely to be erroneous ?when the material is unfamiliar, distorted in a way such that all individuals are prone to make similar errors of estimation.?50 The error-producing effects of anchors are simply a special case of this general point. Anchors are undoubtedly at work in deliberating groups as well, although in theory deliberation might reduce their effects. And anchors have significant effects within the legal system. For example, the plaintiff?s demand is likely to affect damage awards for harms that are difficult to monetize, and groups are no less subject to those effects than individuals.51 Even judges have been found to be subject to irrelevant anchors,52 and there is every reason to believe that multimember courts would be at least as vulnerable to them as individual judges are.53
2. Random or worse. Suppose that people are asked not about the number of jelly beans in a jar, but about the number of atoms in a jelly bean. On that question, people?s answers are hopelessly ill-informed, and there is no reason at all to trust their judgments. Consider a small-scale study at the University of Chicago Law School, one that strongly supports this conclusion. A number of faculty members were asked the weight, in pounds, of the fuel that powers space shuttles. The actual answer is 4 million pounds. The median response was 200,000 the mean was 55,790,555 (because of one outlier choice)?both wildly inaccurate. In a binary choice, of course, people?s answers will be worse than random only if they are unaware of how little they know if they know that they are likely to be wrong, they should choose randomly, which gives them a 50% probability of being right. But sometimes people think they know more than they do, and many tasks do not involve binary choices at all. Statistical groups will err if confusion and ignorance are so widespread that individual?s answers are worse than random. Here too there are evident applications to many contexts in law and politics.
D. Statistical Answers and Experts
Should statistical means be used more than they now are? Do statistical means outperform experts? Everything depends on the competence of the experts. If we could find real experts on the weight of oxen or on how to count jelly beans, and if we understand expertise to be the ability to make accurate assessments, then experts would by stipulation do better than statistical means. Suppose, for example, that a deliberating group of lawyers is trying to decide how many Supreme Court decisions have invalidated a state or federal law, or the number of lines in Antigone, or the weight of the most recent winner of the Kentucky Derby. Would it make any sense to poll the lawyers individually and to assume that the mean response is accurate? The studies outlined above suggest that if the group is large enough, the mean answer will be at least good.54 But there are many ways to do far better.
For many factual questions, of course, a little research would be sufficient to identify the correct answers. But for some factual issues, even significant research is inconclusive, and it is best to consult experts. And if experts are available, it would make sense to obtain a statistical answer from them, rather than to select one or a few. If experts are likely to be right, a statistical group of experts should have the same advantage over individual experts as a statistical group of ordinary people has over ordinary individuals. In fact a great deal of evidence supports this claim.55 In a series of thirty comparisons, statistical groups of experts had 12.5% fewer errors on forecasting tasks involving such diverse issues as company earnings, cattle and chicken prices, real and nominal GNP, survival of patients, and housing starts.56 For example, statistical groups of experts significantly outperformed individual experts in predicting the annual earnings of firms changes in the American economy and annual peek rainfall runoff in eight different countries.57 The implication is straightforward: ?Organizations often call on the best expert they can find to make important forecasts. They should avoid this
practice, and instead combine forecasts from a number of experts.?58 For political polling, it has become standard practice to combine a set of poll results and to rely on the mean or median, rather than to select one or two.59
Consider in this regard the Copenhagen Consensus, designed to inform policy judgments about global risks.60 The Copenhagen Consensus was obtained for a series of possible interventions, involving climate change, water and sanitation, hunger and malnutrition, free trade, and communicable diseases, among others. A number of experts were asked about the best way to promote global welfare, and particularly the welfare of developing countries, assuming that $50 billion were made available. The experts ranked the possible projects, producing an overall ranking (reflecting the mean rankings of the experts taken as a whole).61 I do not mean to suggest that the results of this particular exercise are correct everything depends on whether the relevant experts were in a position to offer reliable answers on the questions at hand. But if statistical means are a good way to aggregate knowledge when ordinary people know something of relevance, then they are also a good way to aggregate knowledge from experts.
III. Deliberating Groups
Although the judgments of statistical groups can be quite accurate, it is easy to imagine that a deliberating group would be much better. In principle, a deliberating group should do well even when its members are error-prone. Deliberation, in the form of an exchange of information and reasons, might well bring them into line. If many group members give answers that are worse than random, perhaps other group members can show them how they have erred. If individuals have been manipulated in their private judgments, perhaps deliberation will undo the effects of the manipulation.62 If individual members have anchored on a misleading value, perhaps deliberation will expose the anchor as such.
To make the analysis tractable, let us focus on how deliberating groups might be able to solve factual questions or cognitive puzzles that have correct solutions. The latter are often questions of instrumental rationality, posing a question about the right strategy for achieving agreed-upon goals. Results in these domains provide a good test of when and whether deliberating groups perform well. To the extent that such groups do badly in answering questions with objectively correct answers, we have reason to suspect that they will also do badly in answering questions for which there is no consensus on truth or validity.
A. Mechanisms and Realities
1. Possibilities. If groups perform better than their average member, we can imagine three principal mechanisms by which the improvement occurs.
 Groups as equivalent to their best members. One or more group members will
often know the right answer, and other group members might well become
convinced of this fact. For this reason groups might perform toward or at the level
of their best members. If some or many members suffer from ignorance, or from a
form of bias that leads to error, other group members might correct them.
Suppose, for example, that a panel of judges is trying to recall relevant Supreme
Court decisions in a somewhat specialized area. If one of the judges is actually
aware of those decisions, the group will be made aware of them too. Or suppose
that a group of military officials is attempting to assess the strengths and
weaknesses of a potential enemy in some part of the world. If one of them is a
specialist, all of them can learn what the specialist knows. Many deliberating
groups contain at least one expert on the question at hand if group members listen
to the expert, they will do at least as well as she does. For these reasons,
deliberation might correct individual errors, rather than propagating them, in a
way that allows convergence on the judgment of the most accurate group
member.
 The whole as the sum of the parts: aggregating information. Deliberation could
aggregate existing information, in a way that leads the group as a whole to know
more than any individual member does. Suppose that the group contains no
experts on the question at issue, but that relevant information is dispersed among group members, so that the group is potentially expert even if its members are not. Or suppose that the group contains a number of experts, but that each member is puzzled about how to solve a particular problem. Deliberation might elicit the relevant information and allow the group to make a sensible judgment. Almost everyone has had the experience of being a part of a group that ended up with a solution that went beyond what any individual member could have produced on her own. In this process, the whole is equal to the sum of the parts?and the sum of the parts is what is sought.  Beyond the sum of the parts: synergy. The give-and-take of group discussion
might sift information and perspectives in a way that leads the group to a good
solution to a problem, one in which the whole is actually more than the sum of
their parts. In such cases, deliberation is, at the very least, an ambitious form of
information aggregation, one in which the exchange of views leads to a creative
answer or solution. And in fact, groups sometimes do outperform their best
members.63
2. Variance, confidence, and legitimacy. To what extent do these mechanisms work in practice? Two points are clear. First, deliberation usually reduces variance.64 After talking with together, group members tend to come into accord with one another.65 Statistical groups thus show far more diversity of opinion than deliberating groups. Second, group members tend to become far more confident of their judgments after they speak with one another. A significant effect of group interactions is a greater sense that one?s post-deliberation conclusion is correct?whether or not it actually is. Corroboration by others increases confidence in one?s judgments.67 It follows that that members of deliberating groups will usually converge on a position on which group members have a great deal of confidence. This is not disturbing if that position is also likely to be
correct?but if it is not, then many group members will end up sharing a view in which they firmly believe, but which turns out to be wrong (a most unfortunate and sometimes quite dangerous situation68).
If the purpose of deliberation is not to produce accurate outcomes, then it might be especially important to know that deliberation ensures less variance and higher confidence. Suppose that a key goal of deliberation is to promote a sense of legitimacy? a belief, by group members, that they have been able to participate in the process and a belief, by all concerned, that the decision is acceptable on its merits. Because deliberation decreases variance and increases confidence in the outcome, it might be favored even if produces errors. There are complex tradeoffs among the relevant variables here. If deliberation significantly increases confidence and legitimacy, then it might be desirable even if the decision is slightly worse?at least if little turns on slight differences in the quality of the outcome. Perhaps what most matters is that group members accept the decision, not that the decision be correct. On the other hand, an increase in legitimacy might not be so important if the decision is leading the group into a serious blunder. For many decisions, a key goal of deliberation is to improve choices. And if deliberation has that effect while also increasing legitimacy, so much the better.
3. Accuracy. Unfortunately, there is no systematic evidence that deliberating groups will usually succeed in aggregating the information that their members have. With respect to questions with definite answers, deliberating groups tend to do about as well as or slightly better than their average member, but not as well as their best members.69 Hence it is false to say that group members usually end up deferring to their internal specialists. Truth does not win out the most that can be said is that under some conditions, the group will converge on the truth if the truth begins with ?at least some initial support? within the group when the task has ?a demonstrably correct answer according to a broadly shared normative framework (e.g., deductive logic).?70 Note here that when groups outperform most of their individual members, it is generally because the issue is one on which a particular answer can be shown, to the satisfaction of all or
most, to be right and that even in that condition, the group might not do well if the demonstrably correct solution lacks significant support at the outset.71
No significant differences are found between deliberating groups and average individual performances in numerical estimates, such as assessment of the number of beans in a jar or the length of lines.72 One study finds that when asked to estimate the populations of American cities, groups did as well as their most accurate individual member73 but this is an atypical result.74 Another study attempted to test whether deliberating groups were particularly good at telling whether people were telling the truth of instead lying.75 The individual votes, predeliberation, were 48 percent correct, about the same as the post-deliberation judgments. Approximately the same number of people shifted toward error as toward correct answers.
In general, simple majority schemes do fairly well at predicting group judgments for many decision tasks. It follows that if the majority is wrong, the group will be wrong as well.76 With experts, the same general conclusion holds. A ?structured approach for combining independent forecasts is invariably more accurate? than ?traditional group meetings,? which do ?not use information efficiently.?77
Let us discuss the key sources of deliberative failure, understood as a failure to make good decisions on the basis of the information that group members actually have.
B. Two Sources of Deliberative Failure: Informational Influences and Social
Pressures
A primary advantage of statistical groups is that members say what they think. But with deliberating groups, this might not happen. Exposure to the views of others might lead people to silence themselves, and for two different reasons.
1. Information. The first reason involves the informational signals provided by the acts and views of other people. If most group members believe that X is true, there is
reason to believe that X is in fact true and that reason might outweigh the purely private reason that a particular group member has to believe that X is false. If other group members share a particular belief, isolated or minority members might not speak out, deferring to the informational signal given by the statements of others.78 Not surprisingly, the strength of the signal will depend on the number and nature of the people who are giving it. People are particularly averse to being the sole dissenter. If all but one person in a deliberating group has said that X is true, then the remaining member is likely to agree that X is true, even to the point of ignoring the evidence of his or her own senses.79 And if the group contains one or more people who are well-known to be authorities, then other group members are likely to defer to them.80
Informational signals come in three different forms, involving conduct, conclusions, and reason-giving. First, group members might purchase certain products, visit particular places, or engage in certain actions their conduct will provide a signal about their beliefs. Second, group members might express their conclusions about some issue. They might say that global warming is a serious problem, that crime is rising in New York City, that minimum wage legislation increases unemployment. Third, group members might give reasons and arguments for their beliefs, going beyond conclusions to explain why they think as they do. If a number of different arguments favor a certain conclusion, and if each of these arguments is plausible, there is more reason to think that the conclusion is right. Conduct, conclusions, and reasons will have different effects in different circumstances we can imagine a group whose members are unimpressed by conclusions but much affected by behavior, or a group whose members pay far more attention to reasons than to conclusions.81 By definition, the deliberative ideal is supposed to include reason-giving, not merely actions or statements of conclusions.82 And when
reasons are given, group members are likely to pay attention to them, in a way that can led people to fail to say what they know.
2. Social influences. The second reason involves social influences. If people fear that their statements will be disliked or ridiculed, they might not speak out, even on questions of fact. Their silence might stem not from a belief that they are wrong, as in the case of informational pressure, but instead but from the risk of social sanctions of various sorts. In the most extreme cases, those sanctions will take the form of criminal punishment or complete exclusion from the group. In less severe cases, those who defy the dominant position within the group will incur a form of disapproval that will lead them to be less trusted, liked, and respected in the future. Here too people are inevitably affected by the number and nature of those with the majority position. A large majority will impose more social pressure than a small one. If certain group members are leaders or authorities, willing and able to impose social sanctions of various sorts, others will be unlikely to defy them publicly.
3. A framework: private benefits vs. social benefits. Participation in deliberative processes, and the effects of informational and social influences, can be put into a more general framework. Suppose that group members are deliberating about some factual question suppose too that each member has some information that bears on the answer to that question. Will members disclose what they know?
For each person, the answer may well depend on the individual benefits and the individual costs of disclosure. In many situations, and entirely apart from informational and social influences, the individual benefits of disclosure will be far less than the social benefits. If I say what I know about a legal issue being examined by a team of lawyers, I will probably receive only a fraction of the benefit that comes from an improved decision by the group. And if each group member thinks this way, the group will receive only a fraction of the available information. Here is this sense in which participants in deliberation typically face a collective action problem, in which each person, following his rational self-interest, will tell the group less than it needs to know. At least this is so if each member receives only a small portion of the benefits that come to the group from a good outcome?a plausible view about the situation facing many institutions, including, for example, corporate boards and administrative agencies. (I take up below the question
whether incentives might be restructured so as to remedy this problem, for instance by rewarding people for correct decisions by the group.83)
If the statements of others suggest that privately held information is wrong or unhelpful, then the private benefit of disclosure is reduced much more. In that event, the group member has reason to believe that disclosure will not improve the group?s decision at all. Things are even worse if those who speak against the apparent consensus will suffer reputational injury (or more). In that event, the private calculus is straightforward: Silence is golden. As we shall see, a great deal can be done to improve the situation, above all by realigning individual incentives and through institutional design but this understanding of the central problem provides a useful starting point.
4. Findings. Both informational pressure and social influences help explain the finding that in a deliberating group, those with a minority position often silence themselves or otherwise have disproportionately little weight.84 There is a more particular finding: Members of low status groups?less educated people, African-Americans, sometimes women?speak less and carry less influence within deliberating groups than their higher-status peers.85 Both informational influence and social pressures, likely to especially strong for low-status members, contribute to this result. The unfortunate consequence can be a loss of information to the group as a whole, in a way that ensures that deliberating groups do far less well than they would if only they could aggregate the information held by group members.
Informational pressure and social pressures also help explain some otherwise puzzling findings about judicial voting on federal courts of appeals. Consider the fact that on three-judge panels, Republican appointees show far more conservative voting patterns when sitting with two other Republican appointees?and that Democratic appointees show far more liberal voting patterns when sitting with two other Democratic appointees.86 Consider too the finding that when sitting with two Republican appointees,
Democratic appointees show quite conservative voting patterns, close to those of Republican appointees in the aggregate data?and that when sitting with two Democratic appointees, Republican appointees are fairly liberal, with overall votes akin to those of Democratic appointees.87 For federal judges, informational pressure and social influences are not the whole story, but they play a substantial role.88
More generally, a comprehensive study demonstrates that majority pressures can be powerful even for factual questions on which some people know the right answer.89 The study involved 1200 people, forming groups of six, five, and four members. Individuals were asked true-false questions, involving art, poetry, public opinion, geography, economics, and politics. They were then asked to assemble into groups, which discussed the questions and produced answers. The majority played a substantial role in determining the group?s answers. The truth played a role too, but a lesser one. If a majority of individuals on the group gave the right answer, the group?s majority moved toward the majority in 79 percent of the cases. If a majority of individuals on the group gave the wrong answer, the group decision nonetheless moved toward the majority in 56 percent of the cases. Hence the truth did have an influence?79 percent is higher than 56 percent?but the majority?s judgment was the dominant one. And because the majority was influential even when wrong, the average group decision was right only slightly more often than the average individual decision (66 percent vs. 62 percent). What is most important is that groups did not take perform as well as they would have if they had properly aggregated the information that group members had.
5. Preconditions and the internal morality of deliberation: a Hayekian challenge to Habermas? Do these points amount to a challenge to deliberation as an ideal, or to deliberative conceptions of democracy? Many of those interested in deliberation have attempted to specify its preconditions, in a way that is intended to ensure against some of the problems that I am emphasizing here. Jurgen Habermas, for example, stresses norms and practices designed to allow victory by ?the better argument?: ?Rational discourse is supposed to be public and inclusive, to grant equal communication rights for participants,
to require sincerity and to diffuse any kind of force other than the forceless force of the better argument. This communicative structure is expected to create a deliberative space for the mobilization of the best available contributions for the most relevant topics.?90 In Habermas? ?ideal speech situation,? all participants attempt to seek the truth they do not behave strategically or attempt to decide they accept a norm of equality.91 Other advocates of deliberation in democracy have spoken similarly about what appropriate deliberation entails.92 On this view, deliberation, properly understood, does not simply involve the exchange of words and opinions. Deliberation has its own internal morality, one that operates as a corrective to some of the effects of deliberative processes in the real world.
These claims point in helpful directions, and it is correct to say that deliberation, properly understood, contains an internal morality that can be invoked to challenge nominally deliberative processes. Unfortunately, preconditions of the sort identified by Habermas will cure few of the problems that I shall outline here. More particularly, those preconditions will do little to affect the four most important kinds of failures on the part of deliberating groups. Each of failures is likely to arise even if discourse is public and inclusive, even if participants are sincere, and even if everyone has equal communication rights. We might therefore take the argument to be made here as a Hayekian critique of Habermas?a critique, that is, that stresses, with Hayek, the diffusion of information of society, and the difficulty of aggregating that information through deliberation (as opposed to the price signal).93 To be sure, some of the relevant problems are reduced if various forms of subtle ?force? are eliminated. But the reduction is only partial. The four problems have distinctive structures I discuss them in sequence.
C. Deliberative Failure, 1: Amplification of Cognitive Errors
It is well-known that individuals do not always process information well. They use heuristics that lead them to predictable errors they are also subject to identifiable
biases, which are also productive of errors.94 A growing literature explores the role of these heuristics and biases95 and their relationship to law and policy.96 For example, most people follow the representativeness heuristic, in accordance with which judgments of probability are influenced by assessments of resemblance (the extent to which A ?looks like? B).97 The representative heuristic helps explain what Paul Rozin and Carol Nemeroff call ?sympathetic magical thinking,? including the beliefs that some objects have contagious properties and that causes resemble their effects.98 The representativeness heuristic often works well, but it can also lead to severe blunders. People often err because they use the availability heuristic to answer difficult questions about probability. When people use this heuristic, they answer a question of probability by asking whether examples come readily to mind.99 In addition, most people are strikingly vulnerable to framing effects, making different decisions depending on the wording of the problem. For a simple example, consider the question whether to undergo a risky medical procedure. When people are told, ?Of those who have this procedure, 90 percent are alive after five years,? they are far more likely to agree to the procedure than when they are told, ?Of those who have this procedure, 10 percent are dead after five years.?100
For purposes of assessing deliberation, a central question is whether groups avoid the errors of the individuals who compose them. There is no clear evidence that they do, and there is considerable evidence that they do not?a vivid illustration of the principle, ?garbage in, garbage out,? in a way that mocks the aspiration to collective correction of individual blunders. In fact individual errors are not merely replicated but actually amplified in group decisions?a process of ?some garbage in, much garbage out.?
Consider some key findings. If individual jurors are biased because of pretrial publicity that misleadingly implicates the defendant, or even because of the defendant?s unappealing physical appearance, juries are likely to amplify rather than to correct those biases.101 Groups have been found to amplify, rather than to attenuate, reliance on the representativeness heuristic102 to reflect even larger framing effects than individuals103 to show more overconfidence than group members104 to be more affected by the biasing effect of spurious arguments from lawyers105 to be more susceptible to the ?sunk cost fallacy?106 and to be more subject to choice-rank preference reversals.107 In an especially revealing finding, groups have been found to make more, rather than fewer, conjunction errors than individuals when individual error rates are high?though fewer when individual error rates are low.108 In addition, groups demonstrate essentially the same level of reliance on the availability heuristic, even when use of that heuristic leads to clear errors.109
Why are cognitive errors propagated and often amplified at the group level? Informational pressures and social influences are unquestionably at work. Suppose, for example, that most members of a group are prone to make conjunction errors (believing that A and B are more likely to be true than A alone).110 If the majority makes conjunction errors, then most people will see others making conjunction errors, and what they see will convey information about what is right. Those who are not specialists in
logic are likely to think: If most people make conjunction errors, perhaps they are not errors at all. Of course some people will not fall prey to those errors and may even correct them but group members would have to have a high degree of confidence to do so. Recall here the finding that groups make more conjunction errors than individuals when the initial rate of individual error is high111?a finding that fits well with the informational explanation of why group amplify errors.
Social influences also contribute to the propagation and amplification of individual mistakes. If most group members make conjunction errors, others might make them too simply in order not to seem disagreeable or foolish?at least if there is no particular incentive to produce the right answer. And if most group members use the availability heuristic, or commit the sunk-cost fallacy, then there will be social pressure to do the same.
To be sure, there is some evidence of group attenuation of biases. For example, groups are slightly less susceptible to hindsight bias.112 Apparently members who are not susceptible to that bias are able to persuade others that it is indeed a bias. Groups are especially likely to outperform the average individual when members are subject to ?egocentric biases.?113 When asked what percentage of other undergraduates will vote for George W. Bush, have cell phones, watch television on Tuesday night, enjoy a particular singer, or believe that Spiderman 2 will win at least one Oscar, most people show a bias in the direction that they themselves favor. They believe that their tastes and preferences are typical. But in groups with diverse views, individual members learn that their own position is not universally held, and hence the bias is reduced.114 Group deliberation supplies an important corrective.
But the broader point is that with group discussion, individual errors are usually propagated, not eliminated,115 and amplification of mistakes is more likely than alleviation. A general review suggests that when individuals show a high degree of bias, groups are likely to be more biased, not less biased, than their median or average
member in such circumstances, ?groups generally can be expected to amplify rather than correct individual bias.?116 This point is an application of the lesson, from the Condorcet Jury Theorem, that as the size of the group expands, the likelihood of group error expands toward 100% if each group member is more likely to be wrong than right. What I am emphasizing here is that social dynamics can aggravate rather than reduce that problem. And if this is so, then jury deliberations, as well as deliberation within multimember courts and the executive branch, are prone to error. Recall here the suggestion that both the CIA and NASA blundered because group processes failed to correct, and instead amplified, initial biases internal to both agencies.117
D. Deliberative Failure, 2: Hidden Profiles and Common Knowledge
Suppose that group members have a great deal of information?enough to produce the unambiguously right outcome if that information is properly aggregated. Even if this is so, an obvious problem is that groups will not perform well if they emphasize shared information and slight information that is held by one or a few members. Unfortunately, countless studies demonstrate that this unfortunate result is highly likely.118 ?Hidden profiles? is the term for accurate understandings that groups could but do not obtain. Hidden profiles are in turn a product of the common knowledge effect, through which information held by all group members has more influence on group judgments than information held by only a few members.119 The most obvious explanation of the effect is the simple fact that as a statistical matter, common knowledge is more likely to be communicated to the group but social influences play a role as well.
1. Examples. Consider a study of serious errors within working groups, both faceto-face and online.120 The purpose of the study was to see how groups might collaborate to make personnel decisions. Resumes for three candidates, applying for a marketing manager position, were placed before group members. The attributes of the candidates
were rigged by the experimenters so that one applicant was clearly the best for the job described. Packets of information were given to subjects, each containing a subset of information from the resumes, so that each group member had only part of the relevant information. The groups consisted of three people, some operating face-to-face, some operating on-line. Almost none of the deliberating groups made what was conspicuously the right choice. The reason is simple: They failed to share information in a way that would permit the group to make that choice. Members tended to share positive information about the winning candidate and negative information about the losers. They suppressed negative information about the winner and positive information about the losers. Hence their statements served to ?reinforce the march toward group consensus rather than add complications and fuel debate.?121
Or consider a simulation of political elections, in which information was parceled out to individual members about three candidates for political office, and in which properly pooled information could have led to what was clearly the best choice, Candidate A.122 In the first condition, each member of the four-person groups was given most of the relevant information (66% of the information about each candidate). In that condition, 67% of group members favored Candidate A before discussion, and 85% after discussion.123 This is clear example of appropriate aggregation of information. Groups significantly outperformed individuals, apparently because of the exchange of information and reasons. Here, then, is a clear illustration of the possibility that groups can aggregate what members know, in a way that produces sensible outcomes.
In the second condition, by contrast, the information that favored Candidate A was parceled out to various members of the group, so that only 33% of information about each candidate was shared, and 67% was unshared. As the condition was designed, the shared information favored two unambiguously inferior candidates, B and C but if the unshared information emerged through discussion, and was taken seriously, Candidate A would be chosen. In that condition, less than 25% of group members favored Candidate A before discussion, a natural product of the initial distribution of information. But (and
this is the key result) that number actually fell after discussion, simply because the shared information had disproportionate influence on group members.124 In other words, groups did worse, not better, than individuals when the key information was distributed selectively. In those conditions, the commonly held information was far more influential than the distributed information, to the detriment of the group?s ultimate decision.
From this and many similar studies, the general conclusion is that when ?the balance of unshared information opposes the initial most popular position . . . the unshared information will tend to be omitted from discussion and, therefore, will have little effect on members? preferences during group discussion.?125 That conclusion has a clear connection with the judgments, mentioned above, about large-scale information failures at the CIA and similar failures at NASA.126 It follows that ?[g]roup decisions and postgroup preferences reflect[] the initial preferences of group members even when the exchange of unshared information should have resulted in substantial shifts in opinion.?127 Nor does discussion increase the recall of unshared information. On the contrary, its major effect is to increase recall of the attributes of the initially most popular candidate.128 The most disturbing conclusion is that when key information is unshared, groups are ?more likely to endorse an inferior option after discussion than? are ?their individual members before discussion.?129
2. The common knowledge effect. These results are best understood as a consequence of the ?common knowledge effect,? by which information held by all group members has the most substantial influence on group judgments, far more than information held by one member or a few.130 More precisely, the ?influence of a particular item of information is directly and positively related to the number of group members who have knowledge of that item before the group discussion and judgment.?131 Under conditions of unshared information, group judgments have been found to be ?not
any more accurate than the average of the individual judgments, even though??and this is the central point?the groups were ?in possession of more information than were any of the individuals.?132
In a key study, deliberating groups would have lost nothing in terms of accuracy if they had simply averaged the judgments of the people involved?a clear finding that deliberation may not improve on the judgments of statistical group.133 The more shared information is (the more that it stands as ?common knowledge?), the more impact it will have on group members before discussion begins?and the more impact it will have as discussion proceeds, precisely because commonly held information is more likely to be discussed.
As might be expected, the group?s focus on shared information increases with the size of the group.134 In another study designed to test judgments about candidates for office, involving both three-person and six-person groups, all discussions focused far more on shared information than on unshared information?but the effect was significantly greater for six-person groups. Most remarkably, ?it was almost as likely for a shared item to be mentioned twice as it was for an unshared item to be mentioned at all.?135And despite the failures of their deliberations, group members were significantly more confident in their judgments after discussion.136
How can these findings be squared with the Condorcet Jury Theorem? The most fundamental point is that in deliberation, individuals are not making judgments on their own they are being influenced by the judgments of others. When interdependent judgments are being made, and when some people are wrong, the Condorcet Jury Theorem offers no clear predictions. Under such circumstances, it is not at all clear that groups will do better than individuals.137 And when groups fail, the tendency toward hidden profiles is often part of the reason.
3. Informational influences and social pressures redux. Why do hidden profiles remain hidden? The two major explanations track the informational and social accounts traced above. When information is held by all or most, it is especially likely, as a statistical matter, to be repeated in group discussion, and hence more likely to be influential than information that is held by one person or a few.138 There are two different points here.139 First, information held by all or most group members is likely to influence individual judgments, and those judgments will in turn affect the judgments of the group. Thus the effects of a shared piece of information will influence the group simply through its impact on predeliberation judgments. Second, shared information, because it is shared, is more likely to be explored during group discussion. Suppose, for example, that a team of five lawyers is deciding whether to appeal an adverse trial court ruling. If each of the five lawyers has certain information indicating that an appeal would be unsuccessful, that information is more likely to emerge ingroup discussion than separate parcels of information, individually held by each lawyer, suggesting that an appeal would likely succeed. If the team of lawyers stresses the information that is antecedently held by each, that information will have a disproportionate influence on its ultimate decision.140 This is a statistical point about information sampling.
But information sampling provides an incomplete account hidden profiles remain even more hidden than would be predicted by that account.141 To understand the additional element, consider the finding that low-status members of groups are ?increasingly reluctant over the course of discussion to repeat unique information.?142 Those in a group who are inexperienced, or are thought to be low on the hierarchy, are particularly loathe to emphasize their privately held information as discussion proceeds. This finding suggests that group members, and especially lower status ones, are alert to the reputational costs of emphasizing information that most group members seem to lack. Lower status members ?are likely to drop unique information like a hot potato??partly because of the difficulty of establishing its credibility and relevance,143 partly because
they may incur group disapproval if they press a line of argument that others reject. It follows that hidden profiles are produced by both informational and reputational pressures imposed by the initial distribution of views.
In the same vein, those who discuss shared information obtain rewards in the form of an enhanced sense of competence and credibility in the eyes of others?and in their own eyes as well.144 In both face-to-face discussions and purely written tasks, people give higher ratings (in terms of knowledge, competence, and credibility) to themselves and to others after receiving information that they knew already. It follows that ?a bearer of valuable, unshared information may need to establish credibility by telling others what they already know before telling them what they do not already know.?145 The general problem is that deliberating groups often perform poorly because they fail to elicit information that could steer them in the right directions.
E. Deliberative Failure, 3: Cascades
1. Informational cascades. Hidden profiles are closely related to informational cascades, which greatly impair group judgments. Cascades need not involve deliberation, but deliberative processes often involve cascades. As in the case of hidden profiles, the central point is that those involved in a cascade do not reveal what they know. As a result, the group does not obtain important information.
To see how informational cascades work, imagine a deliberating jury that is deciding whether a defendant should be subject to a punitive damage award and if so, in what amount.146 Let us also assume that the jurors are announcing their views in sequence, in a temporal queue, and that each juror knows his place on that queue. From his own recollection of the evidence and the jury instructions, and from some personal experience, each juror has some private information about what should be done. But each juror also attends, reasonably enough, to the judgments of others. Andrews is the first to speak. He suggests that the defendant should be subject to a punitive award and a high one?say, $5 million. Barnes now knows Andrews?s judgment it is clear that she too
should certainly urge a punitive award, and a high one, if she agrees independently with Andrews. But if her independent judgment is that no award should be imposed, she would?if she trusts Andrews no more and no less than she trusts herself?be indifferent about what to do, and might simply flip a coin.
Now turn to a third juror, Carlton. Suppose that both Andrews and Barnes have favored a punitive award, and a multimillion dollar one, but that Carlton?s own information, though inconclusive, suggests that no award should be imposed. In that event, Carlton might well ignore what he knows and follow Andrews and Barnes. It is likely, in these circumstances, that both Andrews and Barnes had reasons for their conclusion, and unless Carlton thinks that his own information is better than theirs, he should follow their lead. If he does, Carlton is in a cascade. Now suppose that Carlton is acting in response to what Andrews and Barnes did, not on the basis of his own information, and also that subsequent jurors know what Andrews. Barnes, and Carlton did. On reasonable assumptions, they will do exactly what Carlton did: favor a high punitive damage award regardless of their private information (which, we are supposing, is relevant but inconclusive). This will happen even if Andrews initially blundered.147
If this is what is happening, there is a serious social problem: Jurors who are in the cascade do not disclose the information that they privately hold. In the example just given, jury decisions will not reflect the overall knowledge, or the aggregate knowledge, of those on the jury?even if the information held by individual jurors, if actually revealed and aggregated, would produce a quite different result. The reason for the problem is that individual jurors are following the lead of those who came before. Subsequent jurors might fail to rely on, and fail to reveal, private information that actually exceeds the information collectively held by those who started the cascade.
Cascades often occur in the real world within deliberating groups or otherwise148 they are easy to create in the laboratory. The simplest experiment asked subjects to guess whether the experiment was using Urn A, which contained two red balls and one white, or Urn B, which contained two white balls and one red.149 Subjects could earn $2 for a
correct decision, and hence an economic incentive favored correct individual decisions (a point to which I will return). In each period, the contents of the chosen urn were emptied in a container. A randomly selected subject was asked to make one (and only one) private draw of a ball in each round. After that draw, the subject recorded, on an answer sheet, the color of the draw and her own decision about which urn was involved. The subject did not announce her draw to the group, but she did announce her own decision to everyone. Then the urn was passed to the next subject for her own private draw, which again was not disclosed, and her own decision about the urn, which again was disclosed. This process continued until all subjects had made draws and decisions. At that time the experimenter announced the actual urn used. If the subject picks the urn based only on her private information, she will be right 66.7 percent of the time. The point of the experiment is to see whether people will decide to ignore their own draw in the face of conflicting announcements by predecessors?and to explore whether such decisions will lead to cascades and errors.
In the experiment, cascades often developed and they often produced errors. After a number of individual judgments were revealed, people sometimes announced decisions that were inconsistent with their private draw, but that fit with the majority of previous announcements.150 Over 77% of ?rounds? resulted in cascades, and 15% of private announcements did not reveal a ?private signal,? that is, the information provided by people?s own draw. Consider cases in which one person?s draw (say, red) contradicted the announcement of his predecessor (say, Urn B). In such cases, the second announcement nonetheless matched the first about 11% of the time?far less than a majority, but enough to ensure cascades. And when one person?s draw contradicted the announcement of two or more predecessors, the second announcement was likely to follow those who went before. Notably, the majority of decisions were rationally based
on the available information151?but erroneous cascades nonetheless developed. Here is an actual example of a cascade producing an inaccurate outcome (the urn used was B)152:
Table1: An Informational Cascade
1 2 3 4
a A B b
A A A A
What is noteworthy here, of course, is that the total amount of private information?four whites and two reds?justified the correct judgment, which was in favor of Urn B. But the existence of two early signals, producing rational but incorrect judgments, led everyone else to fall in line. ?[I]nitial misrepresentative signals start a chain of incorrect decisions that is not broken by more representative signals received later.?153 This result maps directly onto real-world decisions by deliberating groups, in which people fail to disclose what they know, to the detriment of the group as a whole.
2. Reputational cascades. In a reputational cascade, people think that they know what is right, or what is likely to be right, but they nonetheless go along with the crowd in order to maintain the good opinion of others. Suppose that Albert suggests that global warming is a serious problem, and that Barbara concurs with Albert, not because she actually thinks that Albert is right, but because she does not wish to seem, to Albert, to be ignorant or indifferent to environmental protection. If Albert and Barbara seem to agree that global warming is a serious problem, Cynthia might not contradict them publicly and might even appear to share their judgment, not because she believes that judgment to be correct, but because she does not want to face their hostility or lose their good opinion.
It should be easy to see how this process might generate a cascade. Once Albert, Barbara, and Cynthia offer a united front on the issue, their friend David might be most reluctant to contradict them even if he thinks that they are wrong. The apparent views of
Private Draw
Decision
5 b
A
6 b
A
Albert, Barbara, and Cynthia carry information that apparent view might be right. But even if David thinks that they are wrong, and has information supporting that conclusion, he might be most reluctant to take them on publicly. In the actual world of group decisions, people are of course uncertain whether publicly expressed statements are a product of independent knowledge, participation in an informational cascade, or reputational pressure. Much of the time, listeners and observers undoubtedly overstate the extent to which the actions of others are based on independent information.
The possibility of reputational cascades is demonstrated by an ingenious variation on the urn experiment mentioned above.154 In this experiment, people were paid twentyfive cents for a correct decision, but seventy-five cents for a decision that matched the decision of the majority of the group. There were punishments for incorrect and nonconforming answers as well. If people made an incorrect decision, they lost twentyfive cents if their decision failed to match the group?s decision, they lost seventy-five cents.
In this experiment, cascades appeared almost all of the time. No fewer than 96.7% of rounds resulted in cascades, and 35.3% of people?s announcements did not match their private signal, that is, the signal given by their own draw. And when the draw of a subsequent person contradicted the announcement of the predecessor, 72.2% of people matched the first announcement. Consider, as a dramatic illustration, this period of the experiment155 (the actual urn for this period was B):
Table 2: Conformity and Cascades
1 2 3 4 5 6 7
a b b b a b b
A A A A A A A
This experiment shows that especially unfortunate results should be expected if people are rewarded not only or not mostly for being correct, but also or mostly for doing what other people do. The problem is that people are not revealing the information that they actually have.
Private Draw
Decision
8 b
A
9 a
A
10 b
A
F. Deliberative Failure, 4: Group Polarization
There are clear links among hidden profiles, social cascades, and the wellestablished phenomenon of group polarization, by which members of a deliberating group end up in a more extreme position in line with their tendencies before deliberation began.156 Group polarization is the typical pattern with deliberating groups. It has been found in hundreds of studies involving over a dozen countries, including the United States, France, Afghanistan, and Germany.157 For example, those who disapprove of the United States, and are suspicious of its intentions, will increase their disapproval and suspicion if they exchange points of view. Indeed, there is specific evidence of the latter phenomenon among citizens of France.158
Group polarization occurs for issues of fact as well as issues of value, though it is easiest to demonstrate for the latter. If the question is whether a terrorist attack will occur in the United States in the next year, group polarization will not be easy to test, simply because the answer is either yes or no, and it is not simple to demonstrate greater extremism in binary choices. But suppose that people are asked, on a bounded scale of zero to eight, how likely it is that a terrorist attack will in the United States in the next year, with zero indicating ?zero probability,? eight indicating ?absolutely certain,? seven indicating, ?overwhelmingly likely,? six ?more probable than not,? and five ?50-50.? In that event, the answers from a deliberating group will tend to reveal group polarization, as people move toward more extreme points on the scale, depending on their initial median point. If the predeliberation median is five, the group judgment will usually be six if the predeliberation median is three, the group judgment will usually be two.159 Recall here that federal judges are highly susceptible to group polarization, as both Democratic and Republican appointees show far more ideological voting patterns when sitting with other judges appointed by a president of the same political party.160 Juries polarize as well.161
Why does group polarization occur? There are three reasons.162 The first and most important involves the now-familiar idea of informational influence, but in a distinctive form. People respond to the arguments made by other people?and the ?argument pool,? in any group with some predisposition in one direction, will inevitably be skewed toward that predisposition. As a statistical matter, the arguments favoring the initial position will be more numerous than the arguments pointing in the other direction. Individuals will have heard of some, but not all, of the arguments that emerge from group deliberation. As a result of the relevant arguments, deliberation will lead people toward a more extreme point in line with what group members initially believed. The second explanation involves social influences. People want to be perceived favorably by other group members. Sometimes people?s publicly stated views are, to a greater or lesser extent, a function of how they want to present themselves. Once they hear what others believe, some will adjust their positions at least slightly in the direction of the dominant position, to hold onto their preserved self-presentation. They shift accordingly.163 The third explanation stresses that people with extreme views tend to have more confidence that they are right, and that as people gain confidence, they become more extreme in their beliefs. In a wide variety of experimental contexts, people?s opinions have been shown to become more extreme simply because their view has been corroborated, and because they have been more confident after learning of the shared views of others.165
Does group polarization led to accurate or inaccurate answers? Do deliberating groups err when they polarize? No general answer would make sense. Everything depends on the relationship between the correct answer and the group?s predeliberation tendency. But as a result of the relevant influences, some people will fail to disclose what they know. As a result, deliberative processes might well fail to move people in the right directions. When individuals are leaning in a direction that is mistaken, the mistake will be amplified by group deliberation. We have already encountered an example: When most people are prone to make conjunction errors, group processes lead to more errors
rather than fewer.166 The same is true when jury members are biased as a result of pretrial publicity here jurors become more biased than individual jurors were.167 This is polarization in action, and it produces major blunders.
G. Deliberative Success?
Thus far I have emphasized several reasons why deliberation often fails to improve on the judgments of statistical groups, and indeed might make those judgments even worse. But there is some intriguing countervailing evidence.
1. Increases in accuracy. When one or more people in a group are confident that they know the right answer to a factual question, the group might be expected to shift in the direction of accuracy.168 And if the question has a readily demonstrable answer, it is more likely that groups will converge on it.169 Suppose that the question is how many people were on the earth in 1940, or the number of Supreme Court decisions invalidating acts of Congress, or the distance between Paris and London. Suppose too that one or a few people know the right answer. If so, there is a good chance that the group will not polarize, but instead accept that answer. When this is so, the reason is simple: The person who is confident that she knows the answer will speak with assurance and authority, and she is likely to be convincing for that very reason. An early study finds that those with correct answers are usually more confident, and hence confidence ?is associated with correctness for both individual and group performance.?170 Consider in this light the finding that pairs tend to do better than individuals on a test involving general vocabulary knowledge those pairs with at least one high-ability member generally performed at the same level as their more competent member.171
Some evidence suggests that while deliberating groups often fail to spread information, they are less likely to neglect unshared information if they believe that there
is a demonstrably correct answer to the question that they are trying to answer.172 Asked to solve a murder mystery, a deliberating group did far better when its members were told that they had sufficient clues to ?determine? the identify of the guilty suspect than when they were told to decide which suspect was ?most likely to have committed the crime.?173 Hence ?adequate consideration of unshared, critical information during group discussion? appears to be affected by ?how members construe their decision-making task?174?so that those who believe that they are solving a problem with a correct solution are more likely to explore shared information than those who think that there are reaching a consensus. It follows that ?discussions may be more data driven and less consensus driven when members believe that a demonstrably correct decision exists.?175 Even here, however, the member who knows the right solution usually requires some initial support in the group otherwise the group will frequently fail.176
Another study finds that groups performed exceedingly well, far better than individual members, in two complex tasks that had demonstrably correct solutions.177 The first involved a statistical problem, requiring subjects to guess the composition of an urn containing blue balls and red balls. The second involved a problem in monetary policy, asking participants to manipulate the interest rate to steer the economy in good directions. People were asked to perform as individuals and in groups. The basic results for the two experiments were similar. Groups significantly outperformed individuals. On a scale of 1-100, the average group score in the urn test was 86.8, as opposed to 83.7 for individuals?a highly significant difference statistically. For the monetary policy problem, the difference was essentially identical. Interestingly, groups did not, on balance, take longer to make decision. In terms of both accuracy and time, there were no
differences between group decisions made with a unanimity requirement and group decisions made by majority rule.
How can these results be explained? An obvious possibility is that group processes play a little role and that the group?s discussion is simply the average of individual judgments. On this view, the judgments of these deliberating groups simply were statistical judgments. But the evidence is inconsistent with this hypothesis groups did far better than their average member.178 Even more remarkably, the performance of the median player did not explain the performance of the group. An alternative hypothesis is that each group contained one or more strong analysts, who were able to move the group in the right direction. But in the experiments, there is little support for this hypothesis. ?In the end, we are left to conclude that neither the average player, nor the median player, not the best player determine the decisions of the group.?179 It seems that in these experiments, the better decisions by groups resulted from the fact that the best points and arguments turned out to spread among the various individual players. Here we find some basis for the claim that under appropriate conditions, groups can do much better than individuals. The relevant conditions appear to include highly competent group members attempting to solve statistical problems that all members knew to have demonstrably correct answers.
2. The deliberative opinion poll. In an interesting combination of theoretical and empirical work, James Fishkin has pioneered the idea of a ?deliberative opinion poll,? in which small groups, consisting of highly diverse individuals, are asked to come together and to deliberate about various issues.180 Deliberative opinion polls have been conducted in several nations, including the United States, England, and Australia. Fishkin finds some noteworthy shifts in individual views, and he evidently believes that the deliberative process produces learning and hence improvements in people?s judgments. Because of the nature of the deliberative opinion poll, it is not possible to test for the amplification of errors, hidden profiles, or cascade effects. But Fishkin does not find a systematic tendency toward group polarization. In his studies, individuals shift both toward and away from the median of predeliberation views. It is therefore tempting to
conclude that properly structured deliberation can avoid some or possibly even all of the problems traced here.
In England, for example, deliberation led to reduced interest in using imprisonment as a tool for combating crime.181 The percentage believing that ?sending more offenders to prison? is an effective way to prevent crime went down from 57% to 38% the percentage believing that fewer people should be sent to prison increased from 29% to 44% belief in the effectiveness of ?stiffer sentences? was reduced from 78% to 65%.182 Similar shifts were shown in the direction of greater enthusiasm for procedural rights of defendants and increased willingness to explore alternatives to prison. In other experiments with the deliberative opinion poll, shifts included a mixture of findings, with larger percentages of individuals concluding that legal pressures should be increased on fathers for child support (from 70% to 85%) and that welfare and health care should be turned over to the states (from 56% to 66%).183
On many particular issues, including the two just mentioned, the effect of deliberation was to create an increase in the popularity of the view that initially had majority support within the group.184 These findings are consistent with the prediction of group polarization. But this was hardly a uniform pattern. On some questions, deliberation increased the percentage of people holding a minority position (with, for example, a jump from 36% to 57% of people favoring policies making divorce ?harder to get?).185 These are not the changes that would be predicted by group polarization.
What explains this? First, and probably most important, Fishkin?s studies presented participants with a set of written materials that attempted to be balanced and that contained detailed arguments pointing on both sides. The likely consequence would be to move people in different directions from those that would be expected by simple group discussion, unaffected by external materials inevitably containing a degree of
authority. Indeed, the very effort to produce balance introduces a degree of unpredictability into group deliberations, simply because the argument pool is different from what it would be if all claims were generated independently by group members. Second, Fishkin?s deliberators did not vote as a group. While group polarization is observed when no group decision is expected, the extent of polarization is likely to decrease, simply because members have not been asked to sign onto a group decision as such. Third, Fishkin?s groups were overseen by a moderator, concerned to ensure a level of openness and likely to alter some of the dynamics discussed here. A moderator, even a neutral one, can do a great deal to reduce polarization, by altering both informational and reputational influences.
Many people are optimistic about the results of deliberative opinion polls and want them to be used more broadly.186 But is there reason for confidence that when structured in the way that such polls have been, people will move toward better answers? An affirmative answer would be premature there is no evidence that it is justified. To test the operation of the deliberative opinion poll, it would be valuable to engage the group on some simple question of fact?for example, whether the beneficiaries of minimum wage legislation mostly consists of people below the poverty line,187 or whether sulfur dioxide emissions in the United States have increased or decreased in the last decade,188 or whether wages have risen, in real terms, over the past decade. On such questions, do deliberative opinion polls move people toward truth rather than error? From existing deliberative opinion polls, taken together with other evidence about group processes,189 it is not at all clear whether deliberation will increase accuracy, even under Fishkin?s conditions. If deliberators become less enthusiastic about ?stiffer sentences,? or more enthusiastic about imposing pressures on fathers to provide child support, social dynamics, not good reasoning, may be responsible and that possibility is not belied by establishing that people have learned a great deal.
The deliberative opinion poll does, however, provide lessons about appropriate institutional design for deliberating bodies. Group polarization can be heightened, diminished, and possibly even eliminated with seemingly small alterations in institutional arrangements. To the extent that informational pressure and social influences are likely to have unfortunate effects, correctives can be introduced, perhaps above all by exposing group members, at one point or another, to arguments to which they are not antecedently inclined. Let us now consider how groups might respond to this insight.
Remedies and Reforms
How might group performance be improved? How can groups counteract the problems I have emphasized? If mistakes come from informational and reputational pressure, then the solution is to take steps to increase the likelihood that people will disclose what they know. The most difficult problem is the propagation of error. If group members use the availability heuristic, or if they fall prey to optimistic bias, blunders will result unless they are corrected by one or more group members. Even here, the best solution is to attempt to ensure that group members say what they believe to be true.
But for those who seek to diminish the effects of informational pressure and social influences, there is a cautionary note. We can imagine groups that actually benefit from both of these, and hence from cascades and polarization.190 Sometimes it is good for people to silence themselves sometimes their contributions would be unhelpful, because what they believe that they know is false.191 If some group members have a bad idea about how to stabilize the economy, litigate a case, or reduce the threat of terrorism, informational pressure and social influences might make them defer to those who know much better. As a result, the group will do better rather than worse.
We have seen that polarization might lead people in the right direction the question is whether a more extreme version of members? antecedent tendency is correct, and that question must be answered on its merits. The process of polarization does not provide that answer. Or consider a cascade in which the early movers actually know the truth, and those who follow them are ignoring private information that they believe to be
true but that would, on reflection, turn out to be erroneous or misleading. If so, the followers are not only rational in disregarding what they know they also lead the group in a better direction because they do not give it bad signals. Those who participate in cascades are acting rationally but the more important point is that if those who start cascades are correct, both individuals and groups are better off as a result. The only problem?and it is a serious one?is that many cascade participants will fail to disclose accurate information, and for that reason the group will suffer, as demonstrated by the experiments discussed above.
Let us focus, then, on the standard cases in which deliberating groups will do worse if they do not learn what group members know. For private and public institutions, the overriding question is how to alter people?s incentives in such a way as to increase the likelihood of disclosure. Many possibilities might be imagined here. Consider two experiments that have more general implications.
A. Restructured Incentives
Is it possible to reduce the pressures that lead group members to silence themselves? Is it possible to ensure that people will internalize some of the benefits that accrue to the group from disclosure?
1. Overcoming reputational influences: priming critical thinking. Self-silencing is partly a product of social norms?of a sense that people will be punished, rather than rewarded, for disclosing information that departs from the group?s inclination. It should be easy to see that group processes can aggravate or eliminate this effect. If consensus is prized, and known to be prized, then self-silencing will be more likely. If the group is known to welcome new and competing information, then the reward structure will be fundamentally different.
Evidence for this claim comes from hidden profile experiments that ?primed? people by asking them to engage in a prior task that involved either ?getting along? or ?critical thinking.? Primed by a task that called for critical thinking, people were far more likely to disclose what they know, and there was a quite substantial reduction of hidden profiles.192 For both private and public groups, the general lesson is that if norms favor
disclosure of privately held information, then self-silencing will be significantly reduced deliberation is likely to benefit as a result. Social norms and institutional culture can go a long way toward reducing the effects of social pressures.
2. Overcoming informational influences: rewarding group success. We have seen that people often do not disclose what they know because they receive only a fraction of the benefits of disclosure this problem is compounded if private information seems likely to be erroneous in light of what others have said. But how would groups perform if individuals knew that they would be rewarded, not if their own answer was correct, but if the majority of the group was correct? It might be speculated that in a situation of this kind, hidden profiles, cascades, and group polarization would be dramatically reduced. The reason is that when people are rewarded when their group is right, they are far more likely to reveal, to that group, what they actually know. In such a situation, incentives are restructured so that people internalize the benefits of disclosure.
For supportive evidence, consider an intriguing variation on the urn experiment, where subjects were paid $2 for a correct group decision and penalized $2 for an incorrect group decision, with the group decision determined by majority rule.193 People were neither rewarded nor punished for a correct individual decision. The result was that in 92% of cases, people?s announcement matched their private draw. And because people revealed their private signals, the system of majority rule produced a huge increase in fully informed decisions?that is, the outcomes that someone would reach if he were somehow able to see all private information held by group members. As an example, consider this period from the majority rule experiment194 (the actual urn was A):
Table 3: No Cascade
What is the explanation for this significantly reduced level of cascades in a system of majority rule? The answer lies in the fact that the individual knows that he has
Private Draw
Decision
nothing to gain from a correct individual decision and everything to gain from a correct group decision. As a result, it is in the individual?s interest to say exactly what he sees, because it is the accurate announcement, from each person, that is most likely to promote an accurate group decision. A simple way to understand this point is to assume that a group has a large number of members and that each member makes an announcement that matches his private draw. As a statistical matter, it is overwhelmingly likely that the majority?s position will be correct. The sophisticated participants in this experiment, from the California Institute of Technology, saw the point.
B. Devil?s Advocates
How can institutional design take advantage of these findings? If hidden profiles and self-silencing are the source of group failure, then an obvious response is to ask some group members to act as ?devil?s advocates,? urging a position that is contrary to the group?s inclination.195 This was a central suggestion of both the Senate Committee reporting on intelligences failures in connection with Iraq and of the review board that investigated large blunders at NASA.196
Those assuming the role of devil?s advocates will not occur the reputational pressure that comes from rejecting the dominant position within the group they have been requested to do precisely that. And because they are asked to take a contrary position, they are freed from the informational influences that can lead to self-silencing. Hidden profiles are less likely to remain hidden if one or more group members are told to disclose the information they have, even if that information runs contrary to the apparent tendency within the group. In at least one well-known case, this approach appeared to work. ?During the Cuban missile crisis, President Kennedy gave his brother, the Attorney General, the unambiguous mission of playing devil?s advocate, with seemingly excellent results in breaking up a premature consensus.?197
Unfortunately, research on devil?s advocacy in small groups does not provide conclusive evidence of the effectiveness of devil?s advocacy in real-world settings.198 To be sure, many experimenters have found that protection of genuine dissenting views can enhance group performance.199 But a formal requirement of devil?s advocacy enhances group performance far less than does the articulation of genuine dissent. When an advocate?s challenges to a group consensus are insincere, members discount his arguments accordingly. At best, he merely facilitates a ?multisided examination of the problems at hand.?200 Because devil?s advocates have no incentive to sway the group?s members to their side, they accomplish their task if they allow the consensus view to refute the unpopular dissenting arguments. Unlike a genuine dissenter, the devil?s advocate has little to gain by zealously challenging the dominant view and as a result tends not to persist in challenging the consensus.201 In any case the perceived sincerity of a dissenter is an important factor in determining minority influence.202 An insincere devil?s advocate is unlikely to provide much help. The lesson is that if devil?s advocacy is to work, it is because the group attempts to ensure that the dissenter actually means what he is saying. If so, better decisions can be expected.
C. Enlisting High-Status Contrarians?and Leadership
Some people are more likely to silence themselves than others. For example, group members are less likely to conform if they have high social status or are extremely confident about their own views.203 In a complementary finding, members of low status groups?less educated people, African-Americans, sometimes women?have been shown to carry less influence within deliberating groups than their higher-status peers.204 Creative groups would do well to exploit these findings.
For example, the problem of unshared information is reduced when that information is held by a leader within a group not surprisingly, the leader?s words count, and people listen to what leaders have to say.205 In a leading experiment, a medical team consisting of a resident physician, an intern, and a third-year medical student showed a tendency to repeat unshared items emphasized by the resident?and in this respect did not fall prey to the problem of hidden profiles.206 More generally, those experienced in the task at hand are more likely to mention and to repeat unshared information.207 One reason for these findings is that those with higher status or competence are less subject to the reputational pressures that come from emphasizing unshared information.208 Another reason is that leaders and experts are more likely to think that their own information is accurate and worth disclosing to the group, notwithstanding the fact that the information held by other group members cuts in the other direction.
The simplest lesson is that leaders and high-status members can do groups a large service by asserting a contrary view, at least for purposes of argument.209 In a similar vein, group leaders should be reluctant to state a firm view at the outset and should in that way allow space for more information to emerge.
D. Predeliberation Anonymity, Secret Ballots, and the Delphi Method
To overcome social influences, people might be asked to register their opinions anonymously, either in advance of deliberation or after it has occurred. The secret ballot can be understood as an effort to insulate people from reputational pressures and to permit them to say what they believe.210 Many institutions should consider more use of the secret ballot simply to elicit more information.
As an ambitious variation, consider the Delphi Technique, which has several key features.211 First, it ensures the anonymity of all members through a self-administered
questionnaire. The purpose of anonymity is precisely ?to diminish the effects of social pressures, as from dominant or dogmatic individuals, or from a majority.?212 Second, it is iterated, and there is a system for controlled feedback on the judgments of others. Members make individual estimates all members are informed of the views of other members and there are additional rounds of estimates, allowing feedback until there is a desired level of convergence. Third, group members are permitted to communicate, but sometimes only their ultimate conclusions (generally in the form of summary statistics involving quartiles or ranges) and typically the conclusions, given anonymously, are provided to others by a facilitator or monitor team, often in the form of a simple summary such as a mean of median value of the group response. Thus ?the feedback comprises the opinions and judgments of all group members and not just the most vocal.?213 (Note here that the Delphi Method is most successful when group members are provided not only with the mean or median estimate, but also with reasons given by group members for their views.214 An account of reasons is most likely to move people in the correct directions.215) Fourth, and finally, the judgments of group members are subject to a statistical aggregation.
The Delphi Method provides a sharp contrast with efforts to obtain the judgments of statistical groups and also with interacting groups containing open deliberation. And in several contexts, the Delphi Method has provided more accuracy than open discussion.216 For general almanac questions, the Delphi Method was found to produce better answers than individual estimates, though open discussion did still better, apparently because it served to correct errors.217 A natural alternative to the Delphi Method would be a system in which ultimate judgments were stated anonymously, but only after deliberation. Anonymity would insulate group members from reputational pressure, and to that extent could reduce the problem of self-silencing. But it would do little to reduce informational pressure.
E. Roles, Experts, and Forewarning
Imagine a deliberating group consisting of people with specific roles, appreciated and known by all group members. One person might be understood to have medical expertise a second might be a lawyer a third might know about public relations a fourth might be a statistician. In such a group, it might be hypothesized that sensible information aggregation would be far more likely, simply because each member knows that each other has something particular to contribute. Hidden profiles should be less likely to remain hidden if there is a strict division of labor, in which each person is knowledgeable, and known to be knowledgeable, about something in particular.218
Several experiments support the hypothesis.219 In one such experiment, each member of a three-person group was given a good deal of information about one of three candidates for office.220 In half of these groups, the ?expertise? of each member was publicly identified to all before discussion began in half of them, there was no such public identification of experts. The bias in favor of shared information was substantially reduced in those groups in which experts were publicly identified as such.221 The reduction of the bias was significantly smaller when there was no public identification of experts and when each group member was simply told, by the experimenter, that he or she was an expert on a particular candidate.222 The lesson is clear: If a group seeks to obtain the information that its members hold, it would make sense to inform all group members, before deliberation begins, that different members have different, and relevant, information to contribute. Unfortunately, however, the effect of role assignment, in reducing hidden profiles, is not huge.223
F. General Lessons
These various findings offer general lessons about how deliberating groups might reduce the adverse effects of informational influences and social pressures. The lessons apply to such diverse groups as corporate boards, juries, multimember judicial panels, and administrative agencies.224 If information is dispersed within the group, leaders would do well not to state a firm view at the outset they might well refrain from expressing any opinion at all until other people have said what they think. Following the model of Franklin Delano Roosevelt, they might indicate sympathy for a wide range of views, encouraging diverse opinions to arise.225 They might suggest in particular that they welcome information and perspectives that diverge from their own. A degree of impartiality, on the part of leaders, would go a long way toward encouraging diversity of views. And if reasonable alternatives are not being discussed, group members might be assigned the task of developing and presenting them. Independent subcommittees might be asked to generate new views, possibly views that compete with one another.
Of course time is limited, and prescriptions that are suitable for some organizations will not be suitable for others. In the context of jury deliberations, for example, subcommittees would make little sense what is required is an initial degree of openness in which jurors explore relevant facts before announcing a conclusion. For regulatory agencies, by contrast, competing subdivisions can help to ensure a range of perspectives. In this vein, Christopher Edley has suggested that Congress should create, within the Department of Homeland Security, an independent Office on Rights and Liberties, whose specific mission would be to ensure that the effort to protect the nation from terrorist threats does not compromise liberty and individual rights.226 In Edley?s account, the Office would receive and address public complaints about rights violations it would also make classified quarterly reports to Congress and the President, along with unclassified reports to the public. The proposal deserves serious consideration as a check on amplification of errors, hidden profiles, and group polarization.
An optimistic view of the structure of the Environmental Protection Agency would suggest that the proliferation of offices with overlapping tasks?including a proregulatory Air Office and a more technocratic Planning Office?ensures a kind of internal system of checks and balances.227 Under existing law, the independent regulatory agencies, including the National Labor Relations Board and the Federal Communications Commission, may not have more than a majority of their members from a single political party.228 This limitation might be understood as an effort to protect against the deliberative pathologies that are likely to result if deliberations are restricted to likeminded people.
Many variations on these themes might be imagined. My goal here has been not to set out an institutional blueprint, but to suggest some general points that deliberating groups might take into account when structuring their processes for eliciting and aggregating information and points of view.
Deliberation is one way to aggregate the information held by group members but there are many other possibilities. Open-source software, for example, provides a method by which decentralized ?bits? of private information can be drawn together in software design, thus ensuring improvements that go far beyond the capacities of small groups of experts.229 With open-source software, expert groups do not deliberate about technological improvements instead numerous contributors can bring their creativity and knowledge to bear. More generally, the Internet itself is easily used as an aggregative mechanism. For example, a ?wiki? is a website that allows any user to add material and to edit what previous users have done.230 Wikipedia operates as a free, web-based encyclopedia231 that attempts to take advantage of the information held by thousands of contributors (?Wikipedians?), who add to and edit the encyclopedia.
In a similar vein, a great deal of recent attention has been paid to weblogs, which can serve to elicit and aggregate the information held by countless contributors.232 If thousands of people are maintaining their own ?blogs,? they should be able to act as factcheckers, and as supplemental information sources, for the most prominent members of the mass media. And if tens of thousands of people are reading the most prominent blogs, then errors, on the part of bloggers, should be immediately corrected.233 Of course blogs may also suffer from amplification of error, hidden profiles, cascade effects, and group polarization. But they hold out the promise of aggregating information held by large numbers of people.
Another way to aggregate such information is to rely on the price signal, which has a similar aggregative function. In fact the great advantage of the price signal is that it aggregates both the information and the tastes of numerous people, producing judgments that incorporate more material than could possibly be assembled by any central planner, even one who insists on deliberation with and among experts.234 And if an emphasis is placed on the information-aggregating properties of markets, it would seem plain that if we are attempting to improve on the answer produced by statistical means and deliberating groups, we might consider an increasingly popular possibility: Create a market.235 Information markets, a recent innovation, have proved remarkably successful at forecasting future events they seem to do far better, in many domains, than deliberating groups. Such markets are worth sustained attention, in part because they offer important lessons about how to make deliberation go better or worse, and in part because they provide a useful model for many private and public organizations.
A central advantage of information markets is that they impose the right incentives for people to disclose the information that they hold. Recall that in a deliberating group, members often have little incentive to say what they know. By speaking out, they provide benefits to others, while possibly facing high private costs. Information markets realign incentives in a way that is precisely designed to overcome these problems. Because investments in such markets are generally not disclosed to the public, investors need not fear reputational sanctions if, for example, they have predicted that a company?s sales will be low or that a certain candidate will be elected president. And because people stand to gain or lose from their investments, they have a strong incentive to use (and in that sense to disclose) whatever private information they hold they can capture, rather than give to others, the benefits of disclosure. The use of private information will be reflected in the price signal. In these crucial ways, the problems that infect deliberating groups are largely eliminated in information markets.
Of course investors, like everyone else, are subject to the informational pressure imposed by the views of others. But a market creates strong incentives for revelation of whatever information people actually hold. For small groups, of course, information markets are likely to be too ?thin? to be useful a certain number of investors is required to get a market off the ground.236 In many contexts, however, private and public organizations might use markets as a complement to or even a substitute for deliberation. Perhaps most important, information markets have been found not to amplify individual errors but to eliminate them the prices that result from trading prove reliable even if many individual traders err.237
A. Practice and Evidence
1. An abandoned initiative. In many imaginable markets, people might make claims about facts, or predictions about the future, and they might stand to gain or lose from their predictions. In the summer of 2003, analysts at the Department of Defense built directly on this idea.238 To predict important events in the world, including terrorist attacks, they sought to create a kind of market in which ordinary people could actually
place bets. The proposed Policy Analysis Market would have allowed people to invest in their predictions about such matters as the growth of the Egyptian economy, the death of Yassir Arafat, the military withdrawal of the United States from specified nations, and the likelihood of terrorist attacks in the United States. Investors would have won or lost money on the basis of the accuracy of their predictions.
Predictably, the Policy Analysis Market produced a storm of criticism. Ridiculed as ?offensive? and ?useless,? the proposal was abandoned. Senator Tom Daschle called the market ?a plan to trade in death? and claimed that the plan was ?the most irresponsible, outrageous and poorly thought-out of anything that I have heard the administration propose to date.?239 Senator Byron Dorgan argued that ?it is morally bankrupt for a government agency to make a profitable game out of the deaths of American troops, heads of state, and nuclear missile attacks.?240 A private Policy Analysis Market, specializing in the Middle East, was promised in 2003, but it did not go forward.241
Amid the war on terrorism, why was the Department of Defense so interested in the Policy Analysis Market? The answer is simple: it wanted to have some assistance in predicting geopolitical events, including those that would endanger American interests, and it believed that a market would provide that help. It speculated that if a large number of people could be given an incentive to aggregate their private information, in the way that the Policy Analysis Market would do, government officials would learn a great deal. Apparently it believed that such a market would provide an important supplement to deliberative processes both within government and without.242
2. Iowa Electronic Markets. If this idea seems fanciful, consider the fact that since 1988, the University of Iowa has run the Iowa Electronic Markets (IEM), which allow people to bet on the outcome of presidential elections. Originally the IEM permitted people to trade only in the expected fraction of the popular vote to be obtained by presidential candidates.243 Securities were offered that would pay $2.50 multiplied by the
specified candidate?s share of the vote. If, for example, George H.W. Bush received 50% of the vote, then the shareholder would receive $1.25. Shares could be bought and sold until the day before the election. Since their opening, the IEM have expanded from these modest roots. In the recent past, traders have been able to bet on the market capitalization that Google will achieve in its initial public offering, the price of Microsoft stock at a future date, and Federal Reserve monetary policy, in addition to betting on American elections.244
For presidential elections?still the most popular markets that IEM operates? traders can now choose from two types of markets.245 In a ?winner-take-all? market, traders win $1 for each ?future? in the winning candidate that they own and nothing for shares of the losing candidate. In a ?vote-share? market, traders in ?candidate futures? win $1 multiplied by the proportion of the popular vote that the candidate received.246 Thus, in a winner-take-all market, a ?Dukakis future? was worth nothing after the election, while in a vote-share market, each Dukakis future paid $0.456. In a winner-takeall market, the market price reflects traders? perception of the likelihood that each candidate will win the election. Perhaps more interestingly, observers can use the prices in a vote-share market much as they might use a poll. These prices are the market?s estimate of each candidate?s likely share of the vote when the election occurs. In each case, the market price reflects the aggregate information held by participants.
The IEM operate much like an ordinary stock market. To enter, each participant must purchase ?unit portfolios? consisting of one future in each candidate for each dollar that the trader puts into the market.247 Once she has bought enough of these ?unit portfolios,? she can unbundle the contracts and trade individual shares. All trading is fully computerized and traders must reach the markets through the Internet.248 Unlike most stock exchanges, the IEM does not allow speculators to sell futures short. Nevertheless, as in a typical stock market, traders can issue bids and asks (limit orders) or accept outstanding offers (market orders). While most traders merely accept market
orders rather than choosing their own prices, a small group of ?marginal traders? trade frequently and post limit orders.249 As we shall see, it is these traders who have the greatest effect on prices.
As a predictor, the Iowa Electronic Markets have produced extraordinarily accurate judgments. Almost all of the time, they have done better than professional polling organizations.250 In the week before the last four elections, the predictions in the Iowa market have shown an average absolute error of just 1.5 percentage points, a significant improvement over the 2.1 percentage point error in the final Gallop polls.251 The IEM have proved accurate not only on election eve but only in long forecasting horizons, both in absolute terms and also when compared to alternative forecasting systems.252 Nor are such markets limited to the United States. In other nations, universities are operating similar markets examples include the University of British Columbia Election stock market, involving Canada,253 and Vienna University of Technology, operating the Austrian Electronic Market.254 Although the relevant districts are quite small, Australian bookmakers have shown a high degree of accuracy in predicting district-level races.255
3. Other information markets: Hollywood, weather, and beyond. Outside of the political context, consider the Hollywood Stock Exchange, in which people predict Oscar nominees and winners (as well as opening weekend box office successes). For the Hollywood Stock Exchange, the level of accuracy has been impressive. ?HSX offers good predictions of a film?s gross receipts before release and, relatively speaking, even better predictions after opening weekend - when a large number of traders have some information in the form of (or at least the possibility of) observing the finished film on screen, along with audience reactions. Apparently, studios have begun relying on these estimates to structure the distribution of their films.?256 The market has proved at least
equal to expert panels in predicting Oscar winners, with (for example) correct predictions of thirty-five of forty Oscar nominees in 2002.257
The futures market for oranges does a better job predicting weather in Florida than the National Weather Service.258 A large prediction market, producing a typical event turnover in the hundreds of millions of dollars and run by the Deutsche Bank and Goldman Sacks, involves the likelihood that economic data released later in the week will show specific values259 the market performs at least as well as the consensus forecasts of a survey of about fifty professional forecasters.260 Wagers at race tracks consistently outperform horse-racing experts in predicting winners.261 Companies have started to use internal prediction markets to answer relevant questions, including likely sales in specific periods.262 The level of accuracy here is also high?far better, in fact, than what would emerge from statistical means or deliberation, where excessive optimism can cause serious problems.263
For example, Hewlett Packard (HP) and the California Institute of Technology initiated a project to study experimental markets as an information aggregation mechanism involving product sales.264 The experimenters chose twelve people who worked in different parts of HP?s business operation. Because of its small size, the market was a very ?thin? one, meaning that there were few participants and that the market was far less liquid than the much ?thicker? Iowa Electronic Markets. Participants were chosen with the thought that each could contribute information from his department in buying and selling the relevant futures, which were tied to sales and bonuses for executives (which, in turn, are closely tied to profits). The markets were organized so that that securities existed for intervals of sales. For example, one security would pay off if sales were between one and ten printers another would pay off if sales were between 10 and 20. In most of the experiments, the possible range of sales was divided into ten intervals
of equal size. On the basis the prices of each security, the experimenters could guess how many units HP would sell that month. Information markets were expected to have large potential advantages over internal projections. Those involved in sales have an incentive to understate projected outcomes, so as to ensure that they do not fall short of expectations this bias, or a competing bias in favor of excessive optimism, might well be reduced through market incentives.
The results showed that the markets? predictions were a considerable improvement over HP?s official forecasts. In no fewer six of the eight markets for which official forecasts were available, the market prediction was significantly closer to the actual outcome than the official forecast265?and this was despite ?anecdotal evidence? that the markets? activities were included as inputs in generating the official forecast.266
In fact information markets are springing up all over the Internet, allowing people to make bets on the likely outcomes of sports, entertainment, finance, and political events. In fact we can find actual or proposed prediction markets about any number of questions: Will gas prices reach $3 per gallon? Will cellular life be found on Mars? Will Osama Bin Laden be captured by a certain date? Will small pox return to the United States? Will there be a sequel to Master and Commander? Will the Federal Communications Commission be abolished? These and other questions are being asked on information markets. Consider the following list:
? Hollywood Stock Exchange? http://www.hsx.com
? Austrian Electronic Markets?http://ebweb.tuwien.ac.at/apsm/
? University of British Columbia Election Stock Market--http://esm.ubc.ca/
? Iowa Electronic Markets?http://www.biz.uiowa.edu/iem/
? Foresight Exchange?http://www.ideosphere.com/fx/
? Tradesports?http://www.tradesports.com
? Centrebet-- http://www.centrebet.com/
? News Futures?http://us.newsfutures.com/home/home.html
? Probability Sports?http://www.probabilitysports.com
? Economic Derivatives?http://www.economicderivatives.com
? Wahlstreet?German political futures market
http://tagesspiegel.wahlstreet.de/share/home/home.html
4. Aggregating information through markets. All in all, prediction markets have been spectacularly successful in terms of the aggregate accuracy of the resulting ?prices.? Why is this? Note that they do not rely on the median or average judgment of a randomly selected group of people. They are genuine markets. Those who participate are selfselected. They must believe that they have relevant information it is costly for them to ?vote,? and they ought not to be expected to do so unless they have something to gain.267 In addition, votes are not weighted equally. If people want to invest a few dollars, they are permitted to do so, but they can invest a great deal more if they are confident of their answer.268 Intensity of belief is captured in prices.269
There is a further point. People are permitted to buy and sell shares on a continuing basis. ?Unlike polls or expert panels in which participants are asked for their independent opinions, each trader in the market sees the net effects of the beliefs of all other traders, and the time series changes in those beliefs. This makes the market more than a static, one-time prediction but rather a dynamic system that can respond instantaneously to the arrival of new information.?270 Moreover, a correct answer is rewarded and an incorrect one is punished. Hence investors have a strong incentive to be right. In these circumstances, accurate answers can emerge even if only a small percentage of participants have good information. In the Iowa Electronic Markets, for example, it turns out that 85% of the traders do not seem to be particularly wise.271 They hold onto their shares for a long period and then simply accept someone else?s prices. The predictions of the market are driven by the other 15%?frequent traders who post their offers rather than accepting those made by other people. To work well, prediction markets do not require accurate judgments by anything like the majority of
participants.272 In this sense, information markets are very different from the ordinary judgments of deliberating groups. The resulting prices do not amplify or even perpetuate cognitive errors on the contrary, they correct them, because shrewd traders are able to invest in a way that corrects for even widespread errors.273
Of course information markets involve a measure of deliberation. Individual investors are likely to have deliberated with others before they invest. In some such markets, investors undoubtedly act as ?teams,? pooling resources after deliberating together about what to do. The point is that ultimate decisions come not from asking group members to come up with a mutually agreeable conclusion, but by reference to the price signal, which will have aggregated a great deal of diverse information. It is for this reason that information markets outperform deliberative processes.
How might institutions take advantage of information markets? It is possible to imagine both internal and public varieties. An internal market would be limited to people within the relevant organization. As we have seen, Hewlitt-Packard has used such a market to predict sales, and the Department of Defense proposed an internal Policy Analysis Market as part of its abandoned initiative on geopolitical events.274 An external market would permit public investment by people outside of the institution for which predictions are being made. In either case, the outcome of the market might well be more accurate than the outcome of deliberation, in which errors might arise and be propagated or even amplified as a result of discussion. (For companies, optimistic bias is an obvious risk,275 one that information markets should reduce.) An organization might rely on an internal market if it seeks to keep the results private or if it believes that an aggregation of information held within the organization will be sufficiently accurate. One risk of an internal market is that it might be too ?thin,? simply because most institutions will have
few investors276 another is that members of the organization might suffer from a systematic bias. Alternatively, an institution might create a public market, available to all, believing that through this route it will obtain more accurate results. In either case, an organization might use an information market instead of group deliberation, or at the very least as an input into such deliberation.
B. Failed Predictions?
In what circumstances might information markets fail? To answer this question, ordinary stock markets are the place to start. A primary concern is that information markets, no less than ordinary ones, can be susceptible to manipulation by powerful speculators. The only known attempt to manipulate an information market occurred during the 2000 presidential election. A group of speculators attempted to manipulate the Iowa Electronic Market by buying large volumes of futures in presidential candidate Patrick Buchanan. The value of Buchanan shares did increase dramatically, but they fell almost immediately when ?well-informed traders . . . seized the opportunity to profit off the manipulative traders.?277 Hence the Iowa market remained stable despite this attempted manipulation. Perhaps other, more plausible efforts at manipulation would succeed but none has thus far.
Another concern is that some of the cognitive biases that afflict individuals will manifest themselves in prediction markets. Just as in group deliberation, investors in a market might be subject to predictable heuristics and biases. The results here are unequivocal: they are. For example, psychologists have found that people overestimate the likelihood that their preferred candidate will win an election?a form of optimistic bias.278 At a certain point in the 1980 campaign, for example, 87% of Jimmy Carter?s supporters believed that he would win, while 80% of Ronald Reagan?s supporters
believed that their candidate would win.279 Obviously, at least one side had overestimated its candidate?s probability of victory at the relevant time.
In the market context, IEM traders show the same bias. In 1988, for example, Dukakis supporters were more likely to hold futures in the Massachusetts governor?s illfated presidential bid than were supporters of George H.W. Bush.280 More strikingly still, Dukakis supporters were more likely to view the candidates? debates as helpful to the Democratic candidate and accordingly bought significant additional futures in his campaign after each debate.281 Bush supporters precisely showed the same pattern. Traders thus exhibited the ?assimilation-contrast? effect.282 People usually assimilate new information in a way that confirms their view of the world, and those who invest in information markets show the same bias. Nonetheless, the Iowa Electronic Markets were more accurate than polls in predicting the outcome of the 1988 presidential election. Even three weeks before the election, the market provided an almost-perfect guess about the candidates? shares of the vote.283 How is such accuracy possible when many traders showed identifiable biases? The answer lies in the behavior of a small group of ?marginal traders? who were far less susceptible to these biases?the ?marginal trader? hypothesis. According to this hypothesis, a small group of active traders who are far less susceptible to the relevant biases have a disproportionately large effect on aggregate market behavior. In trading election futures, these traders did not show the same biases as their fellow traders and earned significant profits at the expense of their quasi-rational colleagues.284 Thus, the biased behavior of most traders did not affect the market price because the marginal traders were prepared to take advantage of their blunders. If marginal traders are active and able to profit from the
bounded rationality of other participants, then there will be no effect on the aggregate market price.285
Another bias that might be expected to affect information markets is the ?favoritelongshot? bias often seen in horse races. In horse-racing, heavy favorites tend to give higher returns than other horses in the field, while longshots tend to offer lower than expected returns.286 If the point generalizes, prediction markets might not be accurate with respect to highly improbable events. The market should be expected to overestimate the likelihood that such events will come to fruition for example, Pat Buchanan futures would be expected to be (and might well have been) overpriced even before the attempted manipulation of the market. By contrast, an information market might underestimate the probability of events that are highly likely to occur.287 But with respect to existing prediction markets, there is little evidence of systematic errors in this vein.
?Prediction bubbles? are also easy to imagine, with investors moving in a certain direction with the belief that many other investors are doing the same. A temporary upsurge in investment in the nomination of Hillary Rodham Clinton as 2004 Democratic nominee might well have been a small bubble, with some investors thinking, not that she would in fact be the nominee, but that others would invest in that judgment, thus inflating the value of the investment. Crashes are possible as well. In any case informational influences can certainly lead individuals to make foolish investments in any market, including prediction markets.288 As information markets develop, significant individual errors should be expected, and undoubtedly they will produce some errors in the price signal.289
In particular contexts, the imaginable problems take a different form. Consider the problem of ?terrorism futures.? It would be extremely valuable to aggregate privately held information about the risk and location of any attack. But do likely investors actually
possible helpful information? Thomas Rietz, a director of the Iowa Electronic Markets, argued that terrorism and world events were fundamentally different from other contexts in which markets have successfully predicted future events.290 When betting on presidential elections, people can use ordinary information sources, along with their network of friends, family, and co-workers, to form an opinion but for most investors, there are no such sources of information for terrorist activity. Another skeptic worried that the market would allow the wealthy to ?hedge? against the possibility of terrorist activity, while ordinary Americans would remain vulnerable to this threat.291 In this view, ?terrorism futures? could operate as an insurance market that would not serve its purpose of providing information. In any event government use of the resulting information could be self-defeating, at least if the information were made public. Terrorists would know the anticipated time and location of attacks, and also know that the government was aware of this?which would make it most unlikely that the prediction would turn out to be accurate. Where the event?s occurrence is endogenous to the outcome of the information market, there is reason for skepticism about its likely performance, certainly if relevant actors have much to lose if the market turns out to be correct.292
But many policy issues, including those potentially involved in the now-defunct Policy Analysis Market, did not have this feature. Consider, for example, the question whether the Egyptian economy is likely to grow in the next year, or whether Yassir Arafat will lead the Palestinian Authority at the end of 2005. Perhaps many investors will lack a great deal of information on such questions, but it is most unlikely that the market prediction will turn out to be self-defeating. Of course the Policy Analysis Market itself raises many questions and doubts. The broader point is that in many domains, information markets are extremely promising, and likely to outperform both statistical means and the products of group deliberation.
Of course it will not always be feasible to use information markets. A jury, for example, could not enlist such markets to decide on questions of guilt or innocence and it is not easy to see how information markets could be used by judges. When the relevant
groups are small, effective markets may be impossible to create, simply because of the absence of significant numbers of investors.293 On the other hand, administrative agencies might well enlist such markets to resolve a number of questions,294 and ambitious efforts are underway to examine how government might enlist them to answer an array of disputed questions.295 Of course information markets might suffer from a legitimacy deficit, at least at the present time. Recall that deliberation increases confidence and decreases variance in many contexts, reliance on information markets might well breed confusion and distrust.296 But at a minimum, such markets should be used, where feasible, as an adjunct to deliberative processes.
Normative Questions and Group Judgments
Deliberating groups are often asked to answer questions that are not purely factual. Issues involving morality, politics, and law require assessment of normative issues. Should cost-benefit analysis be the foundation of regulatory decisions? Should the minimum wage be increased? Should capital punishment be permitted? Can the President be impeached for lying under oath? Should Roe v. Wade be overruled? Should the Constitution be interpreted to require states to reconsider same-sex marriages? When, if ever, is theft morally acceptable?
When people answer such questions, informational influences and social pressures are likely to play a major role. One study demonstrates group polarization with respect to outrage: When individuals are outraged about corporate misconduct, juries are systematically more outraged than their median member.297 And in fact group discussion often produces polarization on normative issues,298 in a way that strongly suggests the presence of hidden profiles. It is on normative questions, above all, the groups end up at a
more extreme point in line with their predeliberation tendencies. I have noted that in many domains, federal judges are subject to group polarization, with both Democratic and Republican appointees showing a tendency to extremism when they are sitting with like-minded others.299
It might be controversial to suggest that groups amplify individual errors, because in the normative domain, we might not be able to say, with confidence, that one or another view counts as an ?error.? Skeptics about morality and law, rejecting the view that moral and legal questions have correct answers, would insist that any shifts introduced by deliberation cannot be said to be right or wrong. But if they are correct, does deliberation have any point300? In any case skepticism is extremely hard to defend for law or morality. We may bracket the debate over whether legal problems have uniquely correct answers in hard cases301 while also agreeing that on multiple and diverse views about legal reasoning, some conclusions are right and others are wrong.302 If deliberation is often likely to lead people to err on questions of fact, it will also lead participants in law to blunder on questions of law. Suppose, for example, that the question is whether a regulatory agency has violated the statute that it is charged with administering, or whether a particular voting scheme violates the equal protection doctrine, or whether the impossibility doctrine relieves a contracting party of the duty to perform. In all of these cases, groups are likely to err if their deliberations are not structured in such a way as to overcome the risks of amplification of errors, hidden profiles, cascade effects, and group polarization.
In the moral domain, skepticism also runs into serious problems.303 Without engaging the complex philosophical issues, we can simply note that many different views
about the nature of morality acknowledge the possibility of individual error?and that if individual error does occur, group error will occur as well. As obvious examples, consider the persistence of slavery and racial segregation. As a less obvious example, consider the fact that people?s answers to many questions depend on how those questions are framed. The framing of options affects judgments not only on factual questions but on moral ones as well, including for example the disputed issue of moral obligations to members of future generations.304 As noted, groups do not show less susceptibility to framing effects than individuals,305 and hence groups will be vulnerable to framing for questions of morality and law as well as for questions of fact.
No information market could be helpful in answering normative questions, simply because there is no way to establish whether a particular investor was correct for normative questions, predictions are not being made at all.306 And for such questions, it might seem odd or perhaps even bizarre to rely on the judgments of statistical groups. To be sure, democratic processes might be seen as an effort to settle moral and political issues by seeking the mean view within the relevant population (views that are formed after deliberation, at least much of the time). But to say the least, it is controversial to claim that ordinarily moral and political questions are best answered by simply finding the mean views of a population-wide sample. Is the morality of abortion, or capital punishment, properly settled by asking for the average view of a group of, say, 1000 people? Is a legal question to be resolved by taking the median view of a large set of people trained in the law? Ordinarily moral and legal answers are found by reference to the reasons offered on behalf of competing positions, not by taking a poll.
Note, however, that empirical questions are often a central component of good answers to normative problems many such problems cannot be resolved without knowing something about the facts. The analysis of mistakes by deliberating groups should apply in full force to the factual components of normative questions. Consider, for example, the suggestion that the minimum wage should be increased. If minimum wage
increases would significantly decrease employment, surely that is relevant to the decision whether to support such increases and it matters too whether minimum wage increases would benefit poor people or mostly people who are not poor.307 To be sure, these are empirical questions on which experts are almost certainly far better than deliberating groups of ordinary people. The point is only that many normative questions cannot sensibly be resolved without information about the actual effects of one or another answer. When this is so, an understanding of the hazards of deliberation, and of how to minimize those hazards, can be used constructively by groups that are attempting to resolve normative questions.
Of course consequences may not be the central part of some normative disputes. Some people believe, for example, that capital punishment is morally unacceptable even if it has a strong effect in deterring murders, and evaluative judgments of various kinds can separate people even if they agree on the facts.308 But the more general point nonetheless holds: Sometimes a certain view of the facts can bring diverse people into line on normative issues, producing a single position despite disagreements on those issues. To this extent, the analysis here applies to normative questions as well. Group judgments on such questions will be distorted by the amplification of errors, hidden profiles, cascade effects, and polarization. It is important to take steps, of the kind that I have catalogued, to reduce those distortions.
What about for purely normative issues, lacking any factual component? Here the argument on behalf of group deliberation is not fundamentally different from what it is elsewhere.309 Unless we are relativists or skeptics, we will agree that one point of deliberation is to ensure that normative questions are correctly answered, that is, are answered by reference to good reasons, even if we disagree about what they are. And if this is so, then there is strong reason to be concerned, for normative questions no less than empirical ones, that group judgments will be impaired by the mechanisms traced here. The structural reforms have an equivalent role in the normative domain. We may therefore take the simple cases I have emphasized, in which deliberation leads to palpable
and demonstrable errors, to provide clear evidence of deliberative pathologies that are likely to occur even when errors are neither palpable nor demonstrable. If a central goal is to ensure that normative questions?in law, politics, and morality?are answered well, then the prescriptions I have outlined deserve a place for numerous deliberating groups, including those not centrally concerned with facts at all.
Groups often contain a great deal of information, and an important task is to elicit and use the information that members actually have. Deliberation is generally thought to be the best way of carrying out that task. But deliberative bodies are subject to serious problems. Much of the time, informational influences and social pressures lead members not to say what they know. As a result, groups tend to propagate and even to amplify cognitive errors. They also emphasize shared information at the expense of unshared information hidden profiles are a result. Cascade effects and group polarization are common.
What can be done by way of response? At the very least, it should be possible to structure deliberation so as to increase the likelihood that relevant information will emerge. A norm in favor of critical thinking, and incentives to reward individuals for good decisions by groups, can overcome some of the relevant pressures. Leaders should take steps to encourage a wide range of views to do this, leaders might be cautious about expressing their own views at the outset and encourage reasons, rather than conclusions, before the views of group members start to harden. Institutions might ensure anonymity and private polling before deliberation they might permit anonymous statements of final conclusions they might create strong incentives, economic and otherwise, to encourage people to disclose what they know.
Information markets have significant advantages over deliberative processes, and in many contexts they might supplement or even replace those processes. Such markets tend to correct rather than to amplify individual errors, above all because they allow shrewd investors to take advantage of the mistakes made by others.310 Because
information markets provide economic rewards for correct individual answers, they realign incentives in a way that promotes disclosure. As a result, they are often more accurate than the judgments of deliberating groups. To the extent feasible, many groups would often do well to enlist information markets in arriving at their judgments, above all because of the accuracy of the price signal.
My emphasis throughout has been on the aggregation of information and the risk that deliberating groups will err on instrumental questions and on issues of fact. But the same risks arise in the normative domain, where informational influences and social pressures also produce forms of self-silencing that are highly damaging to good deliberation. In that domain as elsewhere, incentives make all the difference wellfunctioning groups take steps to ensure that on normative questions as on factual ones, people feel free to disclose what they believe to be true.
