Which Risks First? 
Almost everyone agrees that in controlling risks, the United States does a poor job of setting priorities. Sometimes substantial resources are devoted to controlling small or even de minimis risks. Some serious problems receive little attention. Consider the following chart, showing dramatic disparities in amounts spent per life-year saved; note especially the disparities in the environmental context: EPA 5,700,000.0 
We should not read this evidence for more than it is worth. There is considerable uncertainty in the numbers. Environmental protection has many purposes in addition to the protection of human life, including prevention of adverse health effects short of mortality, aesthetic goals, recreational goals, and prevention of deaths and adverse health effects in animals and plants. These purposes should also be taken into account in deciding which risks are most serious. But we know enough to approve of the general consensus that better priority setting is a crucial task for the modern regulatory state. A recent study suggests that better allocations of existing expenditures could save an additional 60,000 lives at no increased cost, and that with better allocations, we could save the same number of lives we now save with $31 billion in annual savings.2 
We might even conclude that selective attention is the principal problem facing modern regulation. Too often government focuses on pieces or sides of a problem, failing to see that what is at work is a complex whole! (It is notable that the science of ecology and the discipline of economics are both fundamentally concerned with this fact.) Too often government fails to see that if it affects (or fails to affect) one aspect of an environmental problem, it will simultaneously affect other aspects as well, probably involving prices, employment, poverty, international trade, and other environmental problems. It is selective attention that, for example, produces the pervasive phenomenon of risk regulation that actually increases (some, or aggregate) risks.4 And it is selective attention that produces regulations that reduce certain environmental harms but in the process create a range of new and sometimes serious social problems. The problem of selective attention is aggravated by the role of the media, which quite generally focuses on sensationalistic pieces of problems, and by the role of powerful private groups, which can attempt to promote risk redistributionrather than risk reduction. 
On all this there is general and growing agreement. There is, however, no similar consensus on what better priority-setting would specifically entail. If a government not suffering from selective attention attempts to address the worst risks first, what precisely will it do? Some people suggest that government should 2 Tammy 0. Tengs, et al, Five-HundredLife-Saving Interventionsand Their Cost-Effectiveness, 15 Risk Analysis 369 (1995). 
' See Dietrich Dorner, The Logic of Failure: Why Things Go Wrong and What We Can Do to Make Them Right (Metropolitan 1996), for an intriguing discussion of computer simulations that highlight this problem. 
' See John D. Graham and Jonathan Baert Wiener, Risk versus Risk: Tradeoffs in Protectingthe Environment (Harvard 1995). engage in priority-setting by consulting the criterion of private willingness to pay.5 Some people think that the government should try to maximize the number of total lives saved.' If one program would save one hundred lives, and another eighty, the government should (other things being equal) begin with the first program. But other people, referring to pervasive differences between lay and expert evaluations of risk, reject this idea. They say that lay people have more complex, "richer" judgments about which risks are worst and that these judgments should govern regulatory policy. On this view, there is a danger that expert judgments will hide controversial ideas about rationality behind a technocratic smokescreen. 
In this Article, I reject both of these views. A basic assumption is that the American constitutional order is a republic, or a deliberative democracy, in which public representatives are not supposed merely to register existing judgments but "to refine and enlarge the public view."7 If the issue of risk regulation is seen in these terms, representatives should attend to reflective citizen judgments, but they should not treat those judgments uncritically or accept them regardless of the reasons offered on their behalf. Much less should they rely on private willingness to pay, which may reflect unrealistic optimism, ignorance, or confusion. And if we examine the reasons that underlie risk-related judgments, we will conclude that it would be obtuse to say that government should attempt to maximize the number of lives saved, no matter the source and nature of relevant risks. Lives are not fungible with lives; it matters a great deal for what purpose and in what context lives are being put in danger. But it would also be odd to rely entirely on lay judgments, which are frequently based on confusion, ignorance, and selective attention. When those judgments are based on misunderstandings of the facts, they should play no role in policy. 
I contend that government should attempt a three-step inquiry. First it should try to estimate decently-livable life-years saved, rather than total lives saved. Thus the first step in its analysis should be to see how much aggregate extension of decently-livable years can be brought about by different regulatory " See W. Kip Viscusi, Fatal Tradeoffs: Public and PrivateResponsibilities for Risk (Oxford 1992). 
' This is the tendency in Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation (Harvard 1993). 
' Federalist 10 (Madison), in Max Beloff, ed, The Federalist45 (Basil Blackwell 2d ed 1987). initiatives. The second step should incorporate lay judgments to the extent that these are based on reasonable judgments of value rather than factual error or selective attention. In this way, regulators should ask if regulatory priorities should be shifted from the aggregate measure by exploring whether there are important qualities in the context that call for a shift. The key questions here are: -Is the risk inequitably distributed? -Is it especially dreaded? -Is it run involuntarily? -How easily can it be controlled by those exposed? 
Answers to these questions may call for an adjustment of the first-stage judgment. As we will see, however, the second two questions raise complex issues, for risks are not "voluntary or not" or "uncontrollable or not," but instead come with small or high costs of avoidance. The ordinary criterion of decently-livable life-years should be adjusted upward when the costs of risk avoidance are especially high, and adjusted downward when the costs of risk avoidance are especially low. The third step consists of an incorporation of effects short of mortality, including (but not limited to) morbidity, adverse effects on aesthetics and recreation, and mortality effects for plants and animals. 
The discussion of defects in ordinary judgments about risk-unrealistic optimism, heuristics that produce error, and so forth-leads to a degree of skepticism about the criterion of "private willingness to pay," and I offer a few words against the economists' conventional approach. I also discuss institutional arrangements that might help both to ensure that government attacks the worst risks first and to ensure that technocratic and democratic goals are simultaneously promoted by government regulation. 
Many economists attempt to respond to the question of how to engage in sensible priority-setting through the criterion of private willingness to pay ("WT P").8 There are several advantages to resolving environmental questions via this criterion. For one thing, WTP provides simultaneous information on costs and benefits. This is important because an emphasis on decently' See, for example, W. Kip Viscusi, Fatal Tradeoffs: Public and PrivateResponsibilities for Risk (Oxford 1992). livable life-years looks at the benefit side without looking at costs. To know how to proceed, it is of course important to know both. For another thing, WTP appears to have democratic virtues, since it allows risk regulation to be made by consulting actual public judgments. And there can be little doubt that use of WTP would produce more coherence and rationality than the crazy-quilt pattern we now observe. 
Nonetheless, there are three serious problems with proceeding in this way. The first problem is that private willingness to pay may well reflect factual errors, and factual errors should not be a basis for regulatory policy. The second problem is that the available methods for measuring willingness to pay--contingent valuation methods and revealed preference methods--have serious defects. The third problem is that willingness to pay reflects a category mistake; it sees government as a kind of "maximizing machine," attempting to aggregate private preferences. Although much can be gained by consulting private preferences, this is a misconception of government's duties. 
The first problem-reflection of factual errors-is the simplest. People may be willing to pay a great deal to live far from a nuclear power plant; but by itself, this fact does not mean that government should devote a great deal of money to ensure that nuclear power plants are located far from people. By contrast, people may not be willing to pay much to reduce risks from particulate matter; but if particulate matter is a serious contributor to respiratory problems and asthma, the low willingness to pay should not be used for purposes of policy. As we will see, ordinary people frequently lack or misunderstand relevant information and rely on heuristics that produce large-scale mistakes. Those mistakes should not be incorporated into law. 
Perhaps willingness to pay can be based not on factual judgments but on something more abstract, such as the willingness to pay for a statistical life; if so, the factual errors need not be incorporated, and we can rely on the basic criterion. Certainly this idea would produce improvements upon the haphazard and irrational status quo. But it too raises serious problems.9 There is the initial problem of deciding between willingness to pay (how much a person would pay for environmental improvement) and willingness to accept (how much a person would have to be paid to permit environmental deterioration); the relevant numbers 
I borrow in the next several paragraphs from Richard H. Pildes and Cass R. Sunstein, Reinventing the Regulatory State, 62 U Chi L Rev 1 (1995). may be substantially different, and it will be necessary to choose between them.1" This may not be a fundamental objection; perhaps the two numbers can set ceilings and floors, and that itself may be an advance. But many regulatory goods are not traded on markets, and hence "contingent valuation" methods must be used. Rather than looking at actual choices, these methods ask people hypothetical questions about how much they would be willing to pay to avoid certain harms or conditions. The most advanced methods involve lengthy interview sessions designed to provide information, give a sense of context, and allow discussion in a way that fosters deliberative results.1 
Much recent work with contingent valuation techniques has sought to elicit values for different states of health. In such studies, for example, people purport to be willing to pay a much greater amount to avert cancer deaths (from $1.5 million to $9.5 million) than unforeseen instant deaths (from $1 million to $5 million). 2 More generally, this work generates tables like the following: 3 Similarly, these survey techniques purport to show that people value days of illness-from coughing spells, headaches, nausea, sinus congestion, and so forth-in diverse amounts. 4 
Despite their apparent promise, contingent valuation methods have serious limitations. For one thing, it is difficult to believe that people answering hypothetical questions can assign '3 IIdd aatt 39492.. meaningful dollar values to various possible health or other risks. The more context-sensitive the method attempts to become, the more its hypothetical nature becomes problematic, bordering on the fantastic. The leading practitioners of contingent valuation purport to discover that people are willing to pay $90 to have a day of relief from angina if they have had it for only one day, but $288 for ten days of relief if they have had angina for twenty days. 5 It is hard to take these figures seriously. In economic terms, people have a difficult time assigning hypothetical dollar values to bundles of commodities they virtually never confront in everyday experience. 
Moreover, the results of contingent valuation studies suggest that the answers do not show actual valuation of relevant commodities. A special problem is that of "indifference to quantity," reflected in the astonishing and devastating fact that people will give the same dollar number to save 2000, 20,000, and 200,000 birds--or the same number to save one, two, or three wilderness areas."6 Relatedly, the valuation of a resource is much affected by whether it is offered alone or with other goods. Willingness to pay for spotted owls drops significantly when people are asked to value the owl with and in comparison to other species. This evidence suggests that people may be purchasing moral satisfaction rather than stating their real valuation. 7 It is pertinent in this connection that the order and number of questions seems crucial in determining valuation. When asked for their willingness to pay to preserve visibility in the Grand Canyon, people offer a number five times higher when this is the first question than when it is the third question." 
Would it be better to look at actual choices and thus to rely on revealed preferences? Some imaginative and provocative approaches attempt to determine the "value of life" by assessing willingness to pay for risk reductions. 9 The Office of Management and Budget has explicitly supported the willingness-to-pay criterion on the ground that it provides "an aggregate measure of what individuals are willing to forgo so as to enjoy a particular " Id at 89. The dollar figures are mean bid values, and relief means a "mild day." 16 See Peter A. Diamond and Jerry A. Hausman, Contingent Valuation: Is Some Number Better than No Number?, 8 J Econ Persp 45 (Fall 1994); Daniel Kahneman and Ilana Ritov, Determinants of Stated Willingness to Pay for Public Goods: A Study in the HeadlineMethod, 9 J Risk & Uncertainty 5 (1994). 
" See Kahneman and Ritov, 9 J Risk & Uncertainty 5 (cited in note 16). IS See id. " See Viscusi, FatalTradeoffs at 19-21 (cited in note 8). benefit."2" This approach appears to be prevalent in the agencies, where it results in a number of between $1 million and $8 million per life saved. 1 
But there are several problems with willingness-to-pay approaches based on actual market transactions. As noted, market behavior may reflect a lack of information about risks or cognitive problems and motivational influences that lead to inaccurate judgments about the facts.22 To be sure, workers are sometimes informed of risk levels and they can demand a risk premium; but to say the least, full information about workplace risks is rare, especially in light of the fact that some risks depend on complex causal mechanisms and take many years to come to fruition. There are possible motivational distortions as well. Wishful thinking and the desire to reduce cognitive dissonance-by thinking that you are not, in your daily work, exposing yourself to some cancer risk-may lead people to see risks as lower than they really are.' 
It is notable in this connection that people appear to be "risk optimists." They typically believe that they are less likely than other people to fall prey to social dangers. Thus the vast majority of drivers believe that they drive more safely than most drivers; thus most homosexuals believe that they are less likely than others to get AIDS; thus with respect to most hazards, people believe that they are at lower risk than the mean. I discuss this point in more detail below. 
Finally, willingness to pay measures ignore the distinction between the valuations people express in private, market transactions and those that they express in democratic arenas. What people are prepared to pay as private consumers is often, and appropriately, different from what they think society (and they, as members of society) ought to pay to avoid certain risks. Much empirical evidence confirms this point; for example, "[p]eople were, in fact, found on average to bid more for an improvement " See Office of Management and Budget, Regulatory Programof the United States Government, 1990-1991 (GPO 1992). The Administrative Conference reached a similar conclusion, though more cautiously. See Recommendations of the Administrative Conference Regarding Administrative Practice and Procedure and Correction, Recommendation No. 88-7, 53 Fed Reg 39585, 39586-87 (1988). 
21 See Ted R. Miller, Willingness to Pay Comes of Age: Will the System Survive?, 83 Nw U L Rev 876, 886-89 (1989). 
See Part III for further discussion. 
2 See Elliott Aronson, The Social Animal (W. H. Freeman 7th ed 1995); George A. Akerlof and William T. Dickens, The Economic Consequences of CognitiveDissonance, 72 Am Econ Rev 307, 307-08 (1982). for everyone in the United States than for just themselves."24 Judgments made in the context of democratic choice are designed to elicit different motivations and different considerations from those made in market transactions. Through exchange of different perspectives, collective decision making, and social-regarding reasoning, democratic arenas produce distinctive valuations. Partly this is a product of social norms;' partly it is a product of the fact that in the democratic setting, people are aware of the fact that whatever they are doing, they are doing it together. 
There is a further point, having to do with the phenomenon of "adaptive preferences." 21 People may well adapt their conduct and even their desires to what has been available. Consider here the story of the fox and the sour grapes. The fox does not want the grapes because he considers them to be sour; but his belief to this effect is based on the fact that the grapes are unavailable. It is therefore hard to justify their unavailability by reference to his preferences.27 In the environmental context, it might be hypothesized that the preference for environmental quality will be especially weak among people who have not been exposed to pristine areas, clean water, and clean air. If the point is right, it has important implications for positive and normative work.2 
Akerlof and Dickens have argued that workers are unwilling to confront the real magnitude of environmental risks faced in the workplace, because it is too distressing for them to do so.29 On this view, workers, having adapted their preferences and beliefs to a relatively risky status quo, attempt to reduce cognitive dissonance by concluding that the dangers are trivial. The claim is speculative and the relevant evidence is largely anecdotal. But there is some empirical support for the general view. Consider the fact that after the Three Mile Island nuclear power plant accident, it was the people who lived on Three Mile Island who, of all those polled, believed that the relevant risks were lowest."0 
If the general claim is right, it would follow that the demand for environmental legislation might be relatively low among people deprived of exposure to environmental quality, and this phenomenon would be attributable to adaptation of preferences to what is available. It is extremely difficult to test this hypothesis against more 'conventional alternatives stressing learning and rational choice under conditions of deprivation. We might, however, begin to investigate the demand for environmental protection across regions and across nations. It would be especially valuable to see how the demand for environmental quality changes over time, perhaps with exposure to pristine areas, perhaps with a social belief that the degradation of environmental amenities is not inevitable, perhaps with the rise of organizations solving collective action problems of various sorts. 
As a normative matter, it might also follow that existing preferences, as expressed in consumption choices, are an uncertain basis for regulatory policy, since we cannot without circularity justify regulatory outcomes by reference to preferences that those outcomes have generated. Of course, it is right to insist that government should usually respect private choices, partly because of the frustration and resentment that are produced by efforts to bring about change, partly because of the constant risk of ignorance and bias on government's part. But if what I have said here is true, it will be necessary to rethink the under-analyzed and vexing issue of paternalism, in environmental law and elsewhere. 
Let us put willingness to pay to one side and ask what government should attempt to maximize in regulating risks. This is a question of great theoretical interest; but it also has considerable practical importance. Any answer should meet two constraints. First, it should be acceptable from the theoretical point of view. Second, it should be administrable, that is, it should be something that real-world officials can actually use. The two constraints are mutually checking. A theoretically excellent answer 
See Aronson, The Social Animal at 176-78 (cited in note 23). See also the discussion in Part III.B.1 of unrealistic optimism as a distorting factor. It is possible, of course, that the people who lived in this area were better informed. might be rejected because it is too complex or unwieldy, or because it imposes unrealistic informational demands on government. (Some forms of cost-benefit analysis, unaccompanied by constraints on what count as costs and benefits, run afoul of this objection.) A practically useful answer might be indefensible from the standpoint of theory. 
In recent years, many observers and some regulators, seeking a practical answer to the question what they should maximize, have focused on numbers of lives saved."' They decide which risks to regulate first by exploring the aggregate number of lives at risk. Thus many agencies attempt to specify that number in the course of making regulatory choices. In the environmental context, this is a promising start. A program that saves one hundred lives seems better than a program that saves two lives. (Of course to get a full picture, we must add gains in terms of morbidity, aesthetics, recreational opportunities, and tourism as well.) If this is our standard, much progress might be made by attending to the number of lives in danger from various "preventable" risks:32 " This idea is emphasized in Stephen Breyer, Breaking the Vicious Circle: Toward Effective Risk Regulation (Harvard 1993). 
32 j. Michael McGinnis and William H. Foege, Actual Causes of Death in the United States, 270 JAMA 2207, 2208 (1993). 
' The notion of decently livable life years is intended as an improvement on the highly influential standard proposed by Richard Zeckhauser and Donald Shepard, Where Now For Saving Lives, 40 L & Contemp Probs 5, 11-45 (Autumn 1976), which uses the notion of "quality-adjusted life years." For general discussion, see George Tolley, Donald Kenkel, and Robert Fabian, eds, ValuingHealthfor Policy:An Economic Approach 290-94 (Chicago 1994); George W. Torrance, Measurementof Health State Utilities.ForEconomic Appraisal:A Review, 5 J Health Econ 1 (1986). The notion of decently livable life-years is gram "saves lives"; at best it extends them. Compare two regulations. The first extends the lives of one hundred elderly people, but in doing so, it gives them five additional years, accompanied by considerable pain and distress. The second extends the lives of eighty children, and in doing so, it gives each of them a statistical likelihood of fifty or more years of life. The second policy seems preferable to the first along two important dimensions. First: Lives are certainly not fungible, but where regulatory resources are limited and where choices have to be made, it makes sense (other things being equal and as an administrable start) to save as many years as possible. Other things being equal, many years should be chosen over few. Second: If government has a choice between preserving lives in a way that ensures decentlylivable years and preserving lives in a way that ensures a barely functional and extremely painful continued existence, it should choose the former. To someone who has a choice between death and five years of constant and considerable pain, the latter will probably seem a lot better; but for government regulators, it is preferable to provide five good years rather than five difficult ones if there is a choice. We might conclude, then, that government agencies should shift their attention from "lives saved" to "decently-livable life-years saved." 
Notably, the idea of decently-livable life-years is designed to set a floor, not to give some numerical amount to each such year in terms of its overall "quality." The floor might be defined in various ways; I understand it to refer to basic functional capacity. Thus someone who has chronic asthma certainly can live a decently-livable life. Someone who is confined to a hospital cannot. It is easy to imagine borderline cases, and perhaps the floor should be moved up or down, but the notion should have a degree of simplicity and should allow administrators to put to one side some of the harder questions. It is a modest variation on the idea of life-years saved; it subtracts from that amount the number of years saved that, because of some independent condition, are not decently-livable. 
Along this dimension, the idea of decently-livable life-years is far simpler than its close cousin: quality-adjusted ife-years.24 Its simplicity is in some ways a vice but also one of its virtues; instead of adjusting life-years for quality, every life-year above a simpler than quality-adjusted life-years and for that reason is more easily administrable as well as less contentious. 
' See Zeckhauser and Shephard, 40 L & Contemp Probs 5 (cited in note 33). certain floor counts for no less and no more than one. Of course scientific information currently leaves doubts about how many life-years are at risk, and frequently the best that can be done is to specify a range. But this very point suggests that decentlylivable life-years has another advantage over quality-adjusted life-years: it imposes a less severe cognitive demand on government. Specification of the "quality" of lives aided by regulation can be an extremely demanding task. 
In addition to simplicity, the idea of decently-livable lifeyears has the advantage that it is less contentious, and properly so. It is controversial to suggest that people with a chronic problem (respiratory difficulties, for example) deserve less in the way of regulatory help than people without such a problem. To devote resources to those who are suffering no difficulties, at the expense of those who, while functional, have a health problem, is to raise hard questions of equity. It is far less controversial to say that the government will treat everyone above a certain floor the same. 
A shift from lives saved to life-years saved makes a good deal of sense and has a degree of simplicity; but the notion of decently-livable life-years raises many questions. This is not a purely statistical inquiry; it has evaluative dimensions. The best way to handle the resulting problems is to recognize that a judgment of policy is being made and to ensure that that judgment is made by people who are subject to appropriate constraints, informed about relevant facts, and politically accountable. 
An especially controversial issue lurks in the background: it is possible that some lives might be considered not decently-livable because of unjust or highly disadvantageous social conditions. Desperately poor people, for example, may lack decent life prospects already, and a small incremental reduction in their health may seem to push them below the relevant "floor." For purposes of regulatory policy, this ought not to be counted. If it did count, regulatory policy would be devoted to the protection of those already well-off and to the neglect of those in desperate conditions; thus one social injustice would be compounded by another. The question is whether the saved years meet a decent floor, and it should be stipulated that this criterion is met by lives filled with extreme difficulty because of social and economic deprivation alone. 
Social psychologists have uncovered a number of distinctive characteristics of ordinary human judgments about risks. 5 Much of the remainder of this paper will be focused on those characteristics and on their role in regulatory policy. How, if at all, should the basic criterion of decently-livable life-years saved be qualified? Consider, for example, the following table, showing differences between expert and lay judgments about which risks are most serious: 6 
In this section, I discuss judgments that should not, in my view, play a role in government regulation. The most general ' See, for example, Daniel Kahneman and Amos Tversky, Judgment Under Uncertainty: Heuristicsand Biases 3-20 (Cambridge 1990); Paul Slovic, et al, Regulation of Risk: A PsychologicalPerspective,in Roger G. Noll, ed, Regulatory Policy and the Social Sciences 241 (California 1985). 
(Harvard 1993 conclusion is simple: Ordinary judgments should not be controlling when they are based on factual errors. When human judgments depend on heuristics or "frames" that produce mistakes, regulators should not rely on them. But some of these judgments are not easy to characterize, and they raise some questions about the nature of rationality (from the normative point of view) in this context. 
It is predictable that some people will find risks of special concern when they disproportionately affect white people or heterosexuals; risks that affect blacks and homosexuals may well be undervalued. Here, there is a judgment that distributional considerations properly enter into the calculus, and that some risks, because of their distribution, are properly neglected. As we will see, distributional decisions can play an appropriate role in regulatory policy. But where the relevant judgments are invidious, they do not belong. Of course, we can enter into reasonable debates about how to evaluate some judgments. The easiest cases involve a constitutional prohibition on distributional judgments, as for example in the prohibition on measures motivated by prejudice grounded in gender and race. But government might reasonably decide that certain judgments are unacceptable even if they are not unconstitutional. 
B. Misunderstandings of Facts and the Role of Heuristics 
People frequently misstate probabilities. If people are asked to rank various risks in terms of severity, they may well make factual blunders. s7 Some of their judgments about "severity" undoubtedly turn on judgments about value." But it is safe to say that factual mistakes are often at work. 
overconfidence. 
People tend to think that risks are more likely to materialize for others. Thus, there is systematic overconfidence in risk judgments, as the vast majority of people believe that they are less likely than other people to be subject to automobile accidents, "7Of course, judgments of severity may well be based on values as well as facts, and here things are more complex. See discussion in Part V. 
See Slovic, et al, Regulationof Risk (cited in note 35). infection from AIDS, heart attacks, asthma, and many other health risks.89 In one survey, for example, 90 percent of automobile drivers considered themselves to be above-average drivers.' Â° In another survey, students asked to envision their future said that they were far less likely than their classmates to be fired from a job, to have a heart attack or to get cancer, to be divorced after a few years of marriage, or to have a drinking problem.4' 
Reflecting illusions about their own practices, gay men appear systematically to. underestimate the chance that they will get AIDS, even though they do not lack information about AIDS risks in general. 2 Older people similarly underestimate the likelihood that they will be in a car accident or contract major diseases. Unrealistic optimism appears to characterize people in most social categories." People systematically underestimate the extent to which they are at risk, and perceptions of relative invulnerability affect preventive health practices." Consider, for example, the following table, based on a random community-wide survey of attitudes toward health risks; a number below 0 suggests a belief in above-average immunity from the relevant risk: 
Table 5 
Hazard Description Drug Addiction Drinking (alcohol) problem Attempting Suicide Asthma Food Poisoning Poison Ivy rash Sunstroke Nervous breakdown Homicide victim Gallstone Deaf Pneumonia 
Mean -2.17*** -2.02*** -1.94*** -1.36*** -1.25*** -1.19*** -1.17*** -1.15*** -1.14*** -.84"** -.82*** -.80*** 9 See Neil D. Weinstein, Optimistic BiasesAbout PersonalRisks, 246 Science 1232 (1989). 
Shelley E. Taylor, Positive Illusions 10-11 (Basic 1990). 
Id at 33. 
42 Laurie J. Bauman and Karolynn Siegel, MisperceptionAmong Gay Men of the Risk for AIDS Associated With Their Sexual Behavior, 17 J Applied Soc Psych 329 (March 1987). 
4 Id. 
Id at 330-331. 
's Reprinted from Neil D. Weinstein, UnrealisticOptimism About Susceptibility to HealthProblems: Conclusionsfrom a Community-Wide Sample, 10 J Behav Med 481, 486 (1986). 
Evidence of this kind much complicates the view that people often overstate low-probability events. It is true that people may think that low probability events have higher probability than they in fact do. But many individual agents think that they are peculiarly less susceptible to such events, which may mean that they err in the other direction. 
People tend to think that risks are more serious when an incident is readily called to mind or "available."4 If pervasive, the availability heuristic will produce systematic errors. Assessments of risk will be pervasively biased, in the sense that people will think that some risks (of a nuclear accident, for example) are high, whereas others (of a stroke, for example) are relatively low. 
Often people make probability judgments on the basis of an initial value, or "anchor," for which they make insufficient adjustments. 47 The initial value may have an arbitrary or irrational source. When this is so, the probability assessment may go badly wrong. Thus, for example, people may think that the probability of getting AIDS is very low, or very high, and the anchor may not be readily revised. 

Judgments about probability are in large part judgments about whether some process A will bring about some event B. Under what circumstances will driving produce significant increases in air pollution or fatal accidents? When will airbags produce risks to children? Do disposable diapers cause pollution problems? In answering such questions, people ask about the extent to which A is representative of B in the sense that it re.sembles B. People tend to be insensitive to the sample size, to misunderstand the phenomenon of regression to the mean, to have excessive confidence in their own judgments, and to misun.derstand the effect on probability of base-rate frequency." As EL result, people may systematically misunderstand risk levels. 
People have a hard time understanding and evaluating risks that they view in isolation from other risks. Problems emerge when a risk is taken to be much larger than it is, simply by vir-. tue of the fact that it is not placed in context with other risks and events. Sometimes individual judgments, and even social. policies, may emerge because of this effect. 
Here we are dealing not with factual errors, but with "tastes" or preferences that lead people to favor certain approaches to risk. Probability-related tastes present harder questions for the policy analyst. 
People greatly prefer the elimination of a risk over the diminution of a risk, even when the aggregate reduction is the same. Thus it appears that people would much rather see a risk of .001 reduced to zero than a risk of .002 reduced to .001."' It is not 35). 
Id at 63-98. 
,' See Donald A. Redelmeier, et al, UnderstandingPatients'Decisions: Cognitive and Emotional Perspectives,270 JAMA 72, 73 (1993). ple would require a great deal to allow someone to subject them to a new risk; they would pay a great deal less to prevent someone from subjecting them to an existing risk. 
Should government indulge status quo bias, that is, should it impose special barriers to new risks, and be less concerned about old risks? In view of the dramatic number of existing and new risks and the ever-changing nature of any particular status quo, it is far from clear that it should. I take up this question in more detail below. 
Some risks produce a great deal of concern and disturbance regardless of their level; some risks appear as "background noise" and do not create much concern even if their magnitude is high. Human beings are, in short, selectively fatalistic. We lack an account of why people adapt themselves to certain risks but not others; undoubtedly the novelty of the risk matters, and people sometimes adapt themselves to risks that they cannot control. But it is hardly clear that policymakers should follow a selectively fatalistic population; perhaps people are fatalistic about risks that are large and easily diminished, and perhaps they are the opposite of fatalistic-alarmist-about risks that are small and controllable only at high cost. What matters is the source of their fatalism. The most that might be said is that regulators should consider whether a risk comes with low or high costs of adaptation. 
IV. WHAT SHOULD COUNT 
Thus far I have been focusing on heuristic devices and other cognitive processes that lead people to misassess risks. Social psychologists have spent a great deal of time discussing these devices and processes. My basic claim has been that government should be aware of these tendencies to make factual errors and should be on guard against them. 
Social psychologists have also, however, uncovered a quite different source of variation between lay and expert judgments of risk.52 In brief: Experts tend to focus on aggregate lives at stake. Ordinary people-on the now-conventional account-look at a range of more qualitative variables. They care not simply about number of lives at risk but also about whether the risk is equitably distributed, potentially catastrophic, controllable, voluntarily incurred, and so forth. Here is a compilation: 
Table 7' Influencing Factor familiarity personal control voluntariness media attention equity children future generations reversibility dreadedness identifiability of victims accompanying benefits human or natural origin trust in applicable institutions timing of effects understanding past history 
Aggravating new uncontrollable involuntary focussed on by media unfairly distributed children at special risk at risk irreversible especially dreaded victims known benefits clear human origin lack of trust 
Mitigating old controllable voluntary ignored by media equitable distribution children not at risk not at risk reversible not especially dreaded victims not identifiable benefits not visible created by nature good deal of trust effects delayed effects immediate mechanisms or process mechanism or process not understood understood major or minor accidents no past accidents 
Which, if any, of these factors should play a role in regulatory policy? For simple democratic reasons, it might seem tempting to say that all of them should. But this would be a mistake. Sometimes it is hard to separate them from heuristics and factual errors; media attention, for example, is closely connected with the availability heuristic, and we should not think that because the media are focused on a certain risk, government should gave that risk special attention too. (In fact, this is a pathology of regulatory policy.) Past history should be similarly understood; it is a rough proxy for future probability, not a reliable guide to the future. So too with trust. If people do not trust an institution's assurances, they are thinking that the risk is more serious than they are being told. Some of these factors may be a result of framing effects or of a process of selective attention.54 And some of them are easily accounted under the "life-years saved" criterion. If children and future generations are at risk, for example, more life-years are at stake. 
There is, moreover, a puzzle in the fact that people treat as quite serious death-risks that are microscopically small as a statistical matter, while risks that are statistically much larger are treated as "just a part of life." It is certainly possible that people's judgments about risk severity are partly a product of some of the more qualitative considerations listed above; this idea leads to the widespread view that ordinary people have a "richer" rationality than do experts, since ordinary people look at the nature and causes of death, not simply at aggregate deaths at issue. But as Howard Margolis has shown, it is also possible that an apparently "rich" judgment that a certain risk is severe, or not severe, depends not on well-considered judgments of value, but instead on the absence of ordinary contextual cues, on heuristic devices that are not well-adapted to the particular context, or instead on a range of confusing or confused ideas that people cannot fully articulate.55 When people say, for example, that the risk of nuclear power is very serious, they may be responding to their intense visceral concern, possibly based on (uninformed) statistical judgments about likely lives at risk, and on their failure to see that that risk comes accompanied by a range of social benefits. The fact that nuclear power produces benefits as well as risks may not "register" on the viewscreen, and this may help Id. 
I borrow here from the important discussion in Margolis, Dealing With Risk (cited in note 52). 
THE UNIVERSITY OF CHICAGOLEGAL FORUM produce a "high risk" judgment." And when people are asked what underlies that judgment, they may point to qualitative considerations that operate as after-the-fact explanations for the visceral concern, and that are not causes of that concern. 
For automobile accidents, by contrast, people's uninformed statistical judgment may not lead to overestimates of risk or visceral judgments of intense concern, partly because people are well aware that automobile travel produces high benefits as well as costs. Thus, it is possible that a judgment that a certain risk of death is unusually bad is based on an intuitive balancing that prominently includes perceived lives at stake and the perceived presence of small or no benefits associated with the risk-producing activity. And when people are asked to'say why they believe that some risk is especially bad, their answers may not be truly explanatory, but instead rationalizations of more visceral judgments based on other grounds. In other words, the reasons given may not actually lie behind the judgments; people are in fact not very good at giving subjective accounts of what underlies their judgments.57 
All this raises the possibility that people's references to "control" and "involuntariness" may not explain the actual basis of their judgments. This possibility remains to be investigated and tested. For the moment, let us put this possibility to one side and assume that the psychological evidence does suggest that certain risks are perceived as bad very much for more qualitative reasons. The important question is which reasons justify a qualification of the basic criterion of decently-livable life-years. Here are the strongest candidates. 
People seem to think that some risks are especially dreaded and that for this reason they deserve special attention. Deaths from cancer and AIDS fall in this category. There is nothing mysterious to this idea; it need not be taken to suggest any special conception of rationality. The underlying point is probably that the relevant deaths are especially grueling and hence that there is a kind of "pain and suffering premium" on the relevant death: not merely a life lost, but a period of intense emotional '5 See Ali S. Alhakami and Paul Slovic, A PsychologicalStudy of the Inverse Relationship Between Perceived Risk andPerceived Benefit, 14 Risk Analysis 1085 (1994). " See Margolis, Dealingwith Risk (cited in note 52). and physical difficulty as well. This period of intense difficulty might produce "costs" for those with the illness and for friends and family members as well. Sudden, unanticipated deaths cari be dreaded too-consider the idea of dying in an airplane crash-but the relevant premium is lower because it lacks the same degree of suffering. The best way to handle this factor is to supplement the criterion of "decently-livable life-years" in such L way as to take account of the pain and suffering associated with certain deaths. 
Some risks are inequitably distributed. They might, for example, be concentrated among poor people or African-Americans, or instead among homosexuals. Consider, for example, the risk of lead paint poisoning suffered by inner city children, or the risk of AIDS faced disproportionately by African-Americans, poor people, and homosexuals. It is fully legitimate for citizens or for elected representatives to think that inequitably distributed risks deserve special attention from government, as a way of counteracting background injustice. If the distributional judgments are not. invidious, it makes sense to defer to democratic judgments on the point. 
Thus regulators should be permitted to give distributional weights to risks whose distributional incidence is especially troublesome. This point supports special efforts to control environmental risks like asthma, which are concentrated in the inner city, and also to prevent the spread of diseases like breast cancer, whose incidence is concentrated among women. 
It is clear that people perceive voluntarily incurred risks as less troublesome than involuntarily incurred risks. Consider, for example, diverse public reactions to airplane crashes and automobile crashes. Or consider the fact that tobacco is by far the largest source of preventable deaths in the United States. Why do we not devote much more of our regulatory effort to smoking? The reason seems to lie in a judgment that smoking is a voluntary activity and hence that the resulting deaths are less troublesome than are other sorts of death. 
Many people have suggested that the lay judgment to accord greater weight to "involuntary" risks shows a richer conception of rationality and therefore deserves deference from government. But a simple reference to voluntariness, when taken to suggest something special about "lay rationality," raises many puzzles. Most important: How do we know when risk is voluntarily incurred? "Voluntariness" is not a simple question of fact, and it is not, in the cases we are discussing, an all-or-nothing matter. Consider the fact that airplane crashes are conventionally thought "involuntary" and automobile crashes more "voluntary." Certainly it would be possible to see the risks from air travel as voluntarily run; certainly people have a choice about whether to fly, and when they do fly, they pay a certain amount for a certain package, including risks of various sorts. The same is true of automobile safety. The difference between the two risks is hardly so categorical as to justify an assessment that they provide poles of voluntariness and involuntariness. Indeed, it is not clear even what is meant by the suggestion that one is voluntary and the other is not. 
To shed more light on the issue, let us consider three classes of cases. First, consider the question whether workers exposed to cancer risks are voluntarily or involuntarily so exposed. If workers do not know about such risks-if they lack relevant information-we seem to have an easy case of involuntariness. Thus it makes sense to say that risks are run involuntarily when the people running them do not know about them. Lack of information provides a legitimate case for a judgment of involuntary exposure to risk. Of course, information itself can be obtained at some cost, pecuniary or otherwise. We are thus dealing, in cases of this kind, with high costs of risk avoidance in the form of high costs of acquiring relevant information. 
Second, suppose that people who are exposed to a certain risk are aware of the risk, but are not in a contractual relation with the risk-producer. It is easy to imagine that some victims of pollution are in this position. People in Los Angeles may well know that they face high levels of smog. Are they exposed involuntarily? If we conclude that they are, we may mean that a risk is incurred involuntarily when and in the sense that it is typically very expensive for people to avoid it-and when someone else is the cheapest cost avoider. Consider ordinary people subject to cancer risks from toxic air pollutants. Here a claim that the risk is faced "involuntarily" may mean that those who "run" the risk can reduce it only at very high cost, at least compared with those who "produce" the risk. (The quotation marks are necessary for obvious Coasian reasons.) 
But turn now to a third class of cases, involving a wage package or contract that does include compensation for the relevant risks. Assuming that point, we might want to distinguish between two different possibilities. In a case of a high-level scientist, knowledgeable about relevant risks and involved in work that he finds rewarding, we might well conclude that we have a case of voluntariness. (In the same category can be found the case of an astronaut.) But we might not say the same about a low-level worker who does not like his work at all." But what distinguishes the two cases? If knowledge is present, or if the compensation package includes payment for the relevant risk, it is not clear how the two differ. It may be that the reason for running the risk seems in some way better or more worthy in the first case than in the second, but this is not a distinction along the dimension of voluntariness. Thus a judgment that a risk is run "involuntarily" is probably based on 1) a lack of knowledge of the risk, or, more accurately, high costs of obtaining information about the risk, 2) a belief that even if information is present, it would be very costly or difficult for people to avoid the risk, or 3) a belief that the risk is unaccompanied by benefits that people incurring the relevant risks find satisfactorily compensatory in some subjective sense, notwithstanding their belief that the contract is in some sense worth signing. It may seem hard to make sense of the third alternative; what might be at work is a judgment that background inequalities are producing the relevant bargain, or a belief that workers are competing to their collective detriment, and an agreement not to compete would be in their best interests.59 
On this view, the question whether a risk is run voluntarily or not usually is not a categorical one but instead is a question of degree, associated with information, risk-reduction costs, and the existence or absence of accompanying benefits. Of course there are interesting background questions about why and when a risk "codes" as voluntary or involuntary; undoubtedly the answer depends a great deal on heuristic devices and selective attention. 
We might therefore conclude that whether a risk qualifies as involuntary raises many of the questions raised by the question whether government should regulate the market at all. A risk might be characterized as involuntarily run because affected See Elizabeth Anderson, Value in Ethics and Economics 196-203 (Harvard 1993). 
See Robert H. Frank, Choosingthe Right Pond:Human Behaviorand the Quest for Status (Oxford 1983). people lack relevant information; because the transaction costs of bargaining are high; because the risks should be seen to amount to "externalities"; because collective action problems make market outcomes unsatisfactory since, for example, workers are in a prisoner's dilemma best solved through law; or because some motivational or cognitive defect makes successful solutions through markets unlikely. These, of course, are among the conventional grounds for regulation in the first instance. When a risk seems voluntary, and not worthy of substantial regulatory resources, the term "voluntary" is serving as a placeholder for an argument that there is no sufficient ground for government action, because the accompanying benefits are high or the riskreduction costs are low, and because market arrangements take adequate account of these facts. 
From this point we should conclude that a lay judgment that a risk is "voluntary" should not be decisive. A better understanding of what factors underlie and support that judgment should be used for purposes of regulatory policy. The basic criterion of decently-livable life-years might, then, be adjusted upward when those at risk lack relevant information or when the costs of riskavoidance are especially high-or downward when those at risk have the information and when the costs of risk-avoidance are low. 
People find risks less acceptable if those risks do not seem to be within their control. Automobile accidents may seem less troublesome than airline disasters partly for this reason. People have a sense that they cannot control the latter, which are hence wholly involuntary, whereas they can control the former, which have a voluntary element. But it should be clear from the previous discussion that the question is not whether risks can be controlled, but how expensive it is for individuals to control them. People can control their subjection to airplane-related risks by refusing to fly in planes; people can control their subjection to risks from coal-fired power plants by living in areas served by solar energy. The question is not whether a risk can be controlled or not, but at what cost it is controllable, and with what benefits. Individuals tend to "frame" risk control in "all or nothing" terms, depending on the particular temporal event on which they focus. But this is a similar form of selective attention. As with voluntariness, "controllability" is a conclusion more than it is an analytic tool. It is best to look at the factors that account for a judgment that a risk is not controllable. 
I have suggested that many of the "qualitative" factors that underlie lay judgments about risk can be accounted for by the criterion of decently-livable life-years. Some of those factors cannot be incorporated in this way, and this conclusion requires a "stage two" adjustment of the basic criterion. Thus, dreaded risks should be treated differently, because of the problems associated with certain illnesses and deaths. Distributional weights can be given to risks that have disproportionate effects on disadvantaged people. Certain factors underlie lay judgments about voluntariness and control; those factors should be specified and also might be given weights. Of course, numerical weights have their limitations and it is important for those assessing risk to be aware of the qualitative factors and judgments that underlie the numbers. 
In this section I discuss some borderline cases: factors that may or may not justify a deviation from the basic criterion of decently-livable life-years. 
Do risks deserve special attention when future generations are at risk? In one sense the answer is certainly yes: When future generations are at risk, more people are at risk. Of course, there are large questions about the appropriate discount rate. But it seems sensible to say that if a risk will be incurred by people not yet born, it deserves greater attention because its degree is to that extent greater. This claim is easily taken care of via the notion of decently-livable life-years. 
Some psychological studies suggest that people think that potentially catastrophic risks deserve special attention. People's fear of nuclear power, for example, might be attributed to an understanding that if things go wrong, things will go very, very wrong. Thus, low probability, high-danger risks might be treated as worse than their "actuarial value." A one-in-a-million risk of 10,000 deaths might seem worth more than a one-in-a-thousand risk of ten deaths, or a one-in-a-hundred risk of one death. 
This judgment may depend on a refusal to see that all risks must be evaluated in probabilistic terms and that catastrophicness is simply a matter of degree.' Thus, when a low probability, high-danger risk enters the viewscreen, people may focus on the danger itself, may fail to see the low probability, and may fail as well to see that the risk may provide substantial benefits, including reduction in other risks. The special concern for "catastrophic" risks may actually reflect selective attention rather than reasonable underlying judgments of value. Or the special attention given to potential catastrophes may depend on a refusal to trust the officials who give assurances that the probability is low. If the lack of trust is justified, then the lay judgment deserves respect on the ground that the official statements may be or simply are false. But if we put that point to one side, the difficulty lies in discerning why a small risk of a huge disaster is worse than an actuarially equivalent large risk of a small disaster. 
It seems clear that people are especially hostile to new risks. Old risks tend to be taken for granted. Thus an additional risk of .001 percent may well be treated as more troubling than a removal of a risk of .002 percent. The point is connected with the well-known psychological phenomenon of loss aversion. Losses from the status quo are seen as more bad than (equivalent) gains from the status quo are seen as good."' 
At least as a general rule, and putting to one side the possibility that new risks may pose especially high costs of adaptation, government should probably refuse to treat new risks as especially troublesome. On reflection it is not at all clear why a new risk of a certain magnitude is worse than an old risk of the same magnitude. Perhaps it could be said that old risks are an inextricable part of a system of benefits and costs that have already been "coded" at the individual level. Thus, the environmental risks associated with coal-fired power plants are something to ' See Sarah Lichtenstein, et al, When Lives Are In Your Hands:Dilemmas of the Social Decision Maker, in Robin M. Hogarth, ed, Insights in Decision Making:A Tribute to Hillel J. Einhorn91 (Chicago 1990). 
61 See Richard H. Thaler, Quasi Rational Economics 159-60, 167, 169 (Russel Sage 1993). which people have (more or less) adjusted, and a dramatic switch from coal-fired power plants would force people to give up an energy source to which they are acclimated. The case of automobiles is perhaps the most vivid. But new risks often come with benefits as well, and there is no reason why these should not "code" too. 
The strongest argument in favor of more severe regulation of new risks would be that people have adjusted to old risks, and hence an old risk/new risk division nicely corresponds to the actual costs associated with adjustment. When this is so, it makes sense to treat new risks more severely. But the degree of the disparity, as described by lay judgments, reflects status quo bias in a way that is hard to defend in pragmatic terms. 
VI. POSITIVE NOTES 
The discussion thus far has implications for the positive theory of health and safety regulation. It suggests that some apparently odd patterns (see Table 1) may well reflect differences between lay and expert judgments about risk. In this section, I offer several examples. 
We would expect greater resources to be devoted to risks that are especially dreaded. Thus government might well devote more resources to the AIDS crisis and to cancer prevention, partly because these deaths are so dreaded. With AIDS, there is the additional problem that the disease casts a pall over a wide range of sexual acts; this would increase the public "demand" for AIDS-related research. Judge Posner has attributed the large amount of resources devoted to such research to interest-group power."2 But the qualitative nature of risks-producing particularly grim deaths-undoubtedly plays a role in funding decisions. 
It is easy to predict that the availability heuristic would help create a kind of crazy-quilt pattern in regulation, with some events calling for stringent regulation and others calling for little or no regulation at all. The regulation would not be closely asso62 See Thomas J. Philipson and Richard A. Posner, Private Choices and Public Health:The AIDS Epidemic in an Economic Perspective 194-206 (Harvard 1993). ciated with actual risk levels. This is the pattern we observe. Studies of American government show extraordinary disparities in expenditures per life saved.' 
The disparities are plausibly attributed at least in part to the availability heuristic. The dramatic difference between expert and public assessments of risk levels has something to do with this heuristic, and the difference maps closely onto actual differences in expenditures per life saved. The public demand for regulation therefore appears to be a product of the availability heuristic, which is itself endogenous to the nature and levels of public and private publicity. Thus, for example, there are enormous expenditures designed to counteract cancers in the workplace, and relatively low expenditures designed to prevent injuries from automobile accidents. The comparative over-regulation of certain environmental risks may well be a product of the fact that those risks, when they come to fruition, are highly publicized. Through this route, too, we might be able to explain the otherwise inexplicably severe controls on nuclear power. We might also be able to explain the extraordinary safety of air travel as compared with other means of transportation." 
If people are averse to ambiguity, we might expect that political outcomes will avoid ambiguity and present risks in "all or nothing" terms. In fact, this is a pervasive phenomenon in environmental statutes, where administrators are entrusted with ensuring a "safe level" rather than with coping pragmatically amidst ambiguities of both fact and value.' 
Samuelson and Zeckhauser have shown that the affinity for the status quo appears to affect such diverse forms of behavior as brand allegiance, choice of insurance plans, changing public policies, marketing techniques, and investment decisions." If this is correct, large consequences follow. We can predict that much See Table 1. 
See Nancy L. Rose, Fearof Flying?Economic Analyses of Airline Safety, 6 J Econ Persp 75 (Spring 1992). 
' See Marc K. Landy, et al, The EnvironmentalProtectionAgency: Asking the Wrong Questions FromNixon to Clinton 310-34 (Oxford 1994). 
" William Samuelson and Richard Zeckhauser, Status Quo Bias in Decision Making, 1 J Risk & Uncertainty 7 (1988). governmental behavior in the environmental context will be a product of endowment effects. Private and public reactions to risks should reflect a status quo bias. Both supply and demand will be affected. Government regulation of new risks will predictably be more stringent than government regulation of (equivalent) old risks. This is so precisely because the public: demand for regulation will be a product of status quo bias. 
This is in fact what we observe. It is a defining characteristic: of the current system of environmental controls. 7 New risks are regulated far more stringently than old ones, even though this strategy sometimes creates extremely perverse results, by perpetuating the life of the especially severe old risks and thus damaging public health and safety. New stationary sources of air pollution must meet technological requirements not imposed on old sources; new cars are regulated far more heavily than old ones.6 
There are many other examples in the area of environmental regulation. Consider, for example, the controversial and probably irrational Prevention of Significant Deterioration ("PSD") program. 9 The PSD program says roughly that states that met national ambient air quality standards in 1977 cannot suffer a deterioration in air quality, even if the air would remain very clean, and even if there are good reasons for allowing new development. The use of the 1977 benchmark seems puzzling and even senseless. There is no clear reason to conclude that the air cannot, become dirtier than it happened to be in 1977, so long as it is consistent with the other national benchmark standards in the Clean Air Act. Of course, there is good reason to ensure that some areas are pristine or have especially clean air. The PSD program is, however, ill-suited to achieving this goal, since the 1977 benchmark is so broad. 
How, then, can we explain the existence of the PSD program, which seems hard to justify on public interest grounds? Certainly part of the explanation comes from public choice theory. Representatives in "clear air" states disproportionately opposed the program, and those in "dirty air" states disproportionately supported it, no doubt in order to prevent the exodus of revenue67 See Peter Huber, The Old-New Division in Risk Regulation, 69 Va L Rev 1025 (1983). 
. ' See Cass R. Sunstein, After the Rights Revolution: Reconceiving the Regulatory State 92 (Harvard 1990). 
69 Clean Air Act, 42 USC Â§Â§ 7470-92 (1994). producing, polluting companies to "clean air" states.7" But the apparently broad appeal of the PSD program may owe a good deal as well to the endowment effect. The perception that air quality ought at least to stay where it is-that the government should prevent deterioration from the status quo-seems to have widespread appeal. This is so despite the fact that other things being equal, regulatory efforts to make the air cleaner than it now is often face strong political roadblocks. The asymmetry cannot be fully explained on public interest grounds, for prevention of deterioration can be far worse than actual improvements. It probably has a good deal to do with status quo bias and with the initial endowment reflected in air quality at the time the legislation was under consideration. 
Or consider one of the most criticized features of the Clean Air and Clean Water Acts, the pervasive requirement that companies adopt the "best available technology" (BAT).71 This strategy has been challenged on the ground that there is at best an incidental relationship between cost-effective environmental policy and adoption of BAT. In principle, it seems unreasonable to require everyone to adopt the best available technology. Instead, government should allow companies a high degree of flexibility in achieving air quality goals. Some companies should switch to clean energy sources, rather than put expensive technology on dirty energy sources; some companies should go out of business because once they pay the environmental costs, their activity is not worthwhile; some companies should not use BAT at all, since they do business in regions in which adoption of expensive technology is not sensible in light of the variables at stake. 
An interest-group explanation is not entirely implausible for BAT requirements. But the requirements can also be understood as an outgrowth of status quo bias. If the technological status quo is thought to be an appropriate benchmark for legal requirements, its use in environmental law may not be so puzzling. There may be general agreement that the technological status quo is the best and fairest foundation for environmental law, even if this view will not survive critical scrutiny. 
'0 B. Peter Pashigian, EnvironmentalRegulation: Whose Self-Interests are Being Protected?, in George J. Stigler, ed, ChicagoStudies in PoliticalEconomy 498 (Chicago 1988). 
71 See, for example in the Clean Air Act, 42 USC Â§ 7475 (1982) (preconstruction requirements); 42 USC Â§ 7411 (1982) (standards of performance for new stationary sources). 
It is notable too that it appears very difficult (though not impossible) to bring about even rational environmental regulation through tax increases--on, for example, polluting vehicles or gasoline. "Green taxes" are supported by strong justifications, but they are an almost invisible part of national environmental policy. Perhaps the difficulty can be attributed to the influence of the automobile industry; but some leaders in the industry have actually favored gasoline taxes. The difficulty may well be understood in terms of the endowment effect, as that effect operates to define the public demand for regulation. The existing price of gasoline marks the status quo from which departures are measured. Government efforts to raise the price therefore meet strong resistance. Hence, the public is generally quite hostile to any effort to increase the price of gasoline. 
By contrast, there are many popular regulatory requirements that ultimately raise the cost of energy and automobiles, but that do so mostly by affecting new sources. By almost any measure of social welfare, the direct tax approach would be preferable to the regulatory approach.72 I do not deny that there are many possible explanations for currently dysfunctional environmental policy. But a contributing factor may be that a tax or fee imposes highly visible losses as compared with the status quo, whereas the regulatory approach does no such thing. 
Or consider the fact that subsidies to mass transit might well be an especially sensible and inexpensive environmental strategy. If automobiles are a major contributor to air pollution, an important goal is to reduce vehicle miles traveled, as well as (or instead of) improving pollution control devices on cars. This much seems clear from the fact that regulatory requirements have not succeeded in reducing aggregate automobile pollution levels, because the decrease in air pollution per mile traveled has been more than offset by increases in total car use.73 It follows that an imperative for environmental policy is to create incentives that will decrease the use of the underlying polluting activity. But this idea has played relatively little role in policy, especially in the area in which it makes most sense: government expenditures devoted to mass transit and highways. 
Here too the political influence of the automobile industry is a plausible contributing factor. But status quo bias may play a 72 See Robert W. Crandall, Policy Watch: CorporateAverage FuelEconomy Standards, 6 J Econ Persp 171 (Spring 1992). 
73 Robert W. Crandall, Regulatingthe Automobile (Brookings 1986). large role as well. Because Americans have adapted their behavior to frequent use of the automobile, it is especially difficult to change their behavior in the direction of mass transit. This explanation helps to account for the remarkable comparative popularity in Europe of environmental strategies that do deter automobile use and promote mass transit.7' In Europe, people have not so deeply adapted their practices and preferences to automobile use. Social norms are thus a culprit here, and they are taken as given when they might be more changeable and fluid than we think. 
The point is very general. Public policy often takes the status quo-including, very prominently, the existence of particular firms-as if it were a given. Laws that endanger current institutions are subject to special social scrutiny. To some extent, this is fully rational in light of the real costs of transition. But I hypothesize that a large part of the phenomenon is attributable to a bias in favor of the status quo that is far stronger than traditional theory would predict. 
What about risks that do not involve mortality? As I have noted, many risks, especially in the environmental area, are serious because of morbidity effects, harms to recreational opportunities and aesthetic values, and mortality and morbidity effects for plants and animals. Here, there seems to be no alternative but to try to specify the relevant adverse effects in both quantitative and qualitative terms-how many weeks of respiratory problems, how much in the way of damage to crops, how much and what kind of animal morbidity. These specifications might be translated into more commensurable units through some variation on the idea of quality-adjusted or disability-adjusted life years.75 That is, morbidity effects might be analyzed by seeing the extent to which the effects diminish ideal functional capacity. This idea imposes a large cognitive demand on government, and it may be best to rely on simplifying categories. It is possible that we would want to separate the mechanism used to identify the ' See Marcia D. Lowe, Shaping Cities, in Lester R. Brown, ed, State of the World, 1992: A Worldwatch InstituteReport on ProgressToward a SustainableSociety 119 (W. W. Norton 1992). 
7"A clear-headed discussion and criticism is found in Sudhir Anand and Kristina Hanson, Disability-Adjusted Life Years: A CriticalReview, (Harvard School of Public Health, Working Paper No. 96.06, Sept 1995). magnitude of the harm from that used for purposes of allocating resources; the resource allocation judgment might depend, for reasons stated above, on distributional judgments calling for special attention to those who are systematically disadvantaged, lack much wealth, or are without access to relevant public services. I cannot discuss in this space the various possible refinements on the idea of quality-adjusted or disability-adjusted life years. Though the 'appropriate refinements are a large and important task for the future, we can begin to make progress in the less rigorous way suggested here-beginning with decently-livable lifeyears, adjusting the measure in the way suggested above, and adding various non-mortality effects in a relatively uniform way. 
The effort to generate numbers to identify qualitative gains in human lives does not run afoul of some of the objections discussed above, since it does not treat some lives as more or less valuable than others because of pre-existing conditions that do, not prevent basic functional capacity. The crucial task is to rank. various morbidity consequences against one another, so that comparisons can be made. Much the same thing can be said about recreational and aesthetic effects. Adverse consequences, should be ranked against one another, rather than viewed in isolation. And perhaps it will ultimately be possible to come up, with an aggregate number, summing the various components. that come under the general category of "regulatory benefits." The number ought not, however, to disguise the fact that its. ingredients are qualitatively diverse. 
Thus far I have discussed matters of substance, but some of the most pressing questions are institutional. Current American institutions fail to promote either democratic or technocratic goals. The current system is insufficiently democratic in the sense that the pattern of risk regulation cannot be plausibly attributed to considered judgments of the American people. Thai; pattern is more plausibly a combination of interest-group pressure, selective attention, sensationalistic media "scandals," and the "pollutant of the month" syndrome that plagues federal regulation. The current system is insufficiently technocratic be.. cause there is no general or coherent effort to bring the best scientific judgments to bear on risk-regulation. Of course science plays a large role; but its role is episodic rather than global. Instead, American government has a highly fragmented system, with a proliferation of congressional committees reflecting vari.. ous pathologies, and with a wide range of agencies not interacting with one another and operating pursuant to diverse statutory standards. 
What possible remedies are there? Any answer must devote considerable attention to the question how to promote trust in government institutions. 7' Here are four proposals: 
job of compiling information about risk levels and producing better priority-setting.A large problem for American government consists of the congressional committee structure, which ensures that comparative risk analysis will be rare, and which promotes a kind of balkanization of federal law. A straightforward remedy would consist of the creation of a new committee whose principal purpose would be to ensure good priority-setting. Such a committee would have authority over substantive statutes and also over the appropriations process. Its basic goal would be to engage in "risk ranking," to publicize misallocations, and to initiate corrective legislation. Such a committee should rely a great deal on current scientific findings. But it should be aware that value judgments play a legitimate role in deciding which risks are most serious. Thus the committee might adopt a presumption in favor of maximizing the number of decently-livable life-years, but allow adjustments when reasonable judgments of value so require. It would be an advantage to initiate the very process of deliberating about how to decide which risks are most serious. Such a process would alert legislators and perhaps the public to the problems in "safe or unsafe" thinking and to the need to engage in risk comparisons. 
Affairs ("OIRA"), to make sure that it has, and is known to have, the authority to ensure better priority-setting.Under Presidents Reagan and Bush, OIRA was understood as a kind of "cost-benefit" police officer, intervening in a fairly ad hoc way so as to ensure that grossly inefficient regulations would be reconsidered.77 Under President Clinton, this role appears to have diminished, notwithstanding the general interest in "reinventing government" so as to ensure greater attention to results rather than processes. 
" See Stephen Breyer, Breakingthe Vicious Circle: Toward Effective Risk Regulation (Harvard 1993); Paul Slovic, et al, Regulation of Risk: A PsychologicalPerspective, in Roger G. Noll, ed, Regulatory Policy and the Social Sciences 241 (California 1985). 
" See Thomas 0. McGarrity, Reinventing Rationality: The Role of RegulatoryAnalysis in the FederalBureaucracy(Cambridge 1991). 
I suggest that OIRA might command far broader bipartisan support if its main role were seen as ensuring better prioritysetting through maximizing the number of life-years saved through regulation. This role would call for more regulation in some areas and less regulation in others; it would involve recom.mendations and policy guidance for both rulemaking and enforcement action. Of course OIRA could adjust the basic criterion with reference to the judgments of value discussed above. The basic point is that OIRA should not be seen solely as a brake on regulation. Sometimes it should be a spur. Its general goal should be to overcome some of the cognitive problems described above, which affect judgments at the individual level, the public "demand" for regulation,78 and the behavior of government officials themselves. 
harm.7"9 The judicial role in managing risk regulation is inevitably partial and modest. But courts do have power to invalidate the most extreme or ill-considered regulatory proposals or omissions. There has been a modest direction in favor of a "more good than harm" principle embodying a presumptive requirement that costs not be grossly disproportionate to benefits."0 
This idea is a way of overcoming the general problem of selective attention; it is appropriately modest but also has considerable power. It entails at a minimum an interpretive principle allowing agencies to exempt de minimis risks, and perhaps requiring them to do so, on analogy to the old common law idea that absurdity in interpretation will be avoided. It also entails a principle that agencies should be permitted to engage in "healthhealth" analysis where they see fit, ensuring that regulations do not create health problems greater than those that they are intended to reduce.8' Finally, it entails a requirement that under the Administrative Procedure Act,8" agencies should, under "arbitrary or capricious" review, make a plausible showing that a regulation will make things better rather than worse. 
See Roger G. Noll and James E. Krier, Some Implications of Cognitive Psychology for Risk Regulation, 19 J Legal Stud 747 (1990); Cass R. Sunstein, Endogenous Preferences, EnvironmentalLaw, 22 J Legal Stud 217 (1993). 
" See Edward W. Warren and Gary E. Marchant, More Good Than Harm, 20 Ecology L Q 379 (1993); Howard Margolis, Dealing With Risk (Chicago 1996). 
'o See, for example, CorrosionProofFittings v EPA, 947 F2d 1201 (5th Cir 1991). 81See id; Cass R. Sunstein, Health-Health Tradeoffs, 63 U Chi L Rev 1533 (1996). 82 5 USC Â§Â§ 551-59 (1994). and to focus attention on the most serious risks. Justice Breyer has suggested the creation of an elite corps of risk managers, versed in various disciplines and authorized to divert resources from small problems to large ones.s" Most ambitiously, then, the national government might move in the direction of a variation on the "Breyer group" to engage in the sort of analysis I have proposed here, and grant that group the authority to 1) publicize its findings about which risks are most severe, 2) require agencies to engage in similar priority-setting, 3) recommend changes in statutes or regulations, or appropriations, and perhaps 4) engage in some reallocating on its own. 
these proposals raise concerns along the dimension of trust, and it is important to ensure that risk regulation is not seen as a purely technocratic matter. A major goal of these (briefly sketched) proposals is indeed to strengthen the scientific underpinnings of regulation; but there are important democratic goals as well. The most central point here is that the crazy-quilt pattern of current risk regulation cannot plausibly be seen as a good response to democratic convictions. Instead, that pattern reflects some combination of interest-group pressures, selective attention, strategic behavior on the part of politicians, and sensationalistic anecdotes on the part of the mass media. A movement toward better priority-setting (however this is conceived) should start with democratic as well as technocratic goals, and with a recognition that the status quo cannot reasonably be defended on democratic grounds. 
Thus, institutional changes should attend to citizen judgments at both the "input" and "output" sides. At the level of "inputs," it is important to ensure that public officials have an understanding of people's actual concerns and the foundations for those concerns. Citizen panels have been used productively by some agencies with an eye toward this goal.' At the level of "outputs," officials should not rest content with sensible regulations, but should have a continuing obligation to provide information and to engage in discussion about the grounds for regulation and the basis and legitimacy of any citizen concerns. The point is especially important in light of the fact that some groups of citiSee Breyer, Breaking the Vicious Circle (cited in note 76). 
See Richard H. Pildes and Cass R. Sunstein, Reinventing the Regulatory State, 62 U Chi L Rev 1 (1995), for citations and discussion. zens may be less trusting than others, and distrust, once present, may accelerate." 
I have made four basic claims in this essay. First, environmental regulation suffers above all from a problem of selective attention. No reasonable reading of reflective citizen judgments can account for the pattern we now observe, and an understanding of the systemic effects of regulation would much improve the process of priority-setting. Second, the foundation for regulatory policy should be the number of decently-livable life-years saved. Third, government should use expert judgments on that count as the foundation for analysis, and it should qualify those judgments in a limited way. More specifically, it should do so with reference to whether the risks at issue are especially dreaded, inequitably distributed, and controllable or voluntarily incurred by the individuals involved. The latter two factors point in essence to the costs of risk avoidance (including information costs). Numerical weights might be added to different assessments of these variables. Government should not use lay judgments to the extent that they reflect factual errors, even though those judgments do appear to play a role in any persuasive "positive" account of regulation. Fourth, institutional arrangements should be designed so as to allow government to make the relevant judgments in a rational manner. 
This approach is in significant part a technocratic one; it places a high premium on scientific judgments and on getting the numbers right. It rejects the view that those judgments are decisive, but it rejects even more firmly the view that ordinary lay judgments, regardless of their content and grounds, should play a central role in regulatory policy. Those judgments are too frequently the product of framing effects, heuristic devices, or confused factual claims; often they are proxies for factors that can be better analyzed in other ways. By itself, the approach I am suggesting would not solve all of the problems raised by the question which risks should be treated first; a large gap-on which I have offered just a few brief notes-consists in the problem of how to deal with environmental and other risks that do not involve human mortality. But the approach holds out some hope of combinSee id. 
