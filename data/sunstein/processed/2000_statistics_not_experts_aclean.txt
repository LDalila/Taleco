 University of Chicago Law School Chicago Unbound Coase-Sandor Working Paper Series in Law and Economics Statistics, Not Experts Cass R. Sunstein William Meadow Follow this and additional works at: https://chicagounbound.uchicago.edu/law_and_economics Part of the Law Commons Recommended Citation Cass R. Sunstein & William Meadow, "Statistics, Not Experts" ( John M. Olin Program in Law and Economics Working Paper No. 109, 2000). William Meadow and Cass R. Sunstein This paper can be downloaded without charge at: The Chicago Working Paper Series Index: http://www.law.uchicago.edu/Publications/Working/index.html The Social Science Research Network Electronic Paper Collection: Preliminary draft 11/20/00 all rights reserved Statistics, Not Experts William Meadow* and Cass R. Sunstein** Abstract The legal system should rely much more than it now does on statistical evidence. It should be cautious about the judgments of experts, who make predictable cognitive errors. Like everyone else, experts have a tendency to blunder about risk, a point that has been shown to hold for doctors, whose predictions significantly err in the direction of optimism. We present new evidence that individual  doctors' judgments about the ordinary standard of care are incorrect and excessively optimistic. We also show how this evidence bears on legal determinations of negligence, by doctors and others. Trials frequently raise questions that call for expert intervention. Experts are asked to answer a range of questions about what people, or professionals, ordinarily do. If a doctor is accused of negligence, for example, it is necessary to know about the customary practice of doctors. Of course negligence judgments depend, at least in part, on an assessment of ordinary practice.1 But how is ordinary practice assessed? The basic answer is that the assessment comes via statements from expert witnesses, describing the ordinary practice.2 There can be no doubt that experts know a great deal about topics on which ordinary people lack information. But experts, no less than other people, are subject to predictable biases.3 Their judgments about probability are affected  by the same heuristics and biases to which most people are subject, even if (and this is a disputed question) expertise tends to reduce the most serious errors. Our basic proposal here is that the legal system should rely, much more than it now does, on statistical data about doctors’ performance, rather than the opinions of experts about doctors’ performance. For the first time, it is becoming possible for law to rely on this evidence, precisely because such evidence is becoming * Associate Professor, Pediatrics; Associate Director, Neonatology, Assistant Director, MacLean Center for Clinical Medical Ethics, The University of Chicago ** Karl N. Llewellyn Distinguished Service Professor of Jurisprudence, Law School and Department of Political Science, University of Chicago. 1 There is a dispute about the extent to which ordinary practice is determinative. For the classic case, see The T.J. Hooper, 60 F.2d 737 (2d Cir. 1932). 2 We build on existing law here, without intending to enter into debates about the extent to which law should simply incorporate, or instead sometimes improve on, the existing standard of care. On any view, the customary practice is relevant, and that is sufficient for our purposes here. 3 See Jonathan Baron, Thinking and Deciding (2d ed 1994). increasingly available. If our argument is convincing in the medical context, it should apply in many other settings in which experts are asked to testify about negligence or deviations from ordinary practices.  In many settings, the fallible opinions of isolated experts should be supplemented or replaced  with statistical data. A step of this sort would dramatically increase the sense and rationality of tort law. It is now well-known that most normal people tend to be risk optimists, in the sense that they believe themselves to be relatively immune from risks that are faced by similarly situated others.5 This is one of the most robust findings in social psychology. For example, 90% of drivers believe that they are safer than most drivers and less likely to be involved in a serious accident.6 Most people believe that they are distinctly unlikely to be subject to various risks, such as cancer, heart disease, and divorce.7 Smokers appear to know the statistical risk of smoking8; but they believe that they are less likely than most smokers to fall victim to the various risks. In one study, less than half of smokers believed that they have a higher-thanaverage risk of cancer or cardiovascular disease; indeed, most heavy smokers (over forty cigarettes per day) believe that they are not at any increased risk.9 Only one group of people does not show a tendency to excessive optimism: the clinically depressed.10 It would be natural to infer that though unrealistic optimism makes for erroneous predictions about outcomes, it is on balance adaptive, especially insofar as an optimistic attitude increases the probability of a good outcome and otherwise creates hedonic benefits.11 4 Some of the data here is discussed, from a different angle, in William Meadow et al., Ought 'standard care' be the 'standard of care'? A study of the time to administration of antibiotics in children with meningitis, 147 Am J Dis Child 40 (1993). 5 Neil D. Weinstein, Unrealistic Optimism About Future Life Events, 39 J. Personality & Soc. Psych. 806 (1980). Alternatively, it might be thought that some social settings would work against optimistic bias. In markets, for example, entrepreneurs might have an incentive toward realism, especially because market pressures, it might be expected, would punish, and drive out, those who are unrealistically optimistic. Perhaps markets do move people toward realism; but entrepreneurs, no less than anyone else, have been shown to suffer from unrealistic optimism.12 One might intuit that those with specialized knowledge are less prone to this effect. This appears not to be the case. It has almost universally been found that physicians, no less than others, have a substantial tendency to err in predicting outcomes. Most often the errors are in the direction of optimism. All of this is highly suggestive, but not decisive, with respect to the particular point that we mean to investigate here: whether experts make erroneous judgments about the ordinary standard of medical care, and whether the errors go in a predictable  direction. It would be plausible to think that the general tendency toward optimism would affect those judgments as well; but it would also be possible to imagine that (a) doctors’ predictions about their patients’ prospects are systematically overoptimistic, but (b) doctors have an accurate sense of what is ordinarily done by themselves and other doctors. If there is no systematic error with respect to (b), there would be little need to substitute data for experts. We now offer the first real evidence on that question. III. Standard of Care: Experts vs. Data We now summarize some of our own evidence that doctors err with respect to ordinary conduct in their own fields. As expected, the apparent basis for the magnitude and direction of these errors is optimistic bias. Consider the problem of bacterial meningitis in children. For the purposes of the current discussion, it is necessary to know only three things about that problem. Bacterial meningitis is an infection of the brain; it can (usually) be treated with antibiotics; as a general rule, the sooner the antibiotics are started, the better the outcome will be. In the traditional formulation, experts themselves are instructed to rely on their personal "knowledge and training." But for reasons given above, such admonitions raise many problems. In the context at hand, it would be reasonable to predict that experts would tend to be excessively optimistic – that their recollections of the time that antibiotics are initiated in children with meningitis would be tilted toward shorter values than actually occurred.  And if so, experts, relying on their "knowledge and training," will provide inaccurate accounts of behavior. Moreover, and most importantly, the opinions of both of these groups of potential expert witnesses were wrong, and wrong by a large margin. We compared both of these distributions of expert opinion to actual times, determined on the basis of a review of 93 cases of children with meningitis seen at two university medical centers in Chicago. The average value of ABTIME for these 93 children was 120 minutes, with 95% of cases falling in the interval between 30 to 240 minutes. When the medical literature was reviewed in an attempt to extend these observations of actual ABTIME, 200 reported cases of children with meningitis were found from hospitals in South Carolina and California, with an average time comparable to those observed at our Chicago hospitals (median 114-126 minutes). The following table captures the differences: Variations between Expert Opinions and Data-based Observations for ABTIME Whatever "expert" opinion means in this context, it does not mean an accurate opinion. Once again, our fears are confirmed --- we expect anecdotal recall to be inaccurate, biased, and inevitably, systematically imperfect, and we find it to be so. If, as the psychological evidence suggests, our findings here are the rule and not the exception, it is hardly clear that the law should continue to base a system of medical-legal jurisprudence on such a shaky foundation. Of course the evidence that we have offered here is suggestive rather  than exhaustive. Perhaps there are contexts in which doctors, or other experts, have an accurate sense of the ordinary standard of care. But we believe that general evidence of error, together with the particular evidence introduced here, is sufficient to show that both error and optimism are highly likely to infect a wide range of expert testimony.23 This point operates independently of the ordinary incentives, in an adversary system, to assist one’s own side, whatever it may be.24 It therefore makes sense to move toward greater reliance on data, and less reliance on the recollections of isolated experts, certainly in the context of malpractice suits, and probably more generally. Until recently, the legal system has been unable to rely on statistical data for the simple reason that it has not existed. But it is increasingly common to develop data sets about physician choices and behavior, and the legal system will have an increasingly large amount of information on which to draw. A. Statistical Error? Our proposal might be criticized on the ground that statistical analysis is itself subject to error. Of course there can be no assurance that any particular account of relevant data is correct. If this is so, it might be objected, the use of statistical evidence will merely be the beginning of a continuing battle among imperfectly reliable experts. How much would be gained by that? This objection has a degree of truth, but rather than impeaching our proposal, it suggests the need to develop good methods for evaluating any particular claim about what the data establishes. There is no escaping tests of the data in the ordinary way, through the presentation of conflicting views, including that of experts. Data might be met with data; it might also be met with a professional critique. And of course it is possible that an individual expert will be able to 23 See Kahneman and Lovallo, supra note. 24 See Linda Babcock, Self-Serving Bias, in Behavioral Law and Economics (Cass R. Sunstein ed. 2000). show, persuasively, that data does not establish what it claims. These sorts of disputes can be handled in the standard fashion. What we are suggesting here is that because individual experts are distinctly prone to error, it would be far better to begin the process with reliable evidence rather than particular recollection.  If individual experts can show that the statistical data are wrong, the legal system will be better off for the demonstration. But in the long run, we predict, these demonstrations will be the exception rather than the rule. Statistical data are not typically used in negligence cases. In fact the legal system is uncomfortable with the use of such data. They might be excluded, as inadmissible, on several grounds. Perhaps there are alternatives, other than reliance on statistical data, to the problem of idiosyncratic recollections of individual experts.   One possible view is that the opinions of experts, as codified in textbooks or journal publications, should define the standard of care . By this view, when actual practices differ from the theoretical or recommended standards, it is the practitioners who are at fault. They may not know the standard, may disagree with it, or have misinterpreted it, but the burden of proof falls on the practitioners. We have suggested here that there is general reason to believe that expert judgments about the standard of medical care will be erroneous, and that the errors will run in a predictable direction. The usual reason is optimistic bias, as people tend to believe that things can be done more easily, more rapidly, and more successfully than the evidence suggests. To establish this claim, we have drawn on existing evidence, highly suggestive on this point, and more particular evidence, presented here, of mistaken reports with respect to standard of care. Readers with comments should address them to: Dr. William L. Meadow Department of Pediatrics University of Chicago Children’s Hospital C684, MC 6060 5839 South Maryland Avenue Chicago, IL 60637 WLM1@midway.uchicago.edu Cass R. Sunstein Karl N. Llewellyn Distinguished Service Professor of Jurisprudence Law School and Department of Political Science University of Chicago 1111 East 60th Street Chicago, IL 60637 csunstei@midway.uchicago.edu Chicago Working Papers in Law and Economics (Second Series) William M. Landes, Copyright Protection of Letters, Diaries and Other Unpublished Works: An Economic Approach (July 1991). Richard A. Epstein, The Path to The T. J. Hooper: The Theory and History of Custom in the Law of Tort (August 1991). Cass R. Sunstein, On Property and Constitutionalism (September 1991). Richard A. Posner, Blackmail, Privacy, and Freedom of Contract (February 1992). Randal C. Picker, Security Interests, Misbehavior, and Common Pools (February 1992). Tomas J. Philipson & Richard A. Posner, Optimal Regulation of AIDS (April 1992). Douglas G. Baird, Revisiting Auctions in Chapter 11 (April 1992). William M. Landes, Sequential versus Unitary Trials: An Economic Analysis (July 1992). William M. Landes & Richard A. Posner, The Influence of Economics on Law: A Quantitative Study (August 1992). Alan O. Sykes, The Welfare Economics of Immigration Law: A Theoretical Survey With An Analysis of U.S. Policy (September 1992). Douglas G. Baird, 1992 Katz Lecture: Reconstructing Contracts (November 1992). Gary S. Becker, The Economic Way of Looking at Life (January 1993). J. Mark Ramseyer, Credibly Committing to Efficiency Wages: Cotton Spinning Cartels in Imperial Japan (March 1993). Cass R. Sunstein, Endogenous Preferences, Environmental Law (April 1993). Richard A. Posner, What Do Judges and Justices Maximize? (The Same Thing Everyone Else Does) (April 1993). Lucian Arye Bebchuk and Randal C. Picker, Bankruptcy Rules, Managerial Entrenchment, and Firm-Specific Human Capital (August 1993). J. Mark Ramseyer, Explicit Reasons for Implicit Contracts: The Legal Logic to the Japanese Main Bank System (August 1993). William M. Landes and Richard A. Posner, The Economics of Anticipatory Adjudication (September 1993). Kenneth W. Dam, The Economic Underpinnings of Patent Law (September 1993). Alan O. Sykes, An Introduction to Regression Analysis (October 1993). Richard A. Epstein, The Ubiquity of the Benefit Principle (March 1994). Randal C. Picker, An Introduction to Game Theory and the Law (June 1994). William M. Landes, Counterclaims: An Economic Analysis (June 1994). J. Mark Ramseyer, The Market for Children: Evidence from Early Modern Japan (August 1994). Robert H. Gertner and Geoffrey P. Miller, Settlement Escrows (August 1994). Kenneth W. Dam, Some Economic Considerations in the Intellectual Property Protection of Software (August 1994). Cass R. Sunstein, Rules and Rulelessness, (October 1994). David Friedman, More Justice for Less Money: A Step Beyond Cimino (December 1994). Daniel Shaviro, Budget Deficits and the Intergenerational Distribution of Lifetime Consumption (January 1995). Douglas G. Baird, The Law and Economics of Contract Damages (February 1995). Daniel Kessler, Thomas Meites, and Geoffrey P. Miller, Explaining Deviations from the Fifty Percent Rule: A Multimodal Approach to the Selection of Cases for Litigation (March 1995). Sunstein, Schkade, Daniel and