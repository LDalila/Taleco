Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp
JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.
Springer is collaborating with JSTOR to digitize, preserve and extend access to Journal of Risk and
Uncertainty.
The Journal of Risk and Uncertainty, 26:2/3 121-136, 2003 Â© 2003 Kluwer Academic Publishers. Manufactured in The Netherlands.
CASS R. SUNSTEIN csunstei@uchicago.edu Karl N. Llewellyn Dist. Service, Prof, of Jurisprudence Law School, Department of Political Science, University of Chicago Law School, 1111 East 60th Street, Chicago, IL 60637, USA
Abstract When strong emotions are involved, people tend to focus on the badness of the outcome, rather than on the probability that the outcome will occur. The resulting "probability neglect" helps to explain excessive reactions to low-probability risks of catastrophe. Terrorists show a working knowledge of probability neglect, producing public fear that might greatly exceed the discounted harm. As a result of probability neglect, people often are far more concerned about the risks of terrorism than about statistically larger risks that they confront in ordinary life. In the context of terrorism and analogous risks, the legal system frequently responds to probability neglect, resulting in regulation that might be unjustified or even counterproductive. But public fear is itself a cost, and it is associated with many other costs, in the form of "ripple effects" produced by fear. As a normative matter, government should reduce even unjustified fear, if the benefits of the response can be shown to outweigh the costs. Keywords: behavioral economics, terrorism, risk perception, probability JEL Classification: KO, D8
Terrorists show a working knowledge of three noteworthy points about fear. Of these, the first two are well-known. The third point is less well-understood, and it will be my principal emphasis here. Because the three points are related, they should be identified at the outset. The first point is that in the face of ignorance, people assess probabilities through the use of various heuristics, most notably the availability heuristic, in accordance with which probability is measured by asking whether a readily available example comes to mind (T versky and Kahneman, 1 974). In the aftermath of a terrorist act, and for a period thereafter, that act is likely to be both available and salient, and thus to make people think that another such act is likely, whether or not it is in fact. One or two terrorist incidents will have a significant impact on both thought and behavior, with exaggerated risk perceptions a likely result of the substantial publicity given to such incidents. In these ways terrorist acts are no different from floods, earthquakes, and other catastrophes, all of which have immediate effects on behavior (Slovic, 2000). For imperfectly informed agents, use of the availability heuristic may or may not be consistent with Bayesian learning but it can produce significantly exaggerated judgments of probable harm. The second point is that people show a disproportionate fear of risks that seem unfamiliar and hard to control (Slovic, 2000). A new risk is likely to receive far more attention than
is warranted by the sheer numbers. A large disparity between public reactions to old risks and public reactions to new risks characterizes both individual judgment and law itself, which regulates new hazards far more aggressively than old ones (Huber, 1983). Hence it is to be expected that an act of terrorism will cause large changes in private and pub- lic behavior, even if the magnitude of the risk does not justify those changes, and even if statistically equivalent risks occasion little or no concern. And if a risk appears hard to control, people will be especially concerned about it, possibly even terrified (Slovic, 2000). The purpose and effect of terrorism are to make people fear that they "cannot be safe anywhere." For this reason, isolated acts of terrorism, involving a small subset of the population, can cause far more serious dislocations than are warranted by the discounted value of the risk. The third problem, and my principal claim here, is that people are prone to what I shall call probability neglect , especially when their emotions are intensely engaged. Probability neglect is highly likely in the aftermath of terrorism. People fall victim to probability neglect if and to the extent that the intensity of their reaction does not greatly vary even with large differences in the likelihood of harm. When probability neglect is at work, people's attention is focussed on the bad outcome itself, and they are inattentive to the fact that it is unlikely to occur. I will offer a good deal of evidence of probability neglect, suggesting in particular that substantial variations in probability do not greatly affect people's judgments, at least when the outcome engages people's emotions. An understanding of probability neglect has several implications for law and policy, particularly in the context of responses to terrorism.1 It is predictable that in the aftermath of a terrorist attack, the public will alter its behavior and demand a substantial governmental response - even if the magnitude of the risk does not warrant that response, and even if the danger is far less than that presented by other hazards that do not greatly concern people. Hence an act of terrorism will have a large number of "ripple effects" (id.), including a demand for legal interventions that might not reduce risks and that might in fact make things worse. Consider, for example, the possibility that extensive security precautions at airports will lead people to drive rather than to fly because flying is much safer than driving, such precautions might sacrifice many lives on balance. There are prescriptive and normative issues as well. In the face of probability neglect, government is unlikely to be successful if it attempts to reduce fear by emphasizing the low likelihood of another terrorist attack. It might do better if it changes the subject or instead stresses the affirmative social values associated with running the risk (by suggesting, for example, that continuing with ordinary life is a patriotic act). The most important normative issue is straightforward: If probability neglect leads the public to be excessively concerned about terrorism-related risks, should government respond? At first glance, the answer would appear to be negative ordinarily private and public resources should not be devoted to small problems, even if an ignorant public is demanding action. But the negative answer is too simple. Fear, whether rational or not, is itself a cost, and it is likely to lead to a range of other costs, in the form of countless ripple effects, including a reluctance to fly or to appear in public places. If government is able to reduce the level of fear produced by probability neglect, it should do so, at least if the costs outweigh the benefits.
Probability neglect, as I understand it here, should be distinguished from three other phenomena, all of them quite well-known and also bearing on the demand for law in the aftermath of a terrorist attack. I have already mentioned the availability heuristic, used strategically by many actors, including terrorists (Kuran and Sunstein, 1999). Indeed "availability entrepreneurs" take advantage of the availability heuristic by producing or publicizing particular risk-related events (id.). Terrorists are good examples of availability entrepreneurs, often producing fear that greatly outruns statistical reality. Because of social interactions, knowledge of terrorist incidents spreads rapidly through the population, producing social cascades that greatly aggravate fear (id.). It is also well known that people are insensitive to variations in low probabilities. In one study, Kunreuther and his coauthors found that people's perceptions of riskiness did not vary among risks of 1 in 100,000, 1 in 1 million, and 1 in 10 million (Kunreuther, Novemsky, and Kahneman, 2001). They also found little difference in perceptions of riskiness for risks ranging from 1 in 650, to 1 in 6300, to 1 in 68,000. This is a striking form of probability neglect. But insensitivity to variations among low probabilities is different from the more extreme form of insensitivity that I will be emphasizing here. Prospect theory can also be taken to show a form of probability neglect (Kahneman and Tversky, 1979). For present purposes, what is most important is that prospect theory offers an explanation for simultaneous gambling and insurance. With respect to low-probability risks, and those associated with terrorism clearly count as such, the key finding is that most people prefer a certain loss of X to a gamble with an expected value less than X, if the gamble involves a small probability of catastrophe. From the standpoint of expected utility theory, prospect theory predicts an overreaction to a small probability of bad outcomes. And if that aspect of prospect theory is emphasized, it may be possible to understand some aspects of federal risk regulation, which show an exaggerated response to low-probability catastrophes (Noll and Krier, 1990). The same understanding helps illuminate official responses to terrorism as well. Prospect theory suggests that people will seek regulation, as a form of insurance, to prevent harms that are grave but that are highly unlikely to occur and this point helps explain the demand for protection against small risks of catastrophic attacks. But in making this descriptive claim, prospect theory does not set out any special role for emotions, and it does not predict that people will react in any special way to emotionally gripping risks. On the contrary, prospect theory predicts the same reaction to risks that produce strong emotional reactions and to statistically equivalent risks that do not produce such reactions. Prospect theory is both more specialized and more general than the phenomenon to which I seek to draw attention here.
To see how probability neglect operates, consider a study of people's willingness to pay to avoid electric shocks (Rottenstreich and Hsee, 2001). The central purpose of the study was
TERRORISM AND PROBABILITY NEGLECT
Probability neglect in general
2. 7. Some distinctions
2.2. A demonstration
to test the relevance of variations in probability to "affect rich" decisions. The experiment of central importance here attempted to see whether varying the probability of harm would matter more, or less, in settings that trigger strong emotions than in settings that seem relatively emotion-free. In the "strong emotion" setting, participants were asked to imagine that they would participate in an experiment involving some chance of a "short, painful, but not dangerous electric shock." In the relatively emotion-free setting, participants were told that the experiment entailed some chance of a $20 penalty. Participants were asked to say how much they would be willing to pay to avoid participating in the relevant experiment. Some participants were told that there was a 1 % chance of receiving the bad outcome (either the $20 loss or the electric shock) others were told that the chance was 99%. The central result was that variations in probability affected those facing the relatively emotion-free injury, the $20 penalty, far more than they affected people facing the more emotionally evocative outcome of an electric shock. For the cash penalty, the difference between the median payment for a 1% chance and the median payment for a 99% chance was predictably large and indeed consistent with the standard model: $1 to avoid a 1% chance, and $18 to avoid a 99% chance. For the electric shock, by contrast, the difference in probability made little difference to median willingness to pay: $7 to avoid a 1% chance, and $10 to avoid a 99% chance! Hence subjects' responses to affect-poor harms were highly sensitive to differences in probability, whereas for affect-rich harms, responses were remarkably flat across the two probability conditions. The conclusion is that many people will pay a significant amount to avoid a small probability of a hazard that is affectively-laden - and that when strong emotions are involved, the amount that they will pay will not vary greatly with changes in probability. In the context of terrorism, the implication is clear. The risks associated with terrorist attacks are highly likely to trigger strong emotions, in part because of the sheer vividness of the bad outcome and the associated levels of outrage and fear. It follows that even if the likelihood of an attack is extremely low, people will be willing to pay a great deal to avoid it. Once people's minds are focused on the risk, their willingness to pay will be relatively impervious to significant changes in probability. In October 2002, the significant and often expensive precautions taken against possible sniper attacks, by citizens of the Washington, DC area, attest to the phenomenon of probability neglect in the face of vivid adverse outcomes.
To investigate the role of probability and emotions in responses to risk, I conducted an experiment asking eighty-three University of Chicago law students to describe their maximum willingness to pay to reduce levels of arsenic in drinking water. The questions had a high degree of realism. They were based on actual choices confronting the Environmental Protection Agency, involving cost and benefit information within the ballpark of actual figures used by the agency itself (Sunstein, 2002). Participants were randomly sorted into four groups, representing the four conditions in the experiment. In the first condition, people were asked to state their maximum willingness to pay to eliminate a cancer risk of one in 1,000,000. In the second condition, people were asked to state their maximum willingness to pay to eliminate a cancer risk of one in 100,000.
2.3. Emotions and arsenic
In the third condition, people were asked the same question as in the first, but the cancer was described in vivid terms, as "very gruesome and intensely painful, as the cancer eats away at the internal organs of the body." In the fourth condition, people were asked the same question as in the second, but the cancer was described in the same terms as in the third condition. In each condition, participants were asked to check off their willingness to pay among the following options: $0, $25, $50, $100, $200, $400, and $800 or more. Notice that the description of the cancer, in the "highly emotional" conditions, was intended to add little information, consisting simply of a description of many cancer deaths, though admittedly some participants might well have thought that these were especially horrific deaths. The central hypothesis was that the probability variations would matter less in the highly emotional conditions than in the less emotional conditions. More specifically, it was pre- dicted that differences in probability would make relatively little difference in the highly emotional conditions - and that such differences would have more importance in the less emotional conditions. This prediction was meant to describe a substantial departure from expected utility theory, which predicts that an ordinary, risk-averse person should be willing to pay more than 10X to eliminate a risk that is ten times more likely than a risk that he is willing to pay X to eliminate (Corso, Hammitt, and Graham, 2001). It was also expected that the ten-fold difference in probabilities - between 1/100,000 and 1/1,000,000 - would not, in either condition, generate a ten-fold difference in willingness to pay. The results can be found in Table 1. The graph that follows the table shows that the emotional description produces a higher willingness to pay and also that the slope of the emotional description line is somewhat flatter than the slope of the unemotional description line. The latter difference is not huge, but the ratio of the high probability answers, in relation to the low probability answers, is 1.8 for the emotional description and 2.7 for the unemotional description. It follows that the results for the first hypothesis are in the predicted direction.2 With an unemotional description, increasing the probability by a factor of 10 produced a statistically significant increase in mean WTP, from $7 1 .25 to 194.44, Â¿(38) = 2.3, p = .03. In the highly emotional condition, the increase in probability produced a smaller relative increase in WTP, from $132.95 to $241.30, which approaches but did not reach traditional .05 significance level, i(43) = 1 .7, /? = .10. Thus, while increasing the probability by a factor of 10 increased WTP in both emotion conditions, in terms of percentage increases, the effect was more than twice as large in the less emotional condition (a 173% increase in mean WTP) than in the emotional condition (an 8 1 % increase). Because of the small sample, the difference between
Table 1 . Willingness to pay (in dollars) for elimination of arsenic risks.*
Unemotional Emotional
Probability description description Overall
1/1,000,000 71.25(25) 132.95(100) 103.57(50)
1/100,000 194.44(100) 241.30(100) 220.73(100)
Overall 129.61 (50) 188.33(100) 161.45(100)
* Means (medians in parentheses).
TERRORISM AND PROBABILITY NEGLECT
Emotional and Unemotional Descriptions of Arsenic
Deaths.
these increases is not statistically significant, but the result is nonetheless highly suggestive, especially because of its consistency with other similar findings (discussed below).3 The second hypothesis was also supported. The increase in probability did produce a sig- nificant overall difference in mean WTP, from $103.57 to $220.73, F(l, 79) = 7.3, p .01. Consistent with other work on probability neglect, however, varying the probability had a relatively weak effect on WTP. The tenfold increase in the risk produced barely more than a doubling of mean WTP (a 1 13% increase).4 It is noteworthy that in this experiment, the relatively sophisticated participants in the study showed far more sensitivity to probability information than in the studies, described above, by Kunreuther, Novemsky, and Kahneman, but even so, the susceptibility was far less than conventional (normative) theory would predict. From this experiment, there is one other potentially noteworthy result. By itself, making the description of the cancer more emotional appeared to have an effect on mean WTP, raising it from $129.61 to $188.33, although due to the small sample size, the difference did not reach significance, F( 1 , 79) = 1 .6, p = .20.5 The graph shows the extent of the effect. If this result holds up in a larger sample, the dollar magnitude of the effect of a minor change in description is likely to be surprisingly large. Indeed, the effect of merely making the description of the outcome more emotional was about half as large as a tenfold increase in actual risk. For present purposes, however, the major point is that when the question was designed to trigger especially strong emotions, variations in probability had little effect on WTP, less of an effect than when the question was phrased in less emotional terms. This is the kind of probability neglect that I am emphasizing here.
This study has two implications for the public reaction to terrorist attacks. It suggests, first, that simply because such attacks arouse strong emotions, they are likely to trigger more intense fear, and a larger behavioral response, than do statistically identical risks. Here, as in the experiment, there will be a kind of "emotion premium." It suggests, second, that probability neglect will play a role in the public reaction to terrorism, and that many people will focus, much of the time, on the badness of the outcome, rather than on its likelihood.
Probability neglect, when strong emotions are involved, has been found in many other studies (Loewenstein et al., 2001). Consider, for example, experiments designed to test levels of anxiety in anticipation of a painful electric shock of varying intensity, to be administered after a "countdown period" of a stated length. In these studies, the stated intensity of the shock had a significant effect on physiological reactions. But the probability of the shock had no effect. "Evidently, the mere thought of receiving a shock was enough to arouse subjects, and the precise likelihood of being shocked had little impact on their arousal level" (id.) A related study asked people to provide their maximum buying prices for risky investments, which contained different stated probabilities of losses and gains of different magnitudes (id.). Happily for the standard theory, maximum buying prices were affected by the size of losses and gains and also by probabilities. (Note that for most people, this experiment did not involve an affect-rich environment.) But - and this is the key point - reported feelings of worry were not much affected by probability levels. In this study, then, probability did affect behavior, but it did not affect emotions. The point has independent importance for the issue of terrorism, to which I will return: Worry and anxiety are individual losses, even if they do not ultimately affect behavior. Several studies have attempted to compare how people respond to differences in the probability of harm with how people respond to differences in the emotions associated with certain risks (Sandman, Weinstein, and Hallman, 1998 Sandman et al., 1994). Here it is hypothesized that certain low-probability risks, such as those associated with nuclear waste radiation, produce outrage, whereas other low-probability risks, such as those associated with radon exposure, do not. Of course terrorist acts can be seen as the most extreme example of risks that produce outrage. A central finding is consistent with that stressed here: a large difference in statistical seriousness had no effect in the "high outrage" condition, with people responding the same way to a risk of 1 in 100,000 as to a risk of 1 in 1,000,000 (Sandman, Weinstein, and Hallman, 1998). Even when the statistical risk was identical in the high outrage (nuclear waste) and low outrage (radon) cases, people in the nuclear waste case reported a much greater perceived threat and a much higher intention to act to reduce that threat (id.). Indeed, "the effect of outrage was practically as large as the effect of a 4000- fold difference in risk between the high-risk and low-risk conditions" (id.). Efforts to communicate the meaning of differences in risk levels, by showing comparisons to normal risk levels, reduced the effect of outrage but even after those efforts, outrage had nearly the same effect as a 2000-fold increase in risk (id.). A great deal of information appears to be necessary to counteract the effects of strong emotions - showing that people are not impervious to such information, but that when emotions are involved, a great deal of careful work has to be done. It should not be surprising, in this light, that visualization or imagery matters a great deal to people's reactions to risks (Slovic, Monahan, and MacGregor, 2000). When an image of a bad outcome is easily accessible, people will become greatly concerned about a risk, holding probability constant (Loewenstein et al., 2001). Consider the fact that when people are asked how much they will pay for flight insurance for losses resulting from "terrorism," they will pay more than if they are asked how much they will pay for flight insurance from all causes (Johnson et al., 1993). An evident explanation for this peculiar result is that the
TERRORISM AND PROBABILITY NEGLECT
2.4. Other evidence and open questions
word "terrorism" evokes vivid images of disaster, thus crowding out probability judgments. Note also that when people discuss a low-probability risk, their concern rises even if the discussion consists mostly of apparently trustworthy assurances that the likelihood of harm really is infÃ¬nitesmal (Alkahami and Slovic, 1994). One reason is that the discussion makes it easier to visualize the risk and hence to fear it. Probability neglect should be sharply distinguished from use of the availability heuristic, which leads people not to neglect the issue of probability, but to answer the question of probability by substituting a hard question (what is the statistical risk?) with an easy question (do salient examples readily come to mind?). The central point here is not that visualization makes an event seem more probable (though this is also often true and highly relevant to the impact of terrorism), but that visualization, if accompanied by or productive of strong emotions, makes the issue of probability less relevant or even irrelevant. (Many people who are fearful of admittedly low-probability risks, such as those associated with flying in airplanes, report that they visualize the worst-case outcome and do not give adequate attention to the issue of likelihood, which they acknowledge to be low.) In theory, the distinction between use of the availability heuristic and probability neglect should not be obscure. In practice, of course, it will often be hard to know whether the availability heuristic or probability neglect is influencing behavior. The most sensible conclusion is that with respect to risks of injury or harm, vivid images and concrete pictures of disaster can "crowd out" other kinds of thoughts, including the crucial thought that the probability of disaster is really small. With respect to hope, those who operate gambling casinos and state lotteries are well-aware of the underlying mechanisms. They play on people's emotions in the particular sense that they conjure up palpable pictures of victory and easy living, thus encouraging people to neglect the question of probability. With respect to risks, insurance companies, extreme environmental groups, and terrorists do exactly the same. The point explains "why societal concerns about hazards such as nuclear power and exposure to extremely small amounts of toxic chemicals fail to recede in response to information about the very small probabilities of the feared consequences from such hazards" (Slovic et al., 2002). The same point explains why acts of terrorism can create fear that greatly outruns the discounted probability of harm. Of course the phenomenon of probability neglect has its limitations. Many people attend to issues of probability even when emotions are running high. There is considerable heterogeneity in the data, with numerous subjects attending to probability even when the harm is described in graphic terms. It is unclear if "debiasing" is possible (see Sandman, Weinstein, and Hallman, 1998, for suggestive discussion). If people are made alert to probability neglect, will they be less likely to neglect probability? In any case market pressures are likely to diminish the extent of probability neglect. If the costs of neglecting probability are placed "on screen," then people will be more likely to attend to the question of probability (Margolis, 1 993). In this light it is both mildly counterintuitive and quite reasonable, for example, to pre- dict that people would be willing to pay less, in terms of dollars and waiting time, to reduce low-probability risks of a terrorist attack on an airline if they are frequent travellers. Those who travel infrequently should be willing to pay more, simply because they will face lower costs. A preliminary study finds exactly this effect (Harrington, 2002). My principal suggestion is that both private behavior and the demand for a legal response will be more impervious
to variations in probability than the standard theory will predict. The departure from the normative theory should be seen, to a greater or lesser degree, in the responses of public officials, some of whom use probability neglect strategically to promote their own interests.
If probability neglect characterizes individual judgment under certain circumstances, government and law are likely to be neglecting probability under those same circumstances. If people show unusually strong reactions to low-probability catastrophes, a democratic government is likely to act accordingly. Consider the problem of probability neglect outside of the context of terrorism. In the environmental area, there has been an intense debate about whether the National Environmental Policy Act requires agencies to discuss the worst-case scenario in environmental impact statements. Environmental groups sought to ensure discussion of that scenario. They did so in part to stimulate public concern, with the knowledge that the worst case might well have a great deal of salience, even if it is highly unlikely. For its part, the government originally required discussion of the worst case, but changed in its mind, with the apparent understanding that people are too likely to overreact. Hence the current approach, upheld by the Supreme Court,6 requires consideration of low-probability events, but only if they are not entirely remote and speculative. At first glance the current approach, and the Supreme Court's decision, seem entirely reasonable. If there is only a miniscule chance that the worst case will come to fruition, it need not be discussed in environmental impact statements, for the principal effect of the discussion would be to activate fear, which is by hypothesis unwarranted by the facts. But there is an important qualification. While probability neglect makes worst-case analysis easy to criticize, such analysis might be defended if regulators are operating under conditions of uncertainty rather than risk. Under conditions of uncertainty, probabilities cannot be assigned at all, and in such cases it is reasonable to follow the maximin principle (choose the option that has the least-bad worst outcome see Elster, 1983). If we are dealing with uncertainty rather than risk, worst-case analysis can be defended on these standard grounds, simply because it identifies the approach that should be favored by those applying the maximin principle. What I am suggesting is that in the context of terrorism and other emotionally laden hazards, people neglect probability even when the evidence suggests that it is quite low (Rothchild, 2001). A good deal of legislation and regulation can be explained partly by reference to probability neglect when emotions are running high. Consider a few examples:
? In the aftermath of news report about emotionally gripping adverse health effects allegedly caused by abandoned hazardous waste in Love Canal, the government responded with an aggressive program for cleaning up abandoned hazardous waste cites, without examining the probability that illness would actually occur. In fact little was accomplished by early efforts to assure people of the low probability of harm (Kuran and Sunstein, 1999). When the local health department publicized controlled studies showing little evidence of adverse effects, the publicity did not dampen concern, because the numbers "had no
TERRORISM AND PROBABILITY NEGLECT
3. What drives the demand for law?
meaning" (Gibbs, 1998). In fact the numbers seemed to aggravate fear: "One woman, divorced and with three sick children, looked at the piece of paper with numbers and started crying hysterically: 'No wonder my children are sick. Am I going to die? What's going to happen to my children?' " (id.). Questions of this sort contributed to the enactment of new legislation to control abandoned hazardous waste sites, legislation that did not embody careful consideration of the probability of significant health or environmental benefits (Kuran and Sunstein, 1999). Even now, law and policy are affected by interest group pressures and public alarm the government does not take enough account of the probability of significant harm in making clean-up decisions (Hamilton and Viscusi, 1998). ? During a highly publicized campaign designed to show a connection between Alar, a pesticide, and cancer in children, the public demand for action was not much affected by the EPA's cautionary notes about the low probability of getting that disease (Wildavsky,
1995). The mere idea that children might die, as a result of apple consumption, had a significant effect on behavior, with probabilistic information seeming not to reduce people's fears. ? In the fall of 2001, vivid images of shark attacks created a public outcry about new risks for ocean swimmers. This was so notwithstanding the exceedingly low probability of a shark attack, and the absence of any reliable evidence of an increase in shark attacks in the summer of 2001 . Predictably, there was considerable discussion of new legislation to control the problem, and eventually such legislation was enacted in Florida. Public fear was not impervious to the fact that the underlying risk was miniscule but the fear greatly exceeded the statistical risk. ? For a variety of reasons, jury behavior is not likely to be greatly affected by assurance that the risk was unlikely to come to fruition, even if the issue of probability is legally relevant (Foster, Bernstein, and Huber, 1993). In cases involving low-probability risks of emotionally gripping harms, it should be relatively easy to convince jurors to offer high damage awards. Litigators therefore do well to try to engage jurors' emotions by pointing to the worst case. There is a strong implication here for the law of negligence: Even if the law asks the jury to balance the benefits of the defendant's action against the costs, the jury is likely to disregard the issue of probability if its attention is focussed on an outcome that triggers strong emotions (id.). Along the same lines, an understanding of probability neglect helps explain the finding, in both experimental and real- world settings, that juries do not respond favorably to a demonstration that the defendant performed a cost-benefit analysis before proceeding, even if the analysis places a high value on human life (Viscusi, 2000). The reason is that jurors will be focussing on the badness of the outcome, not the low (ex ante) probability that it would have occurred. With respect to terrorism, consider in particular the anthrax scare of October, 200 1 , which was based on exceedingly few incidents. Only four people died of the infection only about a dozen others fell ill. The probability of being infected was exceedingly low. Nonetheless, fear proliferated, with people focussing their attention on the outcome rather than the low probability of the harm. The government responded accordingly, investing massive resources in ensuring against anthrax infections. Private institutions reacted the same way, asking people to take extraordinary care in opening the mail even though the statistical risks
were tiny. To say this is not to suggest that extensive precautions were clearly unjustified in this case. Private and public institutions faced an unknown probability of a major health problem. But it is hard to deny that the public fear was disproportionate to its cause, and that the level of response was disproportionate too. The extraordinary ripple effects attest to the intensity of that fear. In the context of the terrorist attacks of September 11, 2001, of course, public fear led to private and public costs that were orders of magnitude higher than the costs of the attacks themselves (Sunstein, 2002a), and that are best explained in part by reference to probability neglect. The same might be said about the extraordinary public fear produced by the sniper attacks in the Washington, D.C. area in October 2002 the extent of the fear is hard to understand without an appreciation of probability neglect.
4. Prescriptive and normative issues and the role of law
For law and policy, the hardest questions might well be prescriptive and normative ones: How should law and government respond to a quasi-rational public panic, based on an intense emotional reaction to a low-probability risk of terrrorist attack? Let us assume, realistically if perhaps optimistically, that for the foreseeable future, the risk will be quite low, far lower, as a statistical matter, than risks that people willingly accept in many domains (Rothschild, 2001). When people are greatly alarmed about a low-probability hazard, can government officials effectively provide assurance and dampen concern? This is far from clear. The only clear point is that government is unlikely to be entirely successful if it simply emphasizes the low probability that the risk will occur. If officials want to reduce fear, the best approach may well be simple: Alter the public's focus. I have noted that discussions of low-probability risks tend to heighten public concern, even if those discussions consist largely of reassurance. Perhaps the most effective way of reducing fear of a low-probability risk is simply to discuss something else and to let time do the rest. (Recall in this regard President Bush's effort, in the aftermath of the terrorist attacks of 9/11, not to emphasize that the statistical risks were low, but to treat flying as a kind of patriotic act, one that would prevent terrorists from obtaining victory.) Of course, media attention can undermine this approach. With respect to regulatory policy, institutional safeguards might well be the best way of ensuring against the harmful consequences of probability neglect. The Office of Information and Regulatory Affairs, within the Office of Management and Budget, monitors agency action to ensure that it is directed against significant problems. A general requirement of cost-benefit balancing should provide a check on regulations that cannot be grounded in objective fact - and also as an impetus to preventative measures that the public might not seek. If government wants to protect itself against hysteria, analytic requirements and institutional checks will provide a start (Sunstein, 2002a). Now turn to normative issues and suppose that people are greatly concerned about a risk that has a small or even miniscule probability of occurring - anthrax in the mail, a sniper attack at gas stations, or terrorism on airplanes. If government is confident that it knows the facts, and if people are far more concerned than the facts warrant, should the government
TERRORISM AND PROBABILITY NEGLECT
1 3 1
respond, via regulation, to their concerns? Or should it ignore them, on the ground that the concerns are irrational? Consider the individual analogy first. Even if people's fear is itself irrational, it might well be rational for people to take account of that fear in their behavior. If I am afraid to fly, I might decline to do so, on the ground that my fear will make the experience quite dreadful (not only while flying but while anticipating it). At the same time, the fear itself might be irrational, and I might even recognize that fact. If the fear exists, but if I cannot eliminate it, the most rational decision might be not to fly. In certain periods in the last decade, some people have declined to travel to Israel, not because they believe that the risks are statistically large, but because they anticipate their own (less than rational) anxiety, and because they seek, rationally, to avoid an anxiety-pervaded experience. So too at the social level. Suppose, for example, that people are afraid of existing levels of arsenic in drinking water and that they demand steps to ensure that arsenic ingestion will not be hazardous. Suppose too that the risks from existing levels of arsenic are infinitesmal. Is it so clear that government should refuse to do what people want it to do? The fear is by hypothesis real. If people are fearful that their drinking water is "not safe," they are, simply for that reason alone, experiencing a significant loss. In many domains, widespread fear is not merely a loss in itself (one for whose reduction people would be willing to pay), but also leads to an array of additional problems. In the context of arsenic, it might lead people to buy bottled water, even if the result is not to produce any increase in safety. In the context of terrorism, fear is likely to make people reluctant to engage in certain activities, such as flying on airplanes and appearing in public places. The resulting costs can be extremely high. It is plausible to suggest that government should attempt to reduce fear, just as it attempts to produce other gains to people's well-being. The obvious qualification is that if government is able to inform and educate people, it should do that rather than regulate. To the extent that inexpensive policies have substantial reassurance value, government should adopt those policies it should not impose costly regulatory controls. But whether information and education will work is an empirical question on which clear evidence is absent, especially in the presence of probability neglect. Perhaps government will not, in some contexts, be able to assure people that the probability of a terrorist attack is very low and ought not to affect behavior. If information and education do not work, government should respond, just as individuals do, to fears that are not fully rational, but real and by hypothesis difficult to eradicate. Recall that fear is a real social cost and that it is likely to lead to other social costs. If, for example, people are afraid to fly, the economy will suffer in multiple ways so too if people are afraid to send or to receive mail. The reduction of even baseless fear is a social good. Even if it is clear that government should respond, many questions remain. How and how much should government respond? The answer must depend on the extent and cost of the fear and the effect and cost of the response. If people are extremely fearful, a substantial response is of course easier to justify if the cost of an effective response is very high, a refusal to respond might well make sense. With this point, the analysis of appropriate action becomes similar to the analysis of risks in many other settings. We need to know how much good, and how much harm, would be done by the action in question. A special difficulty here consists in the problem of quantifying and monetizing
fear and its consequences, a problem that has yet to be seriously engaged in the relevant literature.
In this Essay, my central claim has been that the probability of harm will be neglected when people's emotions are activated. Probability neglect is especially likely in the context of terrorism. If a terrorist attack is easy to visualize, large-scale changes in thought and behavior are to be expected, even if the statistical risk is lower than that associated with many activities that do not produce public concern. The point helps explain public overreaction to highly publicized, low-probability risks, including those posed by sniper attacks, abandoned hazardous waste dumps, and anthrax. It follows that if a private or public actor is seeking to produce public attention to a neglected risk, it is best to provide vivid, even visual images of the worst that might happen. It also follows that government regulation, affected as it is by the public demand for law, is likely to neglect probability too. At first glance, the government should not capitulate if the public is demonstrating probability neglect and showing an excessive response to the risk of terrorism. The best response is information and education. But public fear is itself a problem and sometimes a quite serious one. If that fear cannot be alleviated without risk reduction, then government should engage in risk reduction, at least if the relevant steps are justified by an assessment of costs and benefits.7
The following provides the experimental materials for the study described in part 2.3.
Assume that you live in an area whose drinking water contains 50 parts per billion of arsenic. Assume also that at this level of arsenic, 1 in 100,000 people who drink this water over a period of years will die of cancer. The Environmental Protection is considering whether to reduce the permissible level of arsenic in drinking water from 50 to 5 parts per billion, which would essentially eliminate the cancer risk. What is the most that you would be willing to pay, in increases in annual water bills, for this reduction?
(1) 0
(2) $25
(3) $50
(4) $100
(5) $200
(6) $400
(7) $800 or more
Assume that you live in an area whose drinking water contains 50 parts per billion of arsenic. Assume also that at this level of arsenic, 1 in 1,000,000 people who drink this water over a period of years will die of cancer. The Environmental Protection is considering whether to reduce the permissible level of arsenic in drinking water from 50 to 5 parts per
TERRORISM AND PROBABILITY NEGLECT
billion, which would essentially eliminate the cancer risk. What is the most that you would be willing to pay, in increases in annual water bills, for this reduction? (3) 0 (4) $25 (3) $50 (4) $100 (5) $200 (6) $400 (7) $800 or more
Assume that you live in an area whose drinking water is contaminated by 50 parts per billion of arsenic, a known carcinogen. Assume also that this level of arsenic will kill 1 in 100,000 people who drink this water over a period of years. Assume finally that the death from arsenic-induced cancer is very gruesome and intensely painful, as the cancer eats away at internal organs of the body. The Environmental Protection is considering whether to reduce the permissible level of arsenic in drinking water from 50 to 5 parts per billion, which would essentially eliminate the cancer risk. What is the most that you would be willing to pay, in increases in annual water bills, for this reduction? (5) 0 (6) $25 (3) $50 (4) $100 (5) $200 (6) $400 (7) $800 or more Assume that you live in an area whose drinking water is contaminated by 50 parts per billion of arsenic, a known carcinogen. Assume also that this level of arsenic will kill 1 in 1,000,000 people who drink this water over a period of years. Assume finally that the death from arsenic-induced cancer is very gruesome and intensely painful, as the cancer eats away at internal organs of the body. The Environmental Protection is considering whether to reduce the permissible level of arsenic in drinking water from 50 to 5 parts per billion, which would essentially eliminate the cancer risk. What is the most that you would be willing to pay, in increases in annual water bills, for this reduction?
(1) 0
(2) $25
(3) $50
(4) $100
(5) $200
(6) $400
(7) $800 or more
I am grateful to Jon Elster, Eric Posner, Richard Posner, and W. Kip Viscusi for helpful comments and to David Schkade for help with the analysis of the experiment in Section 2.3.
1. I discuss the general phenomenon, with particular reference to administrative law and without emphasizing terrorism, in Sunstein (2002b) there is overlap between the two discussions. 2. The data were analyzed using a 2 x 2 ANOVA (Probability x Emotionality of description) for overall means, and by t-tests within cells. 3. Throughout the results, the medians tell a similar (and generally stronger) version of the same story as the means, although they must be interpreted with caution due to the small number of response categories. In particular, most of the medians are either 50 or 100, and these are the only two response options between 25 and 200. Consequently there is a substantial range of underlying "true" medians that would result from unconstrained WTP responses that are consistent with the observed pattern of medians in this study. Means are less sensitive to this feature of responses. 4. The medians show a similar pattern. 5. This relatively small effect might be a product of the fact that the less emotional description did, after all, involve a cancer death, which is known to produce strong reactions. A more pronounced effect might be expected if the death was simply described as a death. 6. Robertson v. Mathow Valley Citizens Council, 490 U.S. 332, 354-356 (1989). 7. I have not explored here the difficult issue of how to monetize public fear.
Alkahami, A.S. and P. Slovic. (1994). "A Psychological Study of the Inverse Relationship Between Perceived Risk and Perceived Benefit," Risk Analysis 14, 1085-1096. Corso, P., J. Hammitt, and J. Graham. (2001). "Valuing Mortality-Risk Reduction: Using Visual Aids to Improve the Validity of Contingent Valuation," Journal of Risk and Uncertainty 23, 165-184. Elster, J. (1983). Explaining Technical Change. Cambridge: Cambridge University Press. Foster, K., D. Bernstein, and P. Huber. (eds.). (1993). Phantom Risk: Scientific Inference and the Law. Cambridge, MA: MIT Press. Gibbs, L.M. (1998). Love Canal: The Story Continues. New York: New Society Publishers. Hamilton, J. and W.K. Viscusi. Calculating Risks: The Spatial and Political Dimensions of Hazardous Waste Policy. Cambridge, MA: MIT Press. Harrington, M. (2002). "People's Willingness To Accept Airport Security Delays in Exchange for Lesser Risk," (unpublished manuscript, on file with author). Huber, P. (1983). "The Old-New Division in Risk Regulation," Virginia Law Review 69, 1025-1 106. Johnson, E.J., J. Hershey, J. Meszaros, and H. Kunreuther. (1993). "Framing, Probability Distortions, and Insurance Decisions," Journal of Risk and Uncertainty 7, 35-41. Kahneman, D. and A. Tversky. (1979). "Prospect Theory: An Analysis of Decision Under Risk," Econometrica 47, 263-291. Kunreuther, H., N. Novemsky, and Daniel Kahneman. (2001). "Making Low Probabilities Useful," Journal of Risk and Uncertainty 23, 103-120. Kuran, T. and C. Sunstein. (1999). "Availability Cascades and Risk Regulation," Stanford Law Review 5 1, 683-768. Loewenstein, G.F., E.U. Weber, C.K. Hsee, and E.S. Welch. (2001). "Risk as Feelings," Psychological Bulletin 127 , 267-286. Margolis, Howard. (1993). Dealing With Risk. Chicago: University of Chicago Press. Noll, R. and J. Krier. (1990). "Some Implications of Cognitive Psychology for Risk Regulation," Journal of Legal Studies 19, 747-779.
TERRORISM AND PROBABILITY NEGLECT
